<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>C++创建对象、C++创建一个实例、C++实例化对象</title>
    <url>/2023/02/10/C++/C++%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1/</url>
    <content><![CDATA[<h1 id="C-创建对象、C-创建一个实例、C-实例化对象"><a href="#C-创建对象、C-创建一个实例、C-实例化对象" class="headerlink" title="C++创建对象、C++创建一个实例、C++实例化对象"></a>C++创建对象、C++创建一个实例、C++实例化对象</h1><blockquote>
<p>csdn：<a href="https://blog.csdn.net/azhexg/article/details/14225545">C++创建对象的三种方式</a></p>
</blockquote>
<p>C++中有三种创建对象的方法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">A</span>(<span class="type">int</span> m):<span class="built_in">n</span>(m)</span><br><span class="line">    &#123; &#125;</span><br><span class="line">    ~<span class="built_in">A</span>()&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x + y;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">A <span class="title">a</span><span class="params">(<span class="number">1</span>)</span></span>;  <span class="comment">//栈中分配  ，由操作系统进行内存的分配和管理</span></span><br><span class="line">    A b = <span class="built_in">A</span>(<span class="number">1</span>);  <span class="comment">//栈中分配  ，由操作系统进行内存的分配和管理</span></span><br><span class="line">    A* c = <span class="keyword">new</span> <span class="built_in">A</span>(<span class="number">1</span>);  <span class="comment">//堆中分配  ，由管理者进行内存的分配和管理，用完必须delete()，否则可能造成内存泄漏</span></span><br><span class="line">    </span><br><span class="line">    a.<span class="built_in">add</span>(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">    b.<span class="built_in">add</span>(<span class="number">1</span>,<span class="number">2</span>);		<span class="comment">//&quot;.&quot; 是结构体成员引用</span></span><br><span class="line">    c-&gt;<span class="built_in">add</span>(<span class="number">1</span>,<span class="number">2</span>);	<span class="comment">//&quot;-&gt;&quot;是指针引用</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">delete</span> c;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第一种和第二种没什么区别，一个隐式调用，一个显式调用，两者都是在进程虚拟地址空间中的栈中分配内存，而第三种使用了new，在堆中分配了内存，而栈中内存的分配和释放是由系统管理，而堆中内存的分配和释放必须由程序员手动释放。采用第三种方式时，必须注意一下几点问题：</p>
<ol>
<li>new创建类对象需要指针接收，一处初始化，多处使用</li>
<li>new创建类对象使用完需delete销毁</li>
<li>new创建对象直接使用堆空间，而局部不用new定义类对象则使用栈空间</li>
<li>new对象指针用途广泛，比如作为函数返回值、函数参数等</li>
<li>频繁调用场合并不适合new，就像new申请和释放内存一样</li>
<li>栈的大小远小于堆的大</li>
<li>栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率 比较高。堆则是C&#x2F;C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构&#x2F;操作系统）在 堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会 分 到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。</li>
</ol>
<p><strong>注意：栈中内存的分配和管理由操作系统决定，而堆中内存的分配和管理由管理者决定。</strong></p>
<p><strong>我们需要的内存很少，你又能确定你到底需要多少内存时，用栈。当你需要在运行时才知道你到底需要多少内存时，请用堆。</strong></p>
<h1 id="C-用new和不用new创建类对象"><a href="#C-用new和不用new创建类对象" class="headerlink" title="C++用new和不用new创建类对象"></a>C++用new和不用new创建类对象</h1><blockquote>
<p><a href="https://blog.csdn.net/lz20120808/article/details/40833517">C++创建对象的两种方法（C++用new和不用new创建类对象）</a></p>
</blockquote>
<h2 id="方法1-ClassName-object-param"><a href="#方法1-ClassName-object-param" class="headerlink" title="方法1  ClassName object(param);"></a>方法1  <code>ClassName object(param);</code></h2><p>这样就声明了一个ClassName类型的object对象，C++会为它分配足够的存放对象所有成员的存储空间。</p>
<p>注意：为节省存储空间，C++创建对象时仅分配用于保存数据成员的空间，而类中定义的成员函数则被分配到存储空间中的一个公用区域，由该类的所有对象共享。</p>
<p>例如，我定义了一个这样的类：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rec</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">Rec</span>(<span class="type">int</span> width,<span class="type">int</span> height);</span><br><span class="line">        ~<span class="built_in">Rec</span>();</span><br><span class="line">        <span class="function"><span class="type">int</span> <span class="title">getArea</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="type">int</span> Rwidth;</span><br><span class="line">        <span class="type">int</span> Rheight;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>当你Rec myRec(5,5);这样创建一个myRec对象， 然后打印出sizeof(myRec);的时候，会得到 8。因为myRec中有2个int类型的数据成员，一个int成员占4个字节，所以myRec对象占8个字节。</p>
<p>这种方法创建的对象，内存分配是分配到栈中的，由C++缺省创建和撤销，自动调用构造函数和析构函数。</p>
<p>注意：该方法创建的对象调用类方法时，必须用“.”，而不能用“-&gt;”.如myRec.getArea()；</p>
<h2 id="方法2-ClassName-object-new-ClassName-param"><a href="#方法2-ClassName-object-new-ClassName-param" class="headerlink" title="方法2  ClassName *object = new ClassName(param);"></a>方法2  <code>ClassName *object = new ClassName(param);</code></h2><p><code>ClassName *object = new ClassName(param);</code></p>
<p><code>delete object;</code></p>
<p>这种方法跟java有点类似，相同的是，它们都是在堆上分配内存来创建对象的（与上不同）；不同的是，<strong>C++用new创建对象时返回的是一个对象指针，object指向一个ClassName的对象，C++分配给object的仅仅是存放指针值的空间</strong>。而且，用new 动态创建的对象必须用delete来撤销该对象。只有delete对象才会调用其析构函数。</p>
<p>注意：new创建的对象不是用“*”或“.”来访问该对象的成员函数的，而是用运算符“-&gt;”;</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Rec *rec=<span class="keyword">new</span> <span class="built_in">Rec</span>(<span class="number">3</span>,<span class="number">4</span>);</span><br><span class="line">rec-&gt;<span class="built_in">getArea</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">delete</span> rec;</span><br></pre></td></tr></table></figure>



<p><strong>一般来说，编译器将内存分为三部分：静态存储区域、栈、堆。静态存储区主要保存全局变量和静态变量，栈存储调用函数相关的变量、地址等，堆存储动态生成的变量。</strong> 在c中是指由malloc,free运算产生释放的存储空间，在c++中就是指new和delete运算符作用的存储区域。</p>
<p>new出来的在堆上，直接定义的在栈上，栈的大小有限制</p>
<p>new的好处：</p>
<p>1、需要的时候才new（在复杂权限和业务逻辑系统中很重要）<br>2、对象可靠性检查(没有栈空间的限制问题)<br>3、对象的适度留用控制</p>
<h1 id="chatgpt回答"><a href="#chatgpt回答" class="headerlink" title="chatgpt回答"></a>chatgpt回答</h1><p>C++创建对象有两种常见的方式：静态分配和动态分配。</p>
<ol>
<li>静态分配：在栈上直接实例化一个对象，这种方式创建的对象随着它的作用域的结束自动销毁。</li>
<li>动态分配：使用 new 运算符在堆上创建对象，这种方式创建的对象必须使用 delete 运算符手动销毁。</li>
</ol>
<h1 id="类、对象"><a href="#类、对象" class="headerlink" title="类、对象"></a>类、对象</h1><blockquote>
<p>runoob：<a href="https://www.runoob.com/cplusplus/cpp-classes-objects.html">C++ 类 &amp; 对象</a></p>
</blockquote>
<p><img src="/2023/02/10/C++/C++%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1/cpp-classes-objects-2020-12-10-11.png" alt="cpp-classes-objects-2020-12-10-11"></p>
<p>私有的成员和受保护的成员不能使用直接成员访问运算符 (.) 来直接访问。</p>
<table>
<thead>
<tr>
<th align="left">概念</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-class-member-functions.html">类成员函数</a></td>
<td align="left">类的成员函数是指那些把定义和原型写在类定义内部的函数，就像类定义中的其他变量一样。</td>
</tr>
<tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-class-access-modifiers.html">类访问修饰符</a></td>
<td align="left">类成员可以被定义为 public、private 或 protected。默认情况下是定义为 private。</td>
</tr>
<tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-constructor-destructor.html">构造函数 &amp; 析构函数</a></td>
<td align="left">类的构造函数是一种特殊的函数，在创建一个新的对象时调用。类的析构函数也是一种特殊的函数，在删除所创建的对象时调用。</td>
</tr>
<tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-copy-constructor.html">C++ 拷贝构造函数</a></td>
<td align="left">拷贝构造函数，是一种特殊的构造函数，它在创建对象时，是使用同一类中之前创建的对象来初始化新创建的对象。</td>
</tr>
<tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-friend-functions.html">C++ 友元函数</a></td>
<td align="left"><strong>友元函数</strong>可以访问类的 private 和 protected 成员。</td>
</tr>
<tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-inline-functions.html">C++ 内联函数</a></td>
<td align="left">通过内联函数，编译器试图在调用函数的地方扩展函数体中的代码。</td>
</tr>
<tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-this-pointer.html">C++ 中的 this 指针</a></td>
<td align="left">每个对象都有一个特殊的指针 <strong>this</strong>，它指向对象本身。</td>
</tr>
<tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-pointer-to-class.html">C++ 中指向类的指针</a></td>
<td align="left">指向类的指针方式如同指向结构的指针。实际上，类可以看成是一个带有函数的结构。</td>
</tr>
<tr>
<td align="left"><a href="https://www.runoob.com/cplusplus/cpp-static-members.html">C++ 类的静态成员</a></td>
<td align="left">类的数据成员和函数成员都可以被声明为静态的。</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++强制类型转换运算符</title>
    <url>/2023/02/21/C++/C++%E5%BC%BA%E5%88%B6%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E8%BF%90%E7%AE%97%E7%AC%A6/</url>
    <content><![CDATA[<h1 id="C-强制类型转换运算符"><a href="#C-强制类型转换运算符" class="headerlink" title="C++强制类型转换运算符"></a>C++强制类型转换运算符</h1><blockquote>
<p><a href="http://c.biancheng.net/view/410.html">C++强制类型转换运算符（static_cast、reinterpret_cast、const_cast和dynamic_cast）</a></p>
<p><a href="https://en.cppreference.com/w/cpp/language/reinterpret_cast">https://en.cppreference.com/w/cpp/language/reinterpret_cast</a> ; <a href="https://zh.cppreference.com/w/cpp/language/reinterpret_cast">https://zh.cppreference.com/w/cpp/language/reinterpret_cast</a></p>
<p><a href="https://blog.csdn.net/komtao520/article/details/79025562">https://blog.csdn.net/komtao520/article/details/79025562</a></p>
</blockquote>
<p>C++ 引入新的强制类型转换机制，主要是为了克服C语言强制类型转换的以下三个缺点。</p>
<ol>
<li><p>没有从形式上体现转换功能和风险的不同。</p>
<p>例如，将 int 强制转换成 double 是没有风险的，而将常量指针转换成非常量指针，将基类指针转换成派生类指针都是高风险的，而且后两者带来的风险不同（即可能引发不同种类的错误），C语言的强制类型转换形式对这些不同并不加以区分。</p>
</li>
<li><p>将多态基类指针转换成派生类指针时不检查安全性，即无法判断转换后的指针是否确实指向一个派生类对象。</p>
</li>
<li><p>难以在程序中寻找到底什么地方进行了强制类型转换。</p>
<p>强制类型转换是引发程序运行时错误的一个原因，因此在程序出错时，可能就会想到是不是有哪些强制类型转换出了问题。</p>
<p>如果采用C语言的老式做法，要在程序中找出所有进行了强制类型转换的地方，显然是很麻烦的，因为这些转换没有统一的格式。</p>
<p>而用 C++ 的方式，则只需要查找<code>_cast</code>字符串就可以了。甚至可以根据错误的类型，有针对性地专门查找某一种强制类型转换。例如，怀疑一个错误可能是由于使用了 reinterpret_cast 导致的，就可以只查找<code>reinterpret_cast</code>字符串。</p>
</li>
</ol>
<p>C++ 强制类型转换运算符的用法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">强制类型转换运算符 &lt;要转换到的类型&gt; (待转换的表达式)</span><br></pre></td></tr></table></figure>

<p>例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">double</span> d = static_cast &lt;<span class="type">double</span>&gt; (<span class="number">3</span>*<span class="number">5</span>); <span class="comment">//将 3*5 的值转换成实数</span></span><br></pre></td></tr></table></figure>





<h2 id="static-cast-静态转换"><a href="#static-cast-静态转换" class="headerlink" title="static_cast 静态转换"></a>static_cast 静态转换</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1iK411n7os/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">shellmad-07_C++新特性 强制转换static_cast</a></p>
</blockquote>
<p>static_cast 用于进行比较“自然”和低风险的转换，如整型和浮点型、字符型之间的互相转换。另外，如果对象所属的类重载了强制类型转换运算符 T（如 T 是 int、int* 或其他类型名），则 static_cast 也能用来进行对象到 T 类型的转换。</p>
<p>static_cast 不能用于在不同类型的指针之间互相转换，也不能用于整型和指针之间的互相转换，当然也不能用于不同类型的引用之间的转换。因为这些属于风险比较高的转换。</p>
<p>基本等价于隐式转换的一种类型转换运算符，可使用于需要明确隐式转换的地方。</p>
<h5 id="可以用于低风险的转换。"><a href="#可以用于低风险的转换。" class="headerlink" title="可以用于低风险的转换。"></a>可以用于低风险的转换。</h5><ul>
<li>整型和浮点型</li>
<li>字符与整型</li>
<li>转换运算符</li>
<li><strong>空指针转换为任何目标类型的指针</strong></li>
</ul>
<h5 id="不可以用与风险较高的转换"><a href="#不可以用与风险较高的转换" class="headerlink" title="不可以用与风险较高的转换"></a>不可以用与风险较高的转换</h5><ul>
<li>不同类型的指针之间互相转换</li>
<li>整型和指针之间的互相转换</li>
<li>不同类型的引用之间的转换</li>
</ul>
<p>举例1：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// int类型、float类型，都是用4个字节编码、表示的</span></span><br><span class="line"><span class="comment">// double类型用8个字节编码</span></span><br><span class="line"><span class="type">int</span> n = <span class="number">5</span>;</span><br><span class="line"><span class="type">float</span> f = <span class="number">10.0f</span>;</span><br><span class="line"><span class="type">double</span> dbl = <span class="number">1.0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 本质上，发生了隐式转换</span></span><br><span class="line">f = n;</span><br><span class="line"></span><br><span class="line"><span class="comment">// static_cast</span></span><br><span class="line">f = static_cast&lt;<span class="type">float</span>&gt;(n);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 什么样的情况可以进行隐式转换：</span></span><br><span class="line"><span class="comment">// 低风险的转换：</span></span><br><span class="line"><span class="comment">// 整型与浮点型</span></span><br><span class="line">n = static_cast&lt;<span class="type">int</span>&gt;(dbl);  <span class="comment">// 8字节转4字节，精度损失</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 字符与整型</span></span><br><span class="line"><span class="type">char</span> ch = <span class="string">&#x27;a&#x27;</span>;	<span class="comment">// char类型用1个字节编码</span></span><br><span class="line">n = static_cast&lt;<span class="type">int</span>&gt;(ch);	<span class="comment">//精度的扩增</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// void*指针的转换</span></span><br><span class="line"><span class="type">void</span>* p = nullptr;</span><br><span class="line"><span class="type">int</span>* pN = static_cast&lt;<span class="type">int</span>*&gt;(p);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CInt</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">	operator <span class="title function_">int</span><span class="params">()</span>&#123;</span><br><span class="line">		<span class="keyword">return</span> m_nInt;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="type">int</span> m_nInt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换运算符 类里面提供一种转换运算符给外界用</span></span><br><span class="line">CInt nObj;</span><br><span class="line"><span class="type">int</span> k = static_cast&lt;<span class="type">int</span>&gt;(nObj); <span class="comment">// 把对象转换成int类型了；等价于 int k = nObj;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 高风险的转换：不能转换的</span></span><br><span class="line"><span class="type">int</span> kk;</span><br><span class="line"><span class="type">char</span>* p;</span><br><span class="line"><span class="comment">// 整型与指针类型转换</span></span><br><span class="line">p = kk; <span class="comment">// 这种方式隐式转换不了</span></span><br><span class="line">p = static_cast&lt;<span class="type">char</span>*&gt;(kk);  <span class="comment">// 这样也是转换不了的，static_cast只能转换低风险</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 父类子类转换</span></span><br><span class="line">CSon* pSon = nullptr;</span><br><span class="line">CFather* pFather = nullptr;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 父类转子类(不安全)</span></span><br><span class="line">pSon = pFather; <span class="comment">// 编译通过不了</span></span><br><span class="line">pSon = static_cast&lt;CSon*&gt;(pFather); <span class="comment">//不安全，没有提供运行时的检测。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 子类转父类(安全)</span></span><br><span class="line">pFather = pSon;</span><br><span class="line">pFather = static_cast&lt;CFather*&gt;(pSon);</span><br></pre></td></tr></table></figure>



<h4 id="父类子类转换："><a href="#父类子类转换：" class="headerlink" title="父类子类转换："></a>父类子类转换：</h4><ul>
<li>父类转子类（不安全）（理解成子类内容比较多，父类转换可能会越界）隐式转换通过不了，static_cast静态转换可以通过，但是不安全，没有提供运行时的检测；</li>
<li>子类转父类（安全）（因为子类包含父类）隐式转换可以通过。</li>
</ul>
<p>举例2：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">public:</span><br><span class="line">    operator <span class="title function_">int</span><span class="params">()</span> &#123; <span class="keyword">return</span> <span class="number">1</span>; &#125;</span><br><span class="line">    operator <span class="type">char</span>*() &#123; <span class="keyword">return</span> <span class="literal">NULL</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    A a;</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    <span class="type">char</span>* p = <span class="string">&quot;New Dragon Inn&quot;</span>;</span><br><span class="line">    n = static_cast &lt;<span class="type">int</span>&gt; (<span class="number">3.14</span>);  <span class="comment">// n 的值变为 3</span></span><br><span class="line">    n = static_cast &lt;<span class="type">int</span>&gt; (a);  <span class="comment">//调用 a.operator int，n 的值变为 1</span></span><br><span class="line">    p = static_cast &lt;<span class="type">char</span>*&gt; (a);  <span class="comment">//调用 a.operator char*，p 的值变为 NULL</span></span><br><span class="line">    n = static_cast &lt;<span class="type">int</span>&gt; (p);  <span class="comment">//编译错误，static_cast不能将指针转换成整型</span></span><br><span class="line">    p = static_cast &lt;<span class="type">char</span>*&gt; (n);  <span class="comment">//编译错误，static_cast 不能将整型转换成指针</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h2 id="reinterpret-cast"><a href="#reinterpret-cast" class="headerlink" title="reinterpret_cast"></a>reinterpret_cast</h2><blockquote>
<p><a href="https://en.cppreference.com/w/cpp/language/reinterpret_cast">https://en.cppreference.com/w/cpp/language/reinterpret_cast</a></p>
<p>b站：<a href="https://www.bilibili.com/video/BV1zz4y1X7Ka/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">shellmad-09_C++新特性 强制转换reinterpret_cast</a></p>
</blockquote>
<p>reinterpret_cast 用于进行各种不同类型的指针之间、不同类型的引用之间以及指针和能容纳指针的整数类型之间的转换。转换时，执行的是逐个比特复制的操作。</p>
<p>这种转换提供了很强的灵活性，但转换的安全性只能由程序员的细心来保证了。例如，程序员执意要把一个 int* 指针、函数指针或其他类型的指针转换成 string* 类型的指针也是可以的，至于以后用转换后的指针调用 string 类的成员函数引发错误，程序员也只能自行承担查找错误的烦琐工作：（C++ 标准不允许将函数指针转换成对象指针，但有些编译器，如 Visual Studio 2010，则支持这种转换）。</p>
<p>比如：<code>reinterpret_cast&lt;void*&gt;(decoder);</code>  、 <code>reinterpret_cast&lt;const int16_t*&gt;(data)</code></p>
<ul>
<li>用于进行各种不同类型的转换<ul>
<li>不同类型指针之间</li>
<li>不同类型引用之间</li>
<li>指针和能容纳的整数类型之间的转换</li>
</ul>
</li>
<li>编译期处理，执行的是逐字节复制的操作</li>
<li>类似于显式强转，后果自负</li>
</ul>
<p>各种类型的指针转换</p>
<p>举例1：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 显示强转</span></span><br><span class="line"><span class="type">int</span> n = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// C语言里的显式强转：</span></span><br><span class="line"><span class="type">int</span>* p = (<span class="type">int</span>*)n;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 整型转指针</span></span><br><span class="line"><span class="type">int</span>* p = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">int</span>*&gt;(n);<span class="comment">//这样可以通过，但是下面用到p时很可能会报错，因为地址1这块地址一般都是不可访问的</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 各种类型的指针转换</span></span><br><span class="line"><span class="type">char</span>*pCh = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">char</span>*&gt;(p);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 父类，子类指针的转换</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CFather</span> &#123;&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CSon</span>: <span class="keyword">public</span> CFather &#123;&#125;;</span><br><span class="line"></span><br><span class="line">CSon* pSon;</span><br><span class="line">CFather* pFather = <span class="literal">nullptr</span>;</span><br><span class="line">pSon = <span class="built_in">reinterpret_cast</span>&lt;CSon*&gt;(pFather); <span class="comment">// 不存在检查</span></span><br></pre></td></tr></table></figure>



<p>举例2：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">public:</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="type">int</span> j;</span><br><span class="line">    A(<span class="type">int</span> n):i(n),j(n) &#123; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    A <span class="title function_">a</span><span class="params">(<span class="number">100</span>)</span>;</span><br><span class="line">    <span class="type">int</span> &amp;r = reinterpret_cast&lt;<span class="type">int</span>&amp;&gt;(a); <span class="comment">//强行让 r 引用 a</span></span><br><span class="line">    r = <span class="number">200</span>;  <span class="comment">//把 a.i 变成了 200 ？</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; a.i &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; a.j &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">// 输出 200,100</span></span><br><span class="line">    <span class="type">int</span> n = <span class="number">300</span>;</span><br><span class="line">    A *pa = reinterpret_cast&lt;A*&gt; ( &amp; n); <span class="comment">//强行让 pa 指向 n</span></span><br><span class="line">    pa-&gt;i = <span class="number">400</span>;  <span class="comment">// n 变成 400</span></span><br><span class="line">    pa-&gt;j = <span class="number">500</span>;  <span class="comment">//此条语句不安全，很可能导致程序崩溃</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; n &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">// 输出 400</span></span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> la = <span class="number">0x12345678abcd</span>LL;</span><br><span class="line">    pa = reinterpret_cast&lt;A*&gt;(la); <span class="comment">//la太长，只取低32位0x5678abcd拷贝给pa</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> u = reinterpret_cast&lt;<span class="type">unsigned</span> <span class="type">int</span>&gt;(pa);<span class="comment">//pa逐个比特拷贝到u</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; hex &lt;&lt; u &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">//输出 5678abcd</span></span><br><span class="line">    <span class="keyword">typedef</span> <span class="title function_">void</span> <span class="params">(* PF1)</span> <span class="params">(<span class="type">int</span>)</span>;</span><br><span class="line">    <span class="keyword">typedef</span> <span class="title function_">int</span> <span class="params">(* PF2)</span> <span class="params">(<span class="type">int</span>,<span class="type">char</span> *)</span>;</span><br><span class="line">    PF1 pf1;  PF2 pf2;</span><br><span class="line">    pf2 = reinterpret_cast&lt;PF2&gt;(pf1); <span class="comment">//两个不同类型的函数指针之间可以互相转换</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line"><span class="number">200</span>, <span class="number">100</span></span><br><span class="line"><span class="number">400</span></span><br><span class="line"><span class="number">5678</span>abed</span><br></pre></td></tr></table></figure>

<p>第 19 行的代码不安全，因为在编译器看来，pa-&gt;j 的存放位置就是 n 后面的 4 个字节。 本条语句会向这 4 个字节中写入 500。但这 4 个字节不知道是用来存放什么的，贸然向其中写入可能会导致程序错误甚至崩溃。</p>
<p>上面程序中的各种转换都没有实际意义，只是为了演示 reinteipret_cast 的用法而已。在编写黑客程序、病毒或反病毒程序时，也许会用到这样怪异的转换。</p>
<p>reinterpret_cast体现了 C++ 语言的设计思想：用户可以做任何操作，但要为自己的行为负责。</p>
<h2 id="const-cast"><a href="#const-cast" class="headerlink" title="const_cast"></a>const_cast</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1jV41167VK/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">shellmad-06_C++新特性 强制转换const_cast</a></p>
</blockquote>
<p>const_cast 运算符仅用于进行去除 const 属性的转换，它也是四个强制类型转换运算符中唯一能够去除 const 属性的运算符。</p>
<p>const_cast中的类型必须是 指针、引用、指向对象类型成员的指针（this指针）</p>
<p>将 const 引用转换为同类型的非 const 引用，将 const 指针转换为同类型的非 const 指针时可以使用 const_cast 运算符。例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="built_in">string</span> s = <span class="string">&quot;Inception&quot;</span>;</span><br><span class="line"><span class="built_in">string</span>&amp; p = const_cast &lt;<span class="built_in">string</span>&amp;&gt; (s);</span><br><span class="line"><span class="built_in">string</span>* ps = const_cast &lt;<span class="built_in">string</span>*&gt; (&amp;s);  <span class="comment">// &amp;s 的类型是 const string*</span></span><br></pre></td></tr></table></figure>



<p>常量对象或是基本数据类型不允许转换为非常量对象，只能通过指针和引用来修改，可以通过const_cast转换成同类型的非const引用或指针：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> s = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> t = const_cast&lt;<span class="built_in">string</span>&gt;(s); 	 <span class="comment">// 错误</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> &amp;t = const_cast&lt;<span class="built_in">string</span>&amp;&gt;(s); <span class="comment">// 转换成引用</span></span><br><span class="line">t = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> n = <span class="number">5</span>;</span><br><span class="line"><span class="type">int</span> k = const_cast&lt;<span class="type">int</span>&gt;(n);		<span class="comment">// 错误</span></span><br><span class="line"><span class="type">int</span> *k = const_cast&lt;<span class="type">int</span>*&gt;(n);   <span class="comment">// 转换成指针</span></span><br><span class="line"></span><br><span class="line">*k = <span class="number">6</span>; <span class="comment">// 转换后指针指向原来的变量</span></span><br></pre></td></tr></table></figure>



<p>常成员函数（不能修改成员变量的值）中去除this指针的const属性：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CTest</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">	CTest() : m_nTest(<span class="number">2</span>) &#123;&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 常成员函数 // 内容不能改变</span></span><br><span class="line">	<span class="type">void</span> <span class="title function_">foo</span><span class="params">(<span class="type">int</span> nTest)</span> <span class="type">const</span>&#123;</span><br><span class="line">		<span class="comment">// void*p = this;	// 错误 这个this类型是 const Ctest *const</span></span><br><span class="line">		<span class="comment">// m_nTest = nTest; // 错误</span></span><br><span class="line">		const_cast&lt;Ctest*<span class="type">const</span>&gt;(this)-&gt;m_nTest = nTest; <span class="comment">//把this类型从const Ctest *const转换成Ctest *const</span></span><br><span class="line">        <span class="comment">//前面的const没有了，可以改变它的内容了，不能改变地址</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">	<span class="type">int</span> m_nTest;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h1 id="dynamic-cast"><a href="#dynamic-cast" class="headerlink" title="dynamic_cast"></a>dynamic_cast</h1><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1FZ4y1p78h/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">shellmad-08_C++新特性 强制转换dynamic_cast</a></p>
</blockquote>
<p>用 reinterpret_cast 可以将多态基类（包含虚函数的基类）的指针强制转换为派生类的指针，但是这种转换不检查安全性，即不检查转换后的指针是否确实指向一个派生类对象。dynamic_cast专门用于将多态基类的指针或引用强制转换为派生类的指针或引用，而且能够检查转换的安全性。对于不安全的指针转换，转换结果返回 NULL 指针。</p>
<p>dynamic_cast 是通过“运行时类型检查”来保证安全性的。dynamic_cast 不能用于将非多态基类的指针或引用强制转换为派生类的指针或引用——这种转换没法保证安全性，只好用 reinterpret_cast 来完成。</p>
<p>用于具有<strong>虚函数的基类</strong>与<strong>派生类</strong>之间的的转换。</p>
<ul>
<li><p>基类必须具备虚函数</p>
<p>原因:dynamic_cast是<strong>运行时类型检查</strong>，需要运行时类型信息(RTTI)，而这个信息是存储与类的<strong>虚函数表</strong>关系紧密，只有一个类定义了虚函数，才会有虚函数表。</p>
</li>
<li><p><strong>运行时检查，转型不成功则返回一个空指针</strong></p>
</li>
<li><p><strong>非必要不要使用dynamic_cast，有额外的函数开销</strong></p>
</li>
</ul>
<p>常见的转换方式：</p>
<ul>
<li>基类指针或引用转派生类指针（<strong>必须使用</strong>dynamic_cast）</li>
<li>派生类指针或引用转基类指针（可以使用dynamic_cast，但是<strong>更推荐使用static_cast</strong>）</li>
</ul>
<p>举例1：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CFather</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">	virtual <span class="type">void</span> <span class="title function_">foo</span><span class="params">()</span>&#123;</span><br><span class="line">		<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;cfather&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="type">int</span> m_nFather;</span><br><span class="line">&#125;;</span><br><span class="line">	</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CSon</span> :</span> public CFather&#123;</span><br><span class="line">public:</span><br><span class="line">	virtual <span class="type">void</span> <span class="title function_">foo</span><span class="params">()</span>&#123;</span><br><span class="line">		<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;cson&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="type">int</span> m_nSon;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">	CFather f;</span><br><span class="line">	CSon s;</span><br><span class="line">	CFather* pFather = &amp;f;</span><br><span class="line">	CSon* pSon = &amp;s;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 向下转换， 父类转子类 不安全</span></span><br><span class="line">	pSon = static_cast&lt;CSon*&gt;(pFather); </span><br><span class="line">	pSon-&gt;m_nSon = <span class="number">123</span>; <span class="comment">//理论上是越界了</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; pSon-&gt;m_nSon &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出 123</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 有一种语法能检测出这种语言是不安全的 : dynamic_cast</span></span><br><span class="line">    <span class="comment">// 在运行时检测转换是否安全，检测出被转换的指针的类型（依赖RTTI 运行时类型识别）</span></span><br><span class="line">    <span class="comment">// 有额外的开销，一般而言只有在向下转换时才必须使用</span></span><br><span class="line">    pSon = dynamic_cast&lt;CSon*&gt;(pFather);  <span class="comment">// 检测到父类不可以转换成子类，变成null</span></span><br><span class="line">    pSon-&gt;m_nSon = <span class="number">123</span>; <span class="comment">//理论上是越界了</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; pSon-&gt;m_nSon &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出 Segmentation fault</span></span><br><span class="line">	<span class="comment">// 修改为：</span></span><br><span class="line">    <span class="keyword">if</span>(pSon != nullptr)&#123;</span><br><span class="line">        pSon-&gt;m_nSon = <span class="number">123</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向上转换， 子类转父类 安全</span></span><br><span class="line">	pFather = static_cast&lt;CFather*&gt;(pSon); </span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>具有多态类型的向下转换时使用，其余情况可以不用。</p>
<p>举例2：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span></span></span><br><span class="line"><span class="class">&#123;</span>  <span class="comment">//有虚函数，因此是多态基类</span></span><br><span class="line">public:</span><br><span class="line">    virtual ~Base() &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span> :</span> public Base &#123; &#125;;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    Base b;</span><br><span class="line">    Derived d;</span><br><span class="line">    Derived* pd;</span><br><span class="line">    pd = reinterpret_cast &lt;Derived*&gt; (&amp;b);</span><br><span class="line">    <span class="keyword">if</span> (pd == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="comment">//此处pd不会为 NULL。reinterpret_cast不检查安全性，总是进行转换</span></span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;unsafe reinterpret_cast&quot;</span> &lt;&lt; <span class="built_in">endl</span>; <span class="comment">//不会执行</span></span><br><span class="line">    pd = dynamic_cast &lt;Derived*&gt; (&amp;b);</span><br><span class="line">    <span class="keyword">if</span> (pd == <span class="literal">NULL</span>)  <span class="comment">//结果会是NULL，因为 &amp;b 不指向派生类对象，此转换不安全</span></span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;unsafe dynamic_cast1&quot;</span> &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">//会执行</span></span><br><span class="line">    pd = dynamic_cast &lt;Derived*&gt; (&amp;d);  <span class="comment">//安全的转换</span></span><br><span class="line">    <span class="keyword">if</span> (pd == <span class="literal">NULL</span>)  <span class="comment">//此处 pd 不会为 NULL</span></span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;unsafe dynamic_cast2&quot;</span> &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">//不会执行</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序的输出结果是：<br>unsafe dynamic_cast1</p>
<p>第 20 行，通过判断 pd 的值是否为 NULL，就能知道第 19 行进行的转换是否是安全的。第 23 行同理。</p>
<p>如果上面的程序中出现了下面的语句：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Derived &amp; r = dynamic_cast &lt;Derived &amp;&gt; (b);</span><br></pre></td></tr></table></figure>

<p>那该如何判断该转换是否安全呢？不存在空引用，因此不能通过返回值来判断转换是否安全。C++ 的解决办法是：dynamic_cast 在进行引用的强制转换时，如果发现转换不安全，就会拋出一个异常，通过处理异常，就能发现不安全的转换。</p>
<p>在visual stdio 菜单栏 项目 -&gt; 属性 -&gt; 左边菜单栏 C&#x2F;C++ 语言 -&gt; 启用运行时类型信息 改为 “是”</p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++智能指针</title>
    <url>/2023/02/20/C++/C++%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/</url>
    <content><![CDATA[<h1 id="C-智能指针"><a href="#C-智能指针" class="headerlink" title="C++智能指针"></a>C++智能指针</h1><h2 id="std-shared-ptr-共享指针"><a href="#std-shared-ptr-共享指针" class="headerlink" title="std::shared_ptr 共享指针"></a>std::shared_ptr 共享指针</h2><blockquote>
<p><a href="http://c.biancheng.net/view/7898.html">C++11 shared_ptr智能指针（超级详细）</a></p>
<p>b站：<a href="https://www.bilibili.com/video/BV1Ye4y127rZ/">C++的共享指针 shared_ptr 如何帮你自动管理内存 </a>  、 <a href="https://www.bilibili.com/video/BV1zD4y1471E/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">C++ 你可能不知道的 shared_ptr 补充知识点</a> </p>
<p><a href="http://www.cppds.com/cpp/memory/shared_ptr.html">http://www.cppds.com/cpp/memory/shared_ptr.html</a></p>
</blockquote>
<p>比如：<code>std::shared_ptr&lt;wenet::FeaturePipelineConfig&gt; feature_config_ = nullptr;</code></p>
<h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><p>共享指针会记录有多少个共享指针指针指向同一个物体（或者说对象，object），当这个数字将为0时，程序就会自动释放这个物体，省去我们手动delete的烦恼。</p>
<p>因此用共享指针的好处是可以<strong>自动管理内存</strong>。用于多个指针指向同一个资源的场景。</p>
<p>因为需要引用计数，有额外开销，因此操作性能（或者说速度）相比于裸指针会一点点下降，可能不适合应用于对性能要求严苛的场景。</p>
<h3 id="写法"><a href="#写法" class="headerlink" title="写法"></a>写法</h3><p>要使用智能指针首先需要 <code>#include &lt;memory&gt;</code>，在std命名空间中，所以可以先写上 <code>using namespace std;</code>（这样后面就不用写<code>std::</code>，不然还要注明是 <code>std::</code>）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个shared_ptr指针</span></span><br><span class="line">shared_ptr&lt;<span class="type">int</span>&gt; p;</span><br><span class="line"><span class="comment">// 初始化这个shared_ptr</span></span><br><span class="line">p = <span class="built_in">make_shared</span>&lt;<span class="type">int</span>&gt;(<span class="number">100</span>);	<span class="comment">//推荐使用make_shared的写法。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者写成</span></span><br><span class="line">shared_ptr&lt;<span class="type">int</span>&gt; p &#123;<span class="keyword">new</span> <span class="built_in">int</span>(<span class="number">100</span>)&#125;;</span><br></pre></td></tr></table></figure>

<p><code>make_shared</code> 会动态分配一块内存，创建对应的资源，然后让shared_ptr指针指向这块内存。</p>
<p><code>make_shared</code> 接受一个类型和对应的初始化参数。</p>
<p>创建完成后，就可以像普通指针一样使用shared_ptr。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">shared_ptr&lt;<span class="type">int</span>&gt; p2 = p;</span><br><span class="line">cout &lt;&lt; *p &lt;&lt; endl;</span><br><span class="line">*p2 = <span class="number">321</span>;</span><br><span class="line">cout &lt;&lt; *p &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出</span></span><br><span class="line"><span class="number">100</span></span><br><span class="line"><span class="number">321</span></span><br></pre></td></tr></table></figure>

<p><code>shared_ptr&lt;int&gt; p2 = p;</code> 是复制shared_prt，让多个指针指向同一个物体，这就是共享。</p>
<h4 id="几种创建方法"><a href="#几种创建方法" class="headerlink" title="几种创建方法"></a>几种创建方法</h4><ol>
<li>通过如下 2 种方式，可以构造出 shared_ptr<T> 类型的空智能指针：</T></li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">std::shared_ptr&lt;<span class="type">int</span>&gt; p1;             <span class="comment">//不传入任何实参</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;<span class="type">int</span>&gt; <span class="title">p2</span><span class="params">(<span class="literal">nullptr</span>)</span></span>;    <span class="comment">//传入空指针 nullptr</span></span><br></pre></td></tr></table></figure>

<p>注意，空的 shared_ptr 指针，其初始引用计数为 0，而不是 1。</p>
<ol start="2">
<li>在构建 shared_ptr 智能指针，也可以明确其指向。例如：</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">std::shared_ptr&lt;<span class="type">int</span>&gt; <span class="title">p3</span><span class="params">(<span class="keyword">new</span> <span class="type">int</span>(<span class="number">10</span>))</span></span>;</span><br></pre></td></tr></table></figure>

<p>由此，我们就成功构建了一个 shared_ptr 智能指针，其指向一块存有 10 这个 int 类型数据的堆内存空间。</p>
<p>同时，C++11 标准中还提供了 std::make_shared<T> 模板函数，其可以用于初始化 shared_ptr 智能指针，例如：</T></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">std::shared_ptr&lt;<span class="type">int</span>&gt; p3 = std::<span class="built_in">make_shared</span>&lt;<span class="type">int</span>&gt;(<span class="number">10</span>);</span><br></pre></td></tr></table></figure>

<p>以上 2 种方式创建的 p3 是完全相同。</p>
<ol start="3">
<li>除此之外，shared_ptr<T> 模板还提供有相应的拷贝构造函数和移动构造函数，例如：</T></li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//调用拷贝构造函数</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;<span class="type">int</span>&gt; <span class="title">p4</span><span class="params">(p3)</span></span>;<span class="comment">//或者 std::shared_ptr&lt;int&gt; p4 = p3;</span></span><br><span class="line"><span class="comment">//调用移动构造函数</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;<span class="type">int</span>&gt; <span class="title">p5</span><span class="params">(std::move(p4))</span></span>; <span class="comment">//或者 std::shared_ptr&lt;int&gt; p5 = std::move(p4);</span></span><br></pre></td></tr></table></figure>

<p>如上所示，p3 和 p4 都是 shared_ptr 类型的智能指针，因此可以用 p3 来初始化 p4，由于 p3 是左值，因此会调用拷贝构造函数。需要注意的是，如果 p3 为空智能指针，则 p4 也为空智能指针，其引用计数初始值为 0；反之，则表明 p4 和 p3 指向同一块堆内存，同时该堆空间的引用计数会加 1。</p>
<p>而对于 std::move(p4) 来说，该函数会强制将 p4 转换成对应的右值，因此初始化 p5 调用的是移动构造函数。另外和调用拷贝构造函数不同，用 std::move(p4) 初始化 p5，会使得 p5 拥有了 p4 的堆内存，而 p4 则变成了空智能指针。</p>
<p>注意，同一普通指针不能同时为多个 shared_ptr 对象赋值，否则会导致程序发生异常。例如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>* ptr = <span class="keyword">new</span> <span class="type">int</span>;</span><br><span class="line"><span class="function">std::shared_ptr&lt;<span class="type">int</span>&gt; <span class="title">p1</span><span class="params">(ptr)</span></span>;</span><br><span class="line"><span class="function">std::shared_ptr&lt;<span class="type">int</span>&gt; <span class="title">p2</span><span class="params">(ptr)</span></span>;<span class="comment">//错误</span></span><br></pre></td></tr></table></figure>



<ol start="4">
<li>在初始化 shared_ptr 智能指针时，还可以自定义所指堆内存的释放规则，这样当堆内存的引用计数为 0 时，会优先调用我们自定义的释放规则。</li>
</ol>
<p>在某些场景中，自定义释放规则是很有必要的。比如，对于申请的动态数组来说，shared_ptr 指针默认的释放规则是不支持释放数组的，只能自定义对应的释放规则，才能正确地释放申请的堆内存。</p>
<p>见下面的 “自定义删除函数”。</p>
<h3 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h3><p>有多少个shared_ptr指向某个物体。</p>
<p>举例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Ball</span>&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">Ball</span>() &#123; cout &lt;&lt; <span class="string">&quot;A ball appears.&quot;</span> &lt;&lt; endl;&#125;</span><br><span class="line">        ~<span class="built_in">Ball</span>() &#123; cout &lt;&lt; <span class="string">&quot;A ball disappears.&quot;</span> &lt;&lt; endl;&#125;</span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">Bounce</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;A ball jumps.&quot;</span> &lt;&lt; endl;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    shared_ptr&lt;Ball&gt; p = <span class="built_in">make_shared</span>&lt;Ball&gt;();</span><br><span class="line">    <span class="comment">// 或者写成：</span></span><br><span class="line">    shared_ptr&lt;Ball&gt; p &#123;<span class="built_in">shared_ptr</span>&lt;Ball&gt;()&#125;;</span><br><span class="line">    </span><br><span class="line">    cout &lt;&lt; p.<span class="built_in">use_count</span>() &lt;&lt; endl;</span><br><span class="line">    shared_ptr&lt;Ball&gt; p2 = p;</span><br><span class="line">    cout &lt;&lt; p.<span class="built_in">use_count</span>() &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; p2.<span class="built_in">use_count</span>() &lt;&lt; endl;</span><br><span class="line">    shared_ptr&lt;Ball&gt; p3 = p2; <span class="comment">//或shared_ptr&lt;Ball&gt; p3 = p;</span></span><br><span class="line">    cout &lt;&lt; p.<span class="built_in">use_count</span>() &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; p2.<span class="built_in">use_count</span>() &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; p3.<span class="built_in">use_count</span>() &lt;&lt; endl;</span><br><span class="line">    p.<span class="built_in">reset</span>();  </span><br><span class="line">    p2.<span class="built_in">reset</span>();</span><br><span class="line">    p3.<span class="built_in">reset</span>();</span><br><span class="line">    p-&gt;<span class="built_in">Bounce</span>(); 	<span class="comment">// 为什么还会输出啊？没有报错</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出：</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">2</span></span><br><span class="line"><span class="number">3</span> <span class="number">3</span> <span class="number">3</span></span><br><span class="line">A ball disappears.</span><br></pre></td></tr></table></figure>

<p>创建3个共享指针指向同一个ball类。依次调用use_count()查看有多少指针指向这个物体。</p>
<p><code>p.reset()</code>，shared_ptr调用reset()后会重置，不再指向原来的物体，这里函数内即使不加reset()，函数结束后也会自动释放，也就是调用<code>~Ball()</code>。</p>
<p>3个shared_ptr都释放后，没有shared_ptr指向开头的ball，就自动释放。？</p>
<ul>
<li><input disabled type="checkbox"> todo：p.reset();之后再访问p-&gt;Bounce();为什么还能打印？？</li>
</ul>
<h4 id="reset-传参数，指向新物体"><a href="#reset-传参数，指向新物体" class="headerlink" title="reset()传参数，指向新物体"></a>reset()传参数，指向新物体</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">shared_ptr&lt;Ball&gt; sp;</span><br><span class="line">sp = <span class="built_in">make_shared</span>&lt;Ball&gt;();</span><br><span class="line">sp.<span class="built_in">reset</span>(<span class="keyword">new</span> Ball);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>sp = reset(new Ball)</code> 表示sp指向一个新ball类对象物体，旧的ball引用计数-1。</p>
<h4 id="自定义删除函数-让shared-ptr释放资源-default-delete"><a href="#自定义删除函数-让shared-ptr释放资源-default-delete" class="headerlink" title="自定义删除函数 让shared_ptr释放资源 default_delete"></a>自定义删除函数 让shared_ptr释放资源 default_delete</h4><p>当名叫sfp的shared_ptr引用计数降为0时，执行close_file这个函数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">close_file</span><span class="params">(FILe* fp)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(fp == <span class="literal">nullptr</span>) <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">fclose</span>(fp)l</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;File close&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    FILE* fp = <span class="built_in">fopen</span>(<span class="string">&quot;data.txt&quot;</span>, <span class="string">&quot;w&quot;</span>);</span><br><span class="line">    shared_ptr&lt;FILE&gt; sfp &#123;fp, close_file&#125;;	<span class="comment">//sfp指向fp的地址</span></span><br><span class="line">	<span class="keyword">if</span>(sfp == <span class="literal">nullptr</span>)</span><br><span class="line">		cerr &lt;&lt; <span class="string">&quot;Error opening file&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//指定 default_delete 作为释放规则</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;<span class="type">int</span>&gt; <span class="title">p6</span><span class="params">(<span class="keyword">new</span> <span class="type">int</span>[<span class="number">10</span>], std::default_delete&lt;<span class="type">int</span>[]&gt;())</span></span>;</span><br><span class="line"><span class="comment">//自定义释放规则</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">deleteInt</span><span class="params">(<span class="type">int</span>*p)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">delete</span> []p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//初始化智能指针，并自定义释放规则</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;<span class="type">int</span>&gt; <span class="title">p7</span><span class="params">(<span class="keyword">new</span> <span class="type">int</span>[<span class="number">10</span>], deleteInt)</span></span>;</span><br></pre></td></tr></table></figure>





<h3 id="shared-prt得到裸指针"><a href="#shared-prt得到裸指针" class="headerlink" title="shared_prt得到裸指针"></a>shared_prt得到裸指针</h3><p><code>p.get()</code>，比如 <code>Ball* rp = p.get()</code> ， 其中p是shared_prt，假设Ball函数接收的参数只能是裸指针（不能接收智能指针），则可以通过调用shared_ptr的 <code>get()</code> 方法，来获取一个裸指针，再指向当前的内存资源。</p>
<p>一块内存资源，同时有智能指针和裸指针指向它时，当所有的智能指针都被摧毁，但是裸指针仍然存在时，此时资源仍然会被释放，此时再用裸指针访问那块资源，会变成未定义的行为，因此此时也就不用释放裸指针了。因此用共享指针时避免和裸指针混用。</p>
<h3 id="aliasing-别名"><a href="#aliasing-别名" class="headerlink" title="aliasing 别名"></a>aliasing 别名</h3><p>举例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Bar</span> &#123; <span class="type">int</span> i = <span class="number">123</span>; &#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Foo</span> &#123; Bar bar; &#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	shared_ptr&lt;Foo&gt; f = <span class="built_in">make_shared</span>&lt;Foo&gt;();</span><br><span class="line">	cout &lt;&lt; f.<span class="built_in">use_count</span>() &lt;&lt; endl;	<span class="comment">// 输出1</span></span><br><span class="line">	<span class="function">shared_ptr&lt;Bar&gt; <span class="title">b</span><span class="params">(f, &amp;(f-&gt;bar))</span></span>;	</span><br><span class="line">	cout &lt;&lt; f.<span class="built_in">use_count</span>() &lt;&lt; endl;	<span class="comment">// 输出2</span></span><br><span class="line">	cout &lt;&lt; b-&gt;i &lt;&lt; endl;   <span class="comment">// 输出123</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h2 id="std-unique-ptr-独享指针"><a href="#std-unique-ptr-独享指针" class="headerlink" title="std::unique_ptr 独享指针"></a>std::unique_ptr 独享指针</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1KG4y187qf/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">C++,为什么你应该尽可能使用unique_ptr替换裸指针*</a>   、 <a href="https://www.bilibili.com/video/BV1yt4y1P7xY/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">C++如何在函数间传递unique_ptr？</a> </p>
</blockquote>
<h3 id="解释-1"><a href="#解释-1" class="headerlink" title="解释"></a>解释</h3><p>是一种零开销的智能指针，可以实现自动内存管理，也没有额外的性能开销。资源独享，不能复制。</p>
<h3 id="写法-1"><a href="#写法-1" class="headerlink" title="写法"></a>写法</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line">unique_ptr&lt;<span class="type">int</span>&gt; UP = <span class="built_in">make_unique</span>&lt;<span class="type">int</span>&gt;(<span class="number">100</span>);</span><br><span class="line"></span><br><span class="line">unique_ptr&lt;Ball&gt; up &#123;<span class="built_in">make_unique</span>&lt;Ball&gt;()&#125;</span><br></pre></td></tr></table></figure>



<p>和裸指针类似的用法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> ball = <span class="built_in">make_unique</span>&lt;Ball&gt;();</span><br><span class="line">ball-&gt;<span class="built_in">Bounce</span>();</span><br><span class="line">(*ball).<span class="built_in">Bounce</span>();</span><br></pre></td></tr></table></figure>



<p>想获得资源的裸指针：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Ball* p = up-&gt;<span class="built_in">get</span>();</span><br></pre></td></tr></table></figure>



<p>释放资源：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">up.<span class="built_in">reset</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 释放资源的同时指向另一份资源（新的类实例）</span></span><br><span class="line">up.<span class="built_in">reset</span>(<span class="keyword">new</span> Ball&#123;&#125;);</span><br></pre></td></tr></table></figure>

<p><code>up.reset()</code>  会释放unique_ptr下面的资源，并把该unique_ptr设置为nullptr</p>
<p>资源解绑：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Ball* ball = up.<span class="built_in">release</span>();</span><br><span class="line"><span class="keyword">delete</span> ball;</span><br><span class="line">ball = <span class="literal">nullptr</span>;</span><br></pre></td></tr></table></figure>

<p><code>up.release()</code> 返回资源的裸指针，同时把该unique_ptr设置成nullptr。</p>
<p>自定义分配函数和释放函数 decltype 。</p>
<h3 id="函数间传递unique-ptr"><a href="#函数间传递unique-ptr" class="headerlink" title="函数间传递unique_ptr"></a>函数间传递unique_ptr</h3><p>函数传参很多时候是传值，需要复制。而unique_ptr不支持复制，因此容易写错。</p>
<p>举例，以下代码会<strong>编译错误</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">pass_up</span><span class="params">(unique_str p)</span></span>&#123;</span><br><span class="line">	cout &lt;&lt; *up &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">auto</span> up = <span class="built_in">unique_str</span>&lt;<span class="type">int</span>&gt;(<span class="number">100</span>);</span><br><span class="line">	<span class="built_in">pass_up</span>(up);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>调用<code>pass_up(up)</code> 时，会产生一个复制<code>up</code>的操作，这是不允许的。</p>
<p>修改如下：</p>
<ol>
<li>访问unique_str的资源</li>
</ol>
<p>如果不需要传递指针本身，要的仅仅是内容的话：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">pass_up</span><span class="params">(<span class="type">int</span>&amp; value)</span></span>&#123;</span><br><span class="line">	cout &lt;&lt; value &lt;&lt; endl; <span class="comment">//引用传递</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">auto</span> up = <span class="built_in">unique_str</span>&lt;<span class="type">int</span>&gt;(<span class="number">100</span>);</span><br><span class="line">	<span class="built_in">pass_up</span>(*up);	<span class="comment">//指针指向的地址内容</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>或者 传递裸指针（裸指针作为参数传递）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">pass_up</span><span class="params">(<span class="type">int</span>* p)</span></span>&#123;</span><br><span class="line">	cout &lt;&lt; *p &lt;&lt; endl; </span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">auto</span> up = <span class="built_in">unique_str</span>&lt;<span class="type">int</span>&gt;(<span class="number">100</span>);</span><br><span class="line">	<span class="built_in">pass_up</span>(up.<span class="built_in">get</span>());	<span class="comment">// 裸指针</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>通过函数改变unique_str本身</li>
</ol>
<p>函数的参数设计为unique_ptr的引用</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">pass_up</span><span class="params">(unique_prt&lt;<span class="type">int</span>&gt;&amp; up)</span></span>&#123;</span><br><span class="line">	cout &lt;&lt; *up &lt;&lt; endl; <span class="comment">//引用传递</span></span><br><span class="line">    up.<span class="built_in">reset</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">auto</span> up = <span class="built_in">unique_str</span>&lt;<span class="type">int</span>&gt;(<span class="number">100</span>);</span><br><span class="line">	<span class="built_in">pass_up</span>(up);</span><br><span class="line">    <span class="keyword">if</span>(up == <span class="literal">nullptr</span>) cout &lt;&lt; <span class="string">&quot;up is reset&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>或者 用 <code>std::move</code> </p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">pass_up</span><span class="params">(unique_prt&lt;<span class="type">int</span>&gt; up)</span></span>&#123;</span><br><span class="line">	cout &lt;&lt; *up &lt;&lt; endl; <span class="comment">//引用传递</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">auto</span> up = <span class="built_in">unique_str</span>&lt;<span class="type">int</span>&gt;(<span class="number">100</span>);</span><br><span class="line">	<span class="built_in">pass_up</span>(<span class="built_in">move</span>(up));</span><br><span class="line">    <span class="keyword">if</span>(up == <span class="literal">nullptr</span>) cout &lt;&lt; <span class="string">&quot;up is moved&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>move</code> 可以转移unique_ptr对资源的控制权。</p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++笔记</title>
    <url>/2023/04/03/C++/C++%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="C-笔记"><a href="#C-笔记" class="headerlink" title="C++笔记"></a>C++笔记</h1><blockquote>
<p>C++ 开源库：<a href="http://ffmpeg.club/cppsdk_download.html">http://ffmpeg.club/cppsdk_download.html</a></p>
<p>C 和 C++ 参考手册：<a href="http://www.cppds.com/">http://www.cppds.com/</a></p>
<p>课程：<a href="https://jiedi.ke.qq.com/">https://jiedi.ke.qq.com/</a></p>
<p><a href="https://www.learncpp.com/">https://www.learncpp.com/</a>  、 中文翻译：<a href="https://learncpp-cn.github.io/%EF%BC%88%E5%8F%AA%E7%BF%BB%E8%AF%91%E4%BA%86%E5%87%A0%E4%B8%AA%EF%BC%89">https://learncpp-cn.github.io/（只翻译了几个）</a></p>
<p>官方文档：<a href="https://zh.cppreference.com/w/">https://zh.cppreference.com/w/</a> </p>
<p>c语言中文网：<a href="http://c.biancheng.net/">http://c.biancheng.net/</a></p>
<p>菜鸟教程：<a href="https://www.runoob.com/cplusplus/cpp-tutorial.html">https://www.runoob.com/cplusplus/cpp-tutorial.html</a></p>
<p>c++学习的书籍要看 c++ primer</p>
<p>C++中文网：<a href="https://c-cpp.com/">https://c-cpp.com/</a></p>
</blockquote>
<h2 id="C-引用传递"><a href="#C-引用传递" class="headerlink" title="C++引用传递"></a>C++引用传递</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>引用传递是 C++ 中的一种传参方式，是在函数调用时通过引用（&amp;）的形式将实际参数的地址传给形式参数，这样在函数内操作形式参数就相当于操作实际参数，也就是说形式参数和实际参数共用同一内存空间，任何改变形式参数的值都会影响到实际参数的值。</p>
<h2 id="C-static关键字"><a href="#C-static关键字" class="headerlink" title="C++ static关键字"></a>C++ static关键字</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>分为static参数（变量）、static函数、static类成员。</p>
<p>在 C++ 中，<code>static</code> 是一种关键字，它可以应用于变量、函数和类成员，具有不同的含义。</p>
<ol>
<li><code>static</code> 变量：</li>
</ol>
<p><code>static</code> 变量是一种特殊的变量，具有静态存储期和块作用域。这意味着该变量在<strong>整个程序执行期间都存在</strong>，并且只能在定义该变量的块内访问。<code>static</code> 变量的初始值在程序开始执行时就被初始化了，并且<strong>只初始化一次</strong>，即使该变量在多个函数中被使用。</p>
<ol>
<li><code>static</code> 函数：</li>
</ol>
<p><code>static</code> 函数是一种<strong>只能在定义该函数的文件中使用的函数</strong>，即它具有内部链接（internal linkage）。这种函数不能在其他文件中被调用，因为它们不会被放在程序的全局符号表中。通常，<code>static</code> 函数在文件中定义的目的是为了将其私有化，只能在该文件中使用，防止它被其他文件误用。</p>
<ol>
<li><code>static</code> 类成员：</li>
</ol>
<p><code>static</code> 类成员是类的成员变量或成员函数，它们属于整个类，而不是类的实例。它们可以被类的所有实例共享，并且只有一个副本。<code>static</code> 类成员在程序开始执行时被初始化，并且只初始化一次。<code>static</code> 类成员可以通过类名和作用域解析运算符 <code>::</code> 来访问，而不需要通过类的实例来访问。</p>
<p>总之，<code>static</code> 关键字的用途是在 C++ 中定义静态变量、函数和类成员，并且这些实体具有特殊的作用域、存储方式和链接属性。</p>
<h3 id="静态函数"><a href="#静态函数" class="headerlink" title="静态函数"></a>静态函数</h3><p>C++ 中的静态函数是指那些<strong>不需要对象就可以调用的函数</strong>，并且在<strong>程序的整个生命周期内仅存在一个实例</strong>。静态函数通常是作为类的工具函数实现，不需要访问类的非静态成员，因此它们不需要类的对象实例。静态函数可以在类内部或者类外部定义。</p>
<p>静态函数的声明方式为：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">return</span>-type function-<span class="built_in">name</span>(arguments) &#123; </span><br><span class="line">   <span class="comment">// function body </span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span>-type <span class="keyword">class</span>-name::function-<span class="built_in">name</span>(arguments) &#123; </span><br><span class="line">   <span class="comment">// function body </span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>



<h3 id="静态参数"><a href="#静态参数" class="headerlink" title="静态参数"></a>静态参数</h3><p>在 C++ 中，函数内的静态参数是指在函数内部声明的静态变量。<strong>这个变量的生命周期是整个程序运行期间</strong>，并且在函数多次调用时，其值不会被重置。因此，静态参数在函数内部可以记录和保存信息，并且在下一次调用该函数时可以使用这些信息。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printCounter</span><span class="params">(<span class="type">static</span> <span class="type">int</span> counter)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  counter++;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Counter: &quot;</span> &lt;&lt; counter &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> counter = <span class="number">0</span>;</span><br><span class="line">  <span class="built_in">printCounter</span>(counter);</span><br><span class="line">  <span class="built_in">printCounter</span>(counter);</span><br><span class="line">  <span class="built_in">printCounter</span>(counter);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Counter: 1</span><br><span class="line">Counter: 2</span><br><span class="line">Counter: 3</span><br></pre></td></tr></table></figure>

<p>这里，静态参数<code>counter</code>在多次调用函数<code>printCounter</code>时保持了其值，并递增。</p>
<h3 id="静态类成员"><a href="#静态类成员" class="headerlink" title="静态类成员"></a>静态类成员</h3><blockquote>
<p>C++中static类成员举例</p>
</blockquote>
<p>在C++中，<code>static</code>关键字可以用来修饰类的成员变量或成员函数，它表示这些成员属于整个类，而不是属于某个具体的对象。下面是一个示例，演示如何在类中使用静态成员变量：</p>
<p>用static修饰的话，就可以直接用 <code>类::类成员</code> 进行访问</p>
<p><strong>初始化要在main函数外部初始化！</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> &#123;</span></span><br><span class="line">public:</span><br><span class="line">    <span class="type">static</span> <span class="type">int</span> count; <span class="comment">// 静态成员变量 count，用来记录创建的 MyClass 对象的数量</span></span><br><span class="line"></span><br><span class="line">    MyClass() &#123; <span class="comment">// 构造函数</span></span><br><span class="line">        count++; <span class="comment">// 每次创建对象时，count 自增 1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ~MyClass() &#123; <span class="comment">// 析构函数</span></span><br><span class="line">        count--; <span class="comment">// 每次销毁对象时，count 自减 1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> MyClass::count = <span class="number">0</span>; <span class="comment">// 静态成员变量 count 的定义和初始化</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    MyClass obj1; <span class="comment">// 创建 MyClass 对象 obj1，count 自增 1</span></span><br><span class="line">    MyClass obj2; <span class="comment">// 创建 MyClass 对象 obj2，count 自增 1</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;The number of MyClass objects: &quot;</span> &lt;&lt; MyClass::count &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 输出 MyClass 对象的数量</span></span><br><span class="line">    <span class="comment">// 输出结果：The number of MyClass objects: 2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的代码中，我们定义了一个类 MyClass，其中包含一个静态成员变量 count，它用来记录创建的 MyClass 对象的数量。在类的构造函数和析构函数中，我们对 count 进行自增和自减操作。在程序的主函数中，我们创建了两个 MyClass 对象，然后通过 MyClass::count 来访问静态成员变量 count，输出 MyClass 对象的数量。</p>
<p>需要注意的是，<strong>静态成员变量的定义和初始化必须在类的外部进行</strong>，例如 MyClass::count &#x3D; 0。而且，在使用静态成员变量时，可以通过类名和作用域解析运算符（::）来访问，例如 MyClass::count。</p>
<h2 id="linux怎么单独编译C-头文件"><a href="#linux怎么单独编译C-头文件" class="headerlink" title="linux怎么单独编译C++头文件"></a>linux怎么单独编译C++头文件</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>要单独编译一个 C++ 头文件，你需要创建一个与头文件同名的 C++ 源文件（通常是 <code>.cpp</code> 文件），然后将这个源文件与该头文件一起编译即可。</p>
<p>假设你有一个名为 <code>foo.h</code> 的头文件，那么你可以创建一个名为 <code>foo.cpp</code> 的源文件，并将其与 <code>foo.h</code> 一起编译，命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">g++ -c foo.cpp -o foo.o</span><br></pre></td></tr></table></figure>

<p>其中，<code>-c</code> 表示只编译，不链接；<code>-o foo.o</code> 表示将编译结果保存为 <code>foo.o</code> 文件。</p>
<p>编译完成后，你可以将 <code>foo.o</code> 文件链接到你的程序中，以使用其中定义的函数和变量，命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">g++ main.cpp foo.o -o main</span><br></pre></td></tr></table></figure>

<p>其中，<code>main.cpp</code> 是你的主程序源文件，<code>-o main</code> 表示将链接结果保存为 <code>main</code> 可执行文件。</p>
<p>这样，你就可以在主程序中使用 <code>foo.h</code> 中定义的函数和变量了。</p>
<h2 id="Linux下编译C-x2F-C-项目指定头文件和链接库搜索路径"><a href="#Linux下编译C-x2F-C-项目指定头文件和链接库搜索路径" class="headerlink" title="Linux下编译C&#x2F;C++项目指定头文件和链接库搜索路径"></a>Linux下编译C&#x2F;C++项目指定头文件和链接库搜索路径</h2><blockquote>
<p><a href="https://blog.csdn.net/u010429831/article/details/103150893">Linux下编译C&#x2F;C++项目指定头文件和链接库搜索路径</a></p>
</blockquote>
<h3 id="头文件路径"><a href="#头文件路径" class="headerlink" title="头文件路径"></a>头文件路径</h3><ul>
<li>方式1：#include &lt;…&gt;</li>
<li>方式2：#include “…”</li>
</ul>
<p>&lt;说明&gt; #include &lt;…&gt; 和 #include “…” 的区别：</p>
<ol>
<li>前者一般会优先搜索 -I 选项后的头文件路径（即用gcc编译时的-I选项），之后就是标准的系统头文件路径。</li>
<li>后者是从当前的目录来搜索</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#示例，会优先从/home/xiaowp/include路径去搜索#include &lt;xxx.h&gt;的头文件</span></span><br><span class="line">gcc foo.c -I/home/xiaowp/include -o foo</span><br></pre></td></tr></table></figure>

<ul>
<li><p>方式3：在gcc命令或者Makefile文件中，使用 <strong>-I 来设置头文件的路径</strong></p>
</li>
<li><p>方式4：设置环境变量。</p>
</li>
</ul>
<ol>
<li><p>在当前用户目录下，设置环境变量，只针对当前用户有效。</p>
<p>vim .bash_profile 或者 .bashrc：</p>
<p>export C_INCLUDE_PATH&#x3D;$C_INCLUDE_PATH:头文件路径    #C语言</p>
<p>export CPLUS_INCLUDE_PATH&#x3D;$CPLUS_INCLUDE_PATH:头文件路径     #C++</p>
</li>
<li><p>设置全局环境变量，对所有用户生效，需要root权限。vim &#x2F;etc&#x2F;profile</p>
<p>&lt;注意&gt; 如果当前用户设置了同样的环境变量，那么将屏蔽掉相同名称的全局环境变量的作用域。</p>
</li>
</ol>
<h3 id="Linux系统标准头文件路径"><a href="#Linux系统标准头文件路径" class="headerlink" title="Linux系统标准头文件路径"></a>Linux系统标准头文件路径</h3><p>&#x2F;usr&#x2F;include</p>
<p>&#x2F;usr&#x2F;local&#x2F;include</p>
<p>可以使用 cpp -v 命令来查看标准系统头文件的路径。</p>
<h2 id="new-和-delete"><a href="#new-和-delete" class="headerlink" title="new 和 delete"></a>new 和 delete</h2><p>内存泄露。是因为有一块内存申请了没释放，这块内存之后无人问津，不同地方多次申请内存后，把内存榨干，无内存可用了。</p>
<p><code>delete p; </code> 不是删除p，而是释放p指向的内存。</p>
<p>举例说明：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> a = <span class="number">100</span>;    <span class="comment">// a的内存是由编译器自动分配的，函数运行结束时，编译器会自动释放内存</span></span><br><span class="line">    <span class="type">int</span> *pp = &amp;a;    <span class="comment">// p存储了a的地址</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> *p = <span class="keyword">new</span> <span class="type">int</span>; <span class="comment">// 动态请求一个int大小的内存</span></span><br><span class="line">    <span class="keyword">delete</span> p; <span class="comment">// 注意，这里不是删除p，而是释放p指向的内存。</span></span><br><span class="line">    p = &amp;a;   <span class="comment">// 删除之后，还可以把p指向别的地方。</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> *ppp = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">100</span>];</span><br><span class="line">    <span class="keyword">delete</span>[] ppp;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>存在一种情况，<strong>加delete也可能会造成内存泄漏</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">some_func</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Object* p = <span class="keyword">new</span> Object;</span><br><span class="line">    p-&gt;<span class="built_in">foo</span>();</span><br><span class="line">    <span class="keyword">delete</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果 <code>p-&gt;foo();</code> 这一步抛出了异常，那么delete这句话可能不会执行。</p>
<p>在哪里释放内存delete掉呢？是这个func()函数里吗，如果外面还有引用呢？一旦数据的使用传递变得复杂，就可能会忘记释放内存。</p>
<h2 id="看汇编"><a href="#看汇编" class="headerlink" title="看汇编"></a>看汇编</h2><p>在visual studio里，菜单栏 调试 –&gt;  窗口 –&gt; 反汇编</p>
<h2 id="C-不允许嵌套定义"><a href="#C-不允许嵌套定义" class="headerlink" title="C++不允许嵌套定义"></a>C++不允许嵌套定义</h2><blockquote>
<p><a href="https://blog.csdn.net/qq_44643644/article/details/105130564">C++不允许函数嵌套定义！（或C++不允许在main函数定义中定义函数）</a></p>
</blockquote>
<ol>
<li>函数内部不能再新定义一个函数，但是可以用新一个函数。</li>
<li>函数不能嵌套定义，但可以在函数中声明函数，在函数外定义函数；</li>
<li>在函数中声明的函数的作用域不是它所在的整个函数；</li>
<li>如果能不在函数中声明函数，就别这样做，这样实现起来逻辑复杂容易出错。</li>
</ol>
<h2 id="C-用类成员函数必须实例化一个类对象"><a href="#C-用类成员函数必须实例化一个类对象" class="headerlink" title="C++用类成员函数必须实例化一个类对象"></a>C++用类成员函数必须实例化一个类对象</h2><p>举例：</p>
<p>a.cc：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;a.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">a::printa</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;a&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>a.h：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">a</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">        <span class="type">void</span> <span class="title function_">printa</span><span class="params">()</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<p>b.cc：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;a.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">        a A; </span><br><span class="line">        A.printa(); <span class="comment">//必须要实例化，才能调用类函数</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>命令行敲 <code>g++ b.cc a.cc -o b</code> </p>
<h2 id="C-虚函数"><a href="#C-虚函数" class="headerlink" title="C++虚函数"></a>C++虚函数</h2><ul>
<li>虚函数用于替换基类提供的实现。 只要有问题的对象实际上是派生类的，总是调用替换，即使该对象是通过基指针而不是派生指针访问的。</li>
<li>虚函数是存在于基类中并由派生类重新定义的成员函数。</li>
<li>当在基类和派生类中使用相同的函数名时，基类中的函数使用关键字 <code>virtual</code> 声明。</li>
<li>当函数变为虚函数时，C++ 会在运行时根据基类指针指向的对象的类型来确定调用哪个函数。 因此，通过使基类指针指向不同的对象，我们可以执行不同版本的虚函数。</li>
</ul>
<p>虚函数规则：</p>
<ul>
<li>虚函数应该是某个类的成员。</li>
<li>虚函数不能是静态成员。</li>
<li>使用对象指针调用虚函数。</li>
<li>它可以是另一个班级的朋友。</li>
<li>C++ 不包含虚拟构造函数，但可以具有虚拟析构函数。</li>
</ul>
<blockquote>
<p>chatgpt</p>
</blockquote>
<p>C++中，虚函数是一种特殊的成员函数，可以被子类继承并重写，使得在运行时根据实际的对象类型动态调用相应的函数。虚函数的实现通过在函数声明前加上 <code>virtual</code> 关键字来实现。</p>
<p>使用虚函数可以实现多态，即让子类对象可以用父类指针或引用进行操作，并且能够在运行时自动调用相应的子类函数。在有继承关系的类中，如果一个函数是虚函数，当通过父类指针或引用调用该函数时，实际上会调用相应子类的函数。这种机制可以避免手动进行类型转换，增加了程序的灵活性和可维护性。</p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++语法</title>
    <url>/2023/04/02/C++/C++%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<h1 id="C-语法"><a href="#C-语法" class="headerlink" title="C++语法"></a>C++语法</h1><h2 id="c-函数后面加一个冒号"><a href="#c-函数后面加一个冒号" class="headerlink" title="c++ 函数后面加一个冒号"></a>c++ 函数后面加一个冒号</h2><blockquote>
<p><a href="https://www.cnblogs.com/Allen-rg/p/11529949.html">c++ 函数后面加一个冒号的含义</a></p>
</blockquote>
<ul>
<li>赋值，冒号后面跟的是赋值，这种写法是C++的特性。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> a;</span><br><span class="line"><span class="type">int</span> b;</span><br><span class="line"><span class="built_in">A</span>( <span class="type">int</span> aa, <span class="type">int</span> bb ):<span class="built_in">a</span>(aa),<span class="built_in">b</span>(bb)</span><br><span class="line">&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 相当于</span></span><br><span class="line"><span class="built_in">A</span>( <span class="type">int</span> aa, <span class="type">int</span> bb )</span><br><span class="line">&#123;</span><br><span class="line">	a=aa;</span><br><span class="line">	b=bb;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ul>
<li>继承，比如<code>class Derived : private Base</code> ，冒号前面是派生类（子类），后面是基类（父类）。</li>
</ul>
<h2 id="C-“-”-作用域符-双冒号"><a href="#C-“-”-作用域符-双冒号" class="headerlink" title="C++ “::” 作用域符 双冒号"></a>C++ “::” 作用域符 双冒号</h2><blockquote>
<p><a href="https://blog.csdn.net/qq_33266987/article/details/53689133">C++ “::” 作用域符 双冒号</a></p>
</blockquote>
<p>左关联（left-associativity)，作用都是为了更明确的调用想要的变量:</p>
<ul>
<li><p>&#x3D;&#x3D;类作用域符&#x3D;&#x3D;：class scope，作用域符号::的前面一般是类名称，后面一般是该类的成员名称</p>
<p>A,B表示两个类，在A,B中都有成员member。那么<br>A::member就表示类A中的成员member，B::member就表示类B中的成员member。</p>
</li>
<li><p>&#x3D;&#x3D;全局作用域符号&#x3D;&#x3D;：global scope，当全局变量在局部函数中与其中某个变量重名，那么就可以用::来区分，如：</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span> zhou; <span class="comment">//全局变量</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">sleep</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> zhou; <span class="comment">//局部变量</span></span><br><span class="line">    <span class="built_in">char</span>(局部变量) = <span class="built_in">char</span>(局部变量) *<span class="built_in">char</span>(局部变量) ;</span><br><span class="line">    ::<span class="built_in">char</span>(全局变量) =::<span class="built_in">char</span>(全局变量) *<span class="built_in">char</span>(局部变量);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>&#x3D;&#x3D;命名空间作用域&#x3D;&#x3D;：namespace::name</p>
<p>想调用namespace std中的cout成员，你就写成std::cout（相当于using namespace std；cout）意思是在这里我想用cout对象是<a href="https://www.baidu.com/s?wd=%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1YvPj-hrANhuHRzm1RduHm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3ErHb1PjnzrHR">命名空间</a>std中的cout（即就是标准库里边的cout）</p>
</li>
<li><p>&#x3D;&#x3D;作用域分解运算符&#x3D;&#x3D;</p>
<p>声明了一个类A，类A里声明了一个成员函数voidf()，但没有在类的声明里给出f的定义，那么在类外定义f时，就要写成voidA::f()，表示这个f()函数是类A的成员函数。例如</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CA</span> &#123;</span><br><span class="line"><span class="keyword">public</span>: </span><br><span class="line">  <span class="type">int</span> ca_var;  </span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span>;  </span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">add</span><span class="params">(<span class="type">int</span> a)</span></span>;  </span><br><span class="line">&#125;;</span><br><span class="line">   </span><br><span class="line"><span class="comment">//那么在实现这个函数时，必须这样书写： </span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">CA::add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> a + b;  </span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"><span class="comment">//另外，双冒号也常常用于在类变量内部作为当前类实例的元素进行表示，比如: </span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">CA::add</span><span class="params">(<span class="type">int</span> a)</span>  </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">  <span class="keyword">return</span> a + ::ca_var;  </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//表示当前类实例中的变量ca_var。</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="c-类名后-lt-gt-里面的内容代表什么"><a href="#c-类名后-lt-gt-里面的内容代表什么" class="headerlink" title="c++ 类名后&lt;&gt;里面的内容代表什么?"></a>c++ 类名后&lt;&gt;里面的内容代表什么?</h2><blockquote>
<p><a href="https://segmentfault.com/q/1010000007107682">c++ 类名后&lt;&gt;里面的内容代表什么?</a></p>
</blockquote>
<ul>
<li>模板的参数</li>
</ul>
<p>下面一个模板,TArgs前面那…有什么意义?<br>类名linq_lambda_retriver后&lt;&gt;里面的内容的应该如何理解?</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> TClass, <span class="keyword">typename</span> TResult, <span class="keyword">typename</span> ...TArgs&gt;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">linq_lambda_retriver</span>&lt;<span class="built_in">TResult</span>(__thiscall TClass::*)(TArgs...)<span class="type">const</span>&gt;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">typedef</span> TResult ResultType;</span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure>

<p>在这里是模板<code>linq_lambda_retriver</code>特化的参数，而且是长度可变的模板参数<br>意思大概是 返回值类型是<code>TResult</code> 参数是<code>TArgs...</code>（这是参数包展开） 调用约定是<code>__thiscall</code>的 <code>TClass</code>的一个<code>const</code> 成员函数指针 类型</p>
<h2 id="C-中using-的使用"><a href="#C-中using-的使用" class="headerlink" title="C++ 中using 的使用"></a>C++ 中using 的使用</h2><blockquote>
<p><a href="https://blog.csdn.net/shift_wwx/article/details/78742459">C++ 中using 的使用</a></p>
</blockquote>
<ul>
<li>&#x3D;&#x3D;命名空间的使用&#x3D;&#x3D;：</li>
</ul>
<p>一般为了代码的冲突，都会用命名空间。例如，对于Android代码会使用Android作为命名空间。</p>
<p>namespace android;</p>
<p>在code中使用的时候可以用**android::**加具体的类方法。也可以直接使用using namespace android;</p>
<ul>
<li>&#x3D;&#x3D;在子类中引用基类的成员&#x3D;&#x3D;：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">T5Base</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">T5Base</span>() :<span class="built_in">value</span>(<span class="number">55</span>) &#123;&#125;</span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">T5Base</span>() &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">test1</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;T5Base test1...&quot;</span> &lt;&lt; endl; &#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">T5Derived</span> : <span class="keyword">private</span> T5Base &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">//using T5Base::test1;</span></span><br><span class="line">    <span class="comment">//using T5Base::value;</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">test2</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;value is &quot;</span> &lt;&lt; value &lt;&lt; endl; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>基类中成员变量value是protected，在private继承之后，对于外界这个值为private，也就是说T5Derived的对象无法使用这个value。</p>
<p>如果想要通过对象使用，需要在public下通过using T5Base::value来引用，这样T5Derived的对象就可以直接使用。</p>
<p>同样的，对于基类中的成员函数test1()，在private继承后变为private，T5Derived的对象同样无法访问，通过using T5Base::test1 就可以使用了。</p>
<p>注意，using只是引用，不参与形参的指定。</p>
<ul>
<li>&#x3D;&#x3D;别名指定&#x3D;&#x3D;</li>
</ul>
<p>在C++11中提出了通过using指定别名。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> value_type = _Ty</span><br></pre></td></tr></table></figure>

<p>以后使用value_type value; 就代表_Ty value；</p>
<p>类似typedef</p>
<h2 id="C-this-指针-this-gt"><a href="#C-this-指针-this-gt" class="headerlink" title="C++ this 指针  this-&gt;"></a>C++ this 指针  this-&gt;</h2><blockquote>
<p><a href="https://www.runoob.com/cplusplus/cpp-this-pointer.html">C++ this 指针</a></p>
</blockquote>
<p>在 C++ 中，每一个对象都能通过 <strong>this</strong> 指针来访问自己的地址。<strong>this</strong> 指针是所有成员函数的隐含参数。因此，在成员函数内部，它可以用来指向调用对象。</p>
<p>友元函数没有 <strong>this</strong> 指针，因为友元不是类的成员。只有成员函数才有 <strong>this</strong> 指针。</p>
<p>举例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Box</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">      <span class="comment">// 构造函数定义</span></span><br><span class="line">      <span class="built_in">Box</span>(<span class="type">double</span> l=<span class="number">2.0</span>, <span class="type">double</span> b=<span class="number">2.0</span>, <span class="type">double</span> h=<span class="number">2.0</span>)</span><br><span class="line">      &#123;</span><br><span class="line">         cout &lt;&lt;<span class="string">&quot;Constructor called.&quot;</span> &lt;&lt; endl;</span><br><span class="line">         length = l;</span><br><span class="line">         breadth = b;</span><br><span class="line">         height = h;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function"><span class="type">double</span> <span class="title">Volume</span><span class="params">()</span></span></span><br><span class="line"><span class="function">      </span>&#123;</span><br><span class="line">         <span class="keyword">return</span> length * breadth * height;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function"><span class="type">int</span> <span class="title">compare</span><span class="params">(Box box)</span></span></span><br><span class="line"><span class="function">      </span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">this</span>-&gt;<span class="built_in">Volume</span>() &gt; box.<span class="built_in">Volume</span>();</span><br><span class="line">      &#125;</span><br><span class="line">   <span class="keyword">private</span>:</span><br><span class="line">      <span class="type">double</span> length;     <span class="comment">// Length of a box</span></span><br><span class="line">      <span class="type">double</span> breadth;    <span class="comment">// Breadth of a box</span></span><br><span class="line">      <span class="type">double</span> height;     <span class="comment">// Height of a box</span></span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="function">Box <span class="title">Box1</span><span class="params">(<span class="number">3.3</span>, <span class="number">1.2</span>, <span class="number">1.5</span>)</span></span>;    <span class="comment">// Declare box1</span></span><br><span class="line">   <span class="function">Box <span class="title">Box2</span><span class="params">(<span class="number">8.5</span>, <span class="number">6.0</span>, <span class="number">2.0</span>)</span></span>;    <span class="comment">// Declare box2</span></span><br><span class="line"> </span><br><span class="line">   <span class="keyword">if</span>(Box1.<span class="built_in">compare</span>(Box2))</span><br><span class="line">   &#123;</span><br><span class="line">      cout &lt;&lt; <span class="string">&quot;Box2 is smaller than Box1&quot;</span> &lt;&lt;endl;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">else</span></span><br><span class="line">   &#123;</span><br><span class="line">      cout &lt;&lt; <span class="string">&quot;Box2 is equal to or larger than Box1&quot;</span> &lt;&lt;endl;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当上面的代码被编译和执行时，它会产生下列结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Constructor called.</span><br><span class="line">Constructor called.</span><br><span class="line">Box2 is equal to or larger than Box1</span><br></pre></td></tr></table></figure>



<p>再举例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Box</span>&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">Box</span>()&#123;;&#125;</span><br><span class="line">        ~<span class="built_in">Box</span>()&#123;;&#125;</span><br><span class="line">        <span class="function">Box* <span class="title">get_address</span><span class="params">()</span>   <span class="comment">//得到this的地址</span></span></span><br><span class="line"><span class="function">        </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">    Box box1;</span><br><span class="line">    Box box2;</span><br><span class="line">    <span class="comment">// Box* 定义指针p接受对象box的get_address()成员函数的返回值，并打印</span></span><br><span class="line">    </span><br><span class="line">    Box* p = box1.<span class="built_in">get_address</span>();  </span><br><span class="line">    cout &lt;&lt; p &lt;&lt; endl;</span><br><span class="line">    </span><br><span class="line">    p = box2.<span class="built_in">get_address</span>();</span><br><span class="line">    cout &lt;&lt; p &lt;&lt; endl; </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>this</strong> 指针的类型可理解为 **Box***。</p>
<p>此时得到两个地址分别为 box1 和 box2 对象的地址。</p>
<blockquote>
<p>C++ Primer Page 258</p>
</blockquote>
<p><strong>引入 this：</strong></p>
<p>当我们调用成员函数时，实际上是替某个对象调用它。</p>
<p>成员函数通过一个名为 this 的额外隐式参数来访问调用它的那个对象，当我们调用一个成员函数时，用请求该函数的对象地址初始化 this。例如，如果调用 total.isbn()则编译器负责把 total 的地址传递给 isbn 的隐式形参 this，可以等价地认为编译器将该调用重写成了以下形式：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//伪代码，用于说明调用成员函数的实际执行过程</span></span><br><span class="line">Sales_data::<span class="built_in">isbn</span>(&amp;total)</span><br></pre></td></tr></table></figure>

<p>其中，调用 Sales_data 的 isbn 成员时传入了 total 的地址。</p>
<p>在成员函数内部，我们可以直接使用调用该函数的对象的成员，而无须通过成员访问运算符来做到这一点，因为 this 所指的正是这个对象。任何对类成员的直接访问都被看作是对 this 的隐式引用，也就是说，当 isbn 使用 bookNo 时，它隐式地使用 this 指向的成员，就像我们书写了 <strong>this-&gt;bookNo</strong> 一样。</p>
<p>对于我们来说，this 形参是隐式定义的。实际上，任何自定义名为 this 的参数或变量的行为都是非法的。我们可以在成员函数体内部使用 this，因此尽管没有必要，我们还是能把 isbn 定义成如下形式：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">isbn</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>-&gt;bookNo; &#125;</span><br></pre></td></tr></table></figure>

<p>因为 this 的目的总是指向“这个”对象，所以 this 是一个常量指针（参见2.4.2节，第56页），我们不允许改变 this 中保存的地址。</p>
<h2 id="class"><a href="#class" class="headerlink" title="class"></a>class</h2><p>把类理解成“类型”，就如同int string一样，是一种类型（其实int是类型的关键字）</p>
<h2 id="查看可执行文件依赖库"><a href="#查看可执行文件依赖库" class="headerlink" title="查看可执行文件依赖库"></a>查看可执行文件依赖库</h2><p>可执行文件a，查看它的依赖库：<code>ldd a</code></p>
<h2 id="指定库路径："><a href="#指定库路径：" class="headerlink" title="指定库路径："></a>指定库路径：</h2><blockquote>
<p><a href="https://segmentfault.com/a/1190000016433897">https://segmentfault.com/a/1190000016433897</a></p>
</blockquote>
<p>export LD_LIBRARY_PATH&#x3D;库:$LD_LIBRARY_PATH</p>
<h1 id="c语言编译成-o文件"><a href="#c语言编译成-o文件" class="headerlink" title="c语言编译成.o文件"></a>c语言编译成.o文件</h1><p><code>gcc -c mian.c</code></p>
<p>如果不加.c，直接编译成可执行文件（而不是object文件）</p>
<h2 id="c-调用c接口"><a href="#c-调用c接口" class="headerlink" title="c++调用c接口"></a>c++调用c接口</h2><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/80214770">C++是如何调用C接口的？</a></p>
</blockquote>
<p>在c的头文件写：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">testCfun</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>



<h2 id="memcpy"><a href="#memcpy" class="headerlink" title="memcpy"></a>memcpy</h2><p>memcpy(dst, src, len);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">memcpy</span>(input + reserved_frame_num * input_dim,</span><br><span class="line">	feature, <span class="keyword">sizeof</span>(<span class="type">float</span>)*input_frame_num*input_dim);</span><br></pre></td></tr></table></figure>

<p>这里是把feature付给的地址是input + reserved_frame_num * input_dim，input[0]到input[reserved_frame_num * input_dim]位置之间保持不变，从(input + reserved_frame_num * input_dim)的地址开始复制。</p>
<h1 id="宏"><a href="#宏" class="headerlink" title="宏"></a>宏</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> 。。。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//如果想当前文件不启用这个</span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> 。。。</span></span><br></pre></td></tr></table></figure>



<hr>
<p><a href="https://zh.cppreference.com/w/cpp/container/vector">https://zh.cppreference.com/w/cpp/container/vector</a></p>
<p><a href="https://qingcms.gitee.io/cppreference/20210212/zh/">https://qingcms.gitee.io/cppreference/20210212/zh/</a></p>
<h2 id="新建数组："><a href="#新建数组：" class="headerlink" title="新建数组："></a>新建数组：</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">vector&lt;string&gt; ans;	<span class="comment">//初始值都是&quot;&quot;</span></span><br><span class="line"><span class="comment">// vector&lt;int&gt; cnt(26); //初始值都是0</span></span><br><span class="line">string s = <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">ans.<span class="built_in">push_back</span>(s)</span><br><span class="line"><span class="comment">// 如果vector一开始规定了大小，可以直接： cnt[1]=100;</span></span><br></pre></td></tr></table></figure>



<h2 id="int转string"><a href="#int转string" class="headerlink" title="int转string"></a>int转string</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">to_string(i)</span><br></pre></td></tr></table></figure>



<h2 id="vector长度："><a href="#vector长度：" class="headerlink" title="vector长度："></a>vector长度：</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s.size()</span><br></pre></td></tr></table></figure>



<h2 id="typedef"><a href="#typedef" class="headerlink" title="typedef"></a>typedef</h2><p>为<strong>类型</strong>取一个新的名字，也可以使用 <strong>typedef</strong> 来为用户自定义的数据类型取一个新的名字，然后使用这个新的数据类型来直接定义结构变量。</p>
<p>下面的实例为单字节数字定义了一个术语 <strong>BYTE</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">char</span> BYTE;</span><br></pre></td></tr></table></figure>



<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">Books</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="type">char</span>  title[<span class="number">50</span>];</span><br><span class="line">   <span class="type">char</span>  author[<span class="number">50</span>];</span><br><span class="line">   <span class="type">char</span>  subject[<span class="number">100</span>];</span><br><span class="line">   <span class="type">int</span>   book_id;</span><br><span class="line">&#125; Book;</span><br></pre></td></tr></table></figure>



<p><strong>#define</strong> 是 C 指令，用于为各种数据类型定义别名，与 <strong>typedef</strong> 类似，但是它们有以下几点不同：</p>
<ul>
<li><strong>typedef</strong> 仅限于为类型定义符号名称，**#define** 不仅可以为类型定义别名，也能为数值定义别名，比如您可以定义 1 为 ONE。</li>
<li><strong>typedef</strong> 是由编译器执行解释的，**#define** 语句是由预编译器进行处理的。</li>
</ul>
<h1 id><a href="#" class="headerlink" title="{}"></a>{}</h1><p>作用域</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">nnet2::AmNnet nnet;</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">bool</span> binary;</span><br><span class="line">  <span class="function">Input <span class="title">ki</span><span class="params">(nnet2_rxfilename, &amp;binary)</span></span>;</span><br><span class="line">  trans_model.<span class="built_in">Read</span>(ki.<span class="built_in">Stream</span>(), binary);</span><br><span class="line">  nnet.<span class="built_in">Read</span>(ki.<span class="built_in">Stream</span>(), binary);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里的binary只在{}内的作用域里有用，指令执行到}之后，binary这个变量就没了。</p>
<h1 id="子类调用父类方法"><a href="#子类调用父类方法" class="headerlink" title="子类调用父类方法"></a>子类调用父类方法</h1><blockquote>
<p><a href="https://developer.aliyun.com/article/857737">https://developer.aliyun.com/article/857737</a></p>
</blockquote>
<ol>
<li>外部通过子类调用父类方法 : 如果调用的方法在子类中没有重写 , 那么调用的就是父类的方法 ;</li>
<li>子类中调用父类的方法 : 使用 “ 父类名称 :: 方法名() “ 进行调用</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Child</span> : <span class="keyword">private</span> Parent, <span class="keyword">public</span> Parent1 &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">parent_method</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//子类中调用父类的方法 , 该操作相当于 Java 中的 super 方法 </span></span><br><span class="line">  Parent::<span class="built_in">parent_method</span>();</span><br><span class="line">  Parent1::<span class="built_in">parent_method</span>();</span><br><span class="line">  cout &lt;&lt; <span class="string">&quot; Child parent_method &quot;</span> &lt;&lt; endl;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>



<h1 id="父类调用子类方法"><a href="#父类调用子类方法" class="headerlink" title="父类调用子类方法"></a>父类调用子类方法</h1><blockquote>
<p><a href="https://blog.csdn.net/Huoon/article/details/67819045">利用函数指针实现父类函数调用子类函数</a></p>
</blockquote>
<p>方法1：</p>
<p>新建的对象是”一个指向子类的父类指针或引用“</p>
<p>利用<strong>多态</strong>机制，一个指向子类的父类指针或引用，当调用被子类重写的<strong>虚函数</strong>vritual时，实际上调用的是子类函数，这是通过多态的方式来实现父类调用子类，该方法需要一个引用或者指针调用虚函数来实现。</p>
<p>我的理解：父类里面有一个方法&#x2F;函数 命名是 virtual 虚函数的，没有实现，而在子类的头文件(.h)也有这个虚函数，子类的实现文件(.cc)里面有实现过程（代码里不用添加virtual了），因此就可以父类调用子类。</p>
<p>如下面所示：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Class Base</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">fun</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Base::fun()&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="keyword">public</span> Base</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">fun</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Derived::fun()&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Base* base = <span class="keyword">new</span> Derived;</span><br><span class="line">base-&gt;<span class="built_in">fun</span>();    <span class="comment">//该结果输出为： &quot;Derived::fun()&quot;</span></span><br></pre></td></tr></table></figure>



<p>kaldi实例：&#x3D;&#x3D;【这个写法要记下来】&#x3D;&#x3D;</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// online2/online-nnet2-feature-pipeline.h</span></span><br><span class="line">OnlineBaseFeature *base_feature_;</span><br><span class="line"><span class="comment">// online2/online-nnet2-feature-pipeline.cc</span></span><br><span class="line">base_feature_-&gt;<span class="built_in">AcceptWaveform</span>(sampling_rate, waveform);</span><br><span class="line"></span><br><span class="line"><span class="comment">// itf/online-feature-itf.h</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OnlineBaseFeature</span>: <span class="keyword">public</span> OnlineFeatureInterface &#123;</span><br><span class="line">	<span class="keyword">public</span>:</span><br><span class="line">		<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">AcceptWaveform</span><span class="params">(BaseFloat sampling_rate,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">const</span> VectorBase&lt;BaseFloat&gt; &amp;waveform)</span> </span>= <span class="number">0</span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//feat/online-feature.h</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OnlineGenericBaseFeature</span>: <span class="keyword">public</span> OnlineBaseFeature &#123;</span><br><span class="line">     <span class="keyword">public</span>:</span><br><span class="line">    	<span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">AcceptWaveform</span><span class="params">(BaseFloat sampling_rate,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">const</span> VectorBase&lt;BaseFloat&gt; &amp;waveform)</span></span>;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// feat/online-feature.cc</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">C</span>&gt;</span><br><span class="line"><span class="type">void</span> OnlineGenericBaseFeature&lt;C&gt;::<span class="built_in">AcceptWaveform</span>(</span><br><span class="line">    BaseFloat sampling_rate, <span class="type">const</span> VectorBase&lt;BaseFloat&gt; &amp;original_waveform) &#123;</span><br><span class="line">    	<span class="comment">//...具体实现</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//可以看出，子类是OnlineGenericBaseFeature，父类是OnlineBaseFeature</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这个写法很经典，可以背下来！</span></span><br></pre></td></tr></table></figure>





<p>方法2：</p>
<p>通过函数指针同样可以实现父类函数访问子类函数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(Base::*pfn)</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">CallFunction</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(fn != <span class="literal">NULL</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            (<span class="keyword">this</span>-&gt;*fn)();  <span class="comment">//调用Derived类中的fun()函数</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">SetPfn</span><span class="params">(pfn fn)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;fn = fn;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    pfn fn;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="keyword">public</span> Base</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Init</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">SetPfn</span>((pfn)&amp;Derived::fun);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">fun</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Derived::fun be called in Base function!&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Derived derived;</span><br><span class="line">derived.<span class="built_in">Init</span>();</span><br><span class="line">derived.<span class="built_in">CallFunction</span>();<span class="comment">//这里调用的是父类的成员函数，该函数通过函数指针调用了子类的普通成员函数，调用结果输出：&quot;Derived::fun be called in Base function!&quot;，即父类成员函数调用了子类成员函数。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="C-函数什么时候要加-amp"><a href="#C-函数什么时候要加-amp" class="headerlink" title="C++函数什么时候要加&amp;"></a>C++函数什么时候要加&amp;</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>在 C++ 中，函数声明和定义时需要加 &amp; 的情况如下：</p>
<ol>
<li>当函数返回类型为引用时，函数名前需要加 &amp;。</li>
<li>当函数作为另一个函数的参数时，如果需要通过引用来操作这个参数，则需要在参数前加 &amp;。</li>
</ol>
<p>加 &amp; 的目的是提高程序的效率，因为通过引用访问变量不需要在内存中复制，而是直接使用原变量的地址。</p>
<p>C++中，当一个函数返回值为一个非基本数据类型的对象时，通常需要使用引用（&amp;）修饰符。为了防止复制对象带来的额外的开销和性能问题，将对象的地址作为引用传递给函数，这样就可以避免复制了。举个例子：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Test</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Test</span>(<span class="type">int</span> a, <span class="type">int</span> b) : <span class="built_in">x</span>(a), <span class="built_in">y</span>(b) &#123;&#125;</span><br><span class="line">    <span class="type">int</span> x;</span><br><span class="line">    <span class="type">int</span> y;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">Test&amp; <span class="title">GetTestObject</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">Test <span class="title">t</span><span class="params">(a, b)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Test &amp;t = <span class="built_in">GetTestObject</span>(<span class="number">10</span>, <span class="number">20</span>);</span><br><span class="line">    cout &lt;&lt; t.x &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; t.y &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的代码中，函数 GetTestObject 返回一个 Test 类型的对象，因此需要加上 &amp; 修饰符。</p>
<p>C++函数返回类型为引用时，函数名前需要加 &amp;的例子：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span>&amp; <span class="title">getMax</span><span class="params">(<span class="type">int</span>&amp; a, <span class="type">int</span>&amp; b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (a &gt; b) ? a : b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> x = <span class="number">5</span>, y = <span class="number">10</span>;</span><br><span class="line">    <span class="type">int</span>&amp; max = <span class="built_in">getMax</span>(x, y);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Max value: &quot;</span> &lt;&lt; max &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这里，getMax函数返回了一个整数引用。通过将函数返回值绑定到变量max，返回的是a或b的引用，而不是一个副本。这使得max变量可以直接修改a或b的值，并且在输出Max value时，打印的是最大值。</p>
<h3 id="C-传参时什么时候要加-amp"><a href="#C-传参时什么时候要加-amp" class="headerlink" title="C++传参时什么时候要加&amp;"></a>C++传参时什么时候要加&amp;</h3><p>C++ 中，在传递参数时要加 &amp; 符号，当且仅当您希望通过函数对参数进行修改并在调用函数后在调用者中反映这些修改时。</p>
<p>当传递非常大的对象（例如数组或结构）时，传递引用可以避免复制完整的对象，从而节省内存和时间。</p>
<p>例如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(<span class="type">int</span> &amp;a, <span class="type">int</span> &amp;b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> temp = a;</span><br><span class="line">    a = b;</span><br><span class="line">    b = temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> x = <span class="number">5</span>, y = <span class="number">10</span>;</span><br><span class="line">    cout&lt;&lt; <span class="string">&quot;Before swap: x = &quot;</span>&lt;&lt; x &lt;&lt; <span class="string">&quot;, y = &quot;</span>&lt;&lt; y &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">swap</span>(x, y);</span><br><span class="line">    cout&lt;&lt; <span class="string">&quot;After swap: x = &quot;</span>&lt;&lt; x &lt;&lt; <span class="string">&quot;, y = &quot;</span>&lt;&lt; y &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的代码中，swap函数通过加 &amp; 对函数的参数进行修改，并在主函数中反映这些修改。</p>
<h3 id="在-C-中，函数声明-x2F-定义什么时候要加-amp"><a href="#在-C-中，函数声明-x2F-定义什么时候要加-amp" class="headerlink" title="在 C++ 中，函数声明&#x2F;定义什么时候要加&amp;"></a>在 C++ 中，函数声明&#x2F;定义什么时候要加&amp;</h3><p>在 C++ 中，当函数返回类型为引用时，函数声明&#x2F;定义前需要加 &amp;。</p>
<p>例如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span>&amp; <span class="title">max</span><span class="params">(<span class="type">int</span> &amp;x, <span class="type">int</span> &amp;y)</span></span>;</span><br></pre></td></tr></table></figure>

<p>此函数返回两个参数中的最大值，并且返回的是引用类型，函数 max 返回了 int 类型的引用。</p>
<p>在 C++ 中，如果函数的返回值是指针或者引用类型，函数名前不需要加 &amp;。</p>
<p>当函数的参数为指针或者引用类型时，为了明确指出参数的传递方式，我们也可以加 &amp;。？？</p>
<h2 id="C-函数什么时候要加"><a href="#C-函数什么时候要加" class="headerlink" title="C++函数什么时候要加*"></a>C++函数什么时候要加*</h2><p>在 C++ 中，当一个函数返回指针类型时，函数声明前需要加一个 * 号。这标志着函数返回了一个指向某个对象的指针，而不是返回该对象本身。例如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> *<span class="title">getPointer</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>

<p>该函数声明了一个返回 int 类型指针的函数。</p>
<h3 id="在-C-中，函数声明-x2F-定义什么时候要加"><a href="#在-C-中，函数声明-x2F-定义什么时候要加" class="headerlink" title="在 C++ 中，函数声明&#x2F;定义什么时候要加*"></a>在 C++ 中，函数声明&#x2F;定义什么时候要加*</h3><p>在 C++ 中，当声明&#x2F;定义一个函数返回值（返回类型）为指针时，通常需要在函数名前加 *。例如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> *<span class="title">getData</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>

<p>这个函数声明表明函数返回一个整型指针。函数名前需要加一个星号，因为该函数返回一个 <code>int</code> 类型的指针。</p>
<h3 id="C-传参什么时候要加"><a href="#C-传参什么时候要加" class="headerlink" title="C++传参什么时候要加*"></a>C++传参什么时候要加*</h3><p>在 C++ 中，函数参数要加*，当该参数是一个指针类型时需要加星号。</p>
<p>例如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">printArray</span><span class="params">(<span class="type">int</span> *array, <span class="type">int</span> size)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; array[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的代码中，第一个参数是一个整型指针，所以需要加*号。</p>
<h2 id="C-传参什么时候用-amp-，什么时候用-？"><a href="#C-传参什么时候用-amp-，什么时候用-？" class="headerlink" title="C++传参什么时候用&amp;，什么时候用*？"></a>C++传参什么时候用&amp;，什么时候用*？</h2><p>在 C++ 中，参数的传递方式主要有两种：值传递和引用传递。</p>
<ul>
<li><strong>当函数需要修改参数的值并且希望在函数外也生效时，使用引用传递</strong>。引用传递通过在形参前加 &amp; 实现，例如：void swap(int &amp;a, int &amp;b)。</li>
<li>当函数仅仅需要读取参数的值并不需要修改时，使用值传递。值传递通过直接在形参写出变量类型和名称实现，例如：int max(int a, int b)。值传递的实现是<strong>复制</strong>了一份。</li>
</ul>
<p>当函数需要处理指针时，可以使用指针参数。指针参数通过在形参前加 * 实现，例如：void swap(int *a, int *b)。</p>
<p>总的来说，需要根据函数的具体需求，确定是使用<strong>值传递、引用传递还是指针传递</strong>。</p>
<p>举例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">// 引用传递</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo1</span><span class="params">(<span class="type">int</span>&amp; ptr)</span> </span>&#123;</span><br><span class="line">  		<span class="comment">// code here</span></span><br><span class="line">        std::cout &lt;&lt; ptr &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 指针传递</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo2</span><span class="params">(<span class="type">int</span> *ptr)</span> </span>&#123;</span><br><span class="line">  		<span class="comment">// code here</span></span><br><span class="line">        std::cout &lt;&lt; *ptr &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="type">int</span> x = <span class="number">42</span>;</span><br><span class="line">    </span><br><span class="line">        <span class="built_in">foo1</span>(x);	<span class="comment">//传进去变量，但是用的时候是引用</span></span><br><span class="line">    	<span class="built_in">foo2</span>(&amp;x);	<span class="comment">//传进去地址</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<h2 id="C-头文件怎么写？"><a href="#C-头文件怎么写？" class="headerlink" title="C++头文件怎么写？"></a>C++头文件怎么写？</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>在C++中，头文件通常包含在两个尖括号（&lt;&gt;）或一对双引号（””）中，并放在源代码文件的开头。通常包括函数和变量的声明、宏定义、结构体和类的定义等。以下是一个头文件的示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> MY_HEADER_FILE_H <span class="comment">// 常用的头文件保护宏</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MY_HEADER_FILE_H</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 头文件内容</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">myFunction</span><span class="params">()</span></span>; <span class="comment">// 函数声明</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// MY_HEADER_FILE_H</span></span></span><br></pre></td></tr></table></figure>

<p>这个示例中的头文件名为”my_header_file.h”，头文件保护宏可以避免重复包含同一个头文件。头文件中包含了一个函数的声明。在源代码文件中，可以使用<code>#include</code>指令来包含头文件，例如<code>#include &quot;my_header_file.h&quot;</code>。</p>
<h2 id="常量指针、指针常量"><a href="#常量指针、指针常量" class="headerlink" title="常量指针、指针常量"></a>常量指针、指针常量</h2><blockquote>
<p>csdn：<a href="https://blog.csdn.net/jackystudio/article/details/11519817">【C++基础之二】常量指针和指针常量</a></p>
</blockquote>
<h4 id="常量指针"><a href="#常量指针" class="headerlink" title="常量指针"></a>常量指针</h4><p>定义：具有只能够读取内存中数据，却不能够修改内存中数据的属性的指针，称为指向常量的指针，简称常量指针。</p>
<p>声明：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> * p; </span><br><span class="line"><span class="type">int</span> <span class="type">const</span> * p;</span><br></pre></td></tr></table></figure>

<p>注：可以将一个常量的地址赋值给一个对应类型的常量指针，因为常量指针不能够通过指针修改内存数据。<strong>只能防止通过指针引用修改内存中的数据，并不保护指针所指向的对象。</strong></p>
<h4 id="指针常量"><a href="#指针常量" class="headerlink" title="指针常量"></a>指针常量</h4><p>定义：指针常量是指指针所指向的位置不能改变，即指针本身是一个常量，但是指针所指向的内容可以改变。</p>
<p>声明：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> * <span class="type">const</span> p=&amp;a;</span><br></pre></td></tr></table></figure>

<p>注：指针常量必须在<strong>声明的同时对其初始化</strong>，不允许先声明一个指针常量随后再对其赋值，这和声明一般的常量是一样的。</p>
<p>举例：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> _tmain(<span class="type">int</span> argc, _TCHAR* argv[])</span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">//定义变量</span></span><br><span class="line">	<span class="type">int</span> a=<span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//定义常量</span></span><br><span class="line">	<span class="type">const</span> <span class="type">int</span> b=<span class="number">2</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//定义常量指针</span></span><br><span class="line">	<span class="type">const</span> <span class="type">int</span> *ptr1=&amp;a;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//定义指针常量，必须赋值</span></span><br><span class="line">	<span class="type">int</span>* <span class="type">const</span> ptr2=&amp;a;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//错误，不能把常量的地址赋给指针变量</span></span><br><span class="line">	<span class="type">int</span> *ptr3=&amp;b;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//正确，可以把常量的地址赋给常量指针</span></span><br><span class="line">	<span class="type">const</span> <span class="type">int</span>* ptr4=&amp;b;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//错误，间接引用常量指针不可以修改内存中的数据</span></span><br><span class="line">	*ptr1=<span class="number">3</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//正确，间接引用指针常量可以修改内存中的数据</span></span><br><span class="line">    *ptr2=<span class="number">4</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//正确，常量指针可以指向其他变量</span></span><br><span class="line">	ptr1=&amp;b;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//错误，指针常量不可以指向其他变量</span></span><br><span class="line">	ptr2=&amp;b;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//常量指针常量，即不可以间接引用修改内存数据，也不可以指向别的变量</span></span><br><span class="line">	<span class="type">const</span> <span class="type">int</span> * <span class="type">const</span> ptr5=&amp;a;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//错误，不可以间接引用修改内存数据</span></span><br><span class="line">	*ptr5=<span class="number">5</span>;</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//错误，不可以修改指向的对象</span></span><br><span class="line">	ptr5=&amp;b;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>const int * p和int const * p;是一样的，都是常量指针。以*为中间划一条线 <code>|</code>，看const修饰谁就谁就是常量。int *const p&#x3D;&amp;a 是指针常量。</p>
<p>也可以理解为 左定值，右定向：</p>
<p>const在<code>*</code>号左边，表示指针指向的内容不能修改（常量指针）<br>const在<code>*</code>号右边，表示指针指向的地址不能修改（指针常量）</p>
<h2 id="C-const"><a href="#C-const" class="headerlink" title="C++ const"></a>C++ const</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>在C++中，<code>const</code>是用来修饰变量、函数、指针等的关键字，它表示它所修饰的内容是<strong>只读</strong>的（即不能被修改）。具体来说：</p>
<ol>
<li><p>对于变量，<code>const</code>可以用来修饰任何类型的变量，例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> x = <span class="number">10</span>; <span class="comment">// 定义一个只读的整数变量 x，不允许对其进行修改</span></span><br><span class="line"><span class="type">const</span> <span class="type">double</span> pi = <span class="number">3.14159</span>; <span class="comment">// 定义一个只读的浮点数常量 pi，不允许对其进行修改</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>对于函数，<code>const</code>可以用来修饰成员函数，表示这个<strong>成员函数不会修改类的成员变量，</strong>例如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">func</span><span class="params">()</span> <span class="type">const</span></span>; <span class="comment">// 声明一个只读的成员函数 func，不允许修改类的成员变量</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MyClass::func</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 在这里不允许修改类的成员变量</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>举例：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">a</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">    <span class="type">int</span> aa = <span class="number">1</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> b = <span class="number">10</span>;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">bb</span><span class="params">()</span> <span class="type">const</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">a::bb</span><span class="params">()</span> <span class="type">const</span> &#123;</span><br><span class="line">    <span class="comment">// a::aa = 2; // 不可以</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; a::aa;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    a aa;</span><br><span class="line">    aa.bb();</span><br><span class="line">    aa.aa = <span class="number">2</span>; <span class="comment">// 可以</span></span><br><span class="line">    <span class="comment">// aa.b++; //不可以</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
<li><p>对于指针，<code>const</code>可以用来修饰指针本身或指针所指向的内容，例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span>* ptr1; <span class="comment">// 定义一个指向只读整数的指针，指针本身可以修改，但指向的内容不可修改</span></span><br><span class="line"><span class="type">int</span>* <span class="type">const</span> ptr2; <span class="comment">// 定义一个只读的指针，指针本身不可修改，但指向的内容可以修改</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span>* <span class="type">const</span> ptr3; <span class="comment">// 定义一个只读的指针，指针本身和指向的内容都不可修改</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p>使用<code>const</code>有以下好处：</p>
<ol>
<li>可以帮助程序员更好地防止程序中出现不必要的变量修改，提高程序的安全性和可靠性。</li>
<li>可以让编译器进行更多的优化，提高程序的性能。</li>
<li>可以帮助程序员更好地理解代码，提高代码的可读性和可维护性。</li>
</ol>
<h2 id="C-二级指针"><a href="#C-二级指针" class="headerlink" title="C++ 二级指针"></a>C++ 二级指针</h2><blockquote>
<p>chatgpt：C++中两个星号**指的是什么？</p>
</blockquote>
<p>在 C++ 中，两个星号 <code>**</code> 是指针的指针，也称为二级指针。它表示一个指向指针的指针变量。</p>
<p>例如，以下代码定义了一个指向指针的指针 <code>pp</code>：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> a = <span class="number">10</span>;</span><br><span class="line"><span class="type">int</span>* p = &amp;a;</span><br><span class="line"><span class="type">int</span>** pp = &amp;p;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>p</code> 是一个指向 <code>a</code> 变量的指针，<code>pp</code> 是一个指向 <code>p</code> 指针的指针。可以通过 <code>pp</code> 指针来修改 <code>p</code> 指针指向的变量：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> b = <span class="number">20</span>;</span><br><span class="line">*pp = &amp;b; <span class="comment">// 现在 p 指向 b // *pp想成是p，于是 p = &amp;b，也就是p指向b的地址（不再指向a的地址了）</span></span><br></pre></td></tr></table></figure>

<p>在这个例子中，<code>*pp</code> 取得了 <code>p</code> 的值，即指向变量 <code>a</code> 的指针，然后将其赋值为指向变量 <code>b</code> 的指针，因此现在 <code>p</code> 指向了变量 <code>b</code>。</p>
<blockquote>
<p>chatgpt：什么时候会用到二级指针？</p>
</blockquote>
<p>在C++或C语言中，二级指针是指一个指向指针的指针。在以下情况下，可能会用到二级指针：</p>
<ol>
<li>函数需要修改指针所指向的内存地址：如果一个函数需要修改一个指针所指向的内存地址，但是这个指针本身是一个函数参数，那么需要传递一个指向指针的指针作为参数，以便在函数内部能够修改指针指向的内存地址。</li>
<li>多级指针数据结构：有些数据结构，如链表或树，可能需要使用二级指针来访问和修改数据。在这种情况下，一个指针存储了一个指向另一个指针的指针，以便可以轻松访问和操作数据结构。</li>
<li>动态内存分配：在动态内存分配过程中，可能需要使用二级指针来分配和释放内存。这是因为动态分配内存时，需要使用指向指针的指针来分配和释放内存，以便正确地管理内存。</li>
</ol>
<blockquote>
<p>chatgpt：不同情况使用二级指针举例</p>
</blockquote>
<p>下面是一些可能会使用二级指针的具体情况：</p>
<ol>
<li>函数需要修改指针所指向的内存地址：假设有一个函数需要修改一个整型指针指向的内存地址，而这个指针本身是一个函数参数，可以使用如下代码：</li>
</ol>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">modifyPointer</span><span class="params">(<span class="type">int</span> **ptr)</span> &#123;</span><br><span class="line">    <span class="type">int</span> *temp = new <span class="type">int</span>;</span><br><span class="line">    *temp = <span class="number">10</span>;</span><br><span class="line">    *ptr = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的例子中，<code>modifyPointer</code> 函数使用了一个指向指针的指针 <code>int **</code>，并且在函数内部创建了一个新的整型指针，将它的值设置为 10，并将这个新指针赋值给传递进来的指针。这样就可以修改指针所指向的内存地址了。</p>
<ol>
<li>多级指针数据结构：假设有一个链表数据结构，其中每个节点都是一个指向下一个节点的指针。这个数据结构可以使用二级指针来操作。例如，可以使用以下代码向链表中添加一个新的节点：</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    <span class="type">int</span> data;</span><br><span class="line">    Node *next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">addNode</span><span class="params">(Node **head, <span class="type">int</span> newData)</span> </span>&#123;</span><br><span class="line">    Node *newNode = <span class="keyword">new</span> Node;</span><br><span class="line">    newNode-&gt;data = newData;</span><br><span class="line">    newNode-&gt;next = *head;</span><br><span class="line">    *head = newNode;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的例子中，<code>addNode</code> 函数使用了一个指向指针的指针 <code>Node **</code>，并在函数内部创建了一个新的节点 <code>newNode</code>。然后将 <code>newNode</code> 的 <code>next</code> 指针设置为传递进来的指针所指向的节点，并将 <code>newNode</code> 赋值给传递进来的指针。这样就可以向链表中添加一个新的节点了。</p>
<ol>
<li>动态内存分配：假设需要动态分配一个二维数组，可以使用二级指针来管理内存。例如，可以使用以下代码动态分配一个 3 行 4 列的二维数组：</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> **array = <span class="keyword">new</span> <span class="type">int</span>*[<span class="number">3</span>];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">    array[i] = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">4</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的例子中，首先动态分配一个 <code>int*</code> 类型的数组，大小为 3，然后在循环中动态分配每个元素的指针，大小为 4。这样就可以动态分配一个 3 行 4 列的二维数组了。</p>
<h2 id="explicit"><a href="#explicit" class="headerlink" title="explicit"></a>explicit</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>在 C++ 中，<code>explicit</code> 是一个关键字，用于修饰构造函数或者转换函数，其<strong>目的是防止编译器进行隐式类型转换</strong>。</p>
<p>当一个类有一个只带一个参数的构造函数时，如果没有使用 <code>explicit</code> 修饰，那么编译器会自动将该构造函数用于将一个参数的表达式转换为该类类型的对象，这被称为隐式类型转换。然而，这种自动转换可能会导致不期望的行为和错误，因此可以使用 <code>explicit</code> 关键字来防止它。</p>
<p>下面是一个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyInt</span> &#123;</span></span><br><span class="line">public:</span><br><span class="line">  MyInt(<span class="type">int</span> value) : value_(value) &#123;&#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">  <span class="type">int</span> value_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">func</span><span class="params">(MyInt my_int)</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  func(<span class="number">123</span>);  <span class="comment">// 这里会进行隐式类型转换，编译器会将 123 转换为 MyInt 类型</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果不使用 <code>explicit</code>，编译器会将 <code>123</code> 隐式转换为 <code>MyInt</code> 类型，然后传递给 <code>func</code> 函数。但是，如果使用 <code>explicit</code> 关键字来修饰 <code>MyInt</code> 的构造函数，那么上述代码就会编译失败，因为不能隐式地将 <code>int</code> 类型转换为 <code>MyInt</code> 类型。</p>
<blockquote>
<p><a href="https://zh.cppreference.com/w/cpp/language/explicit">https://zh.cppreference.com/w/cpp/language/explicit</a></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    A(<span class="type">int</span>) &#123; &#125;      <span class="comment">// 转换构造函数</span></span><br><span class="line">    A(<span class="type">int</span>, <span class="type">int</span>) &#123; &#125; <span class="comment">// 转换构造函数（C++11）</span></span><br><span class="line">    operator <span class="title function_">bool</span><span class="params">()</span> <span class="type">const</span> &#123; <span class="keyword">return</span> <span class="literal">true</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    explicit <span class="title function_">B</span><span class="params">(<span class="type">int</span>)</span> &#123; &#125;</span><br><span class="line">    explicit <span class="title function_">B</span><span class="params">(<span class="type">int</span>, <span class="type">int</span>)</span> &#123; &#125;</span><br><span class="line">    explicit operator <span class="title function_">bool</span><span class="params">()</span> <span class="type">const</span> &#123; <span class="keyword">return</span> <span class="literal">true</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    A a1 = <span class="number">1</span>;      <span class="comment">// OK：复制初始化选择 A::A(int)</span></span><br><span class="line">    A <span class="title function_">a2</span><span class="params">(<span class="number">2</span>)</span>;       <span class="comment">// OK：直接初始化选择 A::A(int)</span></span><br><span class="line">    A a3 &#123;<span class="number">4</span>, <span class="number">5</span>&#125;;   <span class="comment">// OK：直接列表初始化选择 A::A(int, int)</span></span><br><span class="line">    A a4 = &#123;<span class="number">4</span>, <span class="number">5</span>&#125;; <span class="comment">// OK：复制列表初始化选择 A::A(int, int)</span></span><br><span class="line">    A a5 = (A)<span class="number">1</span>;   <span class="comment">// OK：显式转型进行 static_cast</span></span><br><span class="line">    <span class="keyword">if</span> (a1) ;      <span class="comment">// OK：A::operator bool()</span></span><br><span class="line">    <span class="type">bool</span> na1 = a1; <span class="comment">// OK：复制初始化选择 A::operator bool()</span></span><br><span class="line">    <span class="type">bool</span> na2 = static_cast&lt;<span class="type">bool</span>&gt;(a1); <span class="comment">// OK：static_cast 进行直接初始化</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//  B b1 = 1;      // 错误：复制初始化不考虑 B::B(int)</span></span><br><span class="line">    B <span class="title function_">b2</span><span class="params">(<span class="number">2</span>)</span>;       <span class="comment">// OK：直接初始化选择 B::B(int)</span></span><br><span class="line">    B b3 &#123;<span class="number">4</span>, <span class="number">5</span>&#125;;   <span class="comment">// OK：直接列表初始化选择 B::B(int, int)</span></span><br><span class="line"><span class="comment">//  B b4 = &#123;4, 5&#125;; // 错误：复制列表初始化不考虑 B::B(int,int)</span></span><br><span class="line">    B b5 = (B)<span class="number">1</span>;   <span class="comment">// OK：显式转型进行 static_cast</span></span><br><span class="line">    <span class="keyword">if</span> (b2) ;      <span class="comment">// OK：B::operator bool()</span></span><br><span class="line"><span class="comment">//  bool nb1 = b2; // 错误：复制初始化不考虑 B::operator bool()</span></span><br><span class="line">    <span class="type">bool</span> nb2 = static_cast&lt;<span class="type">bool</span>&gt;(b2); <span class="comment">// OK：static_cast 进行直接初始化</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<blockquote>
<p><a href="https://stackoverflow.com/questions/121162/what-does-the-explicit-keyword-mean">https://stackoverflow.com/questions/121162/what-does-the-explicit-keyword-mean</a></p>
</blockquote>
<blockquote>
<p><a href="https://c-cpp.com/cpp/language/explicit">https://c-cpp.com/cpp/language/explicit</a></p>
</blockquote>
<h2 id="std-move"><a href="#std-move" class="headerlink" title="std::move"></a>std::move</h2><blockquote>
<p><a href="https://zh.cppreference.com/w/cpp/utility/move">https://zh.cppreference.com/w/cpp/utility/move</a></p>
<p>csdn：<a href="https://blog.csdn.net/p942005405/article/details/84644069">c++ 之 std::move 原理实现与用法总结</a></p>
</blockquote>
<p>功能将一个左值强制转化为右值引用，继而可以通过右值引用使用该值，以用于移动语义。</p>
<p>从实现上讲，<code>std::move</code>基本等同于一个类型转换：<code>static_cast&lt;T&amp;&amp;&gt;(lvalue);</code></p>
<ol>
<li>C++ 标准库使用比如vector::push_back 等这类函数时,会对参数的对象进行复制,连数据也会复制.这就会造成对象内存的额外创建, 本来原意是想把参数push_back进去就行了,通过std::move，可以避免不必要的拷贝操作。</li>
<li>std::move是将对象的状态或者所有权从一个对象转移到另一个对象，只是转移，没有内存的搬迁或者内存拷贝所以可以提高利用效率,改善性能.。</li>
<li>对指针类型的标准库对象并不需要这么做.</li>
</ol>
<h3 id="用法"><a href="#用法" class="headerlink" title="用法:"></a>用法:</h3><p>原lvalue值被moved from之后值被转移,所以为空字符串. </p>
<h3 id="std-move-的函数原型定义"><a href="#std-move-的函数原型定义" class="headerlink" title="std::move 的函数原型定义"></a>std::move 的函数原型定义</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">template &lt;typename T&gt;</span><br><span class="line">typename remove_reference&lt;T&gt;::type&amp;&amp; <span class="title function_">move</span><span class="params">(T&amp;&amp; t)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> static_cast&lt;typename remove_reference&lt;T&gt;::type&amp;&amp;&gt;(t);</span><br></pre></td></tr></table></figure>



<h3 id="举例："><a href="#举例：" class="headerlink" title="举例："></a>举例：</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> str = <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt; v;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 使用 push_back(const T&amp;) 重载，</span></span><br><span class="line">    <span class="comment">// 表示我们将带来复制 str 的成本</span></span><br><span class="line">    v.push_back(str);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;After copy, str is \&quot;&quot;</span> &lt;&lt; str &lt;&lt; <span class="string">&quot;\&quot;\n&quot;</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 使用右值引用 push_back(T&amp;&amp;) 重载，</span></span><br><span class="line">    <span class="comment">// 表示不复制字符串；而是</span></span><br><span class="line">    <span class="comment">// str 的内容被移动进 vector</span></span><br><span class="line">    <span class="comment">// 这个开销比较低，但也意味着 str 现在可能为空。</span></span><br><span class="line">    v.push_back(<span class="built_in">std</span>::move(str));</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;After move, str is \&quot;&quot;</span> &lt;&lt; str &lt;&lt; <span class="string">&quot;\&quot;\n&quot;</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;The contents of the vector are \&quot;&quot;</span> &lt;&lt; v[<span class="number">0</span>]</span><br><span class="line">                                         &lt;&lt; <span class="string">&quot;\&quot;, \&quot;&quot;</span> &lt;&lt; v[<span class="number">1</span>] &lt;&lt; <span class="string">&quot;\&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*输出</span></span><br><span class="line"><span class="comment">After copy, str is &quot;Hello&quot;</span></span><br><span class="line"><span class="comment">After move, str is &quot;&quot;</span></span><br><span class="line"><span class="comment">The contents of the vector are &quot;Hello&quot;, &quot;Hello&quot;</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>



<h2 id="左值、左值引用、右值、右值引用"><a href="#左值、左值引用、右值、右值引用" class="headerlink" title="左值、左值引用、右值、右值引用"></a>左值、左值引用、右值、右值引用</h2><blockquote>
<p>博客园：<a href="https://www.cnblogs.com/SZxiaochun/p/8017475.html">左值、左值引用、右值、右值引用</a> </p>
</blockquote>
<h4 id="1、左值和右值的概念"><a href="#1、左值和右值的概念" class="headerlink" title="1、左值和右值的概念"></a>1、左值和右值的概念</h4><p>​     左值是可以放在赋值号左边可以被赋值的值；左值必须要在内存中有实体；<br>​     右值当在赋值号右边取出值赋给其他变量的值；右值可以在内存也可以在CPU寄存器。<br>​     一个对象被用作右值时，使用的是它的内容(值)，被当作左值时，使用的是它的地址<strong>。</strong></p>
<h4 id="2、引用"><a href="#2、引用" class="headerlink" title="2、引用"></a>2、引用</h4><p>​    引用是C++语法做的优化，引用的本质还是靠指针来实现的。引用相当于变量的别名。</p>
<p>​    引用可以改变指针的指向，还可以改变指针所指向的值。</p>
<p>​    引用的基本规则：</p>
<ol>
<li>声明引用的时候必须初始化，且一旦绑定，不可把引用绑定到其他对象；即引用必须初始化，不能对引用重定义<strong>；</strong></li>
<li>对引用的一切操作，就相当于对原对象的操作。</li>
</ol>
<h4 id="3、左值引用和右值引用"><a href="#3、左值引用和右值引用" class="headerlink" title="3、左值引用和右值引用"></a>3、左值引用和右值引用</h4><p>  3.1 左值引用<br>     左值引用的基本语法：type &amp;引用名 &#x3D; 左值表达式；</p>
<p>  3.2 右值引用</p>
<p>​    右值引用的基本语法type &amp;&amp;引用名 &#x3D; 右值表达式；</p>
<p>​    右值引用在企业开发人员在代码优化方面会经常用到。</p>
<p>​    右值引用的“&amp;&amp;”中间不可以有空格。</p>
<h2 id="函数对象-operator"><a href="#函数对象-operator" class="headerlink" title="函数对象 operator()"></a>函数对象 operator()</h2><blockquote>
<p>csdn <a href="https://blog.csdn.net/xgf415/article/details/52966475">C++函数对象operator()</a></p>
</blockquote>
<p>函数对象：定义了调用操作符（）的类对象。当用该对象调用此操作符时，其表现形式如同普通函数调用一般。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span> </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">public:  </span><br><span class="line">    <span class="type">void</span> <span class="title function_">operator</span><span class="params">()</span><span class="params">()</span>  </span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    &#125;  </span><br><span class="line">&#125;;  </span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">        A a;</span><br><span class="line">        a();</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出 1</span></span><br></pre></td></tr></table></figure>



<p>有参数的话：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">operator</span><span class="params">()</span> <span class="params">( <span class="type">int</span> val )</span>  <span class="comment">//把参数写在第二个括号里，有个单独的括号在operator后面</span></span><br><span class="line">&#123;  </span><br><span class="line">    <span class="keyword">return</span> val &gt; <span class="number">0</span> ? val : -val;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>





<h2 id="因为有构造函数而可以直接传值的情况"><a href="#因为有构造函数而可以直接传值的情况" class="headerlink" title="因为有构造函数而可以直接传值的情况"></a>因为有构造函数而可以直接传值的情况</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Edge</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> to;     <span class="comment">// 边的目的地</span></span><br><span class="line">    <span class="type">int</span> weight; <span class="comment">// 边的权重</span></span><br><span class="line">    Edge(<span class="type">int</span> t, <span class="type">int</span> w) : to(t), weight(w) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span> &#123;</span></span><br><span class="line">private:</span><br><span class="line">    XXX adj_list; <span class="comment">// 比如 vector&lt;vector&lt;Edge&gt;&gt; adj_list;</span></span><br><span class="line">public:</span><br><span class="line">    Graph(<span class="type">int</span> n) : adj_list(n) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="built_in">vector</span>&lt;Graph&gt; b;</span><br><span class="line">	b.emplace_back(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">/* 这样相当于传了一个Graph类的对象进去，等价于：</span></span><br><span class="line"><span class="comment">    Graph bb(1);</span></span><br><span class="line"><span class="comment">    b.emplace_back(bb); */</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">vector</span>&lt;Edge&gt; a;</span><br><span class="line">    a.emplace_back(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">    <span class="comment">/* 这样相当于传了一个Edge结构体的对象进去，等价于：</span></span><br><span class="line"><span class="comment">    Edge aa(1,2);</span></span><br><span class="line"><span class="comment">    a.emplace_back(aa);</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake入门（一）</title>
    <url>/2023/03/07/C++/CMake%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="CMake入门（一）"><a href="#CMake入门（一）" class="headerlink" title="CMake入门（一）"></a>CMake入门（一）</h1><p>编译：<code>mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; cmake --build .</code></p>
<p><code>cmake .. -ONNXRUNTIME_ROOTDIR=/home/data/yelong/onnxruntime-linux-x64-1.10.0/</code></p>
<h2 id="CMake教程"><a href="#CMake教程" class="headerlink" title="CMake教程"></a>CMake教程</h2><blockquote>
<p><a href="https://www.hahack.com/codes/cmake/">CMake 入门实战</a>、<a href="https://github.com/wzpan/cmake-demo">https://github.com/wzpan/cmake-demo</a></p>
<p><a href="https://aiden-dong.gitee.io/2019/07/20/CMake%E6%95%99%E7%A8%8B%E4%B9%8BCMake%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%BA%94%E7%94%A8/">CMake 教程 | CMake 从入门到应用</a></p>
</blockquote>
<p>在 linux 平台下使用 CMake 生成 Makefile 并编译的流程如下：</p>
<ol>
<li>编写 CMake 配置文件 CMakeLists.txt 。</li>
<li>执行命令 <code>cmake PATH</code> 或者 <code>ccmake PATH</code> 生成 Makefile（<code>ccmake</code> 和 <code>cmake</code> 的区别在于前者提供了一个交互式的界面）。其中， <code>PATH</code> 是 CMakeLists.txt 所在的目录。</li>
<li>使用 <code>make</code> 命令进行编译。</li>
</ol>
<h3 id="CMakeLists-txt-的语法："><a href="#CMakeLists-txt-的语法：" class="headerlink" title="CMakeLists.txt 的语法："></a>CMakeLists.txt 的语法：</h3><p>由命令、注释和空格组成，其中命令是不区分大小写的。符号 <code>#</code> 后面的内容被认为是注释。</p>
<p>命令由命令名称、小括号和参数组成，参数之间使用空格进行间隔。</p>
<h2 id="入门案例：单个源文件"><a href="#入门案例：单个源文件" class="headerlink" title="入门案例：单个源文件"></a>入门案例：单个源文件</h2><p>举例：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标 （这里叫Demo 可执行文件）</span></span><br><span class="line"><span class="keyword">add_executable</span>(Demo main.cc)</span><br></pre></td></tr></table></figure>

<p>依次出现了几个命令：</p>
<ol>
<li><code>cmake_minimum_required</code>：指定运行此配置文件所需的 CMake 的最低版本；</li>
<li><code>project</code>：参数值是 <code>Demo1</code>，该命令表示项目的名称是 <code>Demo1</code> 。</li>
<li><code>add_executable</code>： 将名为 main.cc 的源文件编译成一个名称为 Demo 的可执行文件。</li>
</ol>
<h4 id="编译项目"><a href="#编译项目" class="headerlink" title="编译项目"></a>编译项目</h4><p>&#x3D;&#x3D;在当前目录执行 <code>cmake .</code> ，得到 Makefile 后再使用 <code>make</code> 命令编译&#x3D;&#x3D;得到 Demo1 可执行文件。</p>
<p>（先cmake，再make）</p>
<h2 id="多个源文件"><a href="#多个源文件" class="headerlink" title="多个源文件"></a>多个源文件</h2><h3 id="同一目录，多个源文件"><a href="#同一目录，多个源文件" class="headerlink" title="同一目录，多个源文件"></a>同一目录，多个源文件</h3><p>上面的例子只有单个源文件。现在假如把 <code>power</code> 函数单独写进一个名为 <code>MathFunctions.c</code> 的源文件里，使得这个工程变成如下的形式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./Demo2</span><br><span class="line">    |</span><br><span class="line">    +--- main.cc</span><br><span class="line">    |</span><br><span class="line">    +--- MathFunctions.cc</span><br><span class="line">    |</span><br><span class="line">    +--- MathFunctions.h</span><br></pre></td></tr></table></figure>

<p>这个时候，CMakeLists.txt 可以改成如下的形式：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标</span></span><br><span class="line"><span class="keyword">add_executable</span>(Demo main.cc MathFunctions.cc)</span><br></pre></td></tr></table></figure>

<p>唯一的改动只是在 <code>add_executable</code> 命令中增加了一个 <code>MathFunctions.cc</code> 源文件。这样写当然没什么问题，但是如果源文件很多，把所有源文件的名字都加进去将是一件烦人的工作。更省事的方法是使用 <code>aux_source_directory</code>命令，<strong>该命令会查找指定目录下的所有源文件，然后将结果存进指定变量名</strong>。其语法如下：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">aux_source_directory</span>(&lt;dir&gt; &lt;variable&gt;)</span><br></pre></td></tr></table></figure>

<p>因此，可以修改 CMakeLists.txt 如下：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找当前目录下的所有源文件</span></span><br><span class="line"><span class="comment"># 并将名称保存到 DIR_SRCS 变量</span></span><br><span class="line"><span class="keyword">aux_source_directory</span>(. DIR_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标</span></span><br><span class="line"><span class="keyword">add_executable</span>(Demo <span class="variable">$&#123;DIR_SRCS&#125;</span>)</span><br></pre></td></tr></table></figure>



<h4 id="在CMake中使用C-11"><a href="#在CMake中使用C-11" class="headerlink" title="在CMake中使用C++11"></a>在CMake中使用C++11</h4><p><code>add_definitions(-std=c++11)</code></p>
<h3 id="多个目录，多个源文件"><a href="#多个目录，多个源文件" class="headerlink" title="多个目录，多个源文件"></a>多个目录，多个源文件</h3><p>现在进一步将 MathFunctions.h 和 <a href="http://mathfunctions.cc/">MathFunctions.cc</a> 文件移动到 math 目录下。</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">./Demo3</span><br><span class="line">    |</span><br><span class="line">    +--- main.cc</span><br><span class="line">    |</span><br><span class="line">    +--- <span class="keyword">math</span>/</span><br><span class="line">          |</span><br><span class="line">          +--- MathFunctions.cc</span><br><span class="line">          |</span><br><span class="line">          +--- MathFunctions.h</span><br></pre></td></tr></table></figure>



<p>对于这种情况，需要分别在项目根目录 Demo3 和 math 目录里各编写一个 CMakeLists.txt 文件。为了方便，我们可以先将 math 目录里的文件编译成静态库再由 main 函数调用。</p>
<p>根目录中的 CMakeLists.txt ：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找当前目录下的所有源文件</span></span><br><span class="line"><span class="comment"># 并将名称保存到 DIR_SRCS 变量</span></span><br><span class="line"><span class="keyword">aux_source_directory</span>(. DIR_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加 math 子目录</span></span><br><span class="line"><span class="keyword">add_subdirectory</span>(<span class="keyword">math</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标 ，这里叫Demo（可执行文件）</span></span><br><span class="line"><span class="keyword">add_executable</span>(Demo main.cc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加链接库</span></span><br><span class="line"><span class="keyword">target_link_libraries</span>(Demo MathFunctions)</span><br></pre></td></tr></table></figure>

<p>该文件添加了下面的内容: 第3行，使用命令 <code>add_subdirectory</code> 指明本项目包含一个子目录 math，这样 math 目录下的 CMakeLists.txt 文件和源代码也会被处理 。第6行，使用命令 <code>target_link_libraries</code> 指明可执行文件 main 需要连接一个名为 MathFunctions 的链接库 。</p>
<p>子目录（math&#x2F;）中的 CMakeLists.txt：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查找当前目录下的所有源文件</span></span><br><span class="line"><span class="comment"># 并将名称保存到 DIR_LIB_SRCS 变量</span></span><br><span class="line"><span class="keyword">aux_source_directory</span>(. DIR_LIB_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成链接库</span></span><br><span class="line"><span class="keyword">add_library</span> (MathFunctions <span class="variable">$&#123;DIR_LIB_SRCS&#125;</span>)</span><br></pre></td></tr></table></figure>

<p>在该文件中使用命令 <code>add_library</code> 将 src 目录中的源文件编译为静态链接库。</p>
<p>小结：在根目录和子目录都建了cmakelist，然后子目录生成链接库，根目录通过<code>target_link_libraies</code>来链接这个库，这里链接的指令可以写在生成可执行文件的命令<code>add_executable</code> 之后。</p>
<h2 id="自定义编译选项"><a href="#自定义编译选项" class="headerlink" title="自定义编译选项"></a>自定义编译选项</h2><p>CMake 允许为项目增加编译选项，从而可以根据用户的环境和需求选择最合适的编译方案。</p>
<p>例如，可以将 MathFunctions 库设为一个&#x3D;&#x3D;可选的库&#x3D;&#x3D;，如果该选项为 <code>ON</code> ，就使用该库定义的数学函数来进行运算。否则就调用标准库中的数学函数库。</p>
<h4 id="修改-CMakeLists-文件"><a href="#修改-CMakeLists-文件" class="headerlink" title="修改 CMakeLists 文件"></a>修改 CMakeLists 文件</h4><p>我们要做的第一步是在顶层的 CMakeLists.txt 文件中添加该选项：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入一个配置头文件，用于处理 CMake 对源码的设置</span></span><br><span class="line"><span class="keyword">configure_file</span> (</span><br><span class="line">  <span class="string">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/config.h.in&quot;</span></span><br><span class="line">  <span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;/config.h&quot;</span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否使用自己的 MathFunctions 库</span></span><br><span class="line"><span class="keyword">option</span> (USE_MYMATH</span><br><span class="line">       <span class="string">&quot;Use provided math implementation&quot;</span> <span class="keyword">ON</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否加入 MathFunctions 库</span></span><br><span class="line"><span class="keyword">if</span> (USE_MYMATH)</span><br><span class="line">  <span class="keyword">include_directories</span> (<span class="string">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/math&quot;</span>)</span><br><span class="line">  <span class="keyword">add_subdirectory</span> (<span class="keyword">math</span>)  </span><br><span class="line">  <span class="keyword">set</span> (EXTRA_LIBS <span class="variable">$&#123;EXTRA_LIBS&#125;</span> MathFunctions)</span><br><span class="line"><span class="keyword">endif</span> (USE_MYMATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找当前目录下的所有源文件</span></span><br><span class="line"><span class="comment"># 并将名称保存到 DIR_SRCS 变量</span></span><br><span class="line"><span class="keyword">aux_source_directory</span>(. DIR_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标</span></span><br><span class="line"><span class="keyword">add_executable</span>(Demo <span class="variable">$&#123;DIR_SRCS&#125;</span>)</span><br><span class="line"><span class="keyword">target_link_libraries</span> (Demo  <span class="variable">$&#123;EXTRA_LIBS&#125;</span>)</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ol>
<li>第7行的 <code>configure_file</code> 命令用于加入一个配置头文件 config.h ，这个文件由 CMake 从 <a href="http://config.h.in/">config.h.in</a> 生成，通过这样的机制，将可以通过预定义一些参数和变量来控制代码的生成。</li>
<li>第13行的 <code>option</code> 命令添加了一个 <code>USE_MYMATH</code> 选项，并且默认值为 <code>ON</code> 。</li>
<li>第17行根据 <code>USE_MYMATH</code> 变量的值来决定是否使用我们自己编写的 MathFunctions 库。</li>
</ol>
<h4 id="修改-main-cc-文件"><a href="#修改-main-cc-文件" class="headerlink" title="修改 main.cc 文件"></a>修改 <a href="http://main.cc/">main.cc</a> 文件</h4><p>之后修改 <a href="http://main.cc/">main.cc</a> 文件，让其根据 <code>USE_MYMATH</code> 的预定义值来决定是否调用标准库还是 MathFunctions 库：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;config.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_MYMATH</span></span><br><span class="line">  <span class="meta">#<span class="keyword">include</span> <span class="string">&quot;math/MathFunctions.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">  <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (argc &lt; <span class="number">3</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Usage: %s base exponent \n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">double</span> base = <span class="built_in">atof</span>(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="type">int</span> exponent = <span class="built_in">atoi</span>(argv[<span class="number">2</span>]);</span><br><span class="line">    </span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_MYMATH</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Now we use our own Math library. \n&quot;</span>);</span><br><span class="line">    <span class="type">double</span> result = <span class="built_in">power</span>(base, exponent);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Now we use the standard library. \n&quot;</span>);</span><br><span class="line">    <span class="type">double</span> result = <span class="built_in">pow</span>(base, exponent);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%g ^ %d is %g\n&quot;</span>, base, exponent, result);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="编写-config-h-in-文件"><a href="#编写-config-h-in-文件" class="headerlink" title="编写 config.h.in 文件"></a>编写 <a href="http://config.h.in/">config.h.in</a> 文件</h4><p>上面的程序值得注意的是第2行，这里引用了一个 config.h 文件，这个文件预定义了 <code>USE_MYMATH</code> 的值。但我们并不直接编写这个文件，为了方便从 CMakeLists.txt 中导入配置，我们编写一个 <a href="http://config.h.in/">config.h.in</a> 文件，内容如下：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment">#cmakedefine USE_MYMATH</span></span><br></pre></td></tr></table></figure>

<p>这样 CMake 会自动根据 CMakeLists 配置文件中的设置自动生成 config.h 文件。</p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>CMake</tag>
      </tags>
  </entry>
  <entry>
    <title>Code-Switching论文笔记（一）</title>
    <url>/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Code-Switching论文"><a href="#Code-Switching论文" class="headerlink" title="Code-Switching论文"></a>Code-Switching论文</h1><blockquote>
<p>&#x3D;&#x3D;Zhou, Xinyuan, et al. “Multi-encoder-decoder transformer for code-switching speech recognition.” <em>arXiv preprint arXiv:2006.10414</em> (2020).&#x3D;&#x3D;citations：15</p>
</blockquote>
<blockquote>
<p>&#x3D;&#x3D;Zhang, Shuai, et al. “Reducing language context confusion for end-to-end code-switching automatic speech recognition.” <em>arXiv preprint arXiv:2201.12155</em> (2022).&#x3D;&#x3D; citations：1</p>
</blockquote>
<blockquote>
<p>&#x3D;&#x3D;Zhang, Haobo, et al. “Monolingual Data Selection Analysis for English-Mandarin Hybrid Code-switching Speech Recognition.” <em>arXiv preprint arXiv:2006.07094</em> (2020).&#x3D;&#x3D;citations：1</p>
</blockquote>
<blockquote>
<p>&#x3D;&#x3D;Yue, Xianghu, et al. “End-to-end code-switching asr for low-resourced language pairs.” <em>2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>. IEEE, 2019.&#x3D;&#x3D;citations：17 北理工</p>
</blockquote>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><ul>
<li>We first incorporate a multi-graph decoding approach which creates parallel search spaces for each monolingual and mixed recognition tasks to maximize the utilization of the textual resources from each language. </li>
<li>用LSTM LM的中英文文本训练的LM预训练模型，做rescore</li>
<li>本文数据来源：<a href="http://corporafromtheweb.org/">http://corporafromtheweb.org</a>  ，训练RNN LM通过：<a href="https://github.com/yandex/faster-rnnlm">https://github.com/yandex/faster-rnnlm</a></li>
</ul>
<blockquote>
<p>&#x3D;&#x3D;Winata, Genta Indra, et al. “Meta-transfer learning for code-switched speech recognition.” <em>arXiv preprint arXiv:2004.14228</em> (2020).&#x3D;&#x3D; 香港科技大学 citations：26 </p>
<p>github：<a href="https://github.com/audioku/meta-transfer-learning">https://github.com/audioku/meta-transfer-learning</a>  </p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出一种新的学习方法，叫meta-transfer learning，通过明智地从高资源的单语言数据集中提取信息，在低资源设置的code-switched语音识别系统上进行迁移学习 ；</li>
<li>模型学习识别单个语言，并通过对code-switched数据进行优化来迁移它们，以便更好地识别混合语言语音。</li>
<li>code-switching asr任务的挑战：1.数据稀缺；2.难以捕获不同语言中相似的音素；</li>
<li>过去解决code-switching asr方法分为两类：<ul>
<li><ol>
<li>从单语资源生成<strong>合成</strong>语音数据；但是无法保证生成自然的语码转换语音或文本；</li>
</ol>
</li>
<li><ol start="2">
<li>用大量单语种的数据训练一个<strong>预训练模型</strong>，并利用有限的code-switched数据对模型进行<strong>微调</strong>，但是从单语种抽取得还不够，无法学到充分的知识，并且模型也会忘记之前学过的单语种任务；</li>
</ol>
</li>
</ul>
</li>
<li>meta-transfer learning 是 model  agnostic meta learning (MAML) (Finn et al., 2017)  的扩展；</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220612170404258.png" alt="image-20220612170404258" style="zoom: 80%;">









<blockquote>
<p>&#x3D;&#x3D;Indra Winata, Genta. “Multilingual Transfer Learning for Code-Switched Language and Speech Neural Modeling.” <em>arXiv e-prints</em> (2021): arXiv-2104.&#x3D;&#x3D; citations：4</p>
</blockquote>
<blockquote>
<p>&#x3D;&#x3D;Aguilar, Gustavo, and Thamar Solorio. “From English to code-switching: Transfer learning with strong morphological clues.” <em>arXiv preprint arXiv:1909.05158</em> (2019).&#x3D;&#x3D; citations：21</p>
</blockquote>
<blockquote>
<p>&#x3D;&#x3D;Bai, Junwen, et al. “Joint unsupervised and supervised training for multilingual asr.” <em>ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 2022.&#x3D;&#x3D; citations：7</p>
</blockquote>
]]></content>
      <categories>
        <category>Code-Switching</category>
      </categories>
      <tags>
        <tag>Code-Switching</tag>
      </tags>
  </entry>
  <entry>
    <title>Code-Switching论文笔记（三）中文论文</title>
    <url>/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Code-Switching中文论文"><a href="#Code-Switching中文论文" class="headerlink" title="Code-Switching中文论文"></a>Code-Switching中文论文</h1><blockquote>
<p>&#x3D;&#x3D;端到端的中英文混合语音识别声学建模算法研究_周心远.caj&#x3D;&#x3D; 2021 硕士论文 上海师范大学</p>
<p>Xinyuan  Zhou,  Grandee  Lee,  Emre  Yilmaz,  Yanhua  Long,  Jiaen  Liang  and  Haizhou  Li.  “Self-and-Mixed Attention  Decoder  with  Deep Acoustic  Structure  for  Transformer-based  LVCSR.”  in  Proc.  of  the  21st  Annual  Conference  of  the  International Speech Communication Association (INTERSPEECH). ISCA, 2020</p>
<p>Xinyuan Zhou, Emre Yilmaz, Yanhua Long, Yijie Li and Haizhou Li.  “Multi- Encoder-Decoder Transformer for Codeswitching Speech Recognition.” in Proc. of the  21st  Annual  Conference  of  the  International  Speech  Communication  Association  (INTERSPEECH). ISCA, 2020.</p>
</blockquote>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul>
<li>DNN-HMM框架的局限：<ul>
<li>常规 DNN-HMM语音识别系统是基于拼音、音标等一些声学单元建模，在不同语言之间的声学单元相互独立，且声学属性不同。通过多种不同语言的独立发音字典无法很好地建<br>模不同语言声学属性之间的联系。</li>
<li>其次由于混合语言语音的特殊性，语言转换处训练数据稀疏，DNN-HMM 系统无法有效建模两种语言相接处的声学属性。</li>
</ul>
</li>
</ul>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>提出基于 Transformer 框架和联合 CTC 训练的端到端中英文混合语音识别系统，基于字符建模；</p>
</li>
<li><p>基于 Transformer 框架提出基于自注意力与混合注意力机制的声学建模方法；</p>
</li>
<li><p>为了更好挖掘中英文两种语言之间声学上的共性和区分性，本文提出“多编码器-解码器 Transformer”结构。 </p>
</li>
<li><p>端到端模型通常基于字符建模，建模单元不再完全与声学单元一一对应，能够模糊建模单元与声学属性之间的关联，使得网络能够自动平衡不同语言语音之间的相似性与区分性；同时由于端到端模型摆脱了独立性假设，能够学习到语言切换处的声学属性。</p>
</li>
<li><p>基于 Transformer 结构，文章[70]对如何更高效地建模输入与输出关系展开 了进一步的研究。其对在 Transformer 中使用解码器在每一层都将目标序列与同 一编码器输出计算依赖这一做法提出质疑，并提出 layer-wise coordination 的思 想：即编码器与解码器之间，每层相互计算依赖，并共享编码器与解码器的参数。 通过 layer-wise coordination，网络能够学习源序列与目标序列将在底层表征时的 对齐信息；并且通过参数共享，能够确保编码器与解码器的隐状态处在同一语义 级别，还能减小模型参数量。</p>
<p>受到 Transformer 以及 layer-wise coordination 的启发，提出下图模型结构：</p>
<p>使用基于自注意力与混合注意力机制的解码器(Self-and-Mixed  Attention  Decoder,  SMAD) 以 及 深层声学结构 (Deep  Acoustic Structure, DAS)，以改进基于 Transformer 语音识别模型的声学表征提取。</p>
<p>在原始 Speech-Transformer 的解码器中，首先使用自注意力子层提取语言学的表 征。然后传至另一个 source-target 注意力子层中，与编码器输出一同计算。在每 一层解码器中，使用的是同一个编码器的输出，来学习声学表征与目标间的关系。 本章提出一种统一上述两个注意力机制的模块：自注意力与混合注意力机制 (Self-and-Mixed Attention,  SMA)，作为解码器中唯一的注意力子层。与标准 Transformer 不同，在 SMAD 的输入端，&#x3D;&#x3D;将编码器的声学表征与词向量拼接作为 输入&#x3D;&#x3D;。通过这种方式，SMA &#x3D;&#x3D;可以将输入音频的声学与语言学表征投影至同一子空间，强化声学与语言学之间的关系学习&#x3D;&#x3D;。  （原始论文里，先做了self attention才又做了mix attention，这里其实就是把attention的输入，变为encoder输出和词向量输入拼接起来，只是把输入拼接而已，然后做attention）</p>
</li>
</ul>
<h4 id="基于自注意力与混合注意力机制的-Transformer结构："><a href="#基于自注意力与混合注意力机制的-Transformer结构：" class="headerlink" title="基于自注意力与混合注意力机制的 Transformer结构："></a>基于自注意力与混合注意力机制的 Transformer结构：</h4><img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220527170358448.png" alt="image-20220527170358448" style="zoom:80%;">  

<p>query用的词向量（target），key和value是concat了词向量和encoder输出的，然后key和value乘的W矩阵是一样的，文章说是为了将声学与语言<br>学表征向量投影至同一子空间，拼接后使用同一投影矩阵𝑊；</p>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220527171643821.png" alt="image-20220527171643821" style="zoom:80%;">

<ul>
<li><p>提出深 层 声 学 结 构 (Deep  Acoustic Structure, DAS)，相比于标准 Transformer 中，每层解码器使用相同的编码器输出。<br>本章提出的&#x3D;&#x3D;解码器通过DAS，声学表征在编码器中逐层与语言学表征一同更新&#x3D;&#x3D;。</p>
<p>（就是decoder输出了一部分是来自encoder的信息，把这部分输出作为下一个decoder中的transformer的encoder信息，这和原始transformer不同）<br>该做法的目的如下：</p>
<ul>
<li>声学表征在解码器中再编码，利于进一步提取有效信息。 </li>
<li>将声学与语言学表征投影至同一子空间，利于计算其相互关系与对齐。</li>
</ul>
</li>
<li><p>第二个创新点：</p>
</li>
</ul>
<h4 id="多编码器-解码器-Transformer-的预训练机制"><a href="#多编码器-解码器-Transformer-的预训练机制" class="headerlink" title="多编码器-解码器 Transformer 的预训练机制"></a>多编码器-解码器 Transformer 的预训练机制</h4><p>背景：由于包含中英文混合的语音及文本数据稀缺，中英文混合语音识别被视为典型的低资源任务。在多语言语音识别任务中，为解决声学建模过程中的数据稀缺 问题，可以使用&#x3D;&#x3D;迁移学习  (Transfer Learning)  将预训练的高资源语言声学模 型迁移至目标低资源任务&#x3D;&#x3D;。类似地，在中英混合 ASR 中，也可以使两个预 训练的声学模型适应至资源较少的混合语言条件中。另一种策略是应用&#x3D;&#x3D;多任务学习技术&#x3D;&#x3D;，通过联合训练 ASR 声学模型和语言识别分类器，来发掘混合语言 ASR 中的语言特定属性并减轻数据稀疏性。  但在这些工作中，&#x3D;&#x3D;仅在<strong>解码器或模型的输出层</strong>中捕获了特定于语言的信息&#x3D;&#x3D;。  </p>
<p>入下图所示，结合了两个特定于语言的encoder（在图中分别用蓝色标记为英文相关，和橙 色标记为中文相关），以学习各个语言的属性。目的是通过为每种混合语言使用单独的模块来增强在每个encoder的输出处给出的声学表征向量之间的差异性。</p>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220528154657717.png" alt="image-20220528154657717" style="zoom:80%;">

<p>​	分别使用大型单语英文和中文语料库对特定语言的编码器和相应的注意力模块进行预训练</p>
<ul>
<li><p>预训练：</p>
<p>其实就是中英文分别训练，然后拼起来，就是中英文asr系统，分别训好的模型作为初始化模型</p>
</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220528155234596.png" alt="image-20220528155234596" style="zoom:80%;">

<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据集：国际公开的中英文混合语音识别数据集 SEAME，该数据集和中国人说英文（夹杂英语）不同，是新加坡人说中文夹杂英文，很多都是英语长句，比起我们说的只有夹杂一两个英语单词还不太一样；</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;基于LAS模型的中英文混杂语音识别研究_马夺.caj&#x3D;&#x3D; 西北民族大学 2020  硕士论文</p>
<p>Ma,  Duo,  Guanyu  Li,  Haihua  Xu,  and  Eng  Siong  Chng.  “Improving  code-switching  speech  recognition with data augmentation and system combination.” In 2019 Asia-Pacific Signal and  Information  Processing  Association  Annual  Summit  and  Conference  (APSIPA  ASC),  pp.  1308-1312. IEEE, 2019.</p>
</blockquote>
<h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>训练过程用了计划抽样（schedule sample）[61]：这是由于训练attention过程用的标签训练的（teacher forcing），没有用任何输出概率的预测来影响网络，但是推理时无标签，用的是预测值来作为下一个符号的输入，因此模型泛化性不好；因此用了计划抽样，前期训练用标签，后期训练抽一些预测值作为输入；</p>
<p>Samy  Bengio,  Oriol  Vinyals,  Navdeep  Jaitly,  and  Noam  Shazeer.  Scheduled  Sampling  for  Sequence  Prediction  with  Recurrent  Neural  Networks.  In  <a href="http://arxiv.org/abs/1506.03099">http://arxiv.org/abs/1506.03099</a>,  2015</p>
<p>计划抽样：具体做法是在网络训练时以一定的概率选取网络预测输出标签作为预测下一个标签的条件；</p>
</li>
<li><p>Attention：基于注意力机制的 软对齐方式实现文本层次信息和音频层次信息的对齐。</p>
</li>
<li><p>CTC：基于帧级别的严格单调对齐的连接时序分布网络，直接从语音特征转换到帧级别的标签序列，然后对帧级别的标签序列进行后处理得到文本序列。</p>
</li>
<li><p>▁表示一个空格，中文英文都用bpe建模，</p>
</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220612155642450.png" alt="image-20220612155642450" style="zoom:80%;">

<ul>
<li>要查看用子词建模的语言模型的困惑度</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220612155729885.png" alt="image-20220612155729885" style="zoom:80%;">

<ul>
<li>介绍了多种注意力机制：<ul>
<li>点乘注意力机制</li>
<li>加性注意力机制</li>
<li>位置感知注意力机制[比较好]</li>
<li>收敛的注意力机制</li>
<li>基于LSTM的位置感知注意力机制</li>
<li>基于位置感知的收敛的注意力机制</li>
<li>加性的多头注意力机制</li>
</ul>
</li>
</ul>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据集：国际公开的中英文混合语音识别数据集 SEAME；</li>
<li>模型变大时，梯度累加策略也要加大，多累计几步再更新！这个比较重要，不然可能负优化；</li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul>
<li>调参：</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220612163555584.png" alt="image-20220612163555584" style="zoom:80%;">

<ul>
<li>SEAME 的两个测试集上，词错误率（WER）分别为 24.4%和 17.6%；</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220612163522103.png" alt="image-20220612163522103" style="zoom:80%;">

<hr>
<blockquote>
<p>&#x3D;&#x3D;中英文混合语音识别数据选择与数据增广方法研究_张皓博.caj&#x3D;&#x3D; 新疆大学 硕士论文 2021</p>
<p>Monolingual Data Selection Analysis for English-Mandarin Hybrid Code-Switching Speech Recognition</p>
</blockquote>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><h4 id="声学模型："><a href="#声学模型：" class="headerlink" title="声学模型："></a>声学模型：</h4><ul>
<li><p>数据增广可以增加语音识别模型的鲁棒性，但是<strong>语料的内容</strong>并没有进行相应的扩充，因此在准确度上的收益并不明显。 </p>
</li>
<li><p>最近几年，出现了使用语音<strong>合成</strong>作为语音识别的一种数据增广方式[49] [50] [51] [52]；其中包含了将合成的语音加入训练集的方式，还有使用语音识别、语音合成模型联合训练。</p>
<p>用中英文混合的语音<strong>合成</strong>系统为中英混合语音识别做数据增广；阿里巴巴使用跨语种语音转换（Cross-lingual Voice Conversion）的方式构建了中英文混杂语音识别系统[96]；</p>
<p>（之前雷博说不可行，因为合成的音是确定的，没有上下文信息，那么现在用一个声学模型部分已经挺好的识别模型，再用合成数据，能否改善语言模型那部分（decoder）），感觉是可能可行的，虽然没有改善声学模型，但是改善了语言模型decoder部分？。</p>
</li>
<li><p>使用中文、英文数据训练一个预训练模型， 利用迁移学习的方式[ 55]，构建中英文混杂语音识别系统。当任务中成对的有标签 数据较少，而无标签数据较多时，还可以使用半监督学习构建中英文混杂语音识别 系统[56]。</p>
</li>
</ul>
<h4 id="语言模型："><a href="#语言模型：" class="headerlink" title="语言模型："></a>语言模型：</h4><ul>
<li>在构建语言模型时，我们可以通过<strong>互联网获取任务相关的文本</strong>。语言模型的构建也可以使用<strong>数据增广</strong>的方式[ 57] [58]，还可以通过<strong>一定的策略生成更多中英文混合的文本</strong>，为大词汇量中英文混杂语音识别构建词汇量充足的中英文混杂的语言模型。例如可以<strong>利用 BERT 模型、或是生成对抗神经网络（GAN）进行文本生成</strong>[ 59] [60]，生成的文本可以构建更大的语言模型，也可以指定领域高频话题语料，来生成特定任务上的语言模型。 </li>
<li>一般使用神经网络语言模型来提升语音识别的准确率还需要第二步重打分（Rescore）操作，即在解码器解码出的最有可能的一组结果中，利用神经网络语言模型，对每个结果重打分，选取最优可能的结果；通常重打分的操作<strong>可以在 Lattice 上进行，也可以在 N-best 的结果上进行</strong>，但是<strong>在 Lattice 上解码的结果通常要好于 N-best，因为 Lattice 可以表示更大的假设空间</strong>。 </li>
<li>也有人尝试<strong>不使用重打分的方式让识别过程分两个阶段，他们提出更高效的方式尝试在解码时就使用神经网络语言模</strong>型[84] [85] [86] [87] [88]。</li>
</ul>
<h4 id="解码器："><a href="#解码器：" class="headerlink" title="解码器："></a>解码器：</h4><ul>
<li>为中英文混杂模型构建解码器时，可以将原来单语的解码器中，为那些常发生 翻译替换的中文词添加英文标签，从而来构建混合语音识别的解码器[ 61]。另外，基 于 n-gram 的语言模型，相较于神经网络的语言模型来说，建模能力相对较弱。使 用 RNNLM（Recurrent Neural Network Language Model）构建语音识别的语言模型， 对混合语音识别系统的 n-best 识别结果进行重打分，性能有明显提升[62]；</li>
</ul>
<h4 id="词典"><a href="#词典" class="headerlink" title="词典"></a>词典</h4><ul>
<li>英文：2019 年 Facebook 提出有效的方案，可以让英文词典可直接通过上下文相关的英文字母加边界标记来表示每个词的发音，以此作为声学模型的建模单元[92]；每个字母的开头和结尾使用词边界标志 WB（Word Boundary）标记，大写保持，单词中的部分符号保持。 <ul>
<li>但英文数据很少时（在中英混里占的比例很少），该方法还不如只用音素建模的识别系统！！[该方法会略微变差]</li>
</ul>
</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220605160510235.png" alt="image-20220605160510235" style="zoom:80%;">

<h4 id="端到端混合语音识别系统：TODO（感觉不错，可以好好看看）"><a href="#端到端混合语音识别系统：TODO（感觉不错，可以好好看看）" class="headerlink" title="端到端混合语音识别系统：TODO（感觉不错，可以好好看看）"></a>端到端混合语音识别系统：TODO（感觉不错，可以好好看看）</h4><ul>
<li>中英文混杂的端到端语音识别系统也不断被提出[63] [64] [65] [66]。</li>
<li>（1）数据增广：由于混杂数据相较于纯中文、纯英文 数据较少，训练过程中非常容易过拟合，需要进行数据增广、数据生成的方式防止 模型过拟合，同时提升模型的鲁棒性。因此，数据增广对于中英文混合的端到端语 音识别也是至关重要的[ 67][68]。</li>
<li>（2）语言模型：端到端模型需要大量有标签数据，可 以训练独立的语言模型，然后对端到端模型进行融合，以达到学习足够的文本规则。 但是语言模型的融合、重打分对模型性能地提升还不算高效。</li>
<li>（3）基于深度学习的 端到端模型灵活复杂，相较于传统语音识别，融合多任务学习也能够提升模型性能。例如中英文混杂识别联合语种识别[69] [70] [71]、口音识别 [72] [70] [73]、说话人识别 [74]等都 提出了不同的多任务 ASR 模型。</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul>
<li>HMM-TDNN-F ，chain model</li>
</ul>
<h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据：数据堂ASRU 2019比赛，200小时中英混+500小时中文；</li>
<li>发音词典： 210 个普通话音素，以及 42 个英文音素，两个音素集不存在共用音素；<ul>
<li>改进：发现数据堂的发音词典里面中文部分有很多标注错误的？因此从网上爬取发音，重新做了词典；</li>
<li>改进：中文重新从网上爬；英文用facebook的上下文相关的音素建模，不是用的上下文无关的音素；【但是效果会变差！】</li>
<li>改进：由于比赛给定了语言模型，因此按语言模型的词语，重新对文本进行分词（之前是jieba分词），这个效果挺显著；【发音词典和语言模型若更加匹配，就能构建更优的图网络】</li>
</ul>
</li>
<li>添加中文数据对系统的影响：<ul>
<li><ol>
<li>使用更多的普通话数据，识别结果的中文部分有明显的改善；识别性能的提升主要来自单个英语单词的语句，从这个角度看来，是符合数据匹配猜测的；（数据中只有一个&#x2F;两个英文的文本居多）</li>
</ol>
</li>
<li><ol start="2">
<li>更多的普通话数据不会明显影响英语部分的识别；对于那些包含更多英文单词的语句，添加中文单语数据对性能的提升作用有限，甚至是负面影响</li>
</ol>
</li>
<li><ol start="3">
<li>当添加中文数据超过某个点时，可能会伤害整体的性能，测试集上使用大约 400 小时的普通话数据时，可以获得最佳性能</li>
</ol>
</li>
<li>结果的改善归因于 Man500 数据集合 CS200 数据集在中文方面的紧密的相似性；</li>
</ul>
</li>
<li>数据匹配很关键；</li>
</ul>
<h4 id="基于语音转换（VC）的方法进行数据增广："><a href="#基于语音转换（VC）的方法进行数据增广：" class="headerlink" title="基于语音转换（VC）的方法进行数据增广："></a>基于语音转换（VC）的方法进行数据增广：</h4><ul>
<li>合成只有单个音色，单个说话人，用语音转换的方法扩充不同说话人，就相当于给识别做数据增广；</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220605163659641.png" alt="image-20220605163659641" style="zoom:80%;">

<ul>
<li>Tacotron2-VC 多说话人语音转换系统</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220605163721340.png" alt="image-20220605163721340" style="zoom:80%;">







<hr>
<blockquote>
<p>&#x3D;&#x3D;基于中英文混合模型的语音识别研究&#x3D;&#x3D; 李伟 语音技术 中国电子科技集团公司 第四十三研究所 2011</p>
</blockquote>
<p>太早的论文了，没什么参考价值；</p>
<h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><ul>
<li><p>根据发音学的一些先验知识，提出一种基于主元音及英文音素序列混合的声学模型</p>
<p>就是把中文和英文的音素混在一起，并且做了一些合并的操作；</p>
<p>中文的主元音大概有 40 多个，加上英文的 40多个音素，一共 80 多个音素；</p>
<p>考虑到汉语的声调问题，主元音的音素扩展到 98 个，例如 a 的发音，扩展成a1，a2，a3，a4；</p>
<p>辅音（21 个）都是无调的，不做扩展。</p>
<p>考虑到中文和英文的音素有些发音相同，就把这些音素合并到一起，例如 b，p 等。最终得到的音素个数为126 个；</p>
</li>
</ul>
<img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220605164650257.png" alt="image-20220605164650257" style="zoom:80%;">

<h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h3><ul>
<li>比起纯中文和纯英文模型，准确度下降各自从80%下降到70%，但是中英混合从40%上升到70%</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;论网络流行语中中英文混合语的语码转换现象&#x3D;&#x3D; 程迎新 渤海大学 2015 六盘水师范学院学报</p>
</blockquote>
]]></content>
      <categories>
        <category>Code-Switching</category>
      </categories>
      <tags>
        <tag>Code-Switching</tag>
      </tags>
  </entry>
  <entry>
    <title>各个cpp代码之间关系的软件</title>
    <url>/2023/02/20/C++/%E7%94%BB%E5%90%84%E4%B8%AAcpp%E4%BB%A3%E7%A0%81%E4%B9%8B%E9%97%B4%E5%85%B3%E7%B3%BB%E7%9A%84%E8%BD%AF%E4%BB%B6/</url>
    <content><![CDATA[<h1 id="画各个cpp代码之间关系的软件"><a href="#画各个cpp代码之间关系的软件" class="headerlink" title="画各个cpp代码之间关系的软件"></a>画各个cpp代码之间关系的软件</h1><h2 id="Doxygen"><a href="#Doxygen" class="headerlink" title="Doxygen"></a>Doxygen</h2><blockquote>
<p>官方：<a href="https://www.doxygen.nl/manual/index.html">https://www.doxygen.nl/manual/index.html</a></p>
<p><a href="https://blog.csdn.net/play_fun_tech/article/details/22145943">使用doxygen和graphviz来产生源代码函数调用图</a></p>
</blockquote>
<p>这个软件可以用来画出代码函数的调用关系图。</p>
<p>我下载的是windows版本的doxygen（<a href="https://www.doxygen.nl/files/doxygen-1.9.6-setup.exe">doxygen-1.9.6-setup.exe</a>），安装；还要下载和安装graphviz：（ <a href="http://www.graphviz.org/%EF%BC%89%E3%80%82">http://www.graphviz.org/）。</a></p>
<p>打开doxywizard，选左边菜单栏的wizard，然后填写这几项：</p>
<img src="/2023/02/20/C++/%E7%94%BB%E5%90%84%E4%B8%AAcpp%E4%BB%A3%E7%A0%81%E4%B9%8B%E9%97%B4%E5%85%B3%E7%B3%BB%E7%9A%84%E8%BD%AF%E4%BB%B6/image-20230220094151556.png" alt="image-20230220094151556" style="zoom: 80%;">

<p>wizard选项卡中，选择Project Name作为工程名称，将来会显示在文档的标题中；选择Source code directory，设置源代码所在目录，Destination directory设置文档的生成目录；选择Scan recursively则递归分析源代码目录中的子目录内的源代码。</p>
<p>点左边菜单栏的expert，点build，勾选这几项：</p>
<img src="/2023/02/20/C++/%E7%94%BB%E5%90%84%E4%B8%AAcpp%E4%BB%A3%E7%A0%81%E4%B9%8B%E9%97%B4%E5%85%B3%E7%B3%BB%E7%9A%84%E8%BD%AF%E4%BB%B6/image-20230220094613290.png" alt="image-20230220094613290" style="zoom:67%;">

<p>勾选Build选项中的与函数有关的选项，EXTRACT_ALL必须勾选。</p>
<p>再点菜单栏的dot，填写这几项：</p>
<img src="/2023/02/20/C++/%E7%94%BB%E5%90%84%E4%B8%AAcpp%E4%BB%A3%E7%A0%81%E4%B9%8B%E9%97%B4%E5%85%B3%E7%B3%BB%E7%9A%84%E8%BD%AF%E4%BB%B6/image-20230220171150550.png" alt="image-20230220171150550" style="zoom:80%;">

<p>由于使用到了Graphviz，所以要设置Dot选项，勾选HAVE_DOT，并设置DOT_PATH为Graphviz的bin目录。勾选CALL_GRAPH和CALLER_GRAPH，生成函数调用关系图。</p>
<img src="/2023/02/20/C++/%E7%94%BB%E5%90%84%E4%B8%AAcpp%E4%BB%A3%E7%A0%81%E4%B9%8B%E9%97%B4%E5%85%B3%E7%B3%BB%E7%9A%84%E8%BD%AF%E4%BB%B6/image-20230220171311527.png" alt="image-20230220171311527" style="zoom:80%;">

<p>最后选择Run选项卡，点击Run doxygen，生成文档文件。</p>
<p>打开文档文件，在函数的分析中即可看到函数调用图。</p>
<p>比如我其中一个例子的路径是：<code>K:/c_practice/doxygen_test_2/output/html/index.html</code> 点开，就能在浏览器看见关系图</p>
<p>比如我要看的代码是 <code>wenet_api.cc</code>，可以看见它的结构是：</p>
<img src="/2023/02/20/C++/%E7%94%BB%E5%90%84%E4%B8%AAcpp%E4%BB%A3%E7%A0%81%E4%B9%8B%E9%97%B4%E5%85%B3%E7%B3%BB%E7%9A%84%E8%BD%AF%E4%BB%B6/image-20230220095834547.png" alt="image-20230220095834547" style="zoom:80%;">

<p>里面定义了一个类叫recognizer，定义了一些函数。</p>
<p>recognizer类里有一个函数decode()，下图表示它里头调用了函数，分别是recognizer::initdecoder()和recognizer::updateresult()；它被wenet_decode函数调用了。</p>
<img src="/2023/02/20/C++/%E7%94%BB%E5%90%84%E4%B8%AAcpp%E4%BB%A3%E7%A0%81%E4%B9%8B%E9%97%B4%E5%85%B3%E7%B3%BB%E7%9A%84%E8%BD%AF%E4%BB%B6/image-20230220100944383.png" alt="image-20230220100944383" style="zoom:80%;">







<h2 id="各个软件"><a href="#各个软件" class="headerlink" title="各个软件"></a>各个软件</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>有很多软件可以帮助您绘制各个C++代码之间的关系，以下是其中一些常见的：</p>
<ol>
<li>Visual Studio：Visual Studio是一个非常强大的IDE，其中包括UML建模工具，可以帮助您绘制各个C++代码之间的关系。</li>
<li>Doxygen：Doxygen是一种工具，可以生成代码文档，并在文档中包含各个C++代码之间的关系图。</li>
<li>Code Visual to Flowchart：Code Visual to Flowchart是一种可帮助您将C++代码转换为流程图和UML图的工具。</li>
<li>Dia：Dia是一种开源绘图工具，可以用于创建各种类型的图表，包括UML图，可以用于绘制各个C++代码之间的关系。</li>
<li>Microsoft Visio：Microsoft Visio是一种专业的绘图软件，可以用于创建各种类型的图表，包括UML图，可以用于绘制各个C++代码之间的关系。</li>
</ol>
<p>这些工具都有其自身的优缺点和使用限制，具体选择应该根据您的需求和偏好来决定。</p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>TLG经验</title>
    <url>/2022/06/27/Code-Switching/TLG%E7%BB%8F%E9%AA%8C/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://maimai.cn/article/detail?fid=1659073660&efid=4p-KICL3zTDXOdfF3cePXA">京东：基于WeNet的端到端语音识别优化方案与落地</a></p>
</blockquote>
<ol>
<li>在TLG解码时，适当调大acoustic-scale，来保证am分数和lm分数在同一个量级上，可以使生成的Nbest更加准确，效果较好；</li>
<li>由于CTC spike的稀疏性，如果blank_skip_thresh太大，会降低解码速度，并造成漏字等删除错误，所以可以适当调小blank_skip_thresh，能够在rtf变化较小的情况下，明显降低短音频删除错误，提高识别准确率；</li>
<li>得到Nbest后，在AttentionRescore中除了原有的分数外，同时加入ngram的分数，相比不加ngram分数cer绝对值也能降低0.5%左右（就是在attention decoder计算路径得分时也进行加G分数）</li>
</ol>
<p>在开源 WeNet 的基础上，我们还针对服务的内外客户的业务场景继续了大量优化措施的探索，分别考虑了声学模型和语言模型的优化，在大多数的场景中也都取得了一致性的优化效果：</p>
<ol>
<li>在TLG解码时，适当调大acoustic-scale，来保证am分数和lm分数在同一个量级上，可以使生成的Nbest更加准确，效果较好</li>
<li>由于CTC spike的稀疏性，如果blank_skip_thresh太小，会降低解码速度，并造成漏字等删除错误，所以可以适当调大blank_skip_thresh，能够在rtf变化较小的情况下，明显降低短音频删除错误，提高识别准确率</li>
<li>得到Nbest后，在AttentionRescore中除了原有的分数外，同时加入ngram的分数，相比不加ngram分数cer绝对值也能降低0.5%左右</li>
<li>runtime引擎中增加在线resample功能，可用一套模型处理不同采样率的音频请求，考虑到目前官方实现的使用的是sox的方案，我们更倾向于kaldi中使用的resample方法，这样训练和推理使用同样的方法会避免对CER的扰动</li>
<li>在大量语音使用场景中都专有名词的识别问题，端到端系统大多都采用TTS来合成语音数据，帮助为ASR来训练，有非常明显的识别效果</li>
<li>数据增强在生产系统中特别重要，能大大提高业务场景识别的鲁棒性，我们在数据处理阶段使用on-the-fly来模拟信道的方案对电话场景识别的帮助较为明显</li>
<li>与TLG并行加入动态语言模型的方案，该方案为我们基于原有kaldi系统开发，同时取得不错的场景名词优化效果</li>
</ol>
<p>在工业系统中，RTF和Latency是在线方案中非常重要的指标，为了上线我们也实验了大量的方法，将有效果的方案列出来供大家参考：</p>
<ol>
<li>将LM大小裁剪为原来一半大小，构图为TLG后RTF可相对降低30%左右，cer在合理范围内小幅上升（通常小于0.1%）</li>
<li>将TLG转为ConstFst后，RTF可相对降低10%左右，同时单进程内存占用降低50%左右，使得低资源的环境的部署成为可能</li>
<li>增加min_active选项，通过控制使用TLG解码时活跃token的数目，RTF带来成倍的降低</li>
<li>使用TCMalloc做内存管理，优化内存使用，降低RTF</li>
<li>除TorchScript模型外，同样我们结合ESPnet中的ONNX集成和借鉴<a href="https://maimai.cn/n/online/link?target=https://mp.weixin.qq.com/s?__biz=MzU2NjUwMTgxOQ==&mid=2247484139&idx=1&sn=0018045eff55fee866045c42b6af0351&scene=21%23wechat_redirect">作业帮</a>使用ONNX的经验进行引擎推理优化，并开源了该方案ONNX模型的导出，从而在runtime中获得更优的推理速度，RTF降低大约25%</li>
</ol>
]]></content>
      <categories>
        <category>Code-Switching</category>
      </categories>
      <tags>
        <tag>Code-Switching</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第9章 WFST解码器————Lattice解码</title>
    <url>/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h1 id="Lattice解码用到的数据结构"><a href="#Lattice解码用到的数据结构" class="headerlink" title="Lattice解码用到的数据结构"></a>Lattice解码用到的数据结构</h1><blockquote>
<p>《语音识别原理与应用》 洪青阳 P185</p>
<p>LatticeSimpleDecoder </p>
<p>lattice-faster-decoder</p>
</blockquote>
<p>哈希表 HashList&lt;StateId, Token*&gt; 建立状态节点stateid和token之间的映射关系。</p>
<p>链表：token之间用链表连接，以便解码结束时跟踪到更多的匹配路径。前向链接ForwardLink，令牌列表TokenList</p>
<p>在语音识别中，经常用 Lattice 来保存多种候选的识别结果（单个回溯是不够的），以便后续进行其地处理（如二次解码)。针对有Latice的解码，需要保存多条搜索路径，包括中同遍历的多条路径信息，因此 Token 之间还需要有链表息，以便解码结束时跟踪到更多的匹配路径。</p>
<p>参照 Kaldi 的lattice-faster-decoder 写法，我们给出用于 Lattice 解码的 Token和相关的数据结构定义，包括前向链接 ForwardLink 和令牌列表 TokenList。</p>
<p>ForwardLink 与在快速解码部分定义的转移弧 Arc 不同，它用来链接前后两帧之间的发射转移弧之间的Token，或同一时刻非发射转移弧之间的 Token,ForvardLink 保存的图代价和声学代价更方便后续的 Lattice 剪枝处理。</p>
<p>TokenList 用来和帧索引建立关联，<strong>每帧对应一个 TokenList</strong>，这样能保证随时访自已解码过的任一时刻创建的 Token 列表，而在快速解码部分（之前的那种解码）定义的 Token 和Arc信息则无法关联时间戳信息，只能利用它们做简单的回溯处理。</p>
<h2 id="ForwardLink"><a href="#ForwardLink" class="headerlink" title="ForwardLink"></a>ForwardLink</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ForwardLink</span> &#123;</span><br><span class="line">	Token *next_tok;<span class="comment">//链接传到的 roken</span></span><br><span class="line">	<span class="type">int</span> ilabei; <span class="comment">//转移弧的输人标签</span></span><br><span class="line">    <span class="type">int</span> olabel; <span class="comment">//转移弧的输出标签</span></span><br><span class="line">	<span class="type">float</span> graph_ cost; <span class="comment">//遍历图代价（包含语言模型得分）</span></span><br><span class="line">	<span class="type">float</span> acoustic cost; <span class="comment">//声学代价</span></span><br><span class="line">	ForwardLink *next;	<span class="comment">//指向同一时刻的下一个链接</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Token"><a href="#Token" class="headerlink" title="Token"></a>Token</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Token</span> &#123;</span><br><span class="line">	<span class="type">float</span> tot_cost; <span class="comment">//累计的最优代价（包括语言模型和声学代价）</span></span><br><span class="line">	<span class="type">float</span> extra_cost; <span class="comment">//所有Forwardlink 中与最优路径代价的最小差值</span></span><br><span class="line">	Forwardtink *links; <span class="comment">// 前向链接，指向新创建的 Token，用于 Lattice 生成</span></span><br><span class="line">	Token *next;		<span class="comment">//指向同一时刻的下一个 Token</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h2 id="TokenList"><a href="#TokenList" class="headerlink" title="TokenList"></a>TokenList</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">TokenList</span> &#123;</span><br><span class="line">	Token *toks; <span class="comment">//指向同一时刻的第一个 Token</span></span><br><span class="line">	<span class="type">bool</span> must_ prune forward_ links; <span class="comment">//用于剪枝，默认为true</span></span><br><span class="line">	<span class="type">bool</span> must_prune_ tokens：<span class="comment">//用于剪枝，默认为 tzue</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<h1 id="令牌传播过程"><a href="#令牌传播过程" class="headerlink" title="令牌传播过程"></a>令牌传播过程</h1><p>在进行 Lattice 解码时，从输人语音提取声学特征（T 帧），然后通过令牌(Token）传播，逐帧处理。首先在 WFST 的起始节点，产生一个 Token；然后针对每个活跃节点，把 Token 传播到与该节点相连的转移弧；如果转移弧的输人标签不是 0，则把激活的 Token 对应的帧数加 1，相当于移动到下一帧，实现帧与转移弧（即 HMM 状态的 transition-id）的对齐。</p>
<p>每个 Token 都记录了累计总代价，即之前最优代价加上转移弧对应的图代价<strong>graph_cost（包含语言模型、转移概率、发音词典三部分的代价）</strong>和声学代价acoustic_cost，其中<strong>acoustic_cost 是根据声学特征和声学模型实时计算得出后验概率，然后取反得出的</strong>，因此原始后验概率越高，acoustic_cost 代价越小。</p>
<p>由于解码图庞大，因此 Token 的传播可能会有多条路径，对应t时刻的帧会有多个Token。这些 Token 通过 WFST 解码图的节点标号 StateID区分，即通过t和 StateID可以找到唯一的 Token。</p>
<p>如下图所示，同一时刻的 Token 被汇总到一个 TokenList 保存，T帧则有T个TokenList 来保存，因此 <strong>TokenList构成一个数组</strong>，其中 <strong>数组元素索引与帧索引一一对应</strong>。单个TokenList 元素里面可能包含多个Token，即同一帧对应多个 Token,如第1帧特征 $o_t$,对应 Token 集合 TokenList[1]，由初始状态0转移产生，其包含 4个Token，标为 Token8、Token1、Token9 和 Token2，分别与状态节点8、1、9、2关联，每个Token 都有累计代价cost。其中，<strong>Token2 是状态节点9经非发射转移弧到达状态节点2产生的，注意，其仍然属于第1帧，因此在 Token9 和 Token2之间产生的 ForwardLink 属于同一帧不同 Token 之间的链接</strong>。第2帧、第3帧及后续帧的解码过程依此类推。</p>
<p>WFST 的 Lattice 解码图：</p>
<p>第一帧：</p>
<img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112174327147.png" alt="image-20230112174327147">



<p>第二帧：</p>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112174345697.png" alt="image-20230112174345697"></p>
<p>第三帧：</p>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112174403847.png" alt="image-20230112174403847"></p>
<p>Lattice 解码会保存不同时刻的 TokenList。 如下图所示，每个 TokenList包含同一时刻的多个Token，TokenList 指向第一个 Token，如 TokenList[1]先指向Token8，然后通过 Token8 的next 指针再链接到同一时刻产生的 Token1，依此类推。其中 Token2 由 Token9 通过非发射较移孤产生，因此同时有 ForwardLink 关联。</p>
<p>带Lattice解码的令牌传递过程：</p>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112174420361.png" alt="image-20230112174420361"></p>
<p>在下一时刻即第2帧，TokenList[1]]包含的 Token1被传播到 TokenList[2J的Token6 和 Token10，并通过 ForwardLink 保存链接信息，如 Token1 和 Token6之间有一条 Forwardlink，该链接保存了两个 Token 对应状态节点（即 1和6）之间的转移弧输入标签和输出标签，同时还有该转移弧对应的图代价和针对第2帧的声学得分。Token2 由于是Token10 在同一帧通过 PrOcessNonemitting 产生的，因此它们之间有 ForwardLink 链接。</p>
<p>在第3帧，TokenList[2]的 Token6 被进一步传播到 TokenList[3]的 Token3、Token7 和 Token9， Token10 传播到 Token2， Token2 传播到 Token3 和 Token1,Token3传播到 Token11 和 Token4。注意，TokenList[3]中的 Token3 同时来自TokenList[2]的 Token6 和Token2，此时只会保存 cost 最小的那个Token。</p>
<p>整个 HCLG 编译的 WFST 是庞大的网络，随着帧数的推进，其他 Token 也可扩张到更多的 Token，同时通过 ForwardLink 建立链接关系。一直到最后一帧结束，才停止 Token 的扩张，此时再从 TokenList 寻求最佳路径对应的最后一个Token。如果指定最优结尾 Token, 一定要从 HCLG 的结尾状态（双圆圈）中选择，对比所有结尾状态对应 Token 的cost，选择值最低的，然后从该 Token 倒推得到最优路径对应的转移弧序列。</p>
<h1 id="剪枝策略"><a href="#剪枝策略" class="headerlink" title="剪枝策略"></a>剪枝策略</h1><p>随着 Token 的扩张，每一帧可能对应很多个 Token，这样会导致解码变慢。为加快解码速度，需要采用剪枝策略，即事先设定一个剪枝阈值 （ beam），然后针对每一帧动态调整剪枝上限。剪枝的具体步骤如下：</p>
<ol>
<li><p>在解码过程中，针对<strong>当前帧找出最低代价（best_cost）的 Token</strong>，即最优的 Token，根据该 Token 设定剪枝上限（cur_cost），其值为 best_cost+beam。同时对该Token 进行后续一帧的扩张，计算每个转移弧新的 cost，结合 beam 阈值得到后续扩张的剪枝上限(next_cost)。</p>
</li>
<li><p>第一轮。对同一帧所有Token 做一次剪枝，抑制一批代价超过 cur_cost 的Token，即这批Token 不再扩张，如下图所示的 Token9。</p>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112181949416.png" alt="image-20230112181949416"></p>
</li>
<li><p>第二轮。对当前帧除了最优 Token 之外的其他 Token，也对后续的转移弧计算更新的cost，如果超过扩张剪枝上限next_cost，则该转移弧不再扩张。如下图所示，Token7到Token3的转移弧被剪枝，实际上是不生成Token3。</p>
</li>
</ol>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112181957182.png" alt="image-20230112181957182"></p>
<p>除了默认剪枝阈值 beam，还可设定最大活跃节点数 max_active。对 Token按cost 排序后只保留max active 个有效节点，对应的剪枝國值为 adaptive_beam。</p>
<p>WFST 中的每个状态节点和一个Token 对应，后面不同时刻的特征帧也可能对齐到该状态，即对应到相同的 Token。此时需要比较 cost 值，如果新 Token 的cost 值更低，则替换原有 Token。</p>
<p>以上是通用的剪枝策略，其也适用于上一节的快速解码。对于 Lattice 解码，还可间隔多帧（如25 帧）再做一次基于 ForwardLink 的 Lattice 剪枝。根据每帧TokenList 访问并算出每一条 ForwardLink 和最优路径的cost 差异，如果差值超过Lattice 剪枝阈值就剪掉该 ForwardLink。</p>
<h1 id="Lattice"><a href="#Lattice" class="headerlink" title="Lattice"></a>Lattice</h1><p>语音识别中，Lattice用来保存多种候选结果，每个节点可对应到具体的时间（帧索引），节点之间的弧包含了候选词信息。HTK用Standard Lattice Format（SLF）保存Lattice，而Kaldi则用FST形式保存，但也可转化成SLF形式。</p>
<p>Kaldi Lattice是在解码后，通过每个时刻的TokenList包含的Token和与之关联的ForwardLink遍历生成，并用转移弧Arc保存路径信息。具体实现可查看decoder的GetRawLattice函数。</p>
<p>Lattice的基础结构可以表示为{input, output, weight}，即Lattice包括输入、输出和权重。Lattice每条弧上的状态输入为transition-id，状态输出为words，其中权重weight包含两个值，即图代价（graph_cost）和声学代价（acoustic_cost）。可从ForwardLink参数获取这两个值。</p>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112182717450.png" alt="image-20230112182717450"></p>
<p>Lattice有多条路径，按最后的cost排序，最小的排在前面，即可从Lattice得到最优路径。注意最优路径也可在解码结束时直接获取，无需经过Lattice。</p>
<p>最优路径只包含一个结果，如图所示，即识别结果为“实现数字化整合营销”。</p>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112182813944.png" alt="image-20230112182813944"></p>
<p>如果要保留多个识别结果，则可采用 lattice-nbest 进行转换，将N条弧从起始状态传播到结尾状态，得到N个最好的不同单词序列。</p>
<p>利用得到的 Latice 还可进行二次解码，引人更复杂的语言模型，如递归神经网络语言模型，更新 Lattice 中路径上的得分（注意不能简单替换图代价，因为还有词典和转移概率），得到更优的识别结果。</p>
<p>如果想查看不同输出级别的 Lattice 信息，也可以将词级别的 Lattice 转换成音素级别的 Lattice，但这一步操作会耗费比较多的时间，尤其是在人声嘈杂环境下的识别。</p>
<p>也可将 Lattice 保存成紧凑形式的CompactLattice（本质上是一种 WFSA)，每条弧的输人和输出都是words，它把可能的输人标签序列 transition-ids 全部放在了权重里面，即权重信息包括 {graph_ cost, acoustic_cost, transition-ids sequence}。 Latice 和 CompactLattice 两者结构稍有不同，如下表所示，但这两者包含了相同的内容，因此可以互相转换。<br><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/Lattice%E8%A7%A3%E7%A0%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20230112183229403.png" alt="image-20230112183229403"></p>
]]></content>
      <categories>
        <category>WFST解码</category>
      </categories>
      <tags>
        <tag>WFST解码</tag>
        <tag>《语音识别原理与应用》</tag>
      </tags>
  </entry>
  <entry>
    <title>TLG（九）</title>
    <url>/2022/06/27/Code-Switching/TLG%EF%BC%88%E4%B9%9D%EF%BC%89/</url>
    <content><![CDATA[<h4 id="训练ngram-G"><a href="#训练ngram-G" class="headerlink" title="训练ngram G"></a>训练ngram G</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">训练LM</span></span><br><span class="line">langname=ngram_7g_train_en_zh_hua_lexicon_word</span><br><span class="line">local/train_lms_1gram.sh $langname/lexicon.1 $langname/text_split.biglettle $langname/lm_part_en5</span><br></pre></td></tr></table></figure>



<h4 id="生成-TLG种的-Lexicon-txt："><a href="#生成-TLG种的-Lexicon-txt：" class="headerlink" title="生成 TLG种的 Lexicon.txt："></a>生成 TLG种的 Lexicon.txt：</h4><blockquote>
<p>&#x2F;home&#x2F;yelong&#x2F;data&#x2F;wenet&#x2F;examples&#x2F;aishell&#x2F;s0</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成lexicon.txt：</span></span><br><span class="line">dict=exp/aban-c009/lang.char.txt</span><br><span class="line">bpe_model=exp/aban-c009/bpe.model</span><br><span class="line"></span><br><span class="line">unit_file=$dict</span><br><span class="line">langname=ngram_7g_train_en_zh_hua_lexicon_word</span><br><span class="line">mkdir -p data/local/dict_aban-c009_$langname</span><br><span class="line">cp $unit_file data/local/dict_aban-c009_$langname/units.txt</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">把text_split.biglettle词频大于80的，放进词典，和声学的建模单元放一块，得到lexicon.1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去除声学词典里没有的OOV，中文拆成空格区分，英文bpe</span></span><br><span class="line">python split_sentence_oov.py data/local/dict_aban-c009_$langname/units.txt /home/yelong/data/kaldi/egs/librispeech/s5/$&#123;langname&#125;/lexicon.1 &gt; data/local/dict_aban-c009_$&#123;langname&#125;/lexicon.txt.nosplit</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">PS 等拆分为 ▁P ▁S</span></span><br><span class="line">python split_lexicon.py data/local/dict_aban-c009_$&#123;langname&#125;/lexicon.txt.nosplit &gt; data/local/dict_aban-c009_$&#123;langname&#125;/lexicon.txt</span><br><span class="line">c</span><br></pre></td></tr></table></figure>



<p>用新的词典，对文本</p>
<p>其中，split_sentence_oov.py为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sp = spm.SentencePieceProcessor()</span><br><span class="line">sp.load(<span class="string">&quot;/home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/bpe.model&quot;</span>)</span><br><span class="line"></span><br><span class="line">unit_table = <span class="built_in">set</span>()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(sys.argv[<span class="number">1</span>], <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> fin:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">        unit = line.split()[<span class="number">0</span>]</span><br><span class="line">        unit_table.add(unit)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">contain_oov</span>(<span class="params">units</span>):</span><br><span class="line">    <span class="keyword">for</span> unit <span class="keyword">in</span> units:</span><br><span class="line">        <span class="keyword">if</span> unit <span class="keyword">not</span> <span class="keyword">in</span> unit_table:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__tokenize_by_bpe_model</span>(<span class="params">txt</span>):</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="comment"># CJK(China Japan Korea) unicode range is [U+4E00, U+9FFF], ref:</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fff])&#x27;</span>)</span><br><span class="line">    <span class="comment"># Example:</span></span><br><span class="line">    <span class="comment">#   txt   = &quot;你好 ITS&#x27;S OKAY 的&quot;</span></span><br><span class="line">    <span class="comment">#   chars = [&quot;你&quot;, &quot;好&quot;, &quot; ITS&#x27;S OKAY &quot;, &quot;的&quot;]</span></span><br><span class="line">    chars = pattern.split(txt.upper())</span><br><span class="line">    mix_chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ch_or_w <span class="keyword">in</span> mix_chars:</span><br><span class="line">        <span class="comment"># ch_or_w is a single CJK charater(i.e., &quot;你&quot;), do nothing.</span></span><br><span class="line">        <span class="keyword">if</span> pattern.fullmatch(ch_or_w) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> contain_oov(ch_or_w):</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;yelong&quot;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                tokens.append(ch_or_w)</span><br><span class="line">        <span class="comment"># ch_or_w contains non-CJK charaters(i.e., &quot; IT&#x27;S OKAY &quot;),</span></span><br><span class="line">        <span class="comment"># encode ch_or_w using bpe_model.</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> sp.encode_as_pieces(ch_or_w):</span><br><span class="line">                <span class="keyword">if</span> contain_oov(ch_or_w):</span><br><span class="line">                    <span class="keyword">return</span> <span class="string">&quot;yelong&quot;</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    tokens.append(p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line"></span><br><span class="line"><span class="comment">#src_file=&#x27;text_space_eng&#x27;</span></span><br><span class="line">src_file=sys.argv[<span class="number">2</span>]</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(src_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>) <span class="keyword">as</span> fs:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fs:</span><br><span class="line">        line = line.strip()</span><br><span class="line">        temp = __tokenize_by_bpe_model(line)</span><br><span class="line">        <span class="keyword">if</span> temp != <span class="string">&quot;yelong&quot;</span>:</span><br><span class="line">            <span class="built_in">print</span>(line, <span class="string">&quot; &quot;</span>.join(temp))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="生成-TLG："><a href="#生成-TLG：" class="headerlink" title="生成 TLG："></a>生成 TLG：</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成L.fst和T.fst：</span></span><br><span class="line">langname=ngram_7g_train_en_zh_hua_lexicon_word</span><br><span class="line">tools/fst/compile_lexicon_token_fst.sh \</span><br><span class="line">    data/local/dict_aban-c009_$&#123;langname&#125; data/local/tmp_aban-c009_$&#123;langname&#125; data/local/lang_aban-c009_$&#123;langname&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压为lm.arpa</span></span><br><span class="line">gunzip -c  /home/yelong/data/kaldi/egs/librispeech/s5/$langname/lm_part_en5/srilm/srilm.o3g.kn.gz &gt; /home/yelong/data/kaldi/egs/librispeech/s5/$langname/lm_part_en5/srilm/lm.arpa</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成G.fst、TLG.fst：</span></span><br><span class="line">tools/fst/make_tlg.sh /home/yelong/data/kaldi/egs/librispeech/s5/$langname/lm_part_en5/srilm/ data/local/lang_aban-c009_$langname data/lang_aban-c009_$langname</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="解码测试集"><a href="#解码测试集" class="headerlink" title="解码测试集"></a>解码测试集</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解码</span></span><br><span class="line">export GLOG_logtostderr=1</span><br><span class="line">export GLOG_v=3</span><br><span class="line"></span><br><span class="line">langname=ngram_7g_train_en_zh_hua_lexicon_word</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker：067：</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">wav_dir=/home/data/yelong/docker_seewo/corpus/ftv-5000s/10-sub-ftv-1w/</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">name=$(<span class="built_in">basename</span> <span class="variable">$wav_dir</span>)</span></span><br><span class="line">./tools/decode.sh --nj 10 --acoustic_scale 10 --lattice_beam 30 --max_active 7000 --ctc_weight 0.05 --rescoring_weight 1 --chunk_size -1  --blank_skip_thresh 0.98 --dict_path /home/aban-c009/lang_aban-c009_$langname/words.txt --fst_path /home/aban-c009/lang_aban-c009_$langname/TLG.fst  /home/data/yelong/docker_seewo/corpus/200/doc/wav.scp /home/data/yelong/docker_seewo/corpus/200/doc/text /home/aban-c009/final.zip  /home/aban-c009/lang_aban-c009_$langname/units.txt exp/aban-c009/200.11/lm_10_attention_rescore_ReduceBlankprob_1_OnlyCurBestEqualBlank</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Code-Switching</category>
      </categories>
      <tags>
        <tag>Code-Switching</tag>
      </tags>
  </entry>
  <entry>
    <title>Code-Switching论文笔记（二）网上资料</title>
    <url>/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="网上的资料"><a href="#网上的资料" class="headerlink" title="网上的资料"></a>网上的资料</h1><img src="/2022/06/27/Code-Switching/Code-Switching%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220602152320592.png" alt="image-20220602152320592">

<h1 id="如何构建中英文混合的语音识别模型？"><a href="#如何构建中英文混合的语音识别模型？" class="headerlink" title="如何构建中英文混合的语音识别模型？"></a>如何构建中英文混合的语音识别模型？</h1><blockquote>
<p>知乎：<a href="https://www.zhihu.com/question/58195901/answer/167007697">https://www.zhihu.com/question/58195901/answer/167007697</a></p>
</blockquote>
<h2 id="构建基于HMM的中英文混合语音识别系统"><a href="#构建基于HMM的中英文混合语音识别系统" class="headerlink" title="构建基于HMM的中英文混合语音识别系统"></a>构建基于HMM的中英文混合语音识别系统</h2><blockquote>
<p>kaldi的hkust</p>
</blockquote>
<h3 id="音子集的构建"><a href="#音子集的构建" class="headerlink" title="音子集的构建"></a>音子集的构建</h3><blockquote>
<p>知乎 <a href="https://www.zhihu.com/question/58195901/answer/167007697">https://www.zhihu.com/question/58195901/answer/167007697</a></p>
</blockquote>
<p>音子集是建立词典以及声学模型所必须的，一个好的音子集能够对声学模型产生重要的影响。这部分也是建立中英文混合识别系统的关键所在。下面介绍三种音子集构建方案：</p>
<ul>
<li><strong>a) 音子集合并</strong></li>
</ul>
<p>把中英文各自的建模单元混合成一个大的建模词典</p>
<p>构建音子集最极端的方式就是将中文和英文语言所有的音子集全部放在一起，形成一个合并的音子集。尽管这种粗暴的方式在过去的系统中性能表现并不好，但是这种方式建立的音子集也并不是一点好处都没有。使用中英文所有的音子集能够保留每种语言各自音子集的上下文关系，即他们三音子的数量和跳转关系仍然由各自的语言来定义。而在其它方式形成的音子集中，这种三音子上下文关系将会被共享的音子扰乱。并且当训练数据中两种语言混合的语音数量增多的时候，中文和英文之间三音子的上下文关系也会得到训练和加强。因此将中文和英文所有的音子集合并也不失为一种好的方法，只是传统的实验往往受限于训练数据的规模以及解码方式。</p>
<p>此外，深度神经网络的描述能力比高斯混合模型要好很多，因此对中文和英文所有的音子集的三音子状态建模也合乎情理。</p>
<ul>
<li><strong>b) 音子集映射</strong></li>
</ul>
<p>构建音子集另外一种极端的方式是将一种语言的音子集完全用另外一种语言的音子集来表示。由于不同种类语言的发音方法不同，必然会有一些无法表示的情况，这是就需要用多个音子的组合来表示，当然也有很多是近似的表示。</p>
<p>工程里最快的方案是把英文用中文的音素标注下。学术上我觉得未来端到端方案可以解决，建模单元换成wordpiece这种就一起建模，但需要有足够得数据。这里数据堂之前举行了这个比赛，可以看看当时的ppt。</p>
<p>在中英文混合识别中，由于中文是主要的语言，英文仅仅会出现一些单词或简单的句子，因此可以将英文的音子集映射到中文音子集中，利用中文音子或是音子的组合来表示英文音子。尽管其中有些音子的表示较为牵强，但是使用这种方法能够在已有模型的基础上快速构建中英文混合语音识别的系统。例如已经在大规模的训练数据上建立了中文的连续语音识别系统，那么所有三音子状态都已经有了一个模型。在这种情况下，构建中英文混合语音识别无需重新训练声学模型。只要将待识别的英文单词用中文音子表示，并添加到识别词典当中，那么就能够识别到英文单词。如果想要在中文的句子中识别到出现的英文单词，只需对语言模型进行适当的调整就能实现。</p>
<p>另外，正如历史发展篇中所述，一旦系统变成一个通用的系统那么其性能必然会比专门的系统有所下降。因此，这种方法建立的中英文混合系统虽然对英文的识别率可能不高，但是它一定是对中文识别率影响最小的一个系统。考虑到中英文混合识别系统仍然是以识别中文为主，仅会识别个别的英文单词或简单英文句子，因此这样的一种音子集构建方式和混合语音识别系统搭建方式可以用作搭建一个基线系统。</p>
<ul>
<li><strong>c) 音子集融合</strong></li>
</ul>
<p>音子集的融合指是在简单的音子集合并的基础之上进行进一步处理，通常是将发音类似的音子合并成一个。这里既可以利用专家编撰的方法，也可以使用数据驱动的方法，比如基于混淆矩阵[P.-Y. Shih，2008]的方法。</p>
<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>a)要训练中英文混合的语音识别系统，当然要有中英文混合的标注语音数据。当然音子集映射的方法可以不改变声学模型，因此没有声学训练用的标注语音数据也可以。而其他两种音子集形成的方式都离不开带标注的声学训练数据。</p>
<p>b)语言模型也必须包含中英文混合的数据。</p>
<p>c)词典自然要包含想识别出的所有汉字和单词，音子集就用上述方法构建得到的即可。</p>
<h2 id="构建基于end-to-end的中英文混合语音识别系统"><a href="#构建基于end-to-end的中英文混合语音识别系统" class="headerlink" title="构建基于end-to-end的中英文混合语音识别系统"></a>构建基于end-to-end的中英文混合语音识别系统</h2><p>End-to-end的方法中，中文通常直接使用汉字来建模，而英文为了避免词巨大汇量带来的模型爆炸通常使用Gram-char进行建模，包括uni-char（就是字符），bi-char以及GRAM-CTC[Hairong Liu，2017]中这种数据驱动的Gram-char。对于这种结构的识别系统来说，有了带标注中英文混合语音数据和中英文混合文本数据就足够建立一个识别系统了。</p>
]]></content>
      <categories>
        <category>Code-Switching</category>
      </categories>
      <tags>
        <tag>Code-Switching</tag>
      </tags>
  </entry>
  <entry>
    <title>rescore RTF</title>
    <url>/2022/06/27/Code-Switching/rescore%20RTF/</url>
    <content><![CDATA[<h1 id="rescore-RTF"><a href="#rescore-RTF" class="headerlink" title="rescore RTF"></a>rescore RTF</h1><p>python版本</p>
<p>见10.22.24.2：&#x2F;home&#x2F;yelong&#x2F;data&#x2F;wenet&#x2F;examples&#x2F;aishell&#x2F;s0&#x2F;recognize_lm.py</p>
<p>注意（花哥教）：rescore lm是累计n-best的时间，am是一次的时间（一次出来n-best）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wenet.dataset.dataset <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> wenet.transformer.asr_model <span class="keyword">import</span> init_asr_model</span><br><span class="line"><span class="keyword">from</span> wenet.utils.checkpoint <span class="keyword">import</span> load_checkpoint</span><br><span class="line"><span class="keyword">from</span> wenet.utils.file_utils <span class="keyword">import</span> read_symbol_table, read_non_lang_symbols</span><br><span class="line"><span class="keyword">from</span> wenet.utils.config <span class="keyword">import</span> override_config</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;recognize with your model&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--config&#x27;</span>, default=<span class="string">&#x27;exp/seewo/conformer/train.yaml&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;config file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--test_data&#x27;</span>, default=<span class="string">&#x27;data/xueyuan/data.list1&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;test data file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data_type&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;raw&#x27;</span>,</span><br><span class="line">                        choices=[<span class="string">&#x27;raw&#x27;</span>, <span class="string">&#x27;shard&#x27;</span>],</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;train and cv data type&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gpu&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        default=-<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;gpu id for this rank, -1 for cpu&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--checkpoint&#x27;</span>, default=<span class="string">&#x27;exp/seewo/conformer/77.pt&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;checkpoint model&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dict&#x27;</span>, default=<span class="string">&#x27;exp/seewo/conformer/words.txt&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;dict file&#x27;</span>)</span><br><span class="line">    <span class="comment"># parser.add_argument(&#x27;--dict&#x27;, default=&#x27;data/dict_bpe/lang_char.txt.bpe_100_eng600_chi7200_all7800&#x27;, help=&#x27;dict file&#x27;)</span></span><br><span class="line">    <span class="comment"># parser.add_argument(&#x27;--dict&#x27;, default=&#x27;exp/140-models/lang_char.txt&#x27;, help=&#x27;dict file&#x27;)</span></span><br><span class="line">    <span class="comment"># parser.add_argument(&#x27;--symbol_table_old&#x27;, default=&#x27;exp/140-models/lang_char.txt&#x27;, help=&#x27;dict file&#x27;)</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--non_lang_syms&quot;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&quot;non-linguistic symbol file. One symbol per line.&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--beam_size&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        default=<span class="number">10</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;beam size for search&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--penalty&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">float</span>,</span><br><span class="line">                        default=<span class="number">0.0</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;length penalty&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--result_file&#x27;</span>, default=<span class="string">&#x27;exp/seewo/conformer/test_xueyuan/text&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;asr result file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        default=<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;asr result file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--mode&#x27;</span>,</span><br><span class="line">                        choices=[</span><br><span class="line">                            <span class="string">&#x27;attention&#x27;</span>, <span class="string">&#x27;ctc_greedy_search&#x27;</span>,</span><br><span class="line">                            <span class="string">&#x27;ctc_prefix_beam_search&#x27;</span>, <span class="string">&#x27;attention_rescoring&#x27;</span></span><br><span class="line">                        ],</span><br><span class="line">                        default=<span class="string">&#x27;ctc_prefix_beam_search&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;decoding mode&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--ctc_weight&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">float</span>,</span><br><span class="line">                        default=<span class="number">0.5</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;ctc weight for attention rescoring decode mode&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--decoding_chunk_size&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        default=-<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;&#x27;&#x27;decoding chunk size,</span></span><br><span class="line"><span class="string">                                &lt;0: for decoding, use full chunk.</span></span><br><span class="line"><span class="string">                                &gt;0: for decoding, use fixed chunk size as set.</span></span><br><span class="line"><span class="string">                                0: used for training, it&#x27;s prohibited here&#x27;&#x27;&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_decoding_left_chunks&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        default=-<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of left chunks for decoding&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--simulate_streaming&#x27;</span>,</span><br><span class="line">                        action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;simulate streaming inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--reverse_weight&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">float</span>,</span><br><span class="line">                        default=<span class="number">0.0</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;&#x27;&#x27;right to left weight for attention rescoring</span></span><br><span class="line"><span class="string">                                decode mode&#x27;&#x27;&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--bpe_model&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;data/lang_char/train_unigram1000.model&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;bpe model for english part&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--override_config&#x27;</span>,</span><br><span class="line">                        action=<span class="string">&#x27;append&#x27;</span>,</span><br><span class="line">                        default=[],</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&quot;override yaml config&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--connect_symbol&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;used to connect the output characters&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="built_in">print</span>(args)</span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    args = get_args()</span><br><span class="line">    logging.basicConfig(level=logging.DEBUG,</span><br><span class="line">                        <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s %(levelname)s %(message)s&#x27;</span>)</span><br><span class="line">    os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="built_in">str</span>(args.gpu)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.mode <span class="keyword">in</span> [<span class="string">&#x27;ctc_prefix_beam_search&#x27;</span>, <span class="string">&#x27;attention_rescoring&#x27;</span></span><br><span class="line">                     ] <span class="keyword">and</span> args.batch_size &gt; <span class="number">1</span>:</span><br><span class="line">        logging.fatal(</span><br><span class="line">            <span class="string">&#x27;decoding mode &#123;&#125; must be running with batch_size == 1&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                args.mode))</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(args.config, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fin:</span><br><span class="line">        configs = yaml.load(fin, Loader=yaml.FullLoader)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args.override_config) &gt; <span class="number">0</span>:</span><br><span class="line">        configs = override_config(configs, args.override_config)</span><br><span class="line"></span><br><span class="line">    symbol_table = read_symbol_table(args.<span class="built_in">dict</span>)</span><br><span class="line">    symbol_table_old = read_symbol_table(args.symbol_table_old <span class="keyword">if</span> <span class="string">&#x27;symbol_table_old&#x27;</span> <span class="keyword">in</span> args <span class="keyword">else</span> args.<span class="built_in">dict</span>)    <span class="comment"># --yl</span></span><br><span class="line">    configs[<span class="string">&#x27;output_dim&#x27;</span>] = <span class="built_in">len</span>(symbol_table)   <span class="comment"># --yl</span></span><br><span class="line">    test_conf = copy.deepcopy(configs[<span class="string">&#x27;dataset_conf&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    test_conf[<span class="string">&#x27;filter_conf&#x27;</span>][<span class="string">&#x27;max_length&#x27;</span>] = <span class="number">102400</span></span><br><span class="line">    test_conf[<span class="string">&#x27;filter_conf&#x27;</span>][<span class="string">&#x27;min_length&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    test_conf[<span class="string">&#x27;filter_conf&#x27;</span>][<span class="string">&#x27;token_max_length&#x27;</span>] = <span class="number">102400</span></span><br><span class="line">    test_conf[<span class="string">&#x27;filter_conf&#x27;</span>][<span class="string">&#x27;token_min_length&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    test_conf[<span class="string">&#x27;filter_conf&#x27;</span>][<span class="string">&#x27;max_output_input_ratio&#x27;</span>] = <span class="number">102400</span></span><br><span class="line">    test_conf[<span class="string">&#x27;filter_conf&#x27;</span>][<span class="string">&#x27;min_output_input_ratio&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    test_conf[<span class="string">&#x27;speed_perturb&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    test_conf[<span class="string">&#x27;spec_aug&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    test_conf[<span class="string">&#x27;spec_sub&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    test_conf[<span class="string">&#x27;shuffle&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    test_conf[<span class="string">&#x27;sort&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;fbank_conf&#x27;</span> <span class="keyword">in</span> test_conf:</span><br><span class="line">        test_conf[<span class="string">&#x27;fbank_conf&#x27;</span>][<span class="string">&#x27;dither&#x27;</span>] = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;mfcc_conf&#x27;</span> <span class="keyword">in</span> test_conf:</span><br><span class="line">        test_conf[<span class="string">&#x27;mfcc_conf&#x27;</span>][<span class="string">&#x27;dither&#x27;</span>] = <span class="number">0.0</span></span><br><span class="line">    test_conf[<span class="string">&#x27;batch_conf&#x27;</span>][<span class="string">&#x27;batch_type&#x27;</span>] = <span class="string">&quot;static&quot;</span></span><br><span class="line">    test_conf[<span class="string">&#x27;batch_conf&#x27;</span>][<span class="string">&#x27;batch_size&#x27;</span>] = args.batch_size</span><br><span class="line">    non_lang_syms = read_non_lang_symbols(args.non_lang_syms)</span><br><span class="line"></span><br><span class="line">    test_dataset = Dataset(args.data_type,</span><br><span class="line">                           args.test_data,</span><br><span class="line">                           symbol_table,</span><br><span class="line">                           test_conf,</span><br><span class="line">                           args.bpe_model,</span><br><span class="line">                           non_lang_syms,</span><br><span class="line">                           partition=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    test_data_loader = DataLoader(test_dataset, batch_size=<span class="literal">None</span>, num_workers=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Init asr model from configs</span></span><br><span class="line">    model = init_asr_model(configs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load dict</span></span><br><span class="line">    char_dict = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> symbol_table.items()&#125;</span><br><span class="line">    eos = <span class="built_in">len</span>(char_dict) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    load_checkpoint(model, args.checkpoint, symbol_table, symbol_table_old)</span><br><span class="line">    use_cuda = args.gpu &gt;= <span class="number">0</span> <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">    model = model.to(device)</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer,BertForMaskedLM</span><br><span class="line">    path_to_TAL_EduBERT = <span class="string">&quot;/home/yelong/data/edu-bert/models/TAL-EduBERT&quot;</span></span><br><span class="line">    lm_tokenizer = BertTokenizer.from_pretrained(path_to_TAL_EduBERT)</span><br><span class="line">    lm_model = BertForMaskedLM.from_pretrained(path_to_TAL_EduBERT)</span><br><span class="line">    lm_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    sp = spm.SentencePieceProcessor()</span><br><span class="line">    sp.Load(<span class="string">&#x27;data/lang_char/train_unigram100.model&#x27;</span>)</span><br><span class="line">    all_dura_am, all_dura_lm, wav_dura = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(), <span class="built_in">open</span>(args.result_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fout:</span><br><span class="line">        <span class="keyword">for</span> batch_idx, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_data_loader):</span><br><span class="line">            keys, feats, target, feats_lengths, target_lengths = batch</span><br><span class="line">            feats = feats.to(device)</span><br><span class="line">            target = target.to(device)</span><br><span class="line">            feats_lengths = feats_lengths.to(device)</span><br><span class="line">            target_lengths = target_lengths.to(device)</span><br><span class="line">            <span class="keyword">if</span> args.mode == <span class="string">&#x27;attention&#x27;</span>:</span><br><span class="line">                hyps, _ = model.recognize(</span><br><span class="line">                    feats,</span><br><span class="line">                    feats_lengths,</span><br><span class="line">                    beam_size=args.beam_size,</span><br><span class="line">                    decoding_chunk_size=args.decoding_chunk_size,</span><br><span class="line">                    num_decoding_left_chunks=args.num_decoding_left_chunks,</span><br><span class="line">                    simulate_streaming=args.simulate_streaming)</span><br><span class="line">                hyps = [hyp.tolist() <span class="keyword">for</span> hyp <span class="keyword">in</span> hyps]</span><br><span class="line">            <span class="keyword">elif</span> args.mode == <span class="string">&#x27;ctc_greedy_search&#x27;</span>:</span><br><span class="line">                hyps, _ = model.ctc_greedy_search(</span><br><span class="line">                    feats,</span><br><span class="line">                    feats_lengths,</span><br><span class="line">                    decoding_chunk_size=args.decoding_chunk_size,</span><br><span class="line">                    num_decoding_left_chunks=args.num_decoding_left_chunks,</span><br><span class="line">                    simulate_streaming=args.simulate_streaming)</span><br><span class="line">            <span class="comment"># ctc_prefix_beam_search and attention_rescoring only return one</span></span><br><span class="line">            <span class="comment"># result in List[int], change it to List[List[int]] for compatible</span></span><br><span class="line">            <span class="comment"># with other batch decoding mode</span></span><br><span class="line">            <span class="keyword">elif</span> args.mode == <span class="string">&#x27;ctc_prefix_beam_search&#x27;</span>:</span><br><span class="line">                <span class="keyword">assert</span> (feats.size(<span class="number">0</span>) == <span class="number">1</span>)</span><br><span class="line">                <span class="comment"># hyp, _ = model.ctc_prefix_beam_search(</span></span><br><span class="line">                start_time_am = time.time()</span><br><span class="line">                hyp = model.ctc_prefix_beam_search(</span><br><span class="line">                    feats,</span><br><span class="line">                    feats_lengths,</span><br><span class="line">                    args.beam_size,</span><br><span class="line">                    decoding_chunk_size=args.decoding_chunk_size,</span><br><span class="line">                    num_decoding_left_chunks=args.num_decoding_left_chunks,</span><br><span class="line">                    simulate_streaming=args.simulate_streaming)</span><br><span class="line">                hyps = hyp</span><br><span class="line">                end_time_am = time.time()</span><br><span class="line">                <span class="comment"># hyps = [hyp]</span></span><br><span class="line">            <span class="keyword">elif</span> args.mode == <span class="string">&#x27;attention_rescoring&#x27;</span>:</span><br><span class="line">                <span class="keyword">assert</span> (feats.size(<span class="number">0</span>) == <span class="number">1</span>)</span><br><span class="line">                hyp, _ = model.attention_rescoring(</span><br><span class="line">                    feats,</span><br><span class="line">                    feats_lengths,</span><br><span class="line">                    args.beam_size,</span><br><span class="line">                    decoding_chunk_size=args.decoding_chunk_size,</span><br><span class="line">                    num_decoding_left_chunks=args.num_decoding_left_chunks,</span><br><span class="line">                    ctc_weight=args.ctc_weight,</span><br><span class="line">                    simulate_streaming=args.simulate_streaming,</span><br><span class="line">                    reverse_weight=args.reverse_weight)</span><br><span class="line">                hyps = [hyp]</span><br><span class="line">            dura_am = end_time_am - start_time_am</span><br><span class="line">            all_dura_am += dura_am</span><br><span class="line">            wav_dura += feats_lengths.item()</span><br><span class="line">            dura_lm = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(hyp)):   <span class="comment">#十条</span></span><br><span class="line">                content = []</span><br><span class="line">                <span class="keyword">for</span> w <span class="keyword">in</span> hyps[j][<span class="number">0</span>]:</span><br><span class="line">                    <span class="keyword">if</span> w == eos:</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    content.append(char_dict[w])</span><br><span class="line">                text = sp.DecodePieces([args.connect_symbol.join(content)]).replace(<span class="string">&quot;▁&quot;</span>,<span class="string">&quot; &quot;</span>).lower()</span><br><span class="line">                start_time_lm = time.time() </span><br><span class="line">                lm_inputs_token = lm_tokenizer(text, return_tensors=<span class="string">&quot;pt&quot;</span>, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">                outputs = lm_model(**lm_inputs_token).logits</span><br><span class="line">                <span class="comment"># Perplexity</span></span><br><span class="line">                outputs = F.softmax(outputs[<span class="number">0</span>], dim=-<span class="number">1</span>)</span><br><span class="line">                outputs = torch.log(outputs)</span><br><span class="line">                logit = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(outputs)):</span><br><span class="line">                    logit = logit + outputs[i][lm_inputs_token[<span class="string">&#x27;input_ids&#x27;</span>][<span class="number">0</span>][i]].item()    </span><br><span class="line">                dura_lm += time.time() - start_time_lm          </span><br><span class="line">                <span class="keyword">if</span> j == <span class="built_in">len</span>(hyp) -<span class="number">1</span> :</span><br><span class="line">                    all_dura_lm += dura_lm  </span><br><span class="line">                    logging.info(<span class="string">&#x27;&#123;&#125; &#123;&#125; &#123;:.5&#125; &#123;:.5&#125; &#123;:.5&#125; &#123;:.5&#125;&#x27;</span>.<span class="built_in">format</span>(keys[<span class="number">0</span>], args.connect_symbol.join(content), <span class="built_in">str</span>(<span class="number">100</span>*dura_am/feats_lengths.item()), <span class="built_in">str</span>(<span class="number">100</span>*dura_lm/feats_lengths.item()), <span class="built_in">str</span>(<span class="number">100</span>*(dura_am + dura_lm)/feats_lengths.item()), <span class="built_in">str</span>(logit)))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    logging.info(<span class="string">&#x27;&#123;&#125; &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(keys[<span class="number">0</span>], args.connect_symbol.join(content)))</span><br><span class="line">                <span class="comment"># logging.info(&#x27;&#123;&#125; &#123;&#125; &#123;:.4&#125; &#123;:.4&#125; &#123;:.4&#125; &#123;:.4&#125;&#x27;.format(keys[0], args.connect_symbol.join(content), str(dura_am), str(dura_lm), str(dura_am + dura_lm), str(logit)))</span></span><br><span class="line">                fout.write(<span class="string">&#x27;&#123;&#125; &#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(keys[<span class="number">0</span>], args.connect_symbol.join(content)))</span><br><span class="line">    logging.info(<span class="string">&#x27;&#123;:.5&#125; &#123;:.5&#125; &#123;:.5&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(<span class="number">100</span>*all_dura_am/wav_dura), <span class="built_in">str</span>(<span class="number">100</span>*all_dura_lm/wav_dura), <span class="built_in">str</span>(<span class="number">100</span>*(all_dura_am+all_dura_lm)/wav_dura)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Code-Switching</category>
      </categories>
      <tags>
        <tag>Code-Switching</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第9章 WFST解码器————最优路径解码</title>
    <url>/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/</url>
    <content><![CDATA[<h1 id="WFST解码器"><a href="#WFST解码器" class="headerlink" title="WFST解码器"></a>WFST解码器</h1><blockquote>
<p>厦门大学洪青阳教授的公开课：<a href="https://appqtulvsie4217.pc.xiaoe-tech.com/live_pc/l_5f504e67e4b0158ded4dffed">《语音识别值WFST解码器——基于WFST的维特比解码过程》</a></p>
</blockquote>
<ul>
<li>token：保存解码的中间结果</li>
<li>WFST解码本质上也是Viterbi解码，根据输入的特征序列，进行帧同步对齐，寻求最佳状态序列。  </li>
<li>注意这里的状态不是HMM状态，而是HCLG的状态节点，所遍历状态节点之间的衔接，可能是&#x3D;&#x3D;产生观察值&#x3D;&#x3D;的转移弧（如状态𝑆1和𝑆2、 𝑆2和𝑆3之间的实线），也可能&#x3D;&#x3D;不产生观察值&#x3D;&#x3D;的转移弧（如状态𝑆4和𝑆5之间的虚线）。</li>
</ul>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707144630412.png" alt="image-20210707144630412"></p>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707144643772.png" alt="image-20210707144643772"></p>
<ul>
<li>Emitting arc：发射转移弧，会<strong>产生观察值</strong>，观察值产生声学分数（acoustic_cost），非0的输入标签（ilabel！&#x3D;0）.</li>
<li>Nonemitting arc：非发射转移弧，<strong>不会产生观察值</strong>，没有声学分数，但是状态间能够跳转。简单理解可以想成  o—语:语文—o—文: $\epsilon$ —o 。0的输入标签（ilabel&#x3D;0）</li>
<li>graph_cost：图代价，每条转移弧对应的权重。</li>
<li>weight_cutoff：要剪枝的阈值</li>
</ul>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707144711483.png" alt="image-20210707144711483"></p>
<ul>
<li>cost越小越好</li>
<li>arc.weight：包含hmm 转移概率、词典概率、语言模型概率（不包含am发射概率）（负对数）</li>
<li>acoustic_cost：am发射概率（负对数）</li>
<li>若cost更小，存在该token，有就替换，没有就添加</li>
</ul>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707144701827.png" alt="image-20210707144701827"></p>
<ul>
<li>若cost更小，存在该token，有就替换，没有就创建一个</li>
</ul>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707144724575.png" alt="image-20210707144724575"></p>
<h2 id="基于token的viterbi解码"><a href="#基于token的viterbi解码" class="headerlink" title="基于token的viterbi解码"></a>基于token的viterbi解码</h2><ul>
<li><p>类似HMM的解码过程， WFST的Viterbi解码也是逐帧推进，分别计算每帧的声学得分，然后结合转移弧的权重，得到每个时刻扩展路径的累计代价，这些代价用Token的cost保存。  </p>
</li>
<li><p>WFST的Viterbi解码通过对比指向同一个状态的不同路径的由Token（&#x3D;&#x3D;该Token与状态节点关联&#x3D;&#x3D;，如果状态节点还没有Token，则创建一个新的Token）保存的累计代价（cost） ，选择值更小的并更新Token信息。  </p>
</li>
<li><p>Viterbi算法的每个状态最多只有一个Token，如果有多条路径到某个状态，则Token可能存在冲突，根据值更小原则保持或进行替代 。</p>
</li>
<li><p>token：当走到某状态，会有一个token（没走到不会创建），token中的cost会更新</p>
</li>
</ul>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707144919914.png" alt="image-20210707144919914"></p>
<ul>
<li>prev_toks：历史token</li>
<li>cur_toks：当前token</li>
</ul>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707144944825.png" alt="image-20210707144944825"></p>
<ul>
<li>当前帧的token：状态0，会遍历，cur_token会依次放进8，1，9，第一次，是创建token。9还会走processnonemitting，走到2，创建状态2的token</li>
</ul>
<p>第二帧：</p>
<p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707145013053.png" alt="image-20210707145013053"></p>
<ul>
<li>10-&gt;2：看看状态2的token的cost有没有更小，要不要更新2的token cost</li>
</ul>
<h4 id="回溯："><a href="#回溯：" class="headerlink" title="回溯："></a>回溯：</h4><p><img src="/2023/01/10/WFST%E8%A7%A3%E7%A0%81/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B9%8BWFST%E8%A7%A3%E7%A0%81%E5%99%A8/image-20210707145028147.png" alt="image-20210707145028147"></p>
<p>beam：指的是一个窗口范围，对于一个token，到下一个状态弧在不在这个范围里，不在就舍弃，而不是取前beam个，是beam对应的窗口范围</p>
]]></content>
      <categories>
        <category>WFST解码</category>
      </categories>
      <tags>
        <tag>WFST解码</tag>
        <tag>《语音识别原理与应用》</tag>
      </tags>
  </entry>
  <entry>
    <title>TLG（四）</title>
    <url>/2022/06/27/Code-Switching/TLG%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="基于字建模（中文字英文词）"><a href="#基于字建模（中文字英文词）" class="headerlink" title="基于字建模（中文字英文词）"></a>基于字建模（中文字英文词）</h1><p>。。。</p>
<h1 id="分析以下原因"><a href="#分析以下原因" class="headerlink" title="分析以下原因"></a>分析以下原因</h1><ol>
<li>core&#x2F;decoder&#x2F;ctc_wfst_beam_search.cc里未做am出来相同类merge规整，修改代码后会提升一些</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 函数：void CtcWfstBeamSearch::Search(const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; logp) &#123;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Optional, adding one blank frame if we has skipped it in two same</span></span><br><span class="line">      <span class="comment">// symbols</span></span><br><span class="line">      <span class="comment">/*</span></span><br><span class="line"><span class="comment">      if (cur_best != 0 &amp;&amp; is_last_frame_blank_ &amp;&amp; cur_best == last_best_) &#123;</span></span><br><span class="line"><span class="comment">        decodable_.AcceptLoglikes(last_frame_prob_);</span></span><br><span class="line"><span class="comment">        decoder_.AdvanceDecoding(&amp;decodable_, 1);</span></span><br><span class="line"><span class="comment">        decoded_frames_mapping_.push_back(num_frames_ - 1);</span></span><br><span class="line"><span class="comment">        VLOG(2) &lt;&lt; &quot;Adding blank frame at symbol &quot; &lt;&lt; cur_best;</span></span><br><span class="line"><span class="comment">      &#125;</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (cur_best == last_best_ &amp;&amp; cur_best != <span class="number">0</span> &amp;&amp; is_last_frame_blank_) &#123;</span><br><span class="line">        decodable_.<span class="built_in">AcceptLoglikes</span>(last_frame_prob_);</span><br><span class="line">        decoder_.<span class="built_in">AdvanceDecoding</span>(&amp;decodable_, <span class="number">1</span>);</span><br><span class="line">        decoded_frames_mapping_.<span class="built_in">push_back</span>(num_frames_ - <span class="number">1</span>);</span><br><span class="line">        <span class="built_in">VLOG</span>(<span class="number">2</span>) &lt;&lt; <span class="string">&quot;Adding blank frame at symbol &quot;</span> &lt;&lt; cur_best;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (cur_best != <span class="number">0</span> &amp;&amp; !is_last_frame_blank_ &amp;&amp; cur_best == last_best_)&#123;</span><br><span class="line">        <span class="built_in">VLOG</span>(<span class="number">2</span>) &lt;&lt; <span class="string">&quot;cur frame is same as last frame, skip it(merge it)&quot;</span> &lt;&lt; cur_best;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>lexicon标注有误，像“买LV” 这种，lexicon标注为 L ▁V的，但是am出来▁L概率很高，L的概率很小，但是加上语言分数，语言模型概率P(V|买) 高于P(V|L)，加上声学分就是只出来了L，因此要想避免这种情况，一个是训练语言模型的文本”L V”这种分开的要比较多，使得P(V|L)高，一个是lexicon要人工挑选，尽量声学分数不要太低了。</p>
<p>训练声学模型时，带LV的单词易拆成** L ▁V，L在单词中间，（L没有空格）L的建模多是L在单词中间的发音的建模，而L单独的发音建模是▁L，因此虽然LV经过声学模型bpe拆分成 L ▁V，也是建模单元▁L的概率高；</p>
</li>
<li><p>CTC prefix beam search，带TLG优于不带TLG的结果，说明TLG是有效的（CTC不带语言模型），而attention rescore后TLG作用不明显，说明TLG建模能力没有transoformer的建模能力强（带语言模型了），而且他们的训练文本很接近，这是可以理解的。</p>
</li>
</ol>
<p><img src="/2022/06/27/Code-Switching/TLG%EF%BC%88%E5%9B%9B%EF%BC%89/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16558869769531.png" alt="img"></p>
]]></content>
      <categories>
        <category>Code-Switching</category>
      </categories>
      <tags>
        <tag>Code-Switching</tag>
      </tags>
  </entry>
  <entry>
    <title>Finetune网上博客</title>
    <url>/2023/06/06/Finetune/Finetune%E7%BD%91%E4%B8%8A%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h1 id="finetune网上博客"><a href="#finetune网上博客" class="headerlink" title="finetune网上博客"></a>finetune网上博客</h1><blockquote>
<p>极市 <a href="https://www.cvmart.net/community/detail/6198">花式 Finetune 方法大汇总</a></p>
</blockquote>
<h2 id="1-招式1：使用Pretrain模型做约束"><a href="#1-招式1：使用Pretrain模型做约束" class="headerlink" title="1. 招式1：使用Pretrain模型做约束"></a>1. 招式1：使用Pretrain模型做约束</h2><p>在Finetune阶段，如果我们可用于Finetune的目标任务数据量较少时，很有可能出现过拟合现象，严重影响模型效果；或者在Finetune过程中出现知识遗忘问题（catastrophic memory），把Pretrain阶段学到的有用知识遗忘，丢了西瓜捡了芝麻。为了解决这种问题，学术界提出利用Pretrain模型作为约束，指导Finetune的过程，让Finetune得到的模型更加鲁棒。具体包括：&#x3D;&#x3D;直接使用Pretrain模型的参数作为约束、使用Pretrain模型的中间层表示作为约束、使用Pretrain模型对不同特征注意力强度作为约束&#x3D;&#x3D;。</p>
<p>为了防止模型在Finetune阶段过拟合目标任务数据，或忘记了Pretrain阶段学到的有意义知识，<em><strong>Explicit inductive bias for transfer learning with convolutional networks（ICML 2018）*<strong>这篇文章介绍了一种使用Pretrain模型参数约束Finetune过程的方法：通过添加Pretrain模型参数和Finetune模型参数之间的某种正则化损失，让Finetune后的模型参数和最开始的Pretrain模型参数更加相似。文章中尝试了多种正则化方法，通过最终的实验发现，一个简单的L2正则效果最好，即对于Pretrain模型和Finetune模型的</strong>对应层</strong>的参数计算</em><em>L2距离<strong>，作为Finetune过程中</strong>损失函数的一部分**，公式如下（w为Finetune参数，w0位Pretrain参数）：<br>$$<br>\Omega(\boldsymbol{w})&#x3D;\frac{\alpha}{2}\left|\boldsymbol{w}-\boldsymbol{w}^0\right|_2^2<br>$$<br>通过L2正则化的方法拉近Pretrain模型和Target模型参数也存在一定问题，如何设定正则化的强度直接决定了迁移效果，正则化太弱仍然会导致过拟合和信息遗忘，迁移强度太强会导致Finetune的模型在Target任务上不是最优解。百度的文章 <strong>DELTA: DEEP LEARNING TRANSFER USING FEATURE MAP WITH ATTENTION FOR CONVOLUTIONAL NET- WORKS（ICLR 2019）</strong> 提出，通过约束网络的behavior，即feature map，而非模型参数，来实现约束目标。具体的，约束项可以表示为如下形式：<br>$$<br>\Omega^{\prime}\left(\omega, \omega^</em>, \mathbf{x}<em>i, y_i, z\right)&#x3D;\sum</em>{j&#x3D;1}^N\left(\mathrm{~W}_j\left(z, \omega^*, \mathbf{x}_i, y_i\right) \cdot | \mathrm{FM}_j\left(z, \omega, \mathbf{x}_i\right)-\mathrm{FM}_j\left(z, \omega^*, \mathbf{x}_i\right)\right) |_2^2<br>$$<br>其中，Wj表示第j个卷积层的约束强度，FM表示第i个样本经过参数w提取的feaure map。Wj的计算方法为，使用Pretrain的模型Freeze住底层Feature Extractor参数，Finetune后面Discriminator参数，<strong>通过衡量去掉每个channel后效果的损失，得到这个channel的迁移强度</strong>。如果去掉Pretrain模型某个channel后效果下降特别明显，说明Pretrain得到的这个channel的信息对Target任务是很有效的，这个时候要增大这种channel参数的迁移强度。</p>
<img src="/2023/06/06/Finetune/Finetune%E7%BD%91%E4%B8%8A%E5%8D%9A%E5%AE%A2/006C3FgEgy1h0hixa2vmfj30k00fudh8.jpg" alt="img" style="zoom:80%;">



<p><strong>采用Pretrain模型对Finetune模型进行约束需要引入额外的正则化Loss，可以被称为Transfer Loss</strong>。由于Transfer Loss和Target Task Loss的优化目标不同，如何平衡两个Loss的关系决定了迁移效果。为了统一这两种Loss，<strong>Robust Knowledge Transfer via Hybrid Forward on the Teacher-Student Model（AAAI 2021）</strong> 提出了一种混合前向网络。当一个样本输入时，会通过三种不同的路径得到三种Loss，Loss1和Loss2通过交替进入Student网络（Target Task模型）某层和Teachder网络（Pretrain模型）某层，最终再通过Target Task Head得到；Loss3只进入Student网络通过Target Task Head得到。Loss1和Loss2代表了Student网络和Teachder网络Transfer Loss，Loss3代表了Target Task的优化Loss。与之前方法相比，该方法的三个Loss都是以优化Target Task为目标的，因此可以通过直接对比来判断目前的Transfer强度是否太强。文中设计了一种简单的平衡Transfer Loss和Target Loss的方法，让两个任务的Loss同等重要，随着训练过程动态计算Loss1和Loss2的权重。</p>
<p>TODO…</p>
<img src="/2023/06/06/Finetune/Finetune%E7%BD%91%E4%B8%8A%E5%8D%9A%E5%AE%A2/006C3FgEgy1h0hixa0uljj30k005xjsb.jpg" alt="006C3FgEgy1h0hixa0uljj30k005xjsb">

<img src="/2023/06/06/Finetune/Finetune%E7%BD%91%E4%B8%8A%E5%8D%9A%E5%AE%A2/006C3FgEgy1h0hixa1qmhj30u007hgmq.jpg" alt="006C3FgEgy1h0hixa1qmhj30u007hgmq" style="zoom:80%;">



<h2 id="2-招式2：选择性地对Pretrain模型迁移"><a href="#2-招式2：选择性地对Pretrain模型迁移" class="headerlink" title="2. 招式2：选择性地对Pretrain模型迁移"></a>2. 招式2：选择性地对Pretrain模型迁移</h2><p>Pretrain模型中的参数不一定都是对下游任务有帮助的，因此一些研究提出，<strong>对Pretrain的模型进行有选择性的迁移，重点迁移那些对下游任务帮助大的信息</strong>。<strong>Learning What and Where to Transfer（ICML 2019）</strong> 中提出一种基于<strong>meta-learning</strong>的迁移学习方法。这篇文章的核心思路建立在<strong>FITNETS: HINTS FOR THIN DEEP NETS（ICLR 2015）</strong> 一文提出的迁移方法之上，<strong>让Target模型通过一个回归任务拟合Pretrain模型中间层的表示</strong>，该优化目标可以表示为：<br>$$<br>\mathcal{L}<em>{H T}\left(\mathbf{W}</em>{\text {Guided }}, \mathbf{W}<em>{\mathbf{r}}\right)&#x3D;\frac{1}{2}\left|u_h\left(\mathbf{x} ; \mathbf{W}</em>{\text {Hint }}\right)-r\left(v_g\left(\mathbf{x} ; \mathbf{W}<em>{\text {Guided }}\right) ; \mathbf{W}</em>{\mathbf{r}}\right)\right|^2<br>$$<br>在FitNet中WGuided和WHint分别表示Target模型的Pretrain模型某一对应层的参数。<strong>Learning What and Where to Transfer（ICML 2019）</strong> 对该方法进行了扩展。在What to transfer阶段，对每一个channel的迁移做一个权重学习，每个channel的权重是通过一个单独的网络输入图片在Source模型的输出计算得到的（T代表Target模型，S代表Source模型，与FitNet中的Guided和Hint相对应）：<br>$$<br>\begin{aligned}<br>&amp; \mathcal{L}<em>{\text {wfm }}^{m, n}\left(\theta \mid x, w^{m, n}\right) \<br>&amp; &#x3D;\frac{1}{H W} \sum_c w_c^{m, n} \sum</em>{i, j}\left(r_\theta\left(T_\theta^n(x)\right)<em>{c, i, j}-S^m(x)</em>{c, i, j}\right)^2 \<br>&amp;<br>\end{aligned}<br>$$<br>在Where to transfer阶段，主要决定Source模型到Target模型的迁移层pair，即Source模型的第i层参数要迁移到Target模型的哪一层。类似What to transfer，通过一个单独的网络学习(i,j)这组Source模型到Target模型pair对的迁移强度：<br>$$<br>\mathcal{L}<em>{\mathrm{wfm}}(\theta \mid x, \phi)&#x3D;\sum</em>{(m, n) \in \mathcal{C}} \lambda^{m, n} \mathcal{L}_{\mathrm{wfm}}^{m, n}\left(\theta \mid x, w^{m, n}\right)<br>$$</p>
<p>最终的Loss由上面两个阶段的Loss，以及任务本身的Loss共同组成。在训练阶段，文章采用了Meta-learning的方法，内循环阶段更新总体Loss，外循环阶段更新三个Loss的总和。Meta-learning原理可以参考历史文章<a href="https://link.zhihu.com/?target=http://mp.weixin.qq.com/s?__biz=MzIyOTUyMDIwNg==&mid=2247484082&idx=1&sn=2246b9a98c8a0f8d46fbbd3fc2851267&chksm=e8402493df37ad85ebde8754d7832945f1bddff79094beb8d99aa8931cb06a2c22f855b9b719&scene=21%23wechat_redirect">Meta-learning核心思想及近年顶会3个优化方向</a>。</p>
<img src="/2023/06/06/Finetune/Finetune%E7%BD%91%E4%B8%8A%E5%8D%9A%E5%AE%A2/006C3FgEgy1h0hixa1sffj30k0089t9i.jpg" alt="006C3FgEgy1h0hixa1sffj30k0089t9i">



<h2 id="3-招式3：在Finetune阶段调整网络结构"><a href="#3-招式3：在Finetune阶段调整网络结构" class="headerlink" title="3. 招式3：在Finetune阶段调整网络结构"></a>3. 招式3：在Finetune阶段调整网络结构</h2><p>之前介绍的迁移学习方法，大多数都是通过Finetune对Pretrain模型的参数进行调整。然而<strong>，下游的Target任务可能需要和Source任务采用不同的模型结构来更好的进行学习</strong>。因此，<strong>TransTailor: Pruning the Pre-trained Model for Improved Transfer Learning（AAAI 2021）</strong> 提出了一种在Finetune阶段动态剪枝的方法，实现Finetune阶段不仅能够调整模型参数，还能调整模型网络结构。该方法分为Target-aware Pruning和Importance-aware Finetuning两个阶段。在Target-aware Pruning阶段，对于网络中每一层的每一个filter，都对应一个可学习的权重，把Pretrain模型的参数Freeze住，使用Target任务的数据和优化目标进行训练，得到每组参数最终对应的权重，训练过程可以表示为：<br>$$<br>\alpha^*&#x3D;\arg \min _\alpha \mathcal{L}\left(D_t ; W_f^s \odot \alpha\right)<br>$$<br>这个重要性权重会使用泰勒变换，融合全局各层的打分结果得到全局的打分，最后将打分较低的网络参数剪枝掉。在Importance-aware Finetuning，会结合第一阶段得到的参数打分进行Finetune，具体的，通过将每组参数的打分结果乘到参数上，的到参数的转换结果进行前向传播。最终两个过程交替进行，直到得到最终模型。</p>
<img src="/2023/06/06/Finetune/Finetune%E7%BD%91%E4%B8%8A%E5%8D%9A%E5%AE%A2/006C3FgEgy1h0hixabsy3j30k006tdgj.jpg" alt="006C3FgEgy1h0hixabsy3j30k006tdgj">



<h2 id="4-招式4：学习每组参数Transfer的方式"><a href="#4-招式4：学习每组参数Transfer的方式" class="headerlink" title="4. 招式4：学习每组参数Transfer的方式"></a>4. 招式4：学习每组参数Transfer的方式</h2><p>在利用Pretrain模型进行迁移学习时，我们往往需要决定哪些网络的参数要Freeze，哪些网络参数跟随Target任务Finetune。例如，在CV领域，一些研究表明底层网络能够提取出更一般的图像规律，而接近分类层的参数对于不同Task差异很大，因此为了不将Pretrain阶段学到的知识破坏，将底层参数Freeze，只Finetune上层参数，会最大限度保留Pretrain阶段在大量数据学到的知识，提升迁移学习效果。然而，不同任务需要Freeze的参数存在差异，人工调试不同的Transfer方式（哪些层Freeze、哪些层Finetune）效率很低。同时，一般的Finetune假设每个Target样本都应该使用相同的Finetune方式，这也是不合理的。例如，和source domain更相似的样本，从source domain迁移更多知识更有帮助。因此，学术界出现一些相关工作，自动化学习每层以及每个样本的迁移策略。</p>
<p>在<strong>SpotTune: Transfer Learning through Adaptive Fine-tuning（CVPR 2019）</strong> 这篇文章中，提出了对于<strong>每个样本</strong>学习一个个性化的迁移方式。对于每个样本，经过网络的每层可以选择是使用Pretrain模型的原始参数，还是使用Pretrain模型初始化后Finetune的参数。模型通过一个Policy Network，输入每个样本的特征（一般使用Pretrain模型对样本的表征向量），输出模型每组参数的迁移方式（使用Pretrain模型原始参数，或使用Pretrain模型初始化后Finetune的参数）。这个过程中需要对两种迁移方式进行采样，而采样运算不可导。为了让该运算可导，本文使用了Gumbel-Max Trick生成采样结果。SpotTune的模型结构如下图所示：</p>
<img src="/2023/06/06/Finetune/Finetune%E7%BD%91%E4%B8%8A%E5%8D%9A%E5%AE%A2/006C3FgEgy1h0hixaemucj30k0077mya.jpg" alt="006C3FgEgy1h0hixaemucj30k0077mya">

<p>SpotTune实现了每个样本个性化的Finetune策略学习，但是只能做到layer维度。<strong>AdaFilter: Adaptive Filter Fine-tuning for Deep Transfer Learning（AAAI 2020）</strong> 提出了能够在filter维度实现每个样本的Finetune策略学习。与SpotTune类似，Finetune策略仍然为使用Pretrain模型的原始参数，或使用Pretrain模型初始化后Finetune的参数两种。与SpotTune不同的是，AdaFilter使用RNN学习每层各个channel的Finetune策略，每层的Finetune策略选择依赖于上一层输出的表示（SpotTune则是根据样本同时产出所有层的Finetune策略）。</p>
<p>TODO…</p>
<img src="/2023/06/06/Finetune/Finetune%E7%BD%91%E4%B8%8A%E5%8D%9A%E5%AE%A2/006C3FgEgy1h0hixacx2rj30k00c375s.jpg" alt="006C3FgEgy1h0hixacx2rj30k00c375s">

<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a><strong>5. 总结</strong></h2><p>本文介绍了7篇顶会论文中对Finetune阶段进行的改进，包括Finetune过程使用Pretrain模型做约束、选择性地对Pretrain模型进行迁移、在Finetune阶段调整网络结构以及学习每组参数Transfer的方式4种类型。Pretrain-Finetune的核心问题在于，如何考虑到Target Task的样本特性，将Pretrain的知识合理迁移到Target Task的模型上。其中每个样本个性化地进行Finetune策略学习，可能是后续可以继续深入研究的方向。</p>
]]></content>
      <categories>
        <category>Finetune</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Finetune</tag>
      </tags>
  </entry>
  <entry>
    <title>Rescore、Rescoring</title>
    <url>/2022/06/27/Code-Switching/rescore/</url>
    <content><![CDATA[<h1 id="Rescore、Rescoring"><a href="#Rescore、Rescoring" class="headerlink" title="Rescore、Rescoring"></a>Rescore、Rescoring</h1><p>任务：训好的中英混（中文为主）的声学模型，出来n-best路径，用训好的语言模型，对每条路径（文本序列）得到其语言模型分数，查看每条路径的分数，与之前的n-best每条路径声学模型分数，加权求和，从而选出一条文本序列，作为最终的文本序列；</p>
<p>注意，这里并不是语言模型参与ctc解码过程（lattice过程中加入语言模型分数），而是出来的n-best进行rescoing；</p>
<p>其中，这里的语言模型，可以是：</p>
<ol>
<li>预训练好的中英混模型，但是这个不太可能；</li>
<li>预训练的中文模型（因为任务以中文为主），用现有中英混数据进行finetune（迁移学习）；</li>
</ol>
<p>注意，n-best出来最好有标点，给语言模型比较好？没有标点给语言模型，是不是不太好？</p>
<p>用来rescore的pretrain LM的词典和声学模型的词典可以不同！！</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>finetune NN LM，字建模（词建模 词数太多，分类数太多）</p>
<h2 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h2><ol>
<li>首先用开源的预训练模型LM，对10best进行rescore，选取困惑度最小的路径最为最终结果<ol>
<li><a href="https://github.com/tal-tech/edu-bert">好未来开源模型</a>：效果变差：wer：4% —&gt; 5%</li>
<li>hugging face开源中文模型Albert：wer：TODO</li>
</ol>
</li>
<li>开源的预训练LM作为基础模型，用7G数据作为训练集，1.4w条中的部分作为验证集，fine-tune pretrain LM，得到新的LM，对10best进行rescore，选取困惑度最小的路径，<ol>
<li>基于好未来开源预训练模型进行LM fine-tune，效果 TODO</li>
<li>基于hugging face开源中文模型Albert，效果 TODO</li>
</ol>
</li>
<li>开源的预训练纯中文模型，增加一些和声学模型的词典的英文bpe建模单元相同的英文字，修改模型，部分初始化置零，fine-tune pretrain LM</li>
</ol>
<p>step 1）中文NN LM，这个可以是开源的pretrain model</p>
<p>step 2）固定一些参数，用其他领域中英数据 finetune</p>
<p>step 3）基于步骤2，再固定一些参数，用垂直领域7G中英文本，finetune</p>
]]></content>
      <categories>
        <category>Code-Switching</category>
      </categories>
      <tags>
        <tag>Code-Switching</tag>
      </tags>
  </entry>
  <entry>
    <title>SpotTune Transfer Learning through Adaptive Fine-tuning</title>
    <url>/2023/07/02/Finetune/SpotTune%20Transfer%20Learning%20through%20Adaptive%20Fine-tuning/</url>
    <content><![CDATA[<h1 id="SpotTune-Transfer-Learning-through-Adaptive-Fine-tuning"><a href="#SpotTune-Transfer-Learning-through-Adaptive-Fine-tuning" class="headerlink" title="SpotTune: Transfer Learning through Adaptive Fine-tuning"></a>SpotTune: Transfer Learning through Adaptive Fine-tuning</h1><blockquote>
<p>Guo, Yunhui, et al. “Spottune: transfer learning through adaptive fine-tuning.” <em>Proceedings of the IEEE&#x2F;CVF conference on computer vision and pattern recognition</em>. 2019. citations：344</p>
</blockquote>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><p>利用深度神经网络进行迁移学习的典型方法是使用目标任务的数据对源任务预训练的模型进行微调</p>
<h3 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h3><p>提出了一种自适应微调方法，称为SpotTune，它为目标任务找到每个instance的最佳微调策略。给定来自目标任务的图像，策略网络用于决定样本是经过finetune层还是pretrain层。</p>
<h3 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h3><p>在Visual Decathlon datasets，SpotTune方法效果最好。</p>
<h3 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h3><p>整体模型变成原模型的两倍多大，多了policy network的计算量。</p>
<h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><p>Dynamic Routing：通过某种决策方法在NN里选择用哪些layer哪些不用，来改进精度。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>finetune有这些方式：</p>
<ol>
<li>pretrain网络做初始模型，用target training data更新网络里的所有参数，但是当训练数据少、模型参数多时，很容易过拟合。</li>
<li>pretrain网络做初始模型，前几层freeze，只更新后面几层参数，但是具体要freeze到第几层，要手调试出来，不够高效。（不清楚将微调限制在最后的连续层是否是最好的选择，因为集合效应ensemble effect  削弱了早期或中间层应该与普通的低级或中级特征共享的假设）</li>
</ol>
<p>Transfer Learning  前人工作：</p>
<ol>
<li>[Yosinski ](J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural networks? In NeurIPS, 2014. 1, 2, 5) 分析了底层、中间层、顶层的迁移特征哪个最有影响。但尚不清楚他们的结论是否适用于现在的多路结构，如残差网络或DenseNets。</li>
<li>[Yang](Z. Yang, B. Dhingra, K. He, W. W. Cohen, R. Salakhutdinov, Y. LeCun, et al. Glomo: Unsupervisedly learned relational graphs as transferable representations. arXiv preprint arXiv:1806.05662, 2018. 2) 提出将关系图作为可迁移特征，而不是用一元特征。</li>
<li>[Li ](X. Li, Y. Grandvalet, and F. Davoine. Explicit inductive bias for transfer learning with convolutional networks. In ICML, 2018. 2, 6) 研究了几种明确提高微调模型与原始预训练模型相似度的正则化方案。</li>
</ol>
<p>本文提出一种决策方法，决定对于<strong>每个</strong>样本来说，哪些层要freeze、哪些层要更新。不同样本freeze和更新的层不同。称为input-dependent fine-tuning。</p>
<img src="/2023/07/02/Finetune/SpotTune%20Transfer%20Learning%20through%20Adaptive%20Fine-tuning/image-20230607222549418.png" alt="image-20230607222549418" style="zoom:50%;">

<p>样本输入网络，策略从从神经网络输出参数化的离散分布中采样，它决定预训练模型的哪些层应该微调或将其参数冻结。</p>
<p>因为这些决策函数是离散的，不可微的，因此用Gumbel Softmax sampling approach来训练策略网络。</p>
<p>​	</p>
<p>本文还提出了：We also propose a global variant of our approach that constrains all the input examples to fine-tune the same set of k layers which can be distributed anywhere in the network. This variant results in fewer parameters in the final model as the corresponding set of pre-trained layers can be discarded.</p>
<p>Feature Sharing Across Tasks.  </p>
<h4 id="Dynamic-Routing"><a href="#Dynamic-Routing" class="headerlink" title="Dynamic Routing"></a>Dynamic Routing</h4><p>本文方法用的conditional computation methods。前人提出的dynamic routing方法有： </p>
<ul>
<li>Bengio et al. [2] used sparse activation policies to selectively execute neural network units on a per-example basis  </li>
<li>Shazeer et al. [43] introduced a Sparsely-Gated Mixture-of-Experts layer, where a trainable gating network determines a sparse combination of sub-networks (experts) to use for each example.</li>
<li>Wu, Nagarajan et al. proposed BlockDrop [49], a method that uses reinforcement learning to dynamically select which layers of a Residual Network to execute, exploiting the fact that ResNets are resilient to layer dropping [47]</li>
<li>Veit and Belongie [46] investigated the same idea using Gumbel Softmax [18] for on-the-fly selection of residual blocks.</li>
</ul>
<p>[Veit and Belongie](A. Veit and S. Belongie. Convolutional networks with adaptive inference graphs. In ECCV, 2018. 3) 提出用Gumbel Softmax 实时选择用哪个residual  block，本文的dynamic routing也是基于Gumbel trick，但不是通过丢掉一些层来改进精度，是通过froze或finetune一些层来改进精度的。</p>
<h3 id="SpotTune-Overview"><a href="#SpotTune-Overview" class="headerlink" title="SpotTune Overview"></a>SpotTune Overview</h3><p>以残差网络结构为例，预训练模型是resnet网络结构，则第 $l$ 层的residual block表示为：<br>$$<br>x_l&#x3D;F_l(x_{l-1})+x_{l-1}<br>$$<br>freeze住这里的$F_l$，额外添加一个结构一样的$\hat F_l$（这里以$F_l$参数作为初始化，参数可更新），于是第 $l$ 层的输出表示为：<br>$$<br>x_l&#x3D;I_l(x)\hat F_l(x_{l-1})+(1-I_l(x))F_l(x_{l-1})+x_{l-1}<br>$$<br>其中，$I_l(x)$是一个二进制随机变量，作用是policy，表示在当前输入下，是否应该冻结或微调residual block。（要不然经过固定参数，要不然经过更新参数）</p>
<p>$I_l(x)$ 从freeze或finetune这两个输出类的离散分布中采样。因为是离散的，不可微，难以通过反向传播进行优化。有一些方法允许通过离散节点进行反向传播。本文用的Gumbel Softmax sampling approach来规避这个问题。</p>
<p>Gumbel-Max trick 用来抽取样本，从一个分类分布中抽取，这个分类分布是一个参数化后的分布，写成 ${\alpha_1,\alpha_2,…,\alpha_z}$  ，每个$\alpha_z$ 是<strong>标量</strong>，$z$ 是分类数目。对于本文这个任务，是要选择freeze或finetune，因此 $z&#x3D;2$，每个residual block后都有 $\alpha_1$ 和 $\alpha_2$ ，</p>
<p>整个模型结构如下图：</p>
<p>可以看到，其实是两个一模一样的网络结构并联的，一个是freeze网络，一个是finetune网络，要选择走哪一个网络，选择的方法通过一个额外的policy network，样本输入给policy network，policy network输出通过gumbel-softmax samples，找二分类的argmax，选择是freeze或finetune。</p>
<p>反向传播时，对于gumbel-softmax samples方法用softmax反向传播。</p>
<img src="/2023/07/02/Finetune/SpotTune%20Transfer%20Learning%20through%20Adaptive%20Fine-tuning/image-20230628010926163.png" alt="image-20230628010926163" style="zoom: 67%;">



<p>如果随机变量 $G &#x3D; - \log(- \log(U))$，$U$从均匀分布 $U\sim Unif[0,1]$ 中采样，则称其具有标准Gumbel 分布。</p>
<p>从标准Gumbel分布 $Gumbel(0,1)$ 中抽$z$个样本 $G_i,…,G_z$；</p>
<p>离散样本表示为：<br>$$<br>X &#x3D; \arg \max_i[\log \alpha_i + G_i]<br>$$<br>式子里argmax操作不可微，所以不用argmax，用softmax（平滑、离散变连续）<br>$$<br>Y_i&#x3D;\frac{\exp \left(\left(\log \alpha_i+G_i\right) &#x2F; \tau\right)}{\sum_{j&#x3D;1}^z \exp \left(\left(\log \alpha_j+G_j\right) &#x2F; \tau\right)} \quad \text { for } i&#x3D;1, . ., z<br>$$<br>温度系数$\tau$ 接近0时，接近离散分布（one-hot vector）</p>
<p>前向传播时，先从标准gumbel分布中采样，得到样本G，然后根据上式得到输出X，就就是决策网络的输出。这里每层的$\alpha$ 和G不同，但是每层的输入都是一样的就是input feature。</p>
<p>后向传播时，用的是softmax近似离散argmax操作，公式4的偏导作为离散的偏导来反向传播。</p>
<h3 id="Compact-Global-Policy-Variant"><a href="#Compact-Global-Policy-Variant" class="headerlink" title="Compact Global Policy Variant"></a>Compact Global Policy Variant</h3><p>每层都做policy network计算量较大，本文提了一种在resnet block结构上的简化policy network计算量的方法。</p>
<p>模型结构堆叠了很多个结构相同的resnet block，对于每个resnet block来说，记录里面使用finetune block的比例（训练数据集是target数据集时），引入限制loss：<br>$$<br>l_k&#x3D;\left(\left(\sum_{l&#x3D;1}^L v_l\right)-k\right)^2<br>$$<br>其中 $v_l$ 是比例。也就是说，finetune的比例之和与需要finetune的block数目k越接近越好。</p>
<p>增加另一个loss：<br>$$<br>l_e&#x3D;\sum_{l&#x3D;1}^L-v_l \log v_l .<br>$$<br>The additional loss $l_e$ pushes $v_l$ to be exactly 0 or 1, so that a global policy can be obtained for all the images.   </p>
<p>最终loss：<br>$$<br>l&#x3D;l_c+\lambda_1 l_k+\lambda_2 l_e<br>$$</p>
]]></content>
      <categories>
        <category>Finetune</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Finetune</tag>
      </tags>
  </entry>
  <entry>
    <title>Delay-penalized transducer for low-latency streaming ASR</title>
    <url>/2023/03/12/k2/Delay-penalized%20transducer%20for%20low-latency%20streaming%20ASR/</url>
    <content><![CDATA[<h1 id="Delay-penalized-transducer-for-low-latency-streaming-ASR"><a href="#Delay-penalized-transducer-for-low-latency-streaming-ASR" class="headerlink" title="Delay-penalized transducer for low-latency streaming ASR"></a>Delay-penalized transducer for low-latency streaming ASR</h1><blockquote>
<p>Kang, Wei, et al. “Delay-penalized transducer for low-latency streaming ASR.” <em>arXiv preprint arXiv:2211.00490</em> (2022).</p>
<p>公众号 新一代Kaldi <a href="https://mp.weixin.qq.com/s?__biz=MzkyMzI5NTM2Ng==&mid=2247485555&idx=1&sn=7e67970fff5cd6594a07f1101143f587&scene=21#wechat_redirect">低时延 RNN-T 训练</a></p>
<p>公众号 新一代Kaldi <a href="https://mp.weixin.qq.com/s/zOBbLeqKASLE9cvOYwCM4w">Delay Penalty For RNN-T and CTC</a></p>
<p>github：<a href="https://github.com/k2-fsa/k2/pull/976">https://github.com/k2-fsa/k2/pull/976</a> 、 <a href="https://github.com/k2-fsa/icefall/pull/654">https://github.com/k2-fsa/icefall/pull/654</a></p>
<p>k2 fsa 实现计算 CTC 目标函数：<a href="https://github.com/k2-fsa/next-gen-kaldi-wechat/blob/master/pdf/LF-MMI-training-and-decoding-in-k2-Part-I.pdf">https://github.com/k2-fsa/next-gen-kaldi-wechat/blob/master/pdf/LF-MMI-training-and-decoding-in-k2-Part-I.pdf</a></p>
</blockquote>
<ul>
<li><p><strong>解决什么问题</strong></p>
<p>解决CTC、RNNT的transducer模型（并且是流式模型）本身带来的输出延迟 symbol delay，造成的识别实时性效果体验不佳。</p>
</li>
<li><p><strong>用了什么方法</strong></p>
<p>修改symbol的概率，具体做法是添加一个小常数 $\lambda$ 乘以 (T&#x2F;2 - t)，得到一个值（其中T是帧数，t是输出某个token对应的时刻），在transducer模型输出的可能路径上，把这个值作用在非blank对数概率上(归一化后)。</p>
<p>这里的 (T&#x2F;2 - t) 物理意义是，在输出的 $T \times U$ 的可能路径图上，如果输出token对应的时刻越前（小），则 (T&#x2F;2 - t) 的值越大，设定是这个值（偏移量）越大表示时延越小。希望token输出的时间越早越好。</p>
<p>该方法通过修改symbol的概率，近似等价于对loss添加正则项，进行 时延惩罚，delay-penalized 。</p>
</li>
<li><p><strong>效果如何</strong></p>
</li>
<li><p><strong>还存在什么问题</strong></p>
<p>idea：非流式模型训练时时延低，那么是否可以用非流式模型作为基础模型finetune流式模型，finetune过程 添加正则、或者loss加 该输出symbol的时刻却输出blank的情况 的惩罚，目的就是让流式模型不要老想着看到更多context才输出symbol，用来用来改善流式模型的时延问题。</p>
<p>idea：训练逻辑是对所有可能路径求和，但是hmm就没有对齐问题，因为hmm有转移概率，那么是否可以加一个转移概率，也每次随反向传播而更新。</p>
<p>idea：把可能路径图的右侧可能路径都不要了。只要左侧的。强行让网络学习。</p>
<p>idea：给越早的t越大的鼓励，让它概率越高，最好在读了一半音频的时候就给我输出整条文本，这样添加的第二项还是正数。别人才读了一半就要输出整条识别文本吗，虽然这里的时刻不是真实的时刻，是下采样过的，因此条件可能是满足的，T&#x2F;2对应的已经是差不多读完的时刻了。保险起见所以最好还是有一个对齐groundtruth，只要比groundtruth早，就应该鼓励。所以可以用tts离提出的attention做alignment，修改网络结构，利用上这个attention图，知道大概时间，再鼓励比它早的输出。</p>
</li>
<li><p><strong>本文贡献</strong></p>
<ul>
<li>提出了delay-penalized transducer，进行symbol delay惩罚，不需要用额外的token-time对齐来帮助减少symbol delay。</li>
<li>详细证明了为什么可以鼓励低延迟对齐和惩罚高延迟对齐。</li>
<li>实验表面，通过调整超参数 $\lambda$，可以实现延迟和精度之间的可调权衡。</li>
</ul>
</li>
</ul>
<h2 id="名词"><a href="#名词" class="headerlink" title="名词"></a>名词</h2><h4 id="1-时延-delay"><a href="#1-时延-delay" class="headerlink" title="1. 时延 delay"></a>1. 时延 delay</h4><p>symbol deay，这里的时延指的是<strong>由模型本身带来的输出延迟</strong>，比如一个字是在第 100 帧说的，但是直到送了 150 帧数据进去才输出来。</p>
<p>造成时延的原因：时延问题可以说是端到端模型基因里带来的缺点，一个大家都比较认可的解释是，<code>RNN-T/CTC</code> 这样基于序列的损失函数对于 <code>Alignments</code> 的优化是无差别的，即只管优化能输出 transcript 对应的路径，不管这个路径是先输出 <code>symbol</code> 还是先输出 <code>blank</code>。所以，对于流式模型的训练，由于当前看到的 <code>context</code> 有限，模型总是倾向于看到更多的 context 后再决定是否输出 <code>symbol</code>。</p>
<h4 id="2-alignment"><a href="#2-alignment" class="headerlink" title="2. alignment"></a>2. alignment</h4><p>可能的路径，也叫alignment对齐，也叫token-time alignment。</p>
<h2 id="时延正则"><a href="#时延正则" class="headerlink" title="时延正则"></a>时延正则</h2><p>时延正则的目标是给低时延的路径一些鼓励（加分），给高时延的路径一些抑制（减分）。最终的实现就是给 <code>lattice</code> 中每条输出 <code>symbol</code> 的边加一个分数，这个分数根据边所在的帧而不同，以中轴线为基准，左侧加<code>正值</code>（鼓励），右侧加<code>负值</code>（惩罚），示意图如下图所示。这样位于左上角的路径的分数得到增强，位于右下角的路径分数会被抑制，从而达到降低时延的目的。</p>
<img src="/2023/03/12/k2/Delay-penalized%20transducer%20for%20low-latency%20streaming%20ASR/image-20230309194826398.png" alt="image-20230309194826398" style="zoom:67%;">

<h3 id="路径分数"><a href="#路径分数" class="headerlink" title="路径分数"></a>路径分数</h3><p>原目标函数：最大化所有对齐路径的路径概率之和。<br>$$<br>\mathcal{L}&#x3D;\log \sum_i \exp(s_i)<br>$$<br>$s_i$是某一条可能的路径概率，是log域的概率；计算路径概率和一般用前后向算法，到某个节点 $(t,u)$ 的路径log概率记为$\alpha(t,u)$ ，表示已经输出的token序列 $y_{0…u}$ 和已经输入的特征序列 $x_{0…t}$ ，计算公式可以递归地写为：<br>$$<br>\alpha(t, u)&#x3D;\log \operatorname{Add}(\alpha(t, u-1)+y(t, u-1),\quad \alpha(t-1, u)+\varnothing(t-1, u))<br>$$<br>其中 LogAdd 定义为：<br>$$<br>\log \operatorname{Add}(a, b)&#x3D;\log \left(e^a+e^b\right) .<br>$$<br>初始化 $\alpha(0,0)$ 为 0 . The total log-probabi over all alignments path $\mathcal{L}$ is:<br>$$<br>\mathcal{L}&#x3D;\alpha(T-1, U)+\varnothing(T-1, U)<br>$$<br>由于是所有路径和，流式模型会偏向于图1的蓝线情况，即由于当前看到的 <code>context</code> 有限，模型总是倾向于看到更多的 context 后再决定是否输出 <code>symbol</code>。</p>
<p>随着训练步数增加（随着模型越训越好），时延会增加：</p>
<img src="/2023/03/12/k2/Delay-penalized%20transducer%20for%20low-latency%20streaming%20ASR/image-20230310152857290.png" alt="image-20230310152857290" style="zoom: 67%;">



<h3 id="Delay-penalized-Transducer"><a href="#Delay-penalized-Transducer" class="headerlink" title="Delay-penalized Transducer"></a>Delay-penalized Transducer</h3><p>为了惩罚 RNN-T 模型的时延，我们的想法是在目标函数 $\mathcal{L}$ 上增加一个时延正则项 $\mathcal{L}<em>{\text {delay }}$ ，得到一个新的目标函数 $\mathcal{L}</em>{\text {aug }}$：<br>$$<br>\mathcal{L}<em>{\text {aug }}&#x3D;\mathcal{L}+\mathcal{L}</em>{\text {delay }}<br>$$<br>$\mathcal{L}<em>{\text {delay }}$ 表示 lattice 中所有路径的<strong>平均时延分数</strong>（值越大，代表时延越低）, 定义为:<br>$$<br>\mathcal{L}</em>{\text {delay }}&#x3D;\lambda \sum_i d_i w_i<br>$$<br>其中, <strong>$d_i$ 为路径 $i$ 的时延分数</strong>, $\lambda$ 是一个超参数, $w_i$ 为路径 $i$ 的分数 $s_i$ 在整个 lattice 中的比重：<br>$$<br>w_i&#x3D;\frac{\partial \mathcal{L}}{\partial s_i}&#x3D;\frac{\exp \left(s_i\right)}{\sum_j \exp \left(s_j\right)}<br>$$<br>原本每一条路径的权重都相同，都是1&#x2F;N，N是可能路径数，现在根据路径分数不同，权重也不同，所以路径分数大的，权重也大。</p>
<p>注意这里，我们用前后向算法，是不需要把每条路径都各自有其统计值的，但是这个公式这样写，就变成每条路径都要记录其路径分数了。</p>
<p>此处, $d_i$ 的值越大, 表示路径 $i$ 的时延越低。</p>
<p>通过引入时延正则项 $\mathcal{L}_{\text {delay }}$ ，RNN-T 会被约束着去<strong>增强那些时延较低（ $d_i$ 较大）的路径 ，</strong>为他们赋予一个更高的分数 $s_i$ 。</p>
<p>在优化 $\mathcal{L}$  的过程中，并没有显式计算各个路径 $i$ 的分数 $s_i$。那么问题来了，为了优化  $\mathcal{L}<em>{\text {aug }}$ ，难道我们还要去显示地求出各个路径 $i$ 的分数 $s_i$ ，来计算 $w_i$ 吗？这无疑是一种极其低效且不优雅的做法。下面给出数学公式，证明可以优雅地实现 $\mathcal{L}</em>{\text {aug }}$ 地优化。</p>
<p>所有路径权重 $w_i$ 之和为1，即 $\large \sum_i w_i&#x3D;\sum_i \frac{\partial \mathcal{L}}{\partial s_i}&#x3D;\frac{\sum_i \exp \left(s_i\right)}{\sum_j \exp \left(s_j\right)}&#x3D;1$</p>
<p>新目标函数 $\mathcal{L}<em>{\text {aug }}$ 对路径分数 $s_i$偏导为<br>$$<br>\frac{\partial \mathcal{L}</em>{\text {aug }}}{\partial s_i}&#x3D;\frac{\partial \mathcal{L}}{\partial s_i}+\frac{\partial \mathcal{L}_{\text {delay }}}{\partial s_i}<br>$$<br>根据上式可以写成：</p>
<p>$$<br>\begin{aligned}<br>\frac{\partial \mathcal{L}_{\text {delay }}}{\partial s_i}&amp;&#x3D;\lambda \left( \sum_id_i\frac{\exp(s_i)}{\sum_j\exp(s_j)}\right)’\<br>&amp;&#x3D; \lambda\left(\frac{\sum_id_i \exp(s_i)}{\sum_j\exp(s_j)}\right)’\<br>&amp;&#x3D;\lambda\left(\frac{d_i \exp \left(s_i\right)}{\sum_j \exp \left(s_j\right)}-\frac{\sum_i d_i\left(\exp \left(s_i\right)\right)^2}{\left(\sum_j \exp \left(s_j\right)\right)^2}\right)<br>\end{aligned}<br>$$<br>第二行用除法求导展开得到第三行。</p>
<p>可化简为：<br>$$<br>\frac{\partial \mathcal{L}<em>{\text {delay }}}{\partial s_i}&#x3D;\lambda \frac{\left(d_i-d</em>{\text {avg }}\right) \exp \left(s_i\right)}{\sum_j \exp \left(s_j\right)}<br>$$<br>其中 $d_{\mathrm{avg}}$ 表示为：<br>$$<br>d_{a v g}&#x3D;\sum_i d_i w_i<br>$$<br>因此可以得到<br>$$<br>\frac{\partial \mathcal{L}<em>{\mathrm{aug}}}{\partial s_i}&#x3D;\frac{\left(1+\lambda\left(d_i-d</em>{\mathrm{avg}}\right)\right) \exp \left(s_i\right)}{\sum_j \exp \left(s_j\right)}<br>$$</p>
<p>当 $\lambda$ 很小时，$\left(1+\lambda\left(d_i-d_{\mathrm{avg}}\right)\right)$ 近似于 $\exp \left(\lambda \left(d_i-d_{\mathrm{avg}}\right)\right)$ ，（$1&#x3D;e^0$） ， 因此可以将上式写为：<br>$$<br>\frac{\partial L_{\text {aug }}}{\partial s_i} \approx \frac{\exp \left(\lambda\left(d_i-d_{\text {avg }}\right)+s_i\right)}{\sum_i \exp \left(s_i\right)}<br>$$<br>时延loss的所有路径求和的偏导 $\large \sum_i\frac{\partial \mathcal{L}_{\text {delay }}}{\partial s_i}&#x3D;\lambda \frac{\left(\sum_i d_i-\sum_i d_i \sum_i w_i\right) \exp \left(s_i\right)}{\sum_j \exp \left(s_j\right)} &#x3D; 0$</p>
<p>因此新的loss对所有路径求和的偏导：<br>$$<br>\sum_i \frac{\partial \mathcal{L}<em>{\mathrm{aug}}}{\partial s_i}&#x3D;\sum_i \frac{\partial \mathcal{L}}{\partial s_i}+\sum_i \frac{\partial \mathcal{L}</em>{\text {delay }}}{\partial s_i}&#x3D;1<br>$$<br>归一化为（当$\lambda$很小时）：<br>$$<br>\begin{aligned}<br>\frac{\partial \mathcal{L}<em>{\mathrm{aug}}}{\partial s_i} &amp;\approx \frac{\exp \left(\lambda\left(d_i-d</em>{\mathrm{avg}}\right)+s_i\right)}{\sum_i \exp \left(\lambda\left(d_i-d_{\mathrm{avg}}\right)+s_i\right)} \<br>&amp;\approx \frac{\exp(-\lambda d_{avg})\exp(\lambda d_i+s_i)}{\exp(-\lambda d_{avg})\sum_i\exp(\lambda d_i+s_i)} \<br>&amp;\approx  \frac{\exp(\lambda d_i+s_i)}{\sum_i\exp(\lambda d_i+s_i)}<br>\end{aligned}<br>$$</p>
<p>原来的路径概率分数修改为：<br>$$<br>s_i’&#x3D;\lambda d_i+s_i<br>$$<br>加了一个时延分数（再乘一个常数系数），也就是在路径概率分数也考虑进去了时延的分数。</p>
<p>替换成 $s_i’$ 后，和原来的 loss $\mathcal{L}$ 对 $s_i$ 偏导的形式长得完全一样。</p>
<p>从 $s_i’&#x3D;\lambda d_i+s_i$ 可以看出，新的路径分数和原来的路径分数就差一项 $\lambda d_i$ ，可以说很接近了，那么也可以自如的使用前后向算法了，只是把每个时刻的路径分数要替换一下就好，替换完还是正常的前后向算法公式。（不需要为了计算每条路径的分数，而不得不舍弃用前后向算法了。）</p>
<p>这里提出的假设是，低时延要对应着大的时延分数d，因此把时延分数设置为：<br>$$<br>d_i&#x3D;\sum_u\left(\frac{T-1}{2}-\pi_u\right)<br>$$<br>其中，$u$ 是一句文本的某个字，token。$\pi_u$ 是这条路径下输出一句话的某个字 $u$ 对应音频的时刻，帧索引。也就是这条可能路径认为的，一句话里某个字是什么时候读出的。时刻越前（小），表示越早读出，延迟越小。</p>
<p>对于每个可能路径$i$，都有输出token的时刻$\pi_u$，每个token都有距离中间帧的偏移量，一句话的所有token偏移量求和就是这个可能路径 $i$ 的时延分数 $d_i$ 。</p>
<p>如果输出token对应的时刻越前（小），则 (T&#x2F;2 - t) 的值越大，就是距离中间帧越远，设定是这个值（偏移量）越大表示时延越小。如果比中间帧还晚出来，还会是负的。</p>
<p>其实这里直接用 $\sum_u-\pi_u$ 也可以，加上 $\frac{T-1}{2}$ 是防止时延惩罚项改变loss的值太多、太过了。这个中间帧偏移 $\frac{T-1}{2}$ 是常数，不会影响偏导。是为了使得引入时延正则后，loss 函数的数值不会和原来相差太大。</p>
<h3 id="延迟惩罚具体实现"><a href="#延迟惩罚具体实现" class="headerlink" title="延迟惩罚具体实现"></a>延迟惩罚具体实现</h3><p>在token-time alignment是，对于输出symbol的token（非blank的token）的log概率加上一个值，修改后的symbol token概率值：<br>$$<br>y’(t,u)&#x3D;y(t,u)+\lambda \times \left(\frac{T-1}{2}-t\right)<br>$$<br>如图2所示。</p>
<p>给越早的t越大的鼓励，让它概率越高，最好在读了一半音频的时候就给我输出整条文本，这样添加的第二项还是正数。别人才读了一半就要输出整条识别文本吗，虽然这里的时刻不是真实的时刻，是下采样过的，因此条件可能是满足的，T&#x2F;2对应的已经是差不多读完的时刻了。保险起见所以最好还是有一个对齐groundtruth，只要比groundtruth早，就应该鼓励。</p>
<p>&#x3D;&#x3D;因此，在执行 forward-backward 算法之前，我们只需要将 $y(t,u)$ 替换为 $y’(t,u)$ ，即可以一种简单高效的方式（不用计算每一条路径分数了），近似地优化带时延正则的目标函数 $ \mathcal{L}_{\mathrm{aug}}$。&#x3D;&#x3D;</p>
<h3 id="Delay-penalty-for-CTC"><a href="#Delay-penalty-for-CTC" class="headerlink" title="Delay penalty for CTC"></a>Delay penalty for CTC</h3><blockquote>
<p>k2 fsa 实现计算 CTC 目标函数：<a href="https://github.com/k2-fsa/next-gen-kaldi-wechat/blob/master/pdf/LF-MMI-training-and-decoding-in-k2-Part-I.pdf">https://github.com/k2-fsa/next-gen-kaldi-wechat/blob/master/pdf/LF-MMI-training-and-decoding-in-k2-Part-I.pdf</a></p>
</blockquote>
<p><img src="/2023/03/12/k2/Delay-penalized%20transducer%20for%20low-latency%20streaming%20ASR/image-20230312184510889.png" alt="image-20230312184510889"></p>
<p>假设特征序列的长度为5，标签序列为 $Z,O,O$。利用 k2 fsa 我们可以得到对应的 CTC lattice。在上图所示，在 CTC lattice 中，每条从起点到终点的路径为：特征序列和标签序列之间的合法对齐路径。每条边上有三个属性：（1）输入标签（label）；（2）输出标签（ aux_label）；（3）分数，即 <code>log_softmax(encoder_output)</code>。</p>
<p>例如，以下三条对齐路径对应着不同的输入标签序列，他们的输出标签序列经过去除 $\epsilon$ 后，都可以得到 $Z,O,O$：<br>$$<br>\begin{aligned}<br>&amp; Z, O, \varnothing, O, \varnothing \rightarrow Z, O, \epsilon, O, \epsilon \<br>&amp; Z, Z, O, \varnothing, O \rightarrow Z, \epsilon, O, \epsilon, O \<br>&amp; Z, \varnothing, O, \varnothing, O \rightarrow Z, \epsilon, O, \epsilon, O<br>\end{aligned}<br>$$<br>每条对齐路径的时延, 取决于那些首次输出 symbol 的边的帧索引 $\pi&#x3D;\left{\pi_u\right}_0^{U-1}$, 如下面加粗 的 symbol:<br>$$<br>\begin{aligned}<br>&amp; \mathbf{Z}, \mathbf{O}, \varnothing, \mathbf{O}, \varnothing \rightarrow Z, O, \epsilon, O, \epsilon \<br>&amp; \mathbf{Z}, Z, \mathbf{O}, \varnothing, \mathbf{O} \rightarrow Z, \epsilon, O, \epsilon, O \<br>&amp; \mathbf{Z}, \varnothing, \mathbf{O}, \varnothing, \mathbf{O} \rightarrow Z, \epsilon, O, \epsilon, O<br>\end{aligned}<br>$$<br>每条路径中, 那些<strong>首次</strong>输出 symbol 的边的数量是相同的, 为标签序列的长度 $U$ 。我们可以像 上文 RNN-T一样, 定义每个路径 $i$ 的时延分数 $d_i$ 为：这些帧索引 $\pi_u$ 相对于句子中间帧的 offset</p>
<p><img src="/2023/03/12/k2/Delay-penalized%20transducer%20for%20low-latency%20streaming%20ASR/640.png" alt="640"></p>
<p>如上图所示, 为了在 CTC 中实现 $s_i^{\prime}$, 我们只需要修改 lattice 中首次输出 symbol 的边 (标记为 红色）上的分数 $y_t$, 加上与帧索引（相对于中间帧）的 offset:<br>$$<br>y_t^{\prime}&#x3D;y_t+\lambda \times\left(\frac{T-1}{2}-t\right)<br>$$<br>因此, 在执行动态规划算法求 CTC lattice 中所有路径总分数之前, 我们只需要将 $y_t$ 替换为 $y_t^{\prime}$ , 即可以一种简单高效的方式, 近似地优化带时延正则的目标函数 $\mathcal{L}_{\text {aug }}$ 。</p>
<blockquote>
<p>在 k2-fsa CTC 实现过程中，利用 <code>k2.Fsa.get_total_scores()</code> 求得 lattice 所有路径总分数。</p>
</blockquote>
<p>具体地，如何修改 lattice 上那些<strong>首次</strong>输出 symbol 的边的分数，可以参考 k2 的 PR <a href="https://github.com/k2-fsa/k2/pull/1086%EF%BC%8C%E5%92%8C">https://github.com/k2-fsa/k2/pull/1086，和</a> icefall 的 PR <a href="https://github.com/k2-fsa/icefall/pull/669%EF%BC%8C%E9%87%8C%E9%9D%A2%E6%9C%89%E8%AF%A6%E7%BB%86%E7%9A%84%E6%B3%A8%E9%87%8A%E3%80%82">https://github.com/k2-fsa/icefall/pull/669，里面有详细的注释。</a></p>
<h2 id="实验及结果"><a href="#实验及结果" class="headerlink" title="实验及结果"></a>实验及结果</h2><p>目前 <strong><a href="https://github.com/k2-fsa/k2">k2</a></strong> 和 <strong><a href="https://github.com/danpovey/fast_rnnt">fast_rnnt</a></strong> 两个仓库都已经合并了 <code>delay-penalty</code> 的实现(见 <strong><a href="https://github.com/k2-fsa/k2/pull/976">delay-penalty</a></strong>)，只需要在使用 <code>pruned rnnt</code> 损失函数时多传入一个 <code>delay_penalty</code> 参数就可以实现低延时的 <code>RNN-T</code> 训练（注意：<code>rnnt_loss_smoothed</code> 和 <code>rnnt_loss_pruned</code> 两个地方都要加）。我们在 Streaming Conformer 和 LSTM 上都做了一些实验，结果证明我们提出的时延正则方法很有效果，并且能简单的通过调整超参数来平衡准确率和时延。结果中的 <code>MAD</code> 表示 token 的平均时延，<code>MED</code> 表示最后一个 token 的平均时延，时延都是根据 <strong><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner">Montreal-Forced-Aligner</a></strong> 对齐结果来计算的。</p>
<h3 id="Latency-metrics"><a href="#Latency-metrics" class="headerlink" title="Latency metrics"></a>Latency metrics</h3><p>用两种方法来度量流式模型的时延：(1)   Mean Alignment Delay  (MAD) ，(2) Mean End Delay (MED)  ；这里不是训练过程的时延，测试的是识别结果的时延。而识别结果可能会识别错，这种情况要怎么判断时延？</p>
<p>groudtruth word-time alignments  通过强制对齐工具 Montreal Forced Aligner tool 获得。是把识别结果和音频对应上，<strong>这里只考虑识别结果是正确的词的时延</strong>。</p>
<h4 id="Mean-Alignment-Delay-MAD"><a href="#Mean-Alignment-Delay-MAD" class="headerlink" title="Mean Alignment Delay  (MAD)"></a>Mean Alignment Delay  (MAD)</h4><p>预测对齐与groundtruth之间的word时间差的平均值，定义为：<br>$$<br>\text { MAD }:&#x3D;\frac{1}{\sum_{n&#x3D;0}^{N-1} S_n} \sum_{n&#x3D;0}^{N-1} \sum_{s&#x3D;0}^{S_n-1}\left(\hat{t}_s^n-t_s^n\right)<br>$$<br>其中，$\hat{t}_s^n$  是prediction 的第 $s$ 个词的 timestamp， $t_s^n$ 是ground truth 的第 $s$ 个词的timestamp。 $N$ 是句子数。 $S_n$ 是第 $n$ 句话里预测和参考之间匹配的单词数。</p>
<h4 id="Mean-End-Delay-MED"><a href="#Mean-End-Delay-MED" class="headerlink" title="Mean End Delay (MED)"></a>Mean End Delay (MED)</h4><p>MED只考虑句子中最后一个词的发出时间，定义为：<br>$$<br>\text { MED }:&#x3D;\frac{1}{N} \sum_{n&#x3D;0}^{N-1}\left(\hat{t}<em>{e n d}^n-t</em>{e n d}^n\right),<br>$$<br>其中，$\hat{t}<em>{e n d}^n$ 是prediction 最后一个词的发出时间戳timestamp，$t</em>{e n d}^n$  是 ground truth 最后一个词的发出timestamp。</p>
<h3 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h3><p>todo</p>
<h2 id="相似工作"><a href="#相似工作" class="headerlink" title="相似工作"></a>相似工作</h2><h3 id="FastEmit"><a href="#FastEmit" class="headerlink" title="FastEmit"></a>FastEmit</h3><p>Google 提出的 <strong>FastEmit</strong>：<a href="https://arxiv.org/pdf/2010.11148.pdf">https://arxiv.org/pdf/2010.11148.pdf</a> 。本文工作与fastemit进行了对比，结果不相上下，有时略好。</p>
<p>K2也实现了fastemit：<a href="https://github.com/k2-fsa/k2/pull/1069">https://github.com/k2-fsa/k2/pull/1069</a></p>
<p>fastemit思路：把非blank的参数的反向传播的值弄大一点，让这个误差更大点，表示这个路径起更大的作用？</p>
<h3 id="Self-alignment"><a href="#Self-alignment" class="headerlink" title="Self alignment"></a>Self alignment</h3><blockquote>
<p>Jaeyoung Kim, Han Lu, Anshuman Tripathi, Qian Zhang, and Hasim Sak, “Reducing streaming asr model delay with self alignment,” arXiv preprint arXiv:2105.05005, 2021.  </p>
</blockquote>
<p>思路：提高维特比强制对齐左侧一帧对齐的对数概率，维特比对齐的时间复杂度是 $O(T\times U)$，因为要考虑左侧一帧的对齐情况，还需要多 $O(T\times U)$ 的时间复杂度。</p>
]]></content>
      <categories>
        <category>k2</category>
      </categories>
      <tags>
        <tag>k2</tag>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>Fast and parallel decoding for transducer. RNN-T 的快速 GPU 解码</title>
    <url>/2023/03/13/k2/Fast%20and%20parallel%20decoding%20for%20transducer/</url>
    <content><![CDATA[<h1 id="Fast-and-parallel-decoding-for-transducer-RNN-T-的快速-GPU-解码"><a href="#Fast-and-parallel-decoding-for-transducer-RNN-T-的快速-GPU-解码" class="headerlink" title="Fast and parallel decoding for transducer. RNN-T 的快速 GPU 解码"></a>Fast and parallel decoding for transducer. RNN-T 的快速 GPU 解码</h1><blockquote>
<p>Kang, Wei, et al. “Fast and parallel decoding for transducer.” <em>arXiv preprint arXiv:2211.00484</em> (2022).</p>
<p><a href="https://github.com/k2-fsa/icefall">icefall</a> ：fast_beam_search</p>
<p>公众号 新一代Kaldi  <a href="https://mp.weixin.qq.com/s/f0vpatseghLi2piYpUpmQQ">什么是Next-gen Kaldi?</a></p>
<p>解码算法实现：在K2中用ragged tensor数据结构实现</p>
<p>核心代码实现开源在<a href="https://github.com/k2-fsa/k2">https://github.com/k2-fsa/k2</a> (搜索 rnnt_decode.{h,cu})，应用示例开源在<a href="https://github.com/k2-fsa/icefall">https://github.com/k2-fsa/icefall</a> (搜索fast_beam_search)。</p>
</blockquote>
<ul>
<li><p><strong>解决什么问题</strong></p>
<p>transducer模型每个时间步的输出symbol数量没有约束，不确定一个时间步可以输出几个symbol（可以一直输出symbol直到遇到blank），每个输出都依赖上一个输出symbol，因此难以实现并行解码（本来是串行）。</p>
</li>
<li><p><strong>提出什么方法</strong></p>
<p>设计并实现了在 GPU 上实现高效FSA 解码的方案，为此本文对 RNN-T 做了一些改造。</p>
<ol>
<li>在训练过程中，限制了loss function，使得朝向严格单调对齐的方向输出（音频和文本序列单调对齐）。<strong>在RNN-T中使用了无状态的decoder网络，使用有限的left context。</strong></li>
<li>解码过程中（greedy search和beam search），限制了每步参与解码的symbol（本来是不确定可以输出几个symbol），更有效地并行批量解码。<strong>在解码时限制每一帧语音只能输出一个symbol。</strong></li>
<li>提出搜索图可以运行在GPU上的FSA 并行beam search算法。</li>
</ol>
</li>
<li><p><strong>效果如何</strong></p>
<p>实验表明，在提高解码速度的同时，还能降低WER。</p>
<p>在上述两个前提下，又基于 k2 中的 RaggedTensor 实现了帧同步的 beam search 解码。这可能是现今唯一既能使用  FSA 又能运行于 GPU 的解码方法，通过测试我们发现使用 80M 的模型在英伟达 V100 显卡上能并行跑 200 路以上的语音，LibriSpeech 数据集上的解码实时率低至 0.0025。</p>
</li>
<li><p><strong>还有什么问题</strong></p>
</li>
<li><p><strong>本文贡献</strong></p>
<ul>
<li>通过限制每个时间步发射的符号数量为“1”来加速transducer解码。</li>
<li>提出了一种有约束的transucer模型，来提高解码时one-symbol-per-frame的能力。</li>
<li>实现了一种基于fsa的并行beam search算法，该算法使得搜索图能够高效地运行在GPU上。</li>
</ul>
</li>
</ul>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>在 GPU 上实现了高效的 FSA 解码，为此我们对 RNN-T 做了一些改造，首先我们在 RNN-T 中使用了无状态的 decoder 网络，使用有限的 left context；另外，我们在解码时限制每一帧语音只能输出一个 symbol。在这两个前提下，我们基于 <code>k2</code> 中的 RaggedTensor 实现了帧同步的 beam search 解码。这可能是现今唯一既能使用 FSA 又能运行于 GPU 的解码方法，我们测试发现使用 80M 的模型在英伟达 V100 显卡上能并行跑 200 路以上的语音，LibriSpeech 数据集上的解码实时率低至 0.0025。该工作提交至 ICASSP2023，<code>icefall</code>中的<code>fast_beam_search</code>实现了该种解码办法。</p>
<p>上述章节中提到我们在GPU上实现了FSA-based的高并发解码方法，这个解码方法的实现得益于我们在RNN-T模型上做的两个小创新。第一，我们的decoder网络是一个无状态的网络，从（<a href="https://ieeexplore.ieee.org/document/9054419/%EF%BC%89%E4%BF%AE%E6%94%B9%E8%80%8C%E6%9D%A5%EF%BC%8C%E6%88%91%E4%BB%AC%E5%9C%A8embedding%E5%B1%82%E5%90%8E%E9%9D%A2%E5%8A%A0%E4%BA%86%E4%B8%80%E4%B8%AA%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF%E4%BB%A5%E6%89%AE%E6%BC%94N-gram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%9C%E7%94%A8%E3%80%82%E7%AC%AC%E4%BA%8C%EF%BC%8C%E6%88%91%E4%BB%AC%E5%9C%A8%E8%A7%A3%E7%A0%81%E9%98%B6%E6%AE%B5%E4%B8%A5%E6%A0%BC%E9%99%90%E5%88%B6%E6%AF%8F%E4%B8%80%E5%B8%A7%E8%BE%93%E5%87%BA%E4%B8%80%E4%B8%AA%E7%AC%A6%E5%8F%B7%E3%80%82%E8%BF%99%E4%BD%BF%E5%BE%97%E6%88%91%E4%BB%AC%E8%A7%A3%E7%A0%81%E8%BF%87%E7%A8%8B%E4%B8%8D%E5%AD%98%E5%9C%A8%E8%87%AA%E5%9B%9E%E5%BD%92%EF%BC%8C%E8%80%8C%E4%B8%94%E5%9C%A8%E6%AF%8F%E4%B8%80%E5%B8%A7%E4%B8%8A%E4%B9%9F%E4%B8%8D%E4%BC%9A%E6%9C%89%E5%BE%AA%E7%8E%AF%E5%AD%98%E5%9C%A8%E3%80%82%E5%85%B7%E4%BD%93%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82%E6%96%87%E8%BE%9E%E4%B8%8A%E9%9A%BE%E4%BB%A5%E5%B0%BD%E8%BF%B0%EF%BC%8C%E6%83%B3%E4%BA%86%E8%A7%A3%E5%85%B6%E4%B8%AD%E7%BB%86%E8%8A%82%E5%8F%AF%E4%BB%A5%E5%8F%82%E7%9C%8BDaniel%E7%9A%84proposal">https://ieeexplore.ieee.org/document/9054419/）修改而来，我们在embedding层后面加了一个一维卷积以扮演N-gram语言模型的作用。第二，我们在解码阶段严格限制每一帧输出一个符号。这使得我们解码过程不存在自回归，而且在每一帧上也不会有循环存在。具体的实现细节文辞上难以尽述，想了解其中细节可以参看Daniel的proposal</a>:</p>
<ul>
<li><a href="https://github.com/k2-fsa/k2/issues/885">https://github.com/k2-fsa/k2/issues/885</a></li>
</ul>
<p>最终实现跟这个有些差异；k2中的实现</p>
<ul>
<li><a href="https://github.com/k2-fsa/k2/pull/926">https://github.com/k2-fsa/k2/pull/926</a></li>
</ul>
<p>Icefall中的运用:</p>
<ul>
<li><a href="https://github.com/k2-fsa/icefall/pull/250">https://github.com/k2-fsa/icefall/pull/250</a></li>
<li><a href="https://github.com/k2fsa/icefall/pull/277">https://github.com/k2fsa/icefall/pull/277</a></li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>为了加快RNNT解码速度，相关论文中有如下思路：</p>
<ol>
<li>采用caching缓存技术避免了预测网络中相同预测历史的冗余计算。</li>
<li>用pruning剪枝减少搜索过程中活跃symbol的数量，使计算更有效率。</li>
<li>使用有限的标签上下文label context来合并具有相同预测历史的假设，来减少活跃symbol的数量。</li>
<li>在解码过程中限制每个时间步输出的symbol数为1。</li>
</ol>
<h2 id="Transducer-decoding-algorithms"><a href="#Transducer-decoding-algorithms" class="headerlink" title="Transducer decoding algorithms"></a>Transducer decoding algorithms</h2><h3 id="Traditional-Transducer"><a href="#Traditional-Transducer" class="headerlink" title="Traditional Transducer"></a>Traditional Transducer</h3><p>$(\mathbf{y}, t)$ 转移到 $(\mathbf{y} + a, t)$ with label $a$ ，转移概率 $P (a|\mathbf{y}, t)$ ；</p>
<p>$(\mathbf{y}, t)$ 转移到 $(\mathbf{y}, t+1)$ ，转移概率 $P (\varnothing|\mathbf{y}, t)$  ；</p>
<h3 id="Stateless-Transducer"><a href="#Stateless-Transducer" class="headerlink" title="Stateless Transducer"></a>Stateless Transducer</h3><p>这种transducer下，decoder network （也就是prediction network，输入是上一时刻的symbol） 可以简化为只有最近的符号，例如y的两个符号。</p>
<h3 id="Max-symbols-decoding"><a href="#Max-symbols-decoding" class="headerlink" title="Max-symbols decoding"></a>Max-symbols decoding</h3><p>限制每帧可以输出的最多symbol，每帧都有一个状态空间，$0 \leq n &lt; S$  ，表示当前状态已经输出了几个symbol了。</p>
<p>所以状态的形式是： $(\mathbf{y}, t, n)$。（ $\mathbf{y}$ 是一个序列）</p>
<ul>
<li>当blank $(\varnothing)$ 转移时，形式是 $(\mathbf{y}, t, n)$ →  $(\mathbf{y}, t+1, 0) $ ；</li>
<li>当label $a$ （$a \neq \varnothing  $）转移时（此处 $n \leq S-1$ ），形式是 $(\mathbf{y}, t, n)$ → $(\mathbf{y}+a, t, n+1)$ ；</li>
<li>当label $a$ （$a \neq \varnothing  $）转移时（此处 $n &#x3D; S-1$ ），形式是 $(\mathbf{y}, t, S-1)$ → $(\mathbf{y}+a, t+1, 0)$ ；这相当于假设在给定帧上发射 $S$ 个符号后，blank的概率总是1。</li>
</ul>
<h3 id="FSA-based-decoding"><a href="#FSA-based-decoding" class="headerlink" title="FSA-based decoding"></a>FSA-based decoding</h3><p>提出两个假设来简化算法：</p>
<ol>
<li>使用stateless transducer  ，假设decoder network只依赖非常少的input symbol（前时刻的symbol）。</li>
<li>用max-symbols decoding，假设每帧可输出的symbol数量 $S&#x3D;1$ 。（这和hybrid或CTC解码很像，一帧只会输出一个位置的label）</li>
</ol>
<p>扩展状态空间，用graph进行解码，state的形式是：$((a, b), t, s)   $，$a$ 和  $b$ 是symbols（包括 blank）； $t \geq 0$ 是帧索引； $s$ 是解码图状态。</p>
<p>对于label $c$ （ $c \neq \varnothing  $ ），概率 $q$，解码图上的每条弧 $s$ → $r$ ,  lattice上存在这样的转移：$((a, b), t, s)$ → $((b, c), t+1, r)$ ，转移概率 $P (c|(a, b), t)  $；</p>
<p>对于label $\varnothing $（$\varnothing&#x3D;0$ ），blank转移 $((a, b), t, s) → ((a, b), t+1, s) $ ， 转移概率 $P (\varnothing |(a, b), t)   $ ；</p>
<p>解码算法是在k2 中使用 ragged tensor 数据结构实现的，它可以在GPU上并行快速处理不规则大小的对象</p>
<h3 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h3><p>三个限制：</p>
<ol>
<li>a log-probability <strong>beam</strong>, </li>
<li>a <strong>max-states constraint</strong> (that limits the number of tuples ((a, b), t, s) for a given t)  </li>
<li>a <strong>max-contexts constraint</strong> that limits the number of symbol contexts like (a, b) that are active on a given t</li>
</ol>
<p>On each frame we first do propagation to the next frame without pruning  </p>
<p>We then apply the max-states and beam constraints in one pruning operation; and then apply the max-contexts constraint in a second pruning operation.  </p>
<img src="/2023/03/13/k2/Fast%20and%20parallel%20decoding%20for%20transducer/image-20230313165244454.png" alt="image-20230313165244454" style="zoom: 50%;">



<h2 id="Constrained-Transducer-Training"><a href="#Constrained-Transducer-Training" class="headerlink" title="Constrained Transducer Training"></a>Constrained Transducer Training</h2><p>todo………..</p>
<p>$$<br>\begin{array}{r}<br>\alpha(t, u)&#x3D;\log _{-} \operatorname{add}(\alpha(t-1, u)+\varnothing(t-1, u), \<br>\alpha(t, u-1)+y(t, u-1)))<br>\end{array}<br>$$<br>with the final data-likelihood being $\alpha(T-1, U)+\varnothing(T-1, U)$, the modified transducer is:<br>$$<br>\begin{aligned}<br>&amp; \alpha(t, u)&#x3D;\text { log-add }(\alpha(t-1, u)+\varnothing(t-1, u) \text {, } \<br>&amp; \alpha(t-1, u-1)+y(t-1, u-1))) \<br>&amp;<br>\end{aligned}<br>$$<br>with the final data-likelihood being $\alpha(T, U)$.</p>
]]></content>
      <categories>
        <category>k2</category>
      </categories>
      <tags>
        <tag>k2</tag>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation 视频</title>
    <url>/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/</url>
    <content><![CDATA[<h1 id="Predicting-Multi-Codebook-Vector-Quantization-Indexes-for-Knowledge-Distillation-多码本向量量化索引的知识蒸馏"><a href="#Predicting-Multi-Codebook-Vector-Quantization-Indexes-for-Knowledge-Distillation-多码本向量量化索引的知识蒸馏" class="headerlink" title="Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation. 多码本向量量化索引的知识蒸馏"></a>Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation. 多码本向量量化索引的知识蒸馏</h1><blockquote>
<p>Guo, Liyong, et al. “Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation.” <em>arXiv preprint arXiv:2211.00508</em> (2022). 郭理勇</p>
<p>微信公众号 新一代Kaldi： <a href="https://mp.weixin.qq.com/s/XIg8cY82KtoZ6rW-FdVqEQ">新一代 Kaldi 中基于量化的蒸馏实验</a></p>
<p>相关代码：<a href="https://github.com/k2-fsa/multi_quantization.git">https://github.com/k2-fsa/multi_quantization.git</a> </p>
<p>相关代码：<a href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless6">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless6</a></p>
<p>b站视频：姚增伟 <a href="https://www.bilibili.com/video/BV1xV4y1T7f9/?spm_id_from=333.788.recommend_more_video.13&vd_source=5e9891722f2b62adca440a5e92121b5b">【语音之家】AI产业沙龙—如何应用k2开发语音识别系统</a>  或  <a href="https://xjw.h5.xeknow.com/sl/2yOtKa">https://xjw.h5.xeknow.com/sl/2yOtKa</a> 22分钟起</p>
<p>D:\typora\typora笔记\语音\k2\视频 基于多码本向量量化的蒸馏方案.md</p>
</blockquote>
<p>Traning overhead 几乎可以忽略不计的新型蒸馏框架</p>
<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230315121747110.png" alt="image-20230315121747110" style="zoom: 80%;">

<p>量化过程：</p>
<p>embedding vector里面的值不再是浮点数，而是码本的index，然后用的是8个码本的index来表示一个1280维的embedding vector，，因此有8个index，然后根据是哪个index，从codebook table里把index对应的值取出来，然后把值求和。</p>
<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230428173731483.png" alt="image-20230428173731483" style="zoom:80%;">



<p>分治，现在每个码本是独立的，然后固定后3个码本（2、3、4），选出能让重建误差最小的第1个码本的其中两个index（重建误差最小和次小，top2），然后固定1，3，4码本，选出能让重建误差最小的第2个码本的top2的index；然后固定1，2，4码本，选出能让重建误差最小的第3个码本的top2的index；然后固定1，2，3码本，选出能让重建误差最小的第4个码本的top2的index。于是每个码本都留下了2个index。</p>
<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230428174644333.png" alt="image-20230428174644333" style="zoom:80%;">



<p>分治，合并子问题。</p>
<p>固定3，4码本，选出能让重建误差最小的第1、2个码本的top2的index（index连接有4种可能）；然后固定1，2码本，选出能让重建误差最小的第3、4个码本的top2的index（index连接有4种可能）</p>
<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230428175213781.png" alt="image-20230428175213781" style="zoom:80%;">



<p>分治，再次合并子问题，固定1，2，3，4码本??，选出能让重建误差最小的top1的index（index连接有4种可能）</p>
<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230428175200323.png" alt="image-20230428175200323" style="zoom:80%;">



<p>上面这个例子迭代了3次。</p>
<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230428180015256.png" alt="image-20230428180015256" style="zoom:80%;">





<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230428180030399.png" alt="image-20230428180030399" style="zoom:80%;">



<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230428180226270.png" alt="image-20230428180226270" style="zoom:80%;">



<img src="/2023/04/28/k2/Predicting%20Multi-Codebook%20Vector%20Quantization%20Indexes%20for%20Knowledge%20Distillation/image-20230428180427125.png" alt="image-20230428180427125" style="zoom:80%;">
]]></content>
      <categories>
        <category>k2</category>
      </categories>
      <tags>
        <tag>k2</tag>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>Pruned RNN-T for fast, memory-efficient ASR training. Pruned RNN-T loss</title>
    <url>/2023/03/13/k2/Pruned%20RNN-T%20for%20fast,%20memory-efficient%20ASR%20training/</url>
    <content><![CDATA[<h1 id="Pruned-RNN-T-for-fast-memory-efficient-ASR-training-Pruned-RNN-T-loss"><a href="#Pruned-RNN-T-for-fast-memory-efficient-ASR-training-Pruned-RNN-T-loss" class="headerlink" title="Pruned RNN-T for fast, memory-efficient ASR training. Pruned RNN-T loss"></a>Pruned RNN-T for fast, memory-efficient ASR training. Pruned RNN-T loss</h1><blockquote>
<p>Kuang, Fangjun, et al. “Pruned RNN-T for fast, memory-efficient ASR training.” <em>arXiv preprint arXiv:2206.13236</em> (2022). citations：9</p>
<p>公众号 新一代Kaldi：<a href="https://mp.weixin.qq.com/s?__biz=MzkyMzI5NTM2Ng==&mid=2247483741&idx=1&sn=fc76586359d371f82c46e62c7b762369&scene=21#wechat_redirect">多快好省的 RNN-T 训练</a></p>
<p>公众号 新一代Kaldi：<a href="https://mp.weixin.qq.com/s/M7Oz5b0LbtIxm0PfVb5iww">Pruned RNN-T 何以又快又好</a></p>
<p>开源代码 rnnt_loss.py：<a href="https://github.com/k2-fsa/k2/blob/master/k2/python/k2/rnnt_loss.py">https://github.com/k2-fsa/k2/blob/master/k2/python/k2/rnnt_loss.py</a></p>
<p>Bechmark 的开源代码 transducer-loss-benchmarking：<a href="https://github.com/csukuangfj/transducer-loss-benchmarking">https://github.com/csukuangfj/transducer-loss-benchmarking</a></p>
</blockquote>
<ul>
<li><strong>简介</strong></li>
</ul>
<p>新一代 Kaldi 针对 RNN-T 损失函数的创新性改进。原始的 RNN-T 损失函数在处理长文本或者长语音的时候显存占用较大，训练时间较长。对此，我们提出对 RNN-T 的 log-probability lattice 进行裁剪，能够在不损失训练精度的前提下大幅缩短 RNN-T 损失函数的计算时间。该工作已经被Interspeech2022 收录。</p>
<ul>
<li><strong>解决什么问题</strong></li>
</ul>
<p>在 CTC 模型、RNN-T 模型和 attention-based 模型中，RNN-T 是最适合用于产线部署的流式解码模型。但 RNN-T 具有以下几个痛点：</p>
<ol>
<li>训练时，与其他模型相比，占用的内存至少高一个数量级</li>
<li>解码时，很难通过以 batch 的方式实现并行解码</li>
</ol>
<ul>
<li><p><strong>用了什么方法</strong></p>
<ol>
<li>提出 pruned RNN-T，改变了 RNN-T 模型中最后一层的输出维度：从 <code>(N, T, U, C)</code> 变成了 <code>(N, T, S, C)</code>，其中 $U \gg S$ 。矩阵变小了，内存使用就降低了。</li>
<li>矩阵变小了，Pruned RNN-T 进入 joiner 网络的是更小得多的 <code>(N，T，S，V)</code>向量 ，所以 joiner 网络里面的非线性层和 Linear 层的计算量大大减小，从而大大提高了计算速度。</li>
<li>Pruned RNN-T 的快部分来自<strong>高效的代码实现</strong>。</li>
</ol>
</li>
<li><p><strong>效果如何</strong></p>
<p>具有以下特点：</p>
<p> <strong>“多”</strong></p>
<ul>
<li>可以用更大的 batch size</li>
<li>可以用更大的 vocabulary size</li>
</ul>
<p><strong>“快”</strong></p>
<ul>
<li>目前为止，所有常用开源实现中，训练速度最快</li>
<li>训练出来的模型，在不降低性能的前提下，解码速度更快</li>
</ul>
<p><strong>“好”</strong></p>
<ul>
<li>训练出来的模型，在 GigaSpeech 和 WenetSpeech 的 Leaderboard 上，排名第一</li>
</ul>
<p><strong>“省”</strong></p>
<ul>
<li>省内存</li>
<li>目前为止，所有常用开源实现中，所需内存最少</li>
</ul>
</li>
</ul>
<p>针对问题1，训练部分，展开介绍。</p>
<h2 id="存在问题：RNNT训练时占用内存高"><a href="#存在问题：RNNT训练时占用内存高" class="headerlink" title="存在问题：RNNT训练时占用内存高"></a>存在问题：RNNT训练时占用内存高</h2><p>RNN-T 模型最后一层的输出是一个 4-D 的 tensor，维度是 <code>(N, T, U, C)</code>, 其中</p>
<ul>
<li><code>N</code>: batch size。数值大小: 一般是几十</li>
<li><code>T</code>: encoder 的输出帧数。数值大小：一般是好几百（CTC network，encoder）</li>
<li><code>U</code>: decoder 的输出帧数。数值大小：几十至上百（prediction network，decoder）</li>
<li><code>C</code>: vocabulary size。数值大小：几百至上千</li>
</ul>
<p>所以，RNN-T 训练时，所需的内存（显存）正比于 <code>N</code>, <code>T</code> , <code>U</code>, <code>C</code> 这 4 个数的乘积 <code>NTUC</code>。训练 CTC 或者 attention-based 模型时，所需的内存（显存）一般与 <code>NTC</code> 或者 <code>NUC</code> 成正比。相比较之下，RNN-T 模型的训练，对内存的要求高了一个数量级。</p>
<p>这样一个大的向量需要占据很大的显存，导致没法使用大的 batch size 来训练，另外，如此大的向量也造成 joiner 网络的计算量非常大，从而增加单次迭代的时间。</p>
<blockquote>
<p>为了避免训练时出现 out-of-memory (OOM) 错误，通常的做法是：</p>
<ul>
<li>减少 <code>N</code>，使用一个小的 batch size</li>
<li>减少 <code>C</code>，使用一个较小的 vocabulary size</li>
<li>降低模型参数量</li>
</ul>
<p>但是，使用小的 batch size 会增加模型训练所需的时间；而使用小的 vocabulary size， 可能会影响模型的性能。例如，若以单个汉字为建模单元，vocabulary size 一般是 4000 到 7000 之间。如果使用一个很小的 vocabulary size，那么对于 out-of-vocabulary (OOV) 这种问题，就会更加常见。而降低模型的参数量，也会影响模型的性能。）</p>
</blockquote>
<p>那么如何在不降低模型性能的前提下，做到以下几点呢?</p>
<ul>
<li>降低训练时所需的内存</li>
<li>降低训练所需的时间</li>
</ul>
<h2 id="相似工作"><a href="#相似工作" class="headerlink" title="相似工作"></a>相似工作</h2><p>微软 Improving RNN Transducer Modeling for End-to-End Speech Recognition：通过移除一个 batch 中所需的 padding 来减少内存的占用量。作者对这个方法提供了一个开源的实现，链接如下: <a href="https://github.com/csukuangfj/optimized_transducer">optimized_transducer</a>。相关 benchmark 数据表明，这种方法在所有<strong>标准的 RNN-T</strong> 开源实现中，所需内存最低。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>提出 pruned RNN-T，pruned RNN-T 改变了 RNN-T 模型中最后一层的输出维度：</p>
<ul>
<li>从 <code>(N, T, U, C)</code> 变成了 <code>(N, T, S, C)</code></li>
</ul>
<p>其中，<code>S</code> 是用户指定的一个参数。我们所做的实验中，一般选用 5；而 <code>U</code> 则一般是几十甚至上百。</p>
<p>结果就是，所需的内存与 <code>NTSC</code> 成正比，而不再是 <code>NTUC</code>。</p>
<img src="/2023/03/13/k2/Pruned%20RNN-T%20for%20fast,%20memory-efficient%20ASR%20training/image-20230313144523612.png" alt="image-20230313144523612" style="zoom: 67%;">

<p>图1（a）是针对标准的 RNN-T，图中所有的结点都参与了RNN-T loss 的计算。</p>
<p>作者提出一个很有意思的问题：是不是所有的结点都应该参与计算？然后做出论证，如图2所示。</p>
<p>图2 显示了图 1（a）中每个结点在训练时某一时刻的梯度。我们可以看到，&#x3D;&#x3D;随着训练的进行，靠近对角线上的结点对计算起到的作用最大。也就是说，不同位置的结点，在训练中起到的作用不同。&#x3D;&#x3D;</p>
<p>图1（b）则是针对 pruned RNN-T，图中只有部分结点参与了 RNN-T loss 的计算。</p>
<p>参与计算的结点数量越少，所需的计算量则越少、计算速度就越快，并且所需的内存也越少。</p>
<ul>
<li>哪些结点应该被选出来参与计算呢？</li>
<li>又如何选择这些结点呢？</li>
</ul>
<p>音频和文本的单调对应特性决定了 lattice 中的大多数节点对最终的 Loss 几乎没有贡献。</p>
<h2 id="trivial-joiner-平凡联合网络"><a href="#trivial-joiner-平凡联合网络" class="headerlink" title="trivial joiner 平凡联合网络"></a>trivial joiner 平凡联合网络</h2><p>为了确定剪裁的边界，我们提出了一个<strong>“平凡联合网络”</strong>（<code>trivial joiner</code>）的概念，这个 <code>trivial joiner</code> 是 encoder 和 predictor 的简单相加，即 <code>am + lm</code>。使用这样一个简单的 joiner 网络是为了在<strong>不生成四维向量</strong>的情况下得到一个 lattice，以便在这个 lattice 上求得剪裁边界。下图是 Pruned RNN-T 计算的流程图，我们实际上计算了两次损失函数，一次是在上述的 <code>trivial joiner</code> 上，一次是在正常的包含非线性层的 joiner 上（下图中的 s_range 就是上面提到的 S）。</p>
<p>![640 (1)](640 (1).png)</p>
<p>在一个 lattice 中，每一个节点包含了两个概率，即 $y(t, u)$ 和 $\varnothing(t, u) $， $ y(t, u)$ 表示在第 $t$ 帧给定 $y_{0 . . u}$ 的情况下发射 $y_{u+1}$ 的对数概率， $\varnothing(t, u)$ 则代表在第 $t$ 帧给定 $y_{0 . . u}$ 的情况下 发射 blank 的对数概率。由于 <code>trivial joiner </code>是个简单的相加，所以我们不需要在相加之 后的向量中来获取这两个概率，只需分别在 $a m$ 和 $l m$ 中获得这两个概率，然后将 $a m$ 和 $l m$ 中得到的概率分别加起来就行。获取概率的操作就是个简单的查询，在代码中使用 torc h. gather 来实现，这个过程和乘法分配律非常相似。</p>
<blockquote>
<p>注：两个 shape 不一样的向量相加得先统一 shape，即 <code>logit = am.unsqueeze(2) + lm.unsqueeze(1)</code>,所以如果相加之后再获取概率，我们就不得不生成一个四维向量。</p>
</blockquote>
<h2 id="剪裁边界的确定"><a href="#剪裁边界的确定" class="headerlink" title="剪裁边界的确定"></a>剪裁边界的确定</h2><p>TODO。。。。。。</p>
<h2 id="实验及结果"><a href="#实验及结果" class="headerlink" title="实验及结果"></a>实验及结果</h2><p>pruned RNN-T 在以下几方面的结果:</p>
<ul>
<li>训练速度</li>
<li>训练所需内存</li>
<li>在LibriSpeech test-clean 测试集上的 WER 及 RTF</li>
</ul>
<p>在进行 benchmark 时，我们采用 LibriSpeech test-clean 测试集来生成 RNN-T 模型训练时所需的维度信息， 而不是针对特定的维度进行 benchmark。这样可以考虑每个 batch 中 padding 所造成的影响，尽量还原真实的应用场景。</p>
<p>我们设置了两种 bechmark 模式:</p>
<ul>
<li>(1) 以随机的方式组成 batch。batch size 为 30。</li>
<li>(2) 按照样本时长进行排序的方式组成 batch。每个 batch 中最多包含 1万 帧特征。</li>
</ul>
<p>在论文中，我们对比了 pruned RNN-T 和 常用的开源 RNN-T loss 实现的性能。结果如表 1 和 表 2 所示。我们可以看出，不管是在训练时间还是在内存使用量上， pruned RNN-T 与其他实现相比，都有很大的优势。</p>
]]></content>
      <categories>
        <category>k2</category>
      </categories>
      <tags>
        <tag>k2</tag>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>视频 新一代 Kaldi 中的 Reworked Conformer 模型</title>
    <url>/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/</url>
    <content><![CDATA[<h1 id="新一代-Kaldi-中的-Reworked-Conformer-模型"><a href="#新一代-Kaldi-中的-Reworked-Conformer-模型" class="headerlink" title="新一代 Kaldi 中的 Reworked Conformer 模型"></a>新一代 Kaldi 中的 Reworked Conformer 模型</h1><blockquote>
<p>b站视频：姚增伟 <a href="https://www.bilibili.com/video/BV1xV4y1T7f9/?spm_id_from=333.788.recommend_more_video.13&vd_source=5e9891722f2b62adca440a5e92121b5b">【语音之家】AI产业沙龙—如何应用k2开发语音识别系统</a>  或  <a href="https://xjw.h5.xeknow.com/sl/2yOtKa">https://xjw.h5.xeknow.com/sl/2yOtKa</a></p>
<p>微信公众号 语音之家：<a href="https://mp.weixin.qq.com/s/hhFGmWnTZco0HFxGidHoCQ">【语音之家】AI产业沙龙—如何应用k2开发语音识别系统</a> 、<a href="https://mp.weixin.qq.com/s/TU3vLqaf0GrhI1JsU2nqvA">沙龙回顾 | AI产业沙龙—如何应用k2开发语音识别系统</a> </p>
<p>微信公众号 新一代Kaldi：<a href="https://mp.weixin.qq.com/s/2WrEh3wHzYE6TCKuw_laLw">Reworked Conformer</a></p>
<p><a href="https://medium.com/@nadirapovey/next-gen-kaldi-reworked-conformer-model-8a3828f364af">Next-gen Kaldi: Reworked Conformer Model</a></p>
<p><a href="https://www.youtube.com/watch?v=BXYZI9FEOgU&ab_channel=NadiraPovey">Dan K2 #23 Reworked Conformer Model: BAAI Conference P3</a></p>
<p>Reworked Conformer模型代码:  github：<a href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless2">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless2</a> 、 <a href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless5">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless5</a></p>
</blockquote>
<p>本报告将介绍近期新一代 Kaldi 项目的两个核心贡献点。针对 Conformer 模型存在的问题进行改进，实现了训练稳定、性能更优的 Reworked Conformer 模型，其核心思想已拓展应用于 Emformer 和 LSTM 等模型中。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314163807074.png" alt="image-20230314163807074" style="zoom:80%;">



<p>我们使用的 Conformer 模型包含了 12 个 encoder layer，每个 encoder layer 包含了四个模块：Feed-forward + Self-attention + Convolution + Feed-forward，每个模块的输入处以及 encoder layer 的最后输出处各有一个 LayerNorm。</p>
<p>通过使用模型分析工具 &#x3D;&#x3D;<strong><a href="https://github.com/k2-fsa/icefall/blob/master/icefall/diagnostics.py">diagnostics</a></strong>&#x3D;&#x3D; 对 Conformer 进行分析，我们发现了模型存在的一些问题，并针对问题作出改进，得到 <strong>Reworked Conformer</strong>。 </p>
<blockquote>
<p>模型分析工具 diagnostics 实现于 <strong><a href="https://github.com/k2-fsa/icefall/">icefall</a></strong> 中，可用于查看模型的参数、激活值及梯度的多种统计量，方便用户分析模型是否训练正常。</p>
</blockquote>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314164423146.png" alt="image-20230314164423146" style="zoom: 80%;">

<h3 id="1-将-LayerNorm-替换为-BasicNorm"><a href="#1-将-LayerNorm-替换为-BasicNorm" class="headerlink" title="1. 将 LayerNorm 替换为 BasicNorm"></a>1. 将 LayerNorm 替换为 BasicNorm</h3><p>batchnorm中两个会更新的超参 $\gamma$ 和 $\beta$ 用来缩放和偏置。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314164512588.png" alt="image-20230314164512588" style="zoom:80%;">

<p>BatchNorm 和 LayerNorm的主要区别在于：</p>
<ul>
<li>BatchNorm 的统计维度为 $(B,T)$，在训练过程中累计统计量（均值、方差），测试时使用训练中累计的统计量；</li>
<li>LayerNorm 的统计维度为 $(C)$，无论训练或测试，都要重新计算统计量。</li>
</ul>
<p>BatchNorm 假设了 minibatch 中不同的句子（样本）服从独立同分布（iid）。然而，该假设在ASR模型训练过程中，可能会遇到不成立的情况，例如：</p>
<ul>
<li>按照句子长度划分 minibatch；</li>
<li>使用多个数据集训练，在不同 minibatch 使用不同数据集。</li>
</ul>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314164533510.png" alt="image-20230314164533510" style="zoom:80%;">

<p>因此，我们首先将 Conformer 中所有的 BatchNorm 替换为 LayerNorm。</p>
<h4 id="为什么需要-LayerNorm"><a href="#为什么需要-LayerNorm" class="headerlink" title="为什么需要 LayerNorm"></a>为什么需要 LayerNorm</h4><p>LayerNorm 的作用主要包括：</p>
<ul>
<li>规范化值的范围，避免在训练中因为值太大或太小而导致 loss 出现 nan 或者 inf ；对于任意长度的向量，LayerNorm 会将其长度规范化为 $\sqrt{C}$，其中 $C$ 为特征通道个数。</li>
<li>利用可学习的参数 $\gamma$，调整对应模块对整体模型的贡献。</li>
</ul>
<p>想去除一些layernorm，加快运行。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314171315949.png" alt="image-20230314171315949" style="zoom:80%;">





<p>为什么可以去除layernorm：从公式上看：$y&#x3D;\frac{x-\mathrm{E}[x]}{\sqrt{\operatorname{Var}[x]+\epsilon}} * \gamma+\beta$ ， 中的均值 $x-\mathrm{E}[x]$ 是线性操作，可以认为是不必要的。</p>
<p>分母归一化到 $\sqrt{dim}$ </p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314172738444.png" alt="image-20230314172738444" style="zoom:80%;">



<ul>
<li><strong>为什么需要layernorm</strong>：</li>
</ul>
<p>防止激活层后值太大或太小。</p>
<p>$\gamma$ 可以衡量每个模块的激活值对整个模型的贡献程度。</p>
<p>如果用没有weight decay的adam优化器，会有一个问题，就是和学习率有关，随着训练进行，参数的均方根会变大，模型参数会增大。</p>
<p>因此 $\gamma$ 可以起到<strong>缩放</strong>越来越大的模型参数的作用。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314172841996.png" alt="image-20230314172841996" style="zoom:80%;">





<ul>
<li><strong>layernorm存在的问题</strong>：</li>
</ul>
<ol>
<li><p><strong>module death</strong></p>
<p>发现有些模块在训练之后一直输出很小的值（比如1e-6），因为早期训练过程中，这个模块还没work，则 $\gamma$ 会缩放到一个接近0的值，相当于“关掉这个模块了”，则layernorm里的下层模块的梯度会一直振荡，则这个模块难以学会有用信息，整个模型优化点相当于陷入了鞍点。</p>
</li>
</ol>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314173632253.png" alt="image-20230314173632253" style="zoom:80%;">



<ol start="2">
<li><p><strong>Large constant channel</strong></p>
<p>对于一个训练好的模型，观测layernorm的输入，发现总是会有一个维度（channel）的输入值（绝对值）特别大，且恒定的值：-51+-1。出现这个现象的原因可能是，模型企图抵抗 LayerNorm 去除向量长度的机制。因为layernorm会规范化归一化掉，它的目的似乎是为了“击败”layernorm，和layernorm对抗一样，变成一个非常大的$\epsilon$，从而保留（除了该channel之外的）长度信息（因为layernorm归一化会去除长度信息）。</p>
<p>对于这个值特别大的维度，可以认为是“异常值”，需要手动丢掉这个维度。</p>
</li>
</ol>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314195129456.png" alt="image-20230314195129456" style="zoom:80%;">



<p>以下图为例, 向量 $a$ 和向量 $b&#x3D;a \times 3$ 经过长度规范化后, 长度关系丢失; 向量 $c$ 和向量 $d$ 的 最后一个 channel是一个绝对值很大的恒定值 - 51 , 对于除了该 channel 外的所有 channel, 两 者之间的长度关系 $d[:-1]&#x3D;c[:-1] \times 3$ 在长度规范化的同时也得到保留。</p>
<p>解释一下，这里向量a、b是一个样本，维度是5，5维理解成是长度length为5，长度里的每个元素由channel向量组成，这里channel只有一个元素，长度为1。所以这里的矩阵维度是 [2, 5, 1]，分别是batch、sentence_length、embedding_dim？。。。。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/640.png" alt="640">





<h4 id="BasicNorm"><a href="#BasicNorm" class="headerlink" title="BasicNorm"></a>BasicNorm</h4><p>针对上述问题，对 LayerNorm 作出修改，得到 <strong>BasicNorm</strong>：</p>
<p>去除layernorm，变成“basicnorm”，把分母的方差换成x平方的均值，加一个可学习的值$\epsilon$（起到异常值的作用）</p>
<p>更新参数通过 $\epsilon .\exp()$ 因此都是正数（前面的 $\gamma$ 不一定正数，可能会在0附近方向振荡，难以学习）</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314195955639.png" alt="image-20230314195955639" style="zoom:80%;">

<h4 id="Learnable-scales"><a href="#Learnable-scales" class="headerlink" title="Learnable scales"></a>Learnable scales</h4><ul>
<li>首先，去掉了分子中移除向量均值的操作，因为该操作是一个线性变换，其前面接的是线性层，没有必要进行连续的两次线性变换。</li>
<li>在分母中，**引入一个可学习的参数 $\epsilon$**，充当上述的 large constant channel 的角色，目的是在作长度规范化的同时，保留向量的长度信息。此时，输入的向量长度越大，输出向量的长度就越大。</li>
<li>$\epsilon$ 初始值为 0.25，学习的是该参数的 log 值，用的时候取 exp，确保是正数。</li>
</ul>
<p>现在 BasicNorm 中没有可学习的放缩因子参数 ，为了保留其权衡不同模块贡献的功能，在每个模块中引入可学习的参数 <strong>scales</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.weight -&gt; self.weight * self.weight_scale.exp()</span><br><span class="line">self.bias -&gt; self.bias * self.bias_scale.exp()</span><br></pre></td></tr></table></figure>

<p>由于 scales 是在 log 空间学习，使用时取 exp，为正数，避免了上述由于在 0 左右震荡导致的对应模块参数梯度翻转的问题。</p>
<h3 id="2-ActivationBalancer调整激活值范围"><a href="#2-ActivationBalancer调整激活值范围" class="headerlink" title="2. ActivationBalancer调整激活值范围"></a>2. ActivationBalancer调整激活值范围</h3><p>给swish激活层的输入存在两个激活值异常问题：</p>
<ol>
<li><strong>负数问题 Dead neuron</strong>：</li>
</ol>
<p>如果feedforward（LayerNorm + Linear + Swish + Linear）模块里，linear输出的特征有很多都是“<strong>负数</strong>”，那么经过下一层激活层时，由于激活层用的是swish激活层，就会有很多值接近于零，这些值也是没用的，浪费的。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314201320249.png" alt="image-20230314201320249" style="zoom:80%;">





<ol start="2">
<li><strong>范围异常问题 Wrong dynamic range</strong>：</li>
</ol>
<p>对于一个训练好的模型，给swish激活层的输入的数值应该是<strong>“1”到”3“之间</strong>，（这个是一个比较好的范围）</p>
<p>观察线性层的输出（也就是下一层激活层的输入）发现，存在两种范围异常的情况：一种是太小，1e-5，swish激活会退化成一个线性函数，就没有起到非线性的效果；一种是太大，swish会退化成relu。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230314201724738.png" alt="image-20230314201724738" style="zoom:80%;">

<p>为了解决上述两个问题，提出activationbalancer模块，放在linear和swish中间，这个模块包含两个函数，forward和backward，继承自autograd function，子类。</p>
<p>forward pass 前向计算过程中，没有实际做什么操作，只统计记录了哪些通道是有问题的。</p>
<p>backward pass 反向传播过程中，根据forward pass统计的，对应去修改梯度。比如只有5%的值大于0，接下来就惩罚变成负数。</p>
<p>要达到这个目的，还有另一个做法：增加一个loss，作为正则项。发现这个方法不work，因为会使得padding的地方变成一个很大的数。</p>
<p>作者采用的方法是 <strong>在反向过程中修改梯度</strong> ， 将<strong>梯度值放缩</strong>到 $1+\epsilon$ 或 $1-\epsilon$ （加号还是减号取决于激活值符号和梯度符号）。</p>
<p><strong>没有直接改变数值，而是在梯度值层面上改变！！</strong>好神奇，我没有直接对反向传播的梯度进行过操作。</p>
<p>例如，当统计发现激活值太小的时候：</p>
<ul>
<li>若梯度为负，激活值会朝着数轴的正方向走，这是我们所希望的，此时应当放大梯度；</li>
<li>若梯度为正，激活值会朝着数轴的负方向走，这不是我们所希望的，此时应当缩小梯度。</li>
</ul>
<p>梯度更新要朝着梯度减小的方向走，激活值很小时朝着数轴正方向走才会数值变大，是我们希望的。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315101732428.png" alt="image-20230315101732428" style="zoom:80%;">



<h3 id="3-效果更好的DoubleSwish"><a href="#3-效果更好的DoubleSwish" class="headerlink" title="3. 效果更好的DoubleSwish"></a>3. 效果更好的DoubleSwish</h3><p>发现使用两次swish能得到更好的效果，于是设计了一个函数，叫doubleswish，函数关系是 $x\sigma (x-1)$ （这里并不是直接swish作用两次）</p>
<p>并且这里有个好处，省内存，梯度值和函数值 很有关系，要求梯度只需保留两个变量 一个是函数值 <code>doubleswish(x)</code>，一个是 $\sigma(x-1)$。如果用swish，还需保留变量 $x$（三个变量），因此用doubleswish能起到省内存的作用。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315104938005.png" alt="image-20230315104938005" style="zoom:80%;">



<h3 id="4-固定参数范数，让学习率控制参数相对变化"><a href="#4-固定参数范数，让学习率控制参数相对变化" class="headerlink" title="4. 固定参数范数，让学习率控制参数相对变化"></a>4. 固定参数范数，让学习率控制参数相对变化</h3><p>参数范数会增大的问题，用layernorm或batchnorm可缓解（因为用可学的放缩因子$\gamma$ 来压下来），但是还存在：</p>
<p>难以直接控制学习率的问题，因为相对变化的大小除以当前模型的范数。。。</p>
<p>参数值很大，那么$\gamma$要很小，会出现梯度振荡，模型难以学习，训练不稳定。</p>
<p>随着训练进行，模型参数范数 RMS（Root-Mean-Square）会随之变大，此时学习率无法直接控制模型参数的相对变化大小。尽管，在参数范数 RMS 增大时，LayerNorm 或BatchNorm 中可学习的参数 $\gamma$ 可以通过缩小来控制值的范围，但是  $\gamma$ 太小的时候会导致上述的训练不稳定的问题。</p>
<p>因此，我们在优化器 <strong><a href="https://arxiv.org/abs/1711.05101">AdamW</a></strong> 的基础上修改得到优化器 <strong>Eve</strong>，其核心思想是对于每个非标量参数，当其范数 RMS 超过 0.1 时，对其进行 weight decay，缩小参数范数。</p>
<p>固定参数范数的操作并不会影响模型的性能，原因是我们在每个模块中引入了可学习的参数 scales。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315105300673.png" alt="image-20230315105300673" style="zoom:80%;">





<p>解决方法：fixed parameter norms</p>
<p>限制每个参数向量的rms模到0.1，对adam优化器加惩罚，adamW，</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315112141554.png" alt="image-20230315112141554" style="zoom:80%;">



<h3 id="5-使用Model-level-Warmup-机制，加快收敛"><a href="#5-使用Model-level-Warmup-机制，加快收敛" class="headerlink" title="5. 使用Model-level Warmup 机制，加快收敛"></a>5. 使用Model-level Warmup 机制，加快收敛</h3><p>在传统的Transformer训练中，通常采用先升后降的学习率 warmup 机制，这是一种在训练深层模型中常用的策略。如下图所示，在前面 80,000 个 iteration 线性地增加学习率，然后再按照 $\frac{1}{\sqrt{t}}$减少学习率。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315114828715.png" alt="image-20230315114828715" style="zoom:80%;">





<p>接近残差思想</p>
<p>我们提出 <strong>model-level warmup</strong> 机制，代替上述的学习率 warmup 机制。在前 3,000 个 iteration 中，逐步将 warmup 值从 0.1 增加到 1.0，在每一个 encoder layer 中，返回值为 $warmup*output+(1-warmup)*input$。&#x3D;&#x3D;该机制相当于在早期的训练阶段，减小模型的有效深度，使得训练更加容易&#x3D;&#x3D;。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315120942533.png" alt="image-20230315120942533" style="zoom:80%;">



<p>此时，我们不再需要采用先升后降的学习率 warmup 机制。我们在开始的时候使用较大的学习率，然后逐步降低学习率，如下图所示：</p>
<p>缓解受gpu worker数量影响</p>
<p>我们采用的学习率更新策略，兼顾了当前的 epoch 计数 $n$ 和 iteration $t$ 计数 ：</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315121032817.png" alt="image-20230315121032817" style="zoom:80%;">

<p>该策略的优势在于，由于同时考虑了 epoch 计数，不再需要因为 minibatch 大小改变而调整学习率更新策略。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>如下图所示，相比较于原来的模型（橙色），Reworked Conformer（蓝色）在训练开始阶段的收敛速度显著提升，且能收敛到更低的 loss 值。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315121129113.png" alt="image-20230315121129113" style="zoom:80%;">

<p>由于 Reworked Conformer 中移除了大部分 LayerNorm ，对于每个 minibatch，训练速度大约加快了 10%。</p>
<h3 id="更低的WER"><a href="#更低的WER" class="headerlink" title="更低的WER"></a>更低的WER</h3><p>下面的表格比较了原来的 Conformer 和 Reworked Conformer 的 WER。两者都采用了 Pruned RNN-T 损失函数，在 full-librispeech 数据集上训练了 <strong>26</strong> 个 epoch （avg-8），使用 greedy search 解码方法。可以看出，Reworked Conformer 在 两个测试集上都取得了更低的 WER。</p>
<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315121540860.png" alt="image-20230315121540860" style="zoom:80%;">



<img src="/2023/03/15/k2/%E8%A7%86%E9%A2%91%20reworked%20conformer%20and%20multi-codebook%20vector%20quantization-based%20distillation/image-20230315121636930.png" alt="image-20230315121636930" style="zoom:80%;">



<h2 id="总-结"><a href="#总-结" class="headerlink" title="总 结"></a>总 结</h2><p>本文介绍了新一代 Kaldi 改进后的 Corformer 模型 —— Reworked Conformer，该模型目前已被用于 icefall 的多个 recipe 中，经过大量实验验证了其优越性、稳定性和可靠性。其中涉及到的改进思想，不仅限于 Conformer，也可泛化到其他模型，欢迎大家尝试。</p>
<p><strong>小结</strong>：</p>
<p>reworked conformer这个工作虽然没有写成论文，但是工作量和想法是很多的，出发点是先观察模型中间层的数值，然后考虑该数值对后续层的影响，要怎么解决这些问题。值得一提的是：</p>
<ol>
<li>看出了不同层的输入输出、梯度数值异常；</li>
<li>分析了数值异常的原因；</li>
<li>从各种角度解决数值问题；</li>
</ol>
]]></content>
      <categories>
        <category>k2</category>
      </categories>
      <tags>
        <tag>k2</tag>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>python中的@classmethod、@staticmethod</title>
    <url>/2023/02/09/python/python%20@classmethod%E5%92%8C@staticmethod/</url>
    <content><![CDATA[<h1 id="python中的-classmethod、-staticmethod"><a href="#python中的-classmethod、-staticmethod" class="headerlink" title="python中的@classmethod、@staticmethod"></a>python中的@classmethod、@staticmethod</h1><blockquote>
<p><a href="https://www.bilibili.com/video/BV1jv4y1K7Yu/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">【python】staticmethod与classmethod深度机制解析——要知其所以然</a></p>
</blockquote>
<h2 id="classmethod、-staticmethod-的使用与实现"><a href="#classmethod、-staticmethod-的使用与实现" class="headerlink" title="@classmethod、@staticmethod 的使用与实现"></a>@classmethod、@staticmethod 的使用与实现</h2><h3 id="普通类函数"><a href="#普通类函数" class="headerlink" title="普通类函数"></a>普通类函数</h3><p>写一个类的方法，一般是这样写的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 举例</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用时</span></span><br><span class="line">A().f(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>方法（函数）的第一个参数是self，<strong>self表示把调用这个函数的对象传进去的机制</strong>。</p>
<h3 id="staticmethod-的使用"><a href="#staticmethod-的使用" class="headerlink" title="staticmethod 的使用"></a>staticmethod 的使用</h3><p>而用 staticmethod 的写法是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>:</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">        <span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用时</span></span><br><span class="line">A.f(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#也可以写A().f(1)，也是可以使用的</span></span><br></pre></td></tr></table></figure>

<p>可以看出，和一般的写法很不一样，这种写法更像是通常写函数的样子，只不过把函数放在了class里面而已。</p>
<p>一个定义在class里面的staticmethod，就是一个很普通的函数，使用它的时候，就像使用其它定义在外面的函数一样。</p>
<p>staticmethod decorator，把函数放到了class的命名空间下，让这个函数从属于这个类class了。</p>
<p>调用时，<code>A.f(1)</code>，这里的A是class，而不是class的对象object（如果是类的对象，应该写成 <code>A()</code>）。这种调用的用法很像在全局定义一个<code>f(x)</code>，然后再去调用<code>f(1)</code>。</p>
<p>如果想用类的对象来调用函数，依然也是可以用的（不会报错）。就是@staticmethod修饰过的函数，用 <code>A()f(1)</code>，也就是用类的对象来调用函数，依然也是可以用的。</p>
<h4 id="staticmethod的意义："><a href="#staticmethod的意义：" class="headerlink" title="staticmethod的意义："></a>staticmethod的意义：</h4><ol>
<li>提供了一个更好的封装，这个函数从属于一个类了；</li>
<li>不用建立这个类的对象，直接用类就可以调用这个函数；适用于想把功能绑定在类、而不是类的对象上的场景。</li>
</ol>
<h3 id="classmethod的使用"><a href="#classmethod的使用" class="headerlink" title="classmethod的使用"></a>classmethod的使用</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>:</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">cls, x</span>):</span><br><span class="line">        <span class="built_in">print</span>(cls, x)</span><br><span class="line"></span><br><span class="line">A.f(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;__main__.A&#x27;</span>&gt; <span class="number">1</span></span><br><span class="line"></span><br><span class="line">A().f(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;__main__.A&#x27;</span>&gt; <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>和staticmethod很像，也可以直接在class上调用，或者在class的对象上调用。</p>
<p>classmethod装饰的函数传入的第一个参数是一个类class，但是调用时，不需要传入这个参数（class），和self参数很像。</p>
<p>无论是class或class的object，调用函数时，第一个参数都是class类型。（对于object，会把object的type传进去（对象的类型是class））</p>
<h3 id="staticmethod-的实现"><a href="#staticmethod-的实现" class="headerlink" title="staticmethod 的实现"></a>staticmethod 的实现</h3><p>这段没有看懂。</p>
<h2 id="chatgpt解释"><a href="#chatgpt解释" class="headerlink" title="chatgpt解释"></a>chatgpt解释</h2><blockquote>
<p>chatgpt的回答</p>
</blockquote>
<p><code>classmethod</code>是一种特殊类型的方法，它是针对类对象而不是实例对象进行操作的方法。它的第一个参数永远是类本身，而不是实例，因此可以通过类本身来访问类的属性和方法。下面是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, width, height</span>):</span><br><span class="line">        self.width = width</span><br><span class="line">        self.height = height</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">area</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.width * self.height</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">square</span>(<span class="params">cls, side_length</span>):</span><br><span class="line">        <span class="keyword">return</span> cls(side_length, side_length)</span><br><span class="line"></span><br><span class="line">square = Rectangle.square(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(square.area())  <span class="comment"># 25</span></span><br></pre></td></tr></table></figure>

<p>在上面的例子中，我们通过使用<code>@classmethod</code>装饰器声明了一个类方法<code>square</code>，它接受一个参数<code>side_length</code>，并返回一个具有相同长和宽的矩形。在这个例子中，我们可以通过调用<code>Rectangle.square(5)</code>来获得一个5x5的正方形。</p>
<p><code>staticmethod</code>是另一种特殊类型的方法，它不需要任何类或实例对象作为参数，它与类和实例对象没有任何关系。它是类内部的独立函数，可以通过类名直接访问。下面是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, width, height</span>):</span><br><span class="line">        self.width = width</span><br><span class="line">        self.height = height</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">area</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.width * self.height</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_valid_dimension</span>(<span class="params">dimension</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(dimension, <span class="built_in">int</span>) <span class="keyword">and</span> dimension &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(Rectangle.is_valid_dimension(<span class="number">5</span>))  <span class="comment"># True</span></span><br><span class="line"><span class="built_in">print</span>(Rectangle.is_valid_dimension(-<span class="number">5</span>))  <span class="comment"># False</span></span><br></pre></td></tr></table></figure>

<p>在上面的例子中，我们通过使用<code>@staticmethod</code>装饰器声明了一个静态方法<code>is_valid_dimension</code>，它接受一个参数<code>dimension</code>，并判断它是否是一个有效的整数。我们可以通过调用<code>Rectangle.is_valid_dimension(5)</code>来获得该方法的结果。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python @property、@.setter</title>
    <url>/2023/02/09/python/python%20@property/</url>
    <content><![CDATA[<h1 id="python-property、-setter"><a href="#python-property、-setter" class="headerlink" title="python @property、@.setter"></a>python @property、@.setter</h1><h2 id="函数作为参数"><a href="#函数作为参数" class="headerlink" title="函数作为参数"></a>函数作为参数</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1zg41197cy/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">Python中各种@property、@xxx.setter、@classmethod、@staticmethod 都是些啥啊？</a></p>
</blockquote>
<p>函数作为参数，可以传入函数，但是没写return的话，就会变成返回NoneType</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">say</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;something&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func_1</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;start&quot;</span>)</span><br><span class="line">    func()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;end&quot;</span>)</span><br><span class="line">    </span><br><span class="line">func_1(say)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">start</span><br><span class="line">something</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p>但是由于func_1没有return，当执行的函数赋给一个变量时，比如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">my_func = func_1(say)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">start</span><br><span class="line">something</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"><span class="comment"># my_func 是一个class NoneType的对象</span></span><br><span class="line"><span class="comment"># 所以不能:</span></span><br><span class="line">my_func()</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: <span class="string">&#x27;NoneType&#x27;</span> <span class="built_in">object</span> <span class="keyword">is</span> <span class="keyword">not</span> <span class="built_in">callable</span></span><br></pre></td></tr></table></figure>

<p>由于没有return，这个变量是一个NoneType类的对象。</p>
<p><code>my_func = func_1(say)</code>这句话，我们希望的是<strong>拿到函数的引用</strong>，然后去用这个变量做其它事情，执行其它代码。	</p>
<p>如何使得这个变量也是一个函数呢？！通过 <strong>定义内部方法，然后返回这个引用</strong>！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func_1</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner_func</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;start&quot;</span>)</span><br><span class="line">        func()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;end&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">my_func = func_1(say)</span><br><span class="line">my_func()</span><br></pre></td></tr></table></figure>



<p>因此，这里 func_1 是为了改变、优化传入进来的函数的执行结果。</p>
<p>内部的inner_func通常名字叫“wrapper”</p>
<h2 id="Python中的-property、-xxx-setter"><a href="#Python中的-property、-xxx-setter" class="headerlink" title="Python中的@property、@xxx.setter"></a>Python中的@property、@xxx.setter</h2><blockquote>
<p>廖雪峰：<a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017502538658208">使用@property</a></p>
</blockquote>
<p>举例，一个检查分数，返回分数的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_score</span>(<span class="params">self</span>):</span><br><span class="line">         <span class="keyword">return</span> self._score</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_score</span>(<span class="params">self, value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(value, <span class="built_in">int</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;score must be an integer!&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> value &lt; <span class="number">0</span> <span class="keyword">or</span> value &gt; <span class="number">100</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;score must between 0 ~ 100!&#x27;</span>)</span><br><span class="line">        self._score = value</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = Student()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.set_score(<span class="number">60</span>) <span class="comment"># ok!</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.get_score()</span><br><span class="line"><span class="number">60</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.set_score(<span class="number">9999</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  ...</span><br><span class="line">ValueError: score must between <span class="number">0</span> ~ <span class="number">100</span>!</span><br></pre></td></tr></table></figure>



<p>用@后面添加一个要进行额外操作的方法名称。</p>
<p>能检查参数，又可以用类似属性这样简单的方式来访问类的变量。</p>
<p>Python内置的<code>@property</code>装饰器就是负责把一个方法变成属性调用的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line"></span><br><span class="line"><span class="meta">    @score.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self, value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(value, <span class="built_in">int</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;score must be an integer!&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> value &lt; <span class="number">0</span> <span class="keyword">or</span> value &gt; <span class="number">100</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;score must between 0 ~ 100!&#x27;</span>)</span><br><span class="line">        self._score = value</span><br></pre></td></tr></table></figure>

<p><code>@property</code>的实现比较复杂，我们先考察如何使用。把一个getter方法变成属性，只需要加上<code>@property</code>就可以了，此时，<code>@property</code>本身又创建了另一个装饰器<code>@score.setter</code>，负责把一个setter方法变成属性赋值，于是，我们就拥有一个可控的属性操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = Student()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.score = <span class="number">60</span> <span class="comment"># OK，实际转化为s.set_score(60)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.score <span class="comment"># OK，实际转化为s.get_score()</span></span><br><span class="line"><span class="number">60</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.score = <span class="number">9999</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  ...</span><br><span class="line">ValueError: score must between <span class="number">0</span> ~ <span class="number">100</span>!</span><br></pre></td></tr></table></figure>

<p>注意到这个神奇的<code>@property</code>，我们在对实例属性操作的时候，就知道该属性很可能不是直接暴露的，而是通过getter和setter方法来实现的。</p>
<blockquote>
<p>chatgpt的回答：</p>
</blockquote>
<p>Python 中的 <code>property</code> 是一个内置装饰器，它可以把一个类中的方法设置为属性的读取&#x2F;设置&#x2F;删除方法。</p>
<p>使用方法如下：</p>
<ol>
<li><p>定义 getter 方法，返回需要作为属性读取的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Example</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, value</span>):</span><br><span class="line">        self._value = value</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_value</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._value</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 getter 方法上使用 @property 装饰器，将其标记为属性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Example</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, value</span>):</span><br><span class="line">        self._value = value</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">value</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._value</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果需要为属性提供写入操作，可以定义一个 setter 方法，并在该方法上使用 @property 名称的 setter 装饰器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Example</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, value</span>):</span><br><span class="line">        self._value = value</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">value</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._value</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @value.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">value</span>(<span class="params">self, value</span>):</span><br><span class="line">        self._value = value</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果需要为属性提供删除操作，可以定义一个 deleter 方法，并在该方法上使用 @property 名称的 deleter 装饰器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Example</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, value</span>):</span><br><span class="line">        self._value = value</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">value</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._value</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @value.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">value</span>(<span class="params">self, value</span>):</span><br><span class="line">        self._value = value</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @value.deleter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">value</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">del</span> self._value</span><br></pre></td></tr></table></figure></li>
</ol>
<p>然后，你可以使用如下语句来读取、写入和删除属性值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">example = Example(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(example.value) <span class="comment"># 读取属性值</span></span><br><span class="line">example.value = <span class="number">20</span>   <span class="comment"># 写入属性值</span></span><br><span class="line"><span class="keyword">del</span> example.value     <span class="comment"># 删除</span></span><br></pre></td></tr></table></figure>







<blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1zg41197cy/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">Python中各种@property、@xxx.setter、@classmethod、@staticmethod 都是些啥啊？</a> 说得不好</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        self._name = name</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._name</span><br><span class="line"><span class="meta">    @name.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(name) &lt; <span class="number">5</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;至少5个字符&quot;</span>)</span><br><span class="line">        self._name = name</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_user</span>(<span class="params">cls</span>):</span><br><span class="line">        <span class="keyword">return</span> (cls(<span class="string">&#x27;people&#x27;</span>))</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lenght</span>():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">18</span></span><br></pre></td></tr></table></figure>

<p>@property和@.setter搭配使用</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>视频 基于多码本向量量化的蒸馏方案</title>
    <url>/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<h1 id="视频-基于多码本向量量化的蒸馏方案"><a href="#视频-基于多码本向量量化的蒸馏方案" class="headerlink" title="视频 基于多码本向量量化的蒸馏方案"></a>视频 基于多码本向量量化的蒸馏方案</h1><blockquote>
<p>b站视频：姚增伟 <a href="https://www.bilibili.com/video/BV1xV4y1T7f9/?spm_id_from=333.788.recommend_more_video.13&vd_source=5e9891722f2b62adca440a5e92121b5b">【语音之家】AI产业沙龙—如何应用k2开发语音识别系统</a>  或  <a href="https://xjw.h5.xeknow.com/sl/2yOtKa">https://xjw.h5.xeknow.com/sl/2yOtKa</a> 22分钟起</p>
<p>Guo, Liyong, et al. “Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation.” <em>arXiv preprint arXiv:2211.00508</em> (2022). 郭理勇</p>
<p>微信公众号 新一代Kaldi： <a href="https://mp.weixin.qq.com/s/XIg8cY82KtoZ6rW-FdVqEQ">新一代 Kaldi 中基于量化的蒸馏实验</a></p>
<p>相关代码：<a href="https://github.com/k2-fsa/multi_quantization.git">https://github.com/k2-fsa/multi_quantization.git</a> </p>
<p>相关代码：<a href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless6">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless6</a></p>
<p>D:\typora\typora笔记\语音\k2\Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation.md</p>
</blockquote>
<blockquote>
<p>以下文字和图片主要来自《微信公众号 <a href="https://mp.weixin.qq.com/s/XIg8cY82KtoZ6rW-FdVqEQ">新一代 Kaldi 中基于量化的蒸馏实验</a>》和《b站视频：姚增伟 <a href="https://www.bilibili.com/video/BV1xV4y1T7f9/?spm_id_from=333.788.recommend_more_video.13&vd_source=5e9891722f2b62adca440a5e92121b5b">【语音之家】AI产业沙龙—如何应用k2开发语音识别系统</a>  22分钟起》</p>
</blockquote>
<p>基于多码本向量量化的蒸馏方案，通过将 teacher 模型的高维（如 1280 维）的 float 向量量化为极少数个（如 8 个）uint8 类型的码本索引，显著地降低了存储空间，并基于量化结果进行高效蒸馏。      </p>
<h2 id="1-动机与方案概述"><a href="#1-动机与方案概述" class="headerlink" title="1 动机与方案概述"></a>1 动机与方案概述</h2><h3 id="1-1-动机"><a href="#1-1-动机" class="headerlink" title="1.1 动机"></a>1.1 动机</h3><p>预训练在语音识别中不断刷新 SOTA，但真正用的时候又会有模型太大、流式等问题；</p>
<p>可以使用知识蒸馏的方式用预训练模型 hubert 教 ASR 模型。</p>
<p>假设以 hubert 作为 teacher 模型，其 embedding 将传递给 student 模型用于辅助训练, 传统的蒸馏学习的一种实现方式如下图所示：</p>
<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230315175447111.png" alt="image-20230315175447111" style="zoom:80%;">

<p>为了获取 teacher embedding, 一般有 online 和 offline 两种方式：</p>
<ol>
<li><p>online 的方式需要在训练 student 模型过程中前向 teacher 模型，获取当前 batch 数据对应的 teacher embedding。该方案存在大量重复计算，即每个 epoch 都要把数据过一次 teacher 模型。而且 teacher 模型需要长期驻留显存，如果其参数量过大，还会导致训练过程中只能使用较小的 batch_size， 有可能导致收敛不稳定。</p>
</li>
<li><p>offline 的方式需要在训练 student 模型之前，先把所有的训练数据过一次 teacher 模型,将相应的 teacher embedding 全部存储到磁盘之中，在 student 模型训练时直接从磁盘读取。该方案解决了上述 online 方式的问题，缺陷是可能需要很大的磁盘存储空间。以 HuBERT Extra Large 模型为例，输出帧率为50 frame&#x2F;s，输出维度为1280，因此100小时音频对应的 teacher embedding 需要存储空间 4 * 1280 * 50 * 3600 * 100 Byte &#x3D; 92160000000 Byte &#x3D; 85.8G。在 icefal 的实验设置中，一般会再加上<strong>3倍</strong>语音增广，因此全量1000小时数据对应的 teacher embedding 需要的存储空间为 85.8 * 10 * 3 &#x3D; 2.51T。这还只是从 teacher 模型中抽取一层，如果是多层的话，所需存储空间还要相应增大。</p>
</li>
</ol>
<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230315175021656.png" alt="image-20230315175021656" style="zoom:80%;">

<h3 id="1-2-方案概述"><a href="#1-2-方案概述" class="headerlink" title="1.2 方案概述"></a>1.2 方案概述</h3><p>相对于传统的蒸馏方案， Dan哥变革性地提出了使用量化方式进行知识蒸馏。</p>
<p>对于 offline 方式，我们把一个浮点向量 (float embedding) 量化为一组整数 codebook indexes(CI), 且<strong>每个整数</strong>的范围仅为[0, 255], 因此<strong>每个整数</strong>仅需一个Byte的磁盘空间。比如上述1280维的浮点向量，量化前需要 1280 * 4 Byte空间; 如果我们将浮点向量量化成8个无符号整数，则仅需 8个 Byte（uint8，一个byte是8bit，0-255）, 所需存储空间仅为量化前的 $\frac{1}{640}$ 。</p>
<p>依托这一组量化所得的整数 codebook index 进行蒸馏实验，降低 student 模型语音识别模型错误率。</p>
<p>改进后的蒸馏方案如下图所示，其中最大的变化就是把 <strong>teacher embedding 转化为 CI</strong>：</p>
<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230315180730882.png" alt="image-20230315180730882" style="zoom:80%;">







<h2 id="2-术语字典"><a href="#2-术语字典" class="headerlink" title="2 术语字典"></a>2 术语字典</h2><p>为了消除本文中潜在的歧义，部分关键的高频词汇简介如下：</p>
<p><strong>浮点向量 (float embedding)</strong> : 一般指 teacher 模型中某层的输出向量，作为量化工具的输入；比如 HuBERT Extra Large 的第36层的输出。</p>
<p><strong>codebook index（CI）</strong>: 浮点向量(float embedding)对应生成的一组整数，取值范围[0, 255],只需一个Byte存储；如果不专门强调，CI 一般指量化所得的<strong>一组</strong>整数。</p>
<p><strong>num_codebooks</strong>: codebook index 包含的整数个数，一般为2的幂，比如2，4，8，16，32；在本文实验中，该参数设置为8。</p>
<p><strong>quantizer</strong>: 量化器；输入一个浮点向量，生成对应的 codebook index；其主要包含 encoder 和 decoder 两大模块；encoder 负责将 float embedding 量化为 CI, decoder 负责将 CI 重构为 float embedding。</p>
<p><strong>hubert 模型</strong>：在下文蒸馏实验中，用到了 **<a href="https://github.com/facebookresearch/fairseq/blob/main/examples/hubert/README.md">fairseq 提供的 HuBERT Extra Large Fintuend model</a>**作为 teacher 模型，该模型使用6万小时 Libri-Light <strong>无监督数据</strong>预训练，960小时的 LibriSpeech 做 finetune。为了行文方便，有时候简记为 hubert。</p>
<p><strong>teacher embedding</strong>: 从 teacher 模型某一层的输出的 float embedding, 此概念着重强调其来自于一个 teacher 模型，用于指导 student 模型的训练。</p>
<p><strong>cd_init</strong>: codebook_index initialized value，由 quantizer.encoder模块通过(to_logits + argmax) 生成, to_logits 本质上是 nn.linear。</p>
<p><strong>cd_refined</strong>: codebook_index refined value，由 quantizer.encoder 模块通过函数 _refine_indexes 在 $cd_init$ 的基础上优化生成。最终蒸馏实验用的 CI 一般对应该参数。</p>
<h2 id="3-代码仓库"><a href="#3-代码仓库" class="headerlink" title="3 代码仓库"></a>3 代码仓库</h2><h3 id="3-1-量化相关代码"><a href="#3-1-量化相关代码" class="headerlink" title="3.1 量化相关代码"></a>3.1 量化相关代码</h3><p>最初的代码仓库为 <strong><a href="Danpovey/quantizaiton">Danpovey&#x2F;quantizaiton</a></strong> 后来在Dan哥的建议下，迁移至 <strong><a href="https://github.com/k2-fsa/multi_quantization.git">k2-fsa&#x2F;multi_quantization</a></strong> 并发布到 pypi, 因此可以采用两种方式安装：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install git+https:git@github.com:k2-fsa/multi_quantization.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"></span><br><span class="line">pip install multi_quantization</span><br></pre></td></tr></table></figure>

<p>理论上两种方式是等效的，后续我们也会尽量实现二者的同步更新。</p>
<h3 id="3-2-蒸馏实验相关代码"><a href="#3-2-蒸馏实验相关代码" class="headerlink" title="3.2 蒸馏实验相关代码"></a>3.2 蒸馏实验相关代码</h3><p>主要涉及 icefall 中的 <strong><a href="librispeech/pruned_transducer_stateless6">librispeech&#x2F;pruned_transducer_stateless6</a></strong> 该 recipe 可以分为两大部分：</p>
<ol>
<li><p><strong>quantizer 使用示例</strong>，包含数据准备，quantizer 训练，以及 codebook index 提取。</p>
</li>
<li><p>使用 codebook index 进行 <strong>ASR 蒸馏实验</strong> 该实验中使用 fairseq 驱动其提供的 HuBERT Extra Large 模型作为 teacher 模型。机器配置资源较低的环境可能需要较长的时间提取相应的 codebook indexes. 因此我们已将提取所得的 codebook indexes 开源出来，有需要的朋友可以在示例脚本**<a href="https://github.com/k2-fsa/icefall/blob/master/egs/librispeech/ASR/distillation_with_hubert.sh">distillation_with_hubert</a>**中设置 <strong>use_extracted_codebook&#x3D;True</strong>, 跳过提取过程，下载开源的 codebook index 后，进行 ASR 蒸馏实验。</p>
</li>
</ol>
<h2 id="4-quantizer-相关代码解析"><a href="#4-quantizer-相关代码解析" class="headerlink" title="4 quantizer 相关代码解析"></a>4 quantizer 相关代码解析</h2><h3 id="4-1-quantizer-训练代码示例"><a href="#4-1-quantizer-训练代码示例" class="headerlink" title="4.1 quantizer 训练代码示例"></a>4.1 quantizer 训练代码示例</h3><p>在Dan哥给出的 **<a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/tests/test_train_hdf5.py#L33">quantizer 训练示例代码</a>**中，核心代码及注释如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始化一个 QuantizerTrainer,</span></span><br><span class="line"><span class="comment"># 其中dim 为teacher embedding的维度,在hubert模型中为1280;</span></span><br><span class="line"><span class="comment"># bytes_per_frame为压缩后整数的个数，本文实验中为 8；</span></span><br><span class="line"><span class="comment"># 即训练所得的quantizer,</span></span><br><span class="line"><span class="comment"># 可以将一个1280维的teacher embedding 量化后的一组整数</span></span><br><span class="line"><span class="comment"># 共需8个Bytes即可存储。</span></span><br><span class="line">trainer = QuantizerTrainer(dim=dim,</span><br><span class="line">                           bytes_per_frame=bytes_per_frame,</span><br><span class="line">                           device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读训练数据</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> minibatch_generator(train, repeat=<span class="literal">True</span>):</span><br><span class="line">    <span class="comment"># 训练一个batch</span></span><br><span class="line">    trainer.step(x)</span><br><span class="line">    <span class="comment"># 触发终止训练条件； 目前为训练20，000batch终止。</span></span><br><span class="line">    <span class="keyword">if</span> trainer.done():</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 获取训练所得quantizer</span></span><br><span class="line">quantizer = trainer.get_quantizer()</span><br><span class="line"><span class="comment"># 存储quantizer, 用于后续将teacher embedding 量化为 codebook indexes.</span></span><br><span class="line">torch.save(quantizer.state_dict(), <span class="string">&#x27;quantizer.pt&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h3 id="4-2-quantizer-对-float-embedding-的量化与反量化示例"><a href="#4-2-quantizer-对-float-embedding-的量化与反量化示例" class="headerlink" title="4.2 quantizer 对 float embedding 的量化与反量化示例"></a>4.2 quantizer 对 float embedding 的量化与反量化示例</h3><p>下述代码片段来自 Dan哥提供的 <strong><a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/tests/test_train_hdf5.py#L49">示例代码 </a></strong> ,为了便于添加注释，稍做改动：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  加载训练所得的 quantizer </span></span><br><span class="line">quantizer_fn = <span class="string">&#x27;quantizer.pt&#x27;</span></span><br><span class="line"><span class="comment"># 在codebook_size=256时，num_codebooks 与上文中 bytes_per_frame 值相等, </span></span><br><span class="line"><span class="comment"># 如果仅调用 quantizer 的接口，不深究quantizer的实现原理，可以认为二者就是一个参数；</span></span><br><span class="line"><span class="comment"># codebook_size, CI的分类范围，设置为256类，刚好一个 Byte 就能存储。</span></span><br><span class="line">quantizer2 = Quantizer(dim=dim, num_codebooks=<span class="number">4</span>, codebook_size=<span class="number">256</span>)</span><br><span class="line">quantizer2.load_state_dict(torch.load(quantizer_fn))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 量化</span></span><br><span class="line">codebook_indexes = quantizer2.encode(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反量化（重构）</span></span><br><span class="line">x_approx = quantizer2.decode(codebook_indexes)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="4-3-quantizer-训练算法解析"><a href="#4-3-quantizer-训练算法解析" class="headerlink" title="4.3 quantizer 训练算法解析"></a>4.3 quantizer 训练算法解析</h3><p>本节主要介绍上述 <code>trainer.step(x)</code>背后的主要算法细节</p>
<p>强烈建议<strong>结合 quantization.py 源码</strong>看下面的解析</p>
<p>quantizer 结构如图所示：</p>
<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230316101150352.png" alt="image-20230316101150352" style="zoom:80%;">

<p>图中RRL对应代码中的 Relative Reconstruction Loss；LH（sp, sc）对应代码中的 logprob_loss; LH(sp) 对应 logits_entropy_loss。如Dan哥在注释中所说，logits_entropy_loss 起的作用较小，有时候甚至不用，本文只重点介绍 RRL 与 logprob_loss。</p>
<p>从总体框架上看，其核心思想与自编码器（Autoencoder, AE）类似，即<code>encoder</code>把输入 转化为中间表示，<code>decoder</code> 把该中间表示重构为输出 , 通过不断降低输入 和输出 之间的重构误差，使中间表示能够有效的承载输入 中的信息。在Dan哥的 multi_quantion 项目中，使用的是相对重构误差(Relative Reconstruction Loss, RRL), 摘抄dan哥在注释中的定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">RRL = <span class="built_in">sum</span>-squared of (x - reconstructed_x) / (<span class="built_in">sum</span>-squared of x-x_mean)</span><br></pre></td></tr></table></figure>

<p>相对于上述经典的自编码器autoencoder， Dan哥在 multi_quantizaiton 项目中做出了如下优化：</p>
<ol>
<li><p>中间表示 codebook index，取值范围为[0, 255]; 因此由 float embedding 量化所得的每个整数仅需一个 Byte 的存储空间。</p>
</li>
<li><p>在训练 quantizer 过程中, 通过 <strong><a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L308">_refine_indexes</a></strong> 函数（迭代搜索 codebook_indexes 全局最优函数），迭代搜索 codebook_indexes 的最佳组合，使 encoder 得到的量化结果接近<strong>全局最优</strong>的效果。</p>
</li>
<li><p>在经典重构误差函数（Relative Reconstruction Loss, RRL) 的基础上，添加 <strong><a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L200">logprob_loss</a></strong> （logprob_loss定义）,使得神经网络<code>encoder</code>直接计算出来的codebook_indexes 不断逼近通过迭代搜索的<strong>全局最优</strong>组合。（**<a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L201">Dan哥注释原文</a>**（logprob_loss作用）：This is added to the loss function, so we can select reasonable classes <strong>before</strong> refining the indexes）</p>
</li>
</ol>
<h4 id="4-3-1-quantizer-模块分析"><a href="#4-3-1-quantizer-模块分析" class="headerlink" title="4.3.1 quantizer 模块分析"></a>4.3.1 quantizer 模块分析</h4><p>下述代码抽取于 <strong><a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L38">class Quantizer</a></strong> 定义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Quantizer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 codebook_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 num_codebooks: <span class="built_in">int</span></span>):</span><br><span class="line"></span><br><span class="line">        self.to_logits = nn.Linear(dim, codebook_size * num_codebooks)</span><br><span class="line"></span><br><span class="line">        self.centers = nn.Parameter(self.to_logits.weight.detach().clone().reshape(</span><br><span class="line">            num_codebooks, codebook_size, dim))</span><br><span class="line"></span><br><span class="line">        self.logits_scale = nn.Parameter(torch.zeros(()))</span><br><span class="line">        self.centers_scale = nn.Parameter(torch.zeros(()))</span><br><span class="line">        self.scale_speed = <span class="number">10.0</span> <span class="comment"># affects learning rate of scales</span></span><br></pre></td></tr></table></figure>

<p>在上述<code>__init__</code>函数中，有四处值得注意的点：</p>
<ol>
<li><p>本质上 Quantize 是一个 nn.Module，所以它本质上是 neural net(nn).</p>
</li>
<li><p>其子模块 self.to_logits 是一个 nn.Linear; 该模块是 <strong>encoder</strong> 的主要参数。它将一个输入为<code>dim</code>的向量转化为 <code>codebook_size * num_codebooks</code>;比如 dim &#x3D; 1280; codebook_size * num_codebooks &#x3D; 256 * 8; 在量化过程中，float embedding 转化为 <strong><a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L297">整数codebook_index代码</a></strong> 摘出来即：</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># x  即 float embedding</span></span><br><span class="line"><span class="comment"># _logits 在 to_logits 的基础上增加了一个可学习的scale, 此处功能上可视为nn.Linear</span></span><br><span class="line">logits = self._logits(x) </span><br><span class="line"></span><br><span class="line"><span class="comment"># indexes 即为 cd_init</span></span><br><span class="line">indexes = torch.argmax(logits, dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>argmax 找最大值的索引，作为indexes。</p>
<ol start="3">
<li>self.centers 包含了 num_codebooks * codebook_size * dim 个参数，它是 <strong>decoder</strong> 的主要载体，把整数 codebook_index 重构回 float embedding 的代码摘出来即：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chosen_codebooks = torch.gather(centers, dim=<span class="number">1</span>, index=indexes_expanded)</span><br><span class="line">x_approx = chosen_codebooks.<span class="built_in">sum</span>(dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>一些 logits_scale&#x2F;centers_scale 参数，这些 scale 参数与 <strong><a href="https://mp.weixin.qq.com/s?__biz=MzkyMzI5NTM2Ng==&mid=2247483882&idx=1&sn=2fc14395df62e28b0236fcd12c25efcc&chksm=c1e60a03f69183152bed4fff2e17cc2249e3f59ec21b09b10182562fe6fbe45df0c83d822408&token=1212992197&lang=zh_CN#rd">reworked conformer</a></strong> 中的 scale 参数异曲同工，都起到帮助模型收敛的目的。</li>
</ol>
<p>看到上面 encoder 和 decoder 的相关代码，熟悉 pytorch 的朋友可能本能地觉得 “Ah， 就这! encoder 就做个线性变换，取个 argmax 得到个<strong>位置 index</strong> 就说是 <strong>整数 codebook_index</strong>；decoder 用这个 <strong>位置index</strong> 从 parameters 矩阵找到对应的 embedding 加一块“就是重构结果。</p>
<p>在深入解析Dan哥代码之前，先<strong>算一笔小账</strong>，<strong>encoder 输出的 codebook_indexes 理论上大概有多少种可能？</strong>能够重构出来的向量大概又有多少种？</p>
<p>假设 codebook_size&#x3D;256，num_codebooks&#x3D;1, (当然实际应用中最好不要这样设置，毕竟这个项目的名字就叫 <strong>multi_quantization</strong>, 让 num_codebooks&#x3D;1 白瞎了这个名字).</p>
<p>在 num_codebooks&#x3D;1 时，任意的输入向量 $x$ , 最后都被压缩[0, 255]中的一个整数，自然 codebook_indexes 只有 256种可能，而 decoder 重构出来的结果与 codebook_indexes 一一对应，自然也只有256种可能。</p>
<p>当 num_codebooks&#x3D;2 时，encoder 会输出两个整数，每个数的范围都是[0, 255], 他们的组合有256 * 256 种可能，而 decoder 重构出来的结果与 codebook_indexes 一一对应，自然也有256 * 256种可能。</p>
<p>当 num_codebooks&#x3D;8 时，encoder 的输出为 种组合，这个数已经相当大了，是不是<strong>1800亿亿</strong>？，姑且记作 $Total$ 吧。</p>
<p>而接下来我们要探讨的就是如何从这个巨大的 $Total$  个候选中，如何不断逼近<strong>全局最优组合</strong>。</p>
<h4 id="4-3-2-神奇的-refine-indexes-函数：如何不断逼近全局最优组合"><a href="#4-3-2-神奇的-refine-indexes-函数：如何不断逼近全局最优组合" class="headerlink" title="4.3.2 神奇的 _refine_indexes 函数：如何不断逼近全局最优组合"></a>4.3.2 神奇的 _refine_indexes 函数：如何不断逼近全局最优组合</h4><p>接下来要介绍的_refine_indexes函数 可以说是 multi_quantization 项目中最难的一个函数; 从代码行数可见一斑，算上辅助函数 quantization.py 也只有<strong>820行</strong>，而这个函数独占L308-L547共计<strong>240行</strong>！</p>
<p>下面解析中假设 num_codebooks&#x3D;8, 即一个 float embedding 被量化为 8 个整数。首先根据 encoder 中的 linear + argmax 可以获得一组 codebook_index, 包含8个属于 $[0,255]$ 的整数, 不 妨记作 $c d _i n i t$, 它必然是上面提到的 Total 个组合之一。假设其对应的重构误差为 $R R L _i n i t$ , 现在需要思考一个问题, cd_init 是 Total 中这么多组合中重构误差最小的那么个吗? 或者 说有没有如何找到一组 codebook_index, 让它的重构误差比 $c d$ init 还要来的小?</p>
<p>针对这个问题, 先探究一个特别粗䊁的方案, 记为草量级版本。假设 $c d _i n i t&#x3D;\left[i_1, i_2, i_3, i_4, i_5, i_6, i_7, i_8\right] ;$ 其中 $i_k$ 是一个属于 $[0,255]$ 的整数。假设暂时不动 $\left[i_2, \ldots, i_7, i_8\right]$ 这 7 个数, 我们把 $i_1$ 位置上的其余 256 种可能性都尝试一遍, 不妨记这些所有的 可能性为 $c d _a l l{ }_ 2 56$, 它们对应的重构误差记为 $R R L _a l l _256$; 然后对 $R R L _a l l _256$ 进行排 序, 取最小值对应的组合作为优化后的量化结果,记为 $c d _r e f i n e d$, 对应的重构误差为 $R R L _$refined, 很明显 $R R L _refined \leq R R L _i n i t$ 。</p>
<p>函数 $_refine_index$ 充分发挥上述 <strong>定余求一</strong> 的思想, 在 $c d _i n i t$ 的基础上, 通过多轮迭代优化, 最终获得RRL更低的 $c d _r e f i n e d$ 。</p>
<p>该函数中有三个关键的变量N， K， L, 下图<strong>自下而上</strong>列出迭代搜索过程中，N-K-L三个数值的变化:</p>
<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/640.jpeg" alt="640" style="zoom:80%;">



<p>上图每一层代表一轮搜索的过程。其中<strong>第一层</strong>，可以看做是前述<strong>草量级版本</strong>的 <strong>并行化</strong>，记为<strong>轻量级</strong>版本。其思想在于对于 个位点中的每个 , 穷举其所有的 种可能性，并结合另外7个来自于 的 计算RRL; 对于每个位点，根据RRL的大小对 个候选进行排序，选其中最优的 个进入下一轮迭代。此处对应**<a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L348">Dan哥注释</a>** （K_cutoff注释）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reduce K to K_cutoff by sorting and taking the K_cutoff best possibilities for each choice.</span><br></pre></td></tr></table></figure>



<p>值得注意的是，每个位点是并行处理的。每个位点在确定自己的最优个 $K_cutoff$ 时，并不知道对方的搜索结果。这就面临一个风险， $i_1$ 位置上的最优个 $K_cutoff$ 个候选是和其余7个来自 $c_init$ 中的 index 一起计算 RRL，但是这7个数在它们对应位置的筛选过程中<strong>可能</strong>被<strong>淘汰掉了</strong>。理论上来说，甚至会出现 $RRL_refined &gt; RRL_init$情况！！！</p>
<p><strong>举例</strong>：假设 dim&#x3D;1, num_codebooks&#x3D;2;即我们要把一个float <strong>量化</strong>为两个整数，每个整数的分布范围是[0, 4]，self.centers 包含的参数维度[num_codebooks, codebook_size, dim] &#x3D; [2, 5, 1],其值为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> 忽略最后维度1， 即 shape = [2,5]</span><br><span class="line">[</span><br><span class="line">  [0.1 0.2 0.3 0.4 0.5]</span><br><span class="line">  [0.1 0.2 0.3 0.4 0.5]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>



<p>根据以上假设条件, 如果待量化的输入 $x&#x3D;0.52$, encoder 通过 linear + argmax 得到的 $c d _i n i t&#x3D;[2,2]$; 此时得到的重构结果为 $\hat{x}&#x3D;0.3+0.3&#x3D;0.6$ 。采用上述并行化的轻量级算法, 假设 $K _c u t o f f&#x3D;1$, 对于位点 $i_1$, 由于 $i_2&#x3D;2$, 遍历 $i_1$ 的 5 种全部候选值, 显然最佳结果为 $i_1&#x3D;1$, 即操作 $i_1$ 位置的这部分算法认为它修改后的重构结果应该是 $\hat{x}&#x3D;0.2+0.3&#x3D;0.5$;</p>
<p>但是此刻还有一个并行的算法在操作位点 $i_2$, 在位点 $i_1$ 做出决定时, 它在 $c d _i n i t$ 中的 $i_1&#x3D;2$ 的 基础上做出了 $i_2&#x3D;1$ 的选择, 即它认为它修改后的的重构结果应该为 $\hat{x}&#x3D;0.3+0.2&#x3D;0.5$;</p>
<p>由于 $ K_cutoff &#x3D;1$, 它们都返回了一个最佳候选, 两路并行程序给出的结果汇总后, 得到 cd_refine $&#x3D;[1,1]$, 即 $\hat{x}&#x3D;0.2+0.2&#x3D;0.4$.<br>综上, 本来重构结果与目标距离 $-0.08&#x3D;0.52-0.6$, 一番操作猛如虎之后, 与目标距离成了 $0.12&#x3D;0.52-0.4$, 反倒还增大了 $50 %$ 。！！！</p>
<p>（就像《麦琪的礼物》）</p>
<p>在实际训练过程中，函数 [_refine_indexes] 一般也不会遇到上面给出的极端反例，一般情况下，$R R L _refined \leq R R L _i n i t$ ， 如下所示为 <strong><a href="https://github.com/k2-fsa/multi_quantization/blob/ecea30b79699e2e6f24d253f2563f78e4c1441fc/multi_quantization/quantization.py#L302">连续5次使用函数</a></strong> _refine_indexes 重构误差RRL的变化：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">loss_per_iter=[0.496, 0.451, 0.439, 0.437, 0.436, 0.435],</span><br><span class="line">loss_per_iter=[0.483, 0.442, 0.432, 0.43, 0.429, 0.429],</span><br><span class="line">loss_per_iter=[0.489, 0.447, 0.434, 0.432, 0.43, 0.43],</span><br><span class="line">loss_per_iter=[0.487, 0.445, 0.434, 0.432, 0.431, 0.431],</span><br><span class="line">loss_per_iter=[0.479, 0.438, 0.428, 0.426, 0.425, 0.425],</span><br><span class="line">loss_per_iter=[0.485, 0.443, 0.433, 0.43, 0.43, 0.43],</span><br><span class="line">loss_per_iter=[0.482, 0.442, 0.431, 0.429, 0.428, 0.428],</span><br></pre></td></tr></table></figure>



<p>另外引入的 logprob_loss 也可以一定程度上缓解这种情况，详见后文。</p>
<p>言归正传, 回归到 num_codebooks&#x3D;8, K_cutoff&#x3D;16 的设定, 采用上述<strong>轻量级</strong>算法的搜索之后, $\left[i_1, i_2, \ldots, i_8\right]$ 每个位置都从 256 个候选中挑出了 k_cutoff $&#x3D;16$ 个候选, 他们的排列组合共有 $16^8&#x3D;4,294,967,296$ 个, 确实比最开始的 1800 亿亿个小了很多, 但是依然很大, 而且后续怎 么处理? 要穷举这个 40 亿个潜在结果吗?</p>
<p>针对上述问题, multi_quantization 项目在<strong>轻量级算法</strong>的基础上新增加一个 &#x3D;&#x3D;<a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L505">Combine pairs of choices</a>&#x3D;&#x3D; 的机制。将引入该机制后的算法记为<strong>重量级算法</strong>。</p>
<p>假设 $\left[i_1, i_2, \ldots, i_8\right]$ 每个位点已选出的 $K_cutoff$ 个候选, <strong>combine</strong> 机制将<strong>相邻</strong>两个位点分为一 组, 得到 $\frac{N}{2}$, 穷举每组内部的两个位点的所有组合, 共 $K _c u t o f f * K _c u t o f f$ 个; 结合<strong>定余求一</strong>的思想, 结合 $c _i n i t$ 中其它位点的值, 计算这 $K_{-}$cutoff * K_cutoff 个组合对应的 RRL, 并根 据RRL 取较小的 $K$ _cutoff 个进入下一轮排序。由于此时计算 RRL, 参与排序的是两个相邻位点 的组合, 所以在后续的迭代过程中, 这两个位点要一直捆绑在一起, 即此时 $\mathrm{L}&#x3D;2$ 。依此类推, 在下一轮次的<strong>相邻</strong>组 combine 后, $\mathrm{L}$ 会进一步翻倍为 $\mathrm{L}&#x3D;4$ 。上述解析<a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L347">对应Dan哥代码注释</a> （N&#x2F;K&#x2F;L的变化）:</p>
<p>（如上图所示）</p>
<p>采用这种相邻配对分组计算, 定余求一的方法, 不需要穷举上文提到的 40 亿种组合, 仅需计 算 $K _$cutoff $* K _$cutoff $* \frac{N}{2}&#x3D;16 * 16 * 4&#x3D;1024$ 种组合，而且它们还可以并行计算, 极大 地提高了搜索效率。</p>
<p>回顾一下上面迭代 refine 的示意图, 每一层都代表一次<strong>相邻</strong>组配对, 基于<strong>定余求一</strong>的基本思 想, 对于每个配对的组合选出 $K_{-}$cutoff 个最有候选。每次迭代后, 单个组合的元素个数 L 都 会扩大一倍, 最终 L &#x3D; num_codebooks, 此时最小值 RRL 对应的组合即为需要求解的 cd_refined。</p>
<p>该算法解析即将进入尾声，最后介绍代码中穷举<strong>相邻组</strong>两两配对的 trick,**<a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L517">代码如下</a>**：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">even_indexes = even_indexes.unsqueeze(<span class="number">3</span>).expand(B, new_N, K, K, L).reshape(B, new_N, new_K, L)</span><br><span class="line">odd_indexes = odd_indexes.unsqueeze(<span class="number">2</span>).expand(B, new_N, K, K, L).reshape(B, new_N, new_K, L)</span><br><span class="line">cur_indexes = torch.cat((even_indexes, odd_indexes), dim=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>



<p>这两行代码高度相似，只是 <strong>unsqueeze(3)</strong> 和 <strong>unsqueeze(2)</strong> 的区别，该处差异<strong>刚好穷举</strong>了 even_indexes 和 odd_indexes 的两两组合，简单示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">even = torch.tensor([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>])</span><br><span class="line">odd = torch.tensor([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">L = <span class="number">1</span></span><br><span class="line">K = <span class="number">3</span></span><br><span class="line">new_K = K * K</span><br><span class="line">even = even.unsqueeze(<span class="number">0</span>).expand(K, K).reshape(new_K, L)</span><br><span class="line">odd = odd.unsqueeze(<span class="number">1</span>).expand(K, K).reshape(new_K, L)</span><br><span class="line">cur = torch.cat((odd, even), dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(cur)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对应的输出结果为：</span></span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>



<p>【TODO】我只理解大概意思，需要详细结合代码理解。。。。。。。。。。</p>
<h4 id="4-3-3-logprob-loss-的作用"><a href="#4-3-3-logprob-loss-的作用" class="headerlink" title="4.3.3 logprob_loss 的作用"></a>4.3.3 logprob_loss 的作用</h4><p>在上文 $c d _r e f i n e d$ 迭代搜索过程中, 一个很重要思想就是定余求一, 也就是说我们在搜索某 一个位点上的较佳候选时, 其余的位点是直接用了用 quantizer.to_logits 对应的 (linear + argmax) 计算出来的 $c d _i n i t$ 的值。万一这个初始值 $c d _i n i t$ 很坑怎么办? 在上文中, 我们也 给出来一个案例, 一通操作之后, 重构出来的结果误差还更大了。在 multi_quantizaiton 库 中, Dan哥给出的优化方案让 quantizer.to_logits 模块去学习 refine 之后的结果, 这样 (linear + argmax）给出的 $c d _i n i t$ 就会不断向 cd_refined 组合逼近。对应的<a href="https://github.com/k2-fsa/multi_quantization/blob/446920cabcb384d20132c5dd7d97cb5ec8e27aa8/multi_quantization/quantization.py#L218">代码为</a> </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Get logprob loss and class-entropy loss</span></span><br><span class="line"><span class="comment"># wasteful.. already computed logits..</span></span><br><span class="line">logits = self._logits(x).reshape(-<span class="number">1</span>, self.num_codebooks, self.codebook_size)</span><br><span class="line">logits = logits.log_softmax(dim=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># chosen_logits: (B, num_codebooks, 1)</span></span><br><span class="line">chosen_logits = torch.gather(logits, dim=<span class="number">2</span>,</span><br><span class="line">                             index=indexes.unsqueeze(<span class="number">2</span>))</span><br><span class="line">logprob_loss = -chosen_logits.mean()</span><br></pre></td></tr></table></figure>



<p>如Dan哥在注释中所说, 本质上这就是个交叉墒损失函数（Cross-Entropy loss, CE）。从 CE 的 角度看, 相当于以 $c d _r e f i n e d$ 为 label, 去训练 quantizer.to_logits 模块, 从而促使 $c d _i n i t$ 逐 渐接近 $c$ __refined。</p>
<p>至此，我们浅析了 quantizer 背后的一些关键思想，然而Dan哥的设计前后呼应，非常巧妙；上述解析必然有疏漏之处，读者海涵。</p>
<h2 id="5-蒸馏方案解析"><a href="#5-蒸馏方案解析" class="headerlink" title="5 蒸馏方案解析"></a>5 蒸馏方案解析</h2><h3 id="5-1-codebook-indexes-对应的损失函数"><a href="#5-1-codebook-indexes-对应的损失函数" class="headerlink" title="5.1 codebook indexes 对应的损失函数"></a>5.1 codebook indexes 对应的损失函数</h3><p>如果跳过层层细节，multi_quantization 的功能就是把一个 <strong>float embedding 转化为一组整数 code bookindex</strong>。在蒸馏实验中，由于teacher embedding 往往是frame-level的，所以对应的codebook indexes 也是 frame-level 的。</p>
<p>喔，一组 frame-level 的整数，且分布范围是有限的类别（一般在[0， 255]之间)。这看起来和 <strong>alignment</strong> 非常相似！对于这样的 target, 大家的第一想法恐怕都是用 CE 作为损失函数吧。只不过相对于经典的CE,现在每个 frame 对应多个 target（一组包含多个整数的 codebook index.</p>
<p>在 multi_quantizaiton 库里，提供了一个 <strong><a href="https://github.com/k2-fsa/multi_quantization/blob/ecea30b79699e2e6f24d253f2563f78e4c1441fc/multi_quantization/prediction.py#L132">JointCodebookLoss</a></strong> 类，当其 is_joint&#x3D;False 时，就是完全标准的CE损失函数，下述实验的结果即采用此配置得到。把CE又重新包装为 JointCodebookLoss(JCL) 是出于两方面的考虑：</p>
<ol>
<li><p>在CE之前加一个linear layer,用于连接 student 网络的输出和 codebook index。</p>
</li>
<li><p>探索 codebook loss 的除了CE之外的使用方式，比如设置 is_joint&#x3D;True 时，在上述 linear 的基础上，增加了一个利用已知部分CI预测其余位置CI的 regression 分支，目前JCL和CE在不同设置下互有胜负，现阶段暂时推荐使用CE损失函数。</p>
</li>
</ol>
<h3 id="5-2-pruned-transducer-stateless6中的实验配置"><a href="#5-2-pruned-transducer-stateless6中的实验配置" class="headerlink" title="5.2 pruned_transducer_stateless6中的实验配置"></a>5.2 pruned_transducer_stateless6中的实验配置</h3><h4 id="5-2-1-采用-hubert-作为-teacher-模型的配置"><a href="#5-2-1-采用-hubert-作为-teacher-模型的配置" class="headerlink" title="5.2.1 采用 hubert 作为 teacher 模型的配置"></a>5.2.1 采用 hubert 作为 teacher 模型的配置</h4><p>当前的实验使用的是48层的 HuBERT Extra Large finetuned 后的模型，其输入为 raw audio, 没有 fbank&#x2F;mfcc 等特征提取环节，输出帧率为50，即1s的输入音频，可以得到50 frames的 teacher embedding。</p>
<h4 id="5-2-2-采用-reworked-conformer-作为-studnet-模型"><a href="#5-2-2-采用-reworked-conformer-作为-studnet-模型" class="headerlink" title="5.2.2 采用 reworked conformer 作为 studnet 模型"></a>5.2.2 采用 reworked conformer 作为 studnet 模型</h4><p>其与 stateless4 中的 reworked conformer结构完全一致，只不过它的第6层被链接到 codebook index 对应的蒸馏 loss。</p>
<p>即实现 hubert 48层模型中的<strong>第36层</strong> “连接“到 conformer 12层模型中的<strong>第6层</strong>的蒸馏方案。</p>
<p>值得注意的是 conformer 的帧率是25， 为 hubert teacher 模型帧率50的一半。为了解决这种 mismatch, 我们将 hubert 得到的相邻两帧 codebook indexs 拼做一帧。即提取过程中设置的的 num_codebooks &#x3D; 8, 在蒸馏过程中，conformer 每帧对应的其实是16个整数 target.</p>
<h4 id="5-2-3-quantizer-配置"><a href="#5-2-3-quantizer-配置" class="headerlink" title="5.2.3 quantizer 配置"></a>5.2.3 quantizer 配置</h4><p>quantizer 的训练不需要太多的数据，在该实验配置中，我们选择了 LibriSpeech train-clean-100的前<strong>1000条</strong>语音对应的 teacher embedding 作为 quantizer 的训练数据。值得一提的是，在训练 quantizer 之前这些来自不同语音的 teacher embedding 会完全 <strong>mix</strong> 在一起，充分的 <strong>shuffle</strong>, 避免 quantizer 学习了一些句内信息。</p>
<p>由于 quantizer 是对 <strong>frame-level</strong> 的 level 的 teacher embedding 做量化，为了保证来自 teacher 模型的 codebook index 与 student 模型的输出在时间上对齐， 使用 codebook index 做蒸馏时<strong>建议关掉 time_warp</strong>。</p>
<h2 id="6-实验结果"><a href="#6-实验结果" class="headerlink" title="6. 实验结果"></a>6. 实验结果</h2><h3 id="6-1-采用clean-100h实验结果分析"><a href="#6-1-采用clean-100h实验结果分析" class="headerlink" title="6.1 采用clean-100h实验结果分析"></a>6.1 采用clean-100h实验结果分析</h3><p>表格中结果分别是在(test-clean||test-other)的(Word Error Rate, WER)。</p>
<table>
<thead>
<tr>
<th align="left">-</th>
<th align="left">epoch-20-avg-10</th>
<th align="left">epoch-30-avg-10</th>
<th align="left">epoch-40-avg-10</th>
<th align="left">epoch-50-avg-10</th>
</tr>
</thead>
<tbody><tr>
<td align="left">baseline no distillation</td>
<td align="left">7.09||18.88</td>
<td align="left">6.83||18.19</td>
<td align="left">6.73||17.79</td>
<td align="left">6.75||17.68</td>
</tr>
<tr>
<td align="left">distillation with hubert</td>
<td align="left">5.82||15.98</td>
<td align="left">5.52||15.15</td>
<td align="left">5.45||14.94</td>
<td align="left">5.50||14.77</td>
</tr>
</tbody></table>
<p>在 icefall中，基于 LibriSpeech 的训练一般不推荐超过30个 epoch。上表中的实验刻意训练了50个epoch。在引入 hubert teacher 模型后，从上表可得出两个比较重要的结论：</p>
<ol>
<li><p>由epoch-20&#x2F;30的结果，可以看出收敛速度速度大大加快，</p>
</li>
<li><p>由epoch-40&#x2F;50的结果，可以看出其极限WER也更低。</p>
</li>
</ol>
<h3 id="6-2-采用-full-librispeech-960h-实验结果分析"><a href="#6-2-采用-full-librispeech-960h-实验结果分析" class="headerlink" title="6.2 采用 full librispeech 960h 实验结果分析"></a>6.2 采用 full librispeech 960h 实验结果分析</h3><h4 id="6-2-1-non-streaming-teacher-model-结合-non-streaming-student-model-结果分析"><a href="#6-2-1-non-streaming-teacher-model-结合-non-streaming-student-model-结果分析" class="headerlink" title="6.2.1 non-streaming teacher model 结合 non-streaming student model 结果分析"></a>6.2.1 non-streaming teacher model 结合 non-streaming student model 结果分析</h4><p>训练30个 epoch，解码方法为m odified_beam_search</p>
<table>
<thead>
<tr>
<th align="left">-</th>
<th align="left">test-clean</th>
<th align="left">test-other</th>
</tr>
</thead>
<tbody><tr>
<td align="left">baseline no distillation</td>
<td align="left">2.63</td>
<td align="left">6.19</td>
</tr>
<tr>
<td align="left">ditillation with hubert</td>
<td align="left">2.30</td>
<td align="left">5.57</td>
</tr>
</tbody></table>
<h4 id="6-2-2-non-streaming-teacher-model-结合-streaming-student-model结果分析"><a href="#6-2-2-non-streaming-teacher-model-结合-streaming-student-model结果分析" class="headerlink" title="6.2.2 non-streaming teacher model 结合 streaming student model结果分析"></a>6.2.2 non-streaming teacher model 结合 streaming student model结果分析</h4><p>训练30个 epoch, 解码配置为 left_context_64, chunk_size&#x3D;16, right_context&#x3D;9;</p>
<table>
<thead>
<tr>
<th align="left">-</th>
<th align="left">test-clean</th>
<th align="left">test-other</th>
</tr>
</thead>
<tbody><tr>
<td align="left">baseline no distillation</td>
<td align="left">3.13</td>
<td align="left">8.06</td>
</tr>
<tr>
<td align="left">ditillation with hubert</td>
<td align="left">2.93</td>
<td align="left">7.43</td>
</tr>
</tbody></table>
<p>上述两个全量的实验，可以得出两个比较重要的结论：</p>
<ol>
<li><p>一个非流式的 teacher 模型不仅能够提升非流式的 student 模型，也可以提升流式 student 模型。</p>
</li>
<li><p>由于该 hubert teacher 模型训练时用到的有标签数据也是 LibriSpeech, 其它数据均为无监督数据。而且该蒸馏方案并没有侵入 student 模型结构，为了蒸馏添加的 JointCodebookLoss 分支在测试和上线的时候可以拿掉。因此该方案给出了一种无需增加标注数据的模型，无需修改已有模型结构，仅使用大量无监督数据即可优化已有模型的方案（可以完全复用已有的模型导出&#x2F;量化&#x2F;产线部署工具）。</p>
</li>
</ol>
<h2 id="7-展望"><a href="#7-展望" class="headerlink" title="7. 展望"></a>7. 展望</h2><p>上文设计的实验仅介绍了该量化工具在 ASR 领域的一些应用实例，然而它的功能远不止于此：</p>
<ol>
<li>更为丰富的蒸馏实验设置。</li>
</ol>
<p>上文介绍的蒸馏实验仅使用了一个 teacher 模型，一个 student 模型，二者均各取一层。或许拓展为从 teacher 模型中抽取多层的信息甚至使用多个 teacher 模型，共同指导 student 模型不同层的学习，或许能够得到更好地蒸馏效果。</p>
<ol start="2">
<li>该方案应该也可以拓展到其他机器学习领域，比如唤醒、声纹、NLP等任何可以用到蒸馏学习的任务。</li>
</ol>
<h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h2><p>本文介绍了Dan哥提出的量化工具 multi_quantization 的基本原理及其在 ASR 蒸馏学习领域内的应用。相较于传统的蒸馏方法，该方案能够<strong>大幅度降低</strong>所需的存储空间，同时取得了良好的蒸馏效果。该系统通过结合 hubert 模型，给出了一种在不增加标注数据，不修改模型结构及上线逻辑的情况下，依托海量无监督数据提升产线模型性能的可能性。最后提出了一些潜在的实验方向，希望能够有机会与各位业界同仁一起研究，共同进步。</p>
<h2 id="9-致谢"><a href="#9-致谢" class="headerlink" title="9. 致谢"></a>9. 致谢</h2><p>感谢小米技术委AI实验室孔玉祥、姚增伟、王全东博士和中科院声学所朱涵博士针对该方案的宝贵建议和辛勤付出。</p>
<hr>
<p>encoder作用：将1280维float向量转成8维uint8的整数，每个整数代表每一个码本对应的索引index。</p>
<p>目标：编码解码重构出的$\hat x$，尽量接近输入的x。</p>
<p>如左图所示，N表示码本数，K表示embedding维度（这里是6，用的时候是256），x进来会先经过一个logit逻辑回归分类器，作为初始码本embedding选择，然后迭代优化。</p>
<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230315181327346.png" alt="image-20230315181327346" style="zoom:80%;">



<p>迭代式的编码策略。</p>
<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230315183059172.png" alt="image-20230315183059172" style="zoom:80%;">



<p>分治</p>
<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230315184456112.png" alt="image-20230315184456112" style="zoom:80%;">





<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230316211125538.png" alt="image-20230316211125538" style="zoom:80%;">



<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230316211144202.png" alt="image-20230316211144202" style="zoom:80%;">





<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230316211203576.png" alt="image-20230316211203576" style="zoom:80%;">





<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230316211233218.png" alt="image-20230316211233218" style="zoom:80%;">



<img src="/2023/03/16/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%A0%81%E6%9C%AC%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%E7%9A%84%E8%92%B8%E9%A6%8F%E6%96%B9%E6%A1%88/image-20230316211256390.png" alt="image-20230316211256390" style="zoom:80%;">
]]></content>
      <categories>
        <category>k2</category>
      </categories>
      <tags>
        <tag>k2</tag>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>python 生成器 generators</title>
    <url>/2023/02/02/python/python%20%E7%94%9F%E6%88%90%E5%99%A8/</url>
    <content><![CDATA[<h1 id="python-生成器-Generators"><a href="#python-生成器-Generators" class="headerlink" title="python 生成器 Generators"></a>python 生成器 Generators</h1><blockquote>
<p><a href="https://realpython.com/introduction-to-python-generators/">How to Use Generators and yield in Python</a></p>
</blockquote>
<p>生成器适合在以下场景中使用：</p>
<ol>
<li>处理过大到超出机器内存的数据集</li>
<li>有一个复杂的函数，每次调用它时都需要维护一个内部状态，但该函数太小而无法证明创建自己的类是合理的</li>
</ol>
<p>生成器的特点是不将其内容存储在内存中。生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。</p>
<h3 id="读取大文件"><a href="#读取大文件" class="headerlink" title="读取大文件"></a>读取大文件</h3><p>统计文件的行数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 第一种方法，一次读入</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">csv_reader_1</span>(<span class="params">file_name</span>):</span><br><span class="line">    file = <span class="built_in">open</span>(file_name)</span><br><span class="line">    result = file.read().split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">csv_reader_2</span>(<span class="params">file_name</span>):</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">open</span>(file_name, <span class="string">&quot;r&quot;</span>):</span><br><span class="line">        <span class="keyword">yield</span> row</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">csv_gen = csv_reader_1(<span class="string">&quot;some_csv.txt&quot;</span>)</span><br><span class="line"><span class="comment"># csv_gen = csv_reader_2(&quot;some_csv.txt&quot;)</span></span><br><span class="line">row_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> csv_gen:</span><br><span class="line">    row_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Row count is <span class="subst">&#123;row_count&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>第一种方法中，<code>file.read().split()</code>一次将所有内容加载到内存中，导致<code>MemoryError</code>.</p>
<p>第二种方法，用了yield。执行顺序是，<code>csv_gen = csv_reader_2(&quot;some_csv.txt&quot;)</code>时，并未跳入<code>csv_reader_2</code>函数！！注意这里还没跳入函数，因为这个函数里面有yield，只是把这个函数赋给一个对象，然后直到<code>for row in csv_gen</code>（等价于<code>next()</code>），才跳入<code>csv_reader_2</code>函数内部，然后执行到yield这条，就返回，然后再遇到<code>for row in csv_gen:</code>，再跳入yield位置的下一条开始执行。</p>
<h3 id="生成无限序列"><a href="#生成无限序列" class="headerlink" title="生成无限序列"></a>生成无限序列</h3><p>获得有限序列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = <span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(a)</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>



<p>然而，生成<strong>无限序列</strong>需要使用生成器，因为您的计算机内存是有限的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">infinite_sequence</span>():</span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">yield</span> num</span><br><span class="line">        num += <span class="number">1</span></span><br></pre></td></tr></table></figure>



<p>除了使用<code>for</code>循环，您还可以<code>next()</code>直接调用生成器对象。这对于在控制台中测试生成器特别有用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>gen = infinite_sequence()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(gen)</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(gen)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(gen)</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(gen)</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>在这里，您有一个名为 的生成器<code>gen</code>，您可以通过重复调用 来手动迭代它<code>next()</code>。</p>
<p><strong>注意：</strong>当您使用 时<code>next()</code>，Python 会调用<code>.__next__()</code>您作为参数传入的函数。此参数化允许产生一些特殊效果，但这超出了本文的范围。尝试更改传递给的参数<code>next()</code>，看看会发生什么！</p>
<h3 id="示例-3：检测回文"><a href="#示例-3：检测回文" class="headerlink" title="示例 3：检测回文"></a>示例 3：检测回文</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">is_palindrome</span>(<span class="params">num</span>):</span><br><span class="line">    <span class="comment"># Skip single-digit inputs</span></span><br><span class="line">    <span class="keyword">if</span> num // <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    temp = num</span><br><span class="line">    reversed_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> temp != <span class="number">0</span>:</span><br><span class="line">        reversed_num = (reversed_num * <span class="number">10</span>) + (temp % <span class="number">10</span>)</span><br><span class="line">        temp = temp // <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> num == reversed_num:</span><br><span class="line">        <span class="keyword">return</span> num</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<p>该函数接受一个输入数字，将其反转，并检查反转后的数字是否与原始数字相同。现在您可以使用无限序列生成器来获取所有数字回文的运行列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> infinite_sequence():</span><br><span class="line"><span class="meta">... </span>    pal = is_palindrome(i)</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> pal:</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(i)</span><br><span class="line">...</span><br><span class="line"><span class="number">11</span></span><br><span class="line"><span class="number">22</span></span><br><span class="line"><span class="number">33</span></span><br><span class="line">[...]</span><br><span class="line"><span class="number">99799</span></span><br><span class="line"><span class="number">99899</span></span><br><span class="line"><span class="number">99999</span></span><br><span class="line"><span class="number">100001</span></span><br><span class="line"><span class="number">101101</span></span><br><span class="line"><span class="number">102201</span></span><br><span class="line">KeyboardInterrupt</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">2</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">5</span>, <span class="keyword">in</span> is_palindrome</span><br></pre></td></tr></table></figure>



<h2 id="了解生成器"><a href="#了解生成器" class="headerlink" title="了解生成器"></a>了解生成器</h2><p>生成器函数的外观和行为就像常规函数一样，但具有一个定义特征。生成器函数使用 Python<a href="https://realpython.com/python-keywords/#returning-keywords-return-yield"><code>yield</code>关键字</a>而不是<code>return</code>. 回想一下您之前编写的生成器函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">infinite_sequence</span>():</span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">yield</span> num</span><br><span class="line">        num += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>这看起来像一个典型的<a href="https://realpython.com/defining-your-own-python-function/">函数定义</a>，除了 Python yield 语句和它后面的代码。<code>yield</code>指示将值发送回调用方的位置，但与 不同的是<code>return</code>，之后您不会退出该函数。</p>
<p>相反，函数的<strong>状态</strong>会被记住。这样，当在生成器对象上调用（在循环<code>next()</code>中显式或隐式）时，先前生成的变量会递增，然后再次生成。由于生成器函数看起来像其他函数并且与它们的行为非常相似，因此您可以假设生成器表达式与 Python 中可用的其他理解非常相似。</p>
<h3 id="使用生成器表达式构建生成器"><a href="#使用生成器表达式构建生成器" class="headerlink" title="使用生成器表达式构建生成器"></a>使用生成器表达式构建生成器</h3><p>与列表推导式一样，生成器表达式允许您仅用几行代码即可快速创建生成器对象。它们在使用列表理解的相同情况下也很有用，还有一个额外的好处：您可以创建它们而无需在迭代之前构建并将整个对象保存在内存中。换句话说，当你使用生成器表达式时，你不会有内存损失。以对一些数字进行平方为例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>nums_squared_lc = [num**<span class="number">2</span> <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]	<span class="comment"># list 列表</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nums_squared_gc = (num**<span class="number">2</span> <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>))	<span class="comment"># 生成器</span></span><br></pre></td></tr></table></figure>



<p>执行时：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>nums_squared_lc</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nums_squared_gc</span><br><span class="line">&lt;generator <span class="built_in">object</span> &lt;genexpr&gt; at <span class="number">0x107fbbc78</span>&gt;</span><br></pre></td></tr></table></figure>

<p>第一个对象使用括号构建列表，而第二个对象使用括号创建生成器表达式。输出确认您已经创建了一个生成器对象并且它不同于列表。</p>
<p>比较列表和生成器各自生成对象的大小：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sys</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nums_squared_lc = [i ** <span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sys.getsizeof(nums_squared_lc)</span><br><span class="line"><span class="number">87624</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nums_squared_gc = (i ** <span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(sys.getsizeof(nums_squared_gc))</span><br><span class="line"><span class="number">120</span></span><br></pre></td></tr></table></figure>

<p>可以看出，<strong>生成器对象比列表对象小</strong>。</p>
<p>比较列表和生成器各自求值的速度快慢：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> cProfile</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cProfile.run(<span class="string">&#x27;sum([i * 2 for i in range(10000)])&#x27;</span>)</span><br><span class="line">         <span class="number">5</span> function calls <span class="keyword">in</span> <span class="number">0.001</span> seconds</span><br><span class="line"></span><br><span class="line">   Ordered by: standard name</span><br><span class="line"></span><br><span class="line">   ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.001</span>    <span class="number">0.001</span>    <span class="number">0.001</span>    <span class="number">0.001</span> &lt;string&gt;:<span class="number">1</span>(&lt;listcomp&gt;)</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.001</span>    <span class="number">0.001</span> &lt;string&gt;:<span class="number">1</span>(&lt;module&gt;)</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.001</span>    <span class="number">0.001</span> &#123;built-<span class="keyword">in</span> method builtins.<span class="built_in">exec</span>&#125;</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.000</span> &#123;built-<span class="keyword">in</span> method builtins.<span class="built_in">sum</span>&#125;</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;disable&#x27;</span> of <span class="string">&#x27;_lsprof.Profiler&#x27;</span> objects&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cProfile.run(<span class="string">&#x27;sum((i * 2 for i in range(10000)))&#x27;</span>)</span><br><span class="line">         <span class="number">10005</span> function calls <span class="keyword">in</span> <span class="number">0.003</span> seconds</span><br><span class="line"></span><br><span class="line">   Ordered by: standard name</span><br><span class="line"></span><br><span class="line">   ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">    <span class="number">10001</span>    <span class="number">0.002</span>    <span class="number">0.000</span>    <span class="number">0.002</span>    <span class="number">0.000</span> &lt;string&gt;:<span class="number">1</span>(&lt;genexpr&gt;)</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.003</span>    <span class="number">0.003</span> &lt;string&gt;:<span class="number">1</span>(&lt;module&gt;)</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.003</span>    <span class="number">0.003</span> &#123;built-<span class="keyword">in</span> method builtins.<span class="built_in">exec</span>&#125;</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.001</span>    <span class="number">0.001</span>    <span class="number">0.003</span>    <span class="number">0.003</span> &#123;built-<span class="keyword">in</span> method builtins.<span class="built_in">sum</span>&#125;</span><br><span class="line">        <span class="number">1</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.000</span>    <span class="number">0.000</span> &#123;method <span class="string">&#x27;disable&#x27;</span> of <span class="string">&#x27;_lsprof.Profiler&#x27;</span> objects&#125;</span><br></pre></td></tr></table></figure>

<p>可以看出，<strong>列表求值比生成器求值快</strong>。</p>
<h1 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h1><blockquote>
<p><a href="https://realpython.com/introduction-to-python-generators/">How to Use Generators and yield in Python</a></p>
<p>runoob <a href="https://www.runoob.com/w3cnote/python-yield-used-analysis.html">Python yield 使用浅析</a></p>
</blockquote>
<p>调用生成器函数或使用生成器表达式时，会返回一个称为生成器的特殊迭代器。可以将此生成器分配给一个变量以便使用它。当在生成器上调用特殊方法时，例如<code>next()</code>，函数内的代码将执行到<code>yield</code>。</p>
<p>当命中 Python yield 语句时，程序暂停函数执行并将产生的值返回给调用者。（相反，<code>return</code>完全停止函数执行。）当一个函数被挂起时，该函数的状态被保存。这包括生成器本地的任何变量绑定、指令指针、内部堆栈和任何异常处理。</p>
<p>这允许在调用生成器的方法之一时恢复函数执行。这样，所有函数评估都会在 之后立即恢复<code>yield</code>。可以通过使用多个 Python yield 语句来查看实际效果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">multi_yield</span>():</span><br><span class="line"><span class="meta">... </span>    yield_str = <span class="string">&quot;This will print the first string&quot;</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> yield_str</span><br><span class="line"><span class="meta">... </span>    yield_str = <span class="string">&quot;This will print the second string&quot;</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> yield_str</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>multi_obj = multi_yield()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">next</span>(multi_obj))</span><br><span class="line">This will <span class="built_in">print</span> the first string</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">next</span>(multi_obj))</span><br><span class="line">This will <span class="built_in">print</span> the second string</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">next</span>(multi_obj))</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure>

<p>仔细看看最后一次调用<code>next()</code>. 您可以看到执行已因<a href="https://realpython.com/python-traceback/">回溯</a>而爆炸。这是因为生成器和所有迭代器一样，可能会被耗尽。除非你的生成器是无限的，否则你只能迭代一次。一旦所有值都被评估，迭代将停止并且<code>for</code>循环将退出。如果您使用<code>next()</code>，那么您将得到一个显式<code>StopIteration</code>异常。</p>
<p><strong>注意：</strong> <code>StopIteration</code>是一个自然异常，它被引发以表示迭代器结束。<code>for</code>例如，循环是围绕<code>StopIteration</code>. <code>for</code>您甚至可以使用循环来实现自己的<a href="https://realpython.com/python-while-loop/"><code>while</code>循环</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>letters = [<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;y&quot;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>it = <span class="built_in">iter</span>(letters)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">try</span>:</span><br><span class="line"><span class="meta">... </span>        letter = <span class="built_in">next</span>(it)</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">except</span> StopIteration:</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(letter)</span><br><span class="line">...</span><br><span class="line">a</span><br><span class="line">b</span><br><span class="line">c</span><br><span class="line">y</span><br></pre></td></tr></table></figure>





<p>一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，<strong>但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行</strong>。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值。</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fab</span>(<span class="params"><span class="built_in">max</span></span>): </span><br><span class="line">    n, a, b = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span> </span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="built_in">max</span>: </span><br><span class="line">        <span class="keyword">yield</span> b      <span class="comment"># 使用 yield</span></span><br><span class="line">        <span class="comment"># print b </span></span><br><span class="line">        a, b = b, a + b </span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> fab(<span class="number">5</span>): </span><br><span class="line">    <span class="built_in">print</span> (n)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">&gt;&gt;&gt;f = fab(<span class="number">5</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.<span class="built_in">next</span>() </span><br><span class="line"><span class="number">1</span> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.<span class="built_in">next</span>() </span><br><span class="line"><span class="number">1</span> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.<span class="built_in">next</span>() </span><br><span class="line"><span class="number">2</span> </span><br></pre></td></tr></table></figure>







<h2 id="使用高级生成器方法"><a href="#使用高级生成器方法" class="headerlink" title="使用高级生成器方法"></a>使用高级生成器方法</h2><p>除了<code>yield</code>，生成器对象还可以使用以下方法：</p>
<ul>
<li><code>.send()</code></li>
<li><code>.throw()</code></li>
<li><code>.close()</code></li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>视频 基于新一代kaldi项目的语音识别应用实例-郭理勇 小米</title>
    <url>/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/</url>
    <content><![CDATA[<h1 id="视频-基于新一代kaldi项目的语音识别应用实例-郭理勇-小米"><a href="#视频-基于新一代kaldi项目的语音识别应用实例-郭理勇-小米" class="headerlink" title="视频 基于新一代kaldi项目的语音识别应用实例-郭理勇 小米"></a>视频 基于新一代kaldi项目的语音识别应用实例-郭理勇 小米</h1><blockquote>
<p>b站 语音之家 <a href="https://www.bilibili.com/video/BV14j411P7B1/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">基于新一代kaldi项目的语音识别应用实例-郭理勇 小米</a></p>
<p>微信公众号 语音之家 <a href="https://mp.weixin.qq.com/s/wjGptPrxeK0jDkyQ5AUUVw">基于新一代kaldi项目的语音识别应用实例</a></p>
</blockquote>
<p>团队在小米有一个7人小组，同时也有很多来自开源社区广大工程师的支持。另外 Daniel Povey 教授领衔开发了k2 Lhotse 和 Icefall 项目，数据处理项目是以 Piotr 博士领衔开发。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (2).png" alt="640 (2)" style="zoom: 67%;">





<p>k2的愿景是能够无缝集成有限状态自动机(FSA)和有限状态传感器(FST)算法到基干自动机的机器学习工具包，如PyTorch和TensorFlow。对于语音识别的应用，这应该可以很容易地插值和组合各种训练目标，如交叉熵，CTC和MMI，并共同优化语音识别系统与多个解码通道，包括lattice rescoring和置信度估计。我们希望k2也能有许多其他的应用。</p>
<p>我们实现的关键算法之一是剪枝具有“密集”FSA(即对应于神经网络输出的符号对数概率)的通用FSA的组合。这可用于ASR、CTC和LF-MMI训练的快速解码实现。与现有技术相比，这不会在单词错误率方面提供直接优势；但重点是在一个更为通用和可扩展的框架中这样做，以允许ASR技术的进一步发展。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640.png" alt="图片" style="zoom:67%;">

<p>第一段讲的是无缝融合，k2与Pytorch以及状态求导转换机的无缝结合。结合的目的在于可以很容易地修改结合各种不同的损失函数，像这里写到的交叉熵损失函数、CTC损失函数。第二个重点在于Compose函数，如何把一个神经网络的 embedding 转成状态机，转成状态机后，它就可以与很多传统的状态机的状态图去结合计算。我们今天主要针对这两段展开介绍。</p>
<p>第一个就是Pytorch的无缝融合。既然说到k2 与 Pytorch是无缝融合。我们先来看看原来的缝在哪里。在没有k2的时候，也有很多把状态图的算法实现出来给Pytorch打补丁。早期的时候，我们有一个用pybind11给Kaldi 打包的项目（注：第一代Kaldi 项目中的pybind11分支），它和Pytorch有那么一点点的缝，不像k2那么无缝结合。它的缝在于底层内存分配没有用 torch的Allocator。<strong>k2底层内存分配直接采用torch::Allocator</strong>。<strong>k2 消除的另一缝在于它关键数据结构和算法都继承了 torch.autograd.Function</strong>。熟悉 Pytorch 的朋友可能知道，一旦继承了这个 function 之后，相当于就被 Pytorch 的 outograd graph 图追踪。所以k2的这些函数和Pytorch的自动求到就无缝结合上了。</p>
<p>在无缝结合的基础上，k2另一个愿景是实现很多FSA和FST算法，并且这些算法实现可以高效地运行于显卡之上。<strong>整个k2的运算不是在 tensor 维度，而是在 FST 维度</strong>。<strong>在k2里面有一个函数，它可以把Pytorch的tensor embedding转换为FSA。随后整个计算就转为了一个FSA&#x2F;FST的操作</strong>，一个神经网络的embedding转化为FST&#x2F;FSA的效果如上页ppt右图所示。这个示意图画的是，如果我有两个时刻，每个时刻有8类概率，那么这个 T x C &#x3D; 2 x 8的这么一个矩阵，它转成FST&#x2F;FSA后大概就长这个样子。这个也很容易理解，现在就2帧，第一个时刻和第二个时刻之间可以随意跳，第零个时刻和第一个时刻之间也可以随意跳，跳转概率就是每个token自己神经网络对应的概率。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (3).png" alt="640 (3)" style="zoom:67%;">







<p>k2要将所有的东西都转换为FST&#x2F;FSA。接下来我们分析一个应用：k2是如何计算CTC损失函数的。现在假设 logits 也就是神经网络的输出为 2 x 8，标注文本只有一个token。即：两个时刻个logits, 一个tokenn。如果用Pytorch去计算的话，就是左边这个真实的代码，只需要调用 torch.Function.ctc_loss，一行就出来了(结果是5.0157)。</p>
<p>如果用k2去实现的话，整个流程大概如右图所示。我们刚才说，k2把所有的概念所有的变量都转换为了FST&#x2F;FSA。那么看到这个右边，k2计算CTC loss整体分为两大块。首先是左边，左边先处理文本信息label，然后和ctc_graph compose得到decoding_graph(注：逻辑上可以通过compose实现，在实际生产环节，会直接采用更为高效的k2.ctc_graph,“跳过”compose过程)。右边是处理神经网络的输出nnet_output，将它转为dense_fsa_vec，就是我们前一页看的那个图。然后decoding_graph和dense_fsa_vec compose后去做一个lattice，最后lattice再最大score。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (4).png" alt="640 (4)" style="zoom: 80%;">









<p>token也就是右上角这个文本对应的fst也很好理解，token就是1，跳一步生成一个1。最后这个-1到0的边，是k2里自定义的一个特殊要求，每一个fst必须以-1结尾，这个不影响我们的理解，所以这个-1我们可以暂时忽略。左边的CTC graph，熟悉CTC的朋友可能知道，一般我们在论文里面画CTC gragh也都是这样画。现在把CTC graph和文本对应的线性序列去做compose的话，它会得到左下角这个图。左下角这个图其实就是表示怎样生成一个token 1。我们解释一下这个图，一个状态机可以看作一个集合，它的每一个状态就是一个路径。首先这个路径无法穷举，因为含有自环。我们就列出来几个，可以看出，无论左下角这个图怎么走，它最后输出的token都是1。所以这页PPT 展示了如果文本标注是一个token 1，它所对应的fst图结构会如左下角所示。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (5).png" alt="640 (5)">





<p>刚才我们将文本处理完了，现在处理神经网络。神经网络会转成这么一个dense_fsa，它和文本token对应的图结构（左上）去做intersect之后，输出左下角这个图。我们大概走一下这个图，比如0到1、1到3，它输出0 1，那么0是一个blank我们不要，相当于输出一个token 1。边上的概率就是从神经网络里拿到的，此时得到这个lattice，可以看到确实只有两个时刻（最后-1对应的边可以忽略）。各个边上的概率就是从神经网络上获取的概率，然后输出的label刚好就是我们文本要求的一个1。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (6).png" alt="640 (6)" style="zoom:80%;">









<p>那再对这个lattice做一个tot_score，得到5.0157。这个基于k2的CTC的损失函数结果有三个注意的点，首先它也等于5.0157（和前面torch.Function.ctc_loss结果完全一致）。第二点是，它是一个torch的tensor，这个的意义在于，神经网络的tensor转换为fsa&#x2F;fst后经过k2的一番操作它还是一个tensor。从这个角度上我们可以说k2和Pytorch是无缝融合的。第三个点在于它有一个grad_fn，如果熟悉Pytorch就知道任何一个tensor只要它有grad_fn，它就可以做backward。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (7).png" alt="640 (7)" style="zoom:80%;">





<p>目前位置，我们以基于k2的CTC损失函数为例，解释了一下什么是Pytorch与k2的无缝融合。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (8).png" alt="640 (8)" style="zoom:80%;">


<p>明明Pytorch一行就能实现的东西，k2搞得这么复杂化简为繁是不是吃饱了没事干。其实不是，前面的几页PPT都是为接下来的两篇论文做铺垫。</p>
<p>第一篇是英伟达最近被Interspeech接收的一篇论文。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (9).png" alt="640 (9)" style="zoom:80%;">



<p>我们回顾一下，这个就是刚才说的k2计算CTC的主要步骤。这篇论文主要修改了绿色这个点，也就是ctc_graph这一块儿。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (10).png" alt="640 (10)" style="zoom:80%;">





<p>看一下论文中的截图，常见的ctc_graph图是图a，论文里提出将这个图改为更简单一点的c、d。总体上来说，改了之后别的流程都不需要动，只需要把绿色这块儿的结构改了，就可以调用k2完成后续的计算。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (11).png" alt="640 (11)" style="zoom:80%;">





<p>它最终获得的效果是，如果去裁剪一下这个图，不按标准做法去做，去画一个特别小的图，准确率会有一定的损失，但是图的大小和内存占用可以小2到4倍。看到这里，我们就想这篇论文的工作，没有k2也是可以实现的。但是肯定会复杂一点，而且Pytorch CTC也不支持这样的操作。那k2究竟为这项工作带来多大的便利性呢。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (12).png" alt="640 (12)" style="zoom:80%;">





<p>我们看一下它的代码实现。这个代码是真实的代码，我直接从英伟达开源项目NVIDIA NeMo里截取出来的。看一下它是如何实现的，为什么说使用k2会给这个论文带来极大的便利性。他们最核心的函数就是我画红框和绿框的这两个，它调用的接口是<strong>k2.Fsa.from_str</strong>。我们只需要把边的信息写成一行一行的文本文件或者写成string类型。它前面这个构图实际上就写了一个for循环，构建了一个Python的代码。然后再写一个字符串的处理函数，就把这个图构出来了。构出来以后呢，直接就使用k2.Fsa.from_str导入进来。右边这个也是写一个字符串的处理函数去构一个图。构图之后，用k2.Fsa.from_str就把这个图导进来了。<strong>导进来之后，对k2来说，无论是标准的CTC拓扑图，还是改进后的拓扑图，或者还是你自己特地设计出来的别的图，只要合法，都能用k2.Fsa.from_str导进来，后续都可以用compose、intersect操作计算出来损失函数。</strong>所以说k2的便利性做的特别好。总体上来讲，<strong>用户只需要用python 字符串处理程序生成图，后续的操作都可以交给k2来探索不同结构的fst 的效果。</strong></p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (13).png" alt="640 (13)" style="zoom:80%;">







<p>第二篇我们分享北京大学和腾讯基于k2的ICASSP论文，最近被ICASSP接受了。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (15).png" alt="640 (15)" style="zoom:80%;">





<p>它的工作是在经典的端到端训练框架上加了两个loss。一个是Character-Level CTC Loss，一个是LF-MMI Loss。结合上面那个例子，使用k2来实现这个的话就是天衣无缝了。我们只需要把图导进来，LF-MMI也是一个分子图一个分母图。把图做进来后，剩下的compose和intersect操作k2都是无缝支持的。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (16).png" alt="640 (16)" style="zoom:80%;">







<p>他们这里面也提到引入图操作的损失函数，准确率会获得大约4.1%到4.4%的提升。他们这个工作也是基于k2来实现的，也开源了，感兴趣的朋友可以关注一下。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (17).png" alt="640 (17)" style="zoom:80%;">







<p>这两篇是友商基于k2实现的论文，可以看一下他们用了大概哪些接口。第一个接口就是k2.Fsa.from_str，我个人感觉，翻译成·白话就是只要你会用Python处理字符串，你就可以构建Fsa的图，导进来后和pytorch无缝结合。from_str()还有一个接口是openfst&#x3D;True（下图写成openfsa应该是openfst）。如果你现在已经有了一个由openfst构建的图，转成字符串后k2也可以识别，可以非常丝滑得导入。k2的图也可以非常丝滑地转成openfst的图。另一个我个人非常推荐的就是k2.to_dot，之前PPT里的都不是我特意去找什么画图工具画的，就是使用的k2.to_dot。可以看到截图里还有代码，调用k2.to_dot(fsa)。如果你在k2里做了一个字符串，想看看画的图对不对，直接就可以所见即所得，所得即所见，非常方便。<strong>还有一个函数就是k2.convert_dense_to_fsa_vec，如果想把一个torch的tensor转成fsa，只需要调用这个函数，接下整个fsa操作完成后返回的仍然是torch的tensor</strong>。tensor转成fsa之后，剩下的可以调用一系列k2里的工具，你可以用compose、intersect等各种各样的工具去处理它，处理完后返回的tensor与Pytorch无缝衔接，并且可导。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (18).png" alt="640 (18)" style="zoom:80%;">







<p>我们继续讲一下Pytorch这个可导该怎么理解。一种我个人感觉不是很全面的理解方式，可能受我们早期kaldi-pybind11的影响，总是觉得k2的函数是不是只能到最后计算损失函数的时候稍微用一下。以前把Pytorch和LF-MMI损失函数结合起来的时候，要把kaldi的LF-MMI函数打包成一个Python的接口。这样的话这个接口只能实现LF-MMI这个函数，别的什么都实现不了。从那个时代过来的朋友可能会有一个误区，觉得k2是不是也这样。input音频，经过Pytorch的transformer、Linear或是什么一大段处理，处理完后再送给k2的一个操作，返回一个loss。事实上这个理解是对的，刚才那两篇论文里也是这么实现的，但不是特别全面。因为我们说Pytorch与k2是完全无缝兼容的，两者的操作完全可以穿插着来。比如我现在有10个函数，第一个函数是Pytorch的函数。那现在我处理完后，我感觉到现在这个环节我需要一个k2的函数把它处理一下，比如k2的regular_tensor之类的去处理一下。那你第二个环节可以去插入一个k2的操作，k2的操作返回一个Pytorch的tensor。那你紧接着由可以在第三个环节插入一个Pytorch,在第四个环节插入一个k2。像三明治一样，一层加一层。我觉得这个可能是Pytorch与k2无缝理解的一种方式。包括我们最近在实现的MWER这样一种损失函数就是穿插着来的，先对神经网络的tensor做一个Pytorch的操作，然后做k2的操作，然后又是Pytorch的操作…..所以说完全无缝兼容。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (19).png" alt="640 (19)" style="zoom:80%;">







<p>k2里的工具就像是乐高的积木。那能用积木块搭成什么样子完全取决于社区广大工程师的思维探索。k2的工具并不会限制我们的能力，不像原来那种对kaldi工具打个包，那你只能用原有的版本，干不了别的。k2的工具是非常丰富的，你想怎么组装就怎么组装，实现什么功能能限制的就只有我们自己的思维了,k2这个工具其实已经完全做好了。</p>
<p>前面pr了一堆友商的论文，我们也介绍一下我们自己的论文。前面有朋友问有没有论文链接，这边也给了链接。第一个就是Puned RNN-T的函数，我个人觉得不那么谦虚地讲可能是地球上最快的RNN-T损失计算方法。第二个就是RNN-T高速并行的解码方法，它可以实现基于CUDA加速，可以多个音频同时解码，并且集成了基于FST的解码图。第三个工作是label delay的控制方法，我们这个方法不仅可以用在RNN-T上也可用在CTC上。第四个引入的Training overhead几乎可以忽略不计的新型蒸馏框架，Dan哥前面有介绍，这边都给出了论文链接。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (20).png" alt="640 (20)" style="zoom:80%;">









<p>接下来介绍k2工程部署的工作sherpa。这个图可能画的不是特别的全，因为sherpa这个项目正在不断地发展。但是我们还是希望以这个图尽量把sherpa项目的思想和大概设计展示给大家。第一是我们把这个项目以sherpa为核心分为前端和后端。后端支持k2的解码，包括各种各样的MACE、NCNN、ONNX这些神经网络的引擎。这些引擎驱动的模型或者来自于我们Icefall的训练，或者来自于WeNet的训练，甚至来自于Torchaudio和Espnet的训练。一旦能导成ONNX或者Torchscript的模型，就可以使用sherpa来驱动。Sherpa建立好语音服务的后端引擎后，你可以通过websocket或者HTTP，以及python的前端或者C++前端或者Javascript前端完全无缝地结合起来。解释到这里我还想解释一下为什么新一代kaldi选择用项目组的方式来组建这个项目而不是像kaldi一样单个项目。结合刚才我们两个工作，比如像英伟达和腾讯他们开源的项目都用了k2。从他们论文需求上讲，他们可能只是需要fst或者fsa的操作，他们只需要把k2的子项目去集成到他们整个语音项目里，不需要用我们sherpa、lhotest。另外一块比如说现在有一些公司或者团队他们想用sherpa项目，他们模型的工具可能是他们自己自研的一套。但是不影响，使用sherpa项目只需要把训练的流程转成ONNX或者任意一种sherpa支持的格式，那你就可以用sherpa驱动起来。我觉得这个也可以大概显示出来我们使用项目组，把各个子项目进行解耦管理的优势。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (21).png" alt="640 (21)" style="zoom:80%;">







<p>正如Dan哥所说，现场放demo总是可能有风险，再加上时间有限。对我们工作感兴趣的朋友，可以扫码关注一下公众号，也可以加入我们的群。我们尽量做到每周更新。朋友们对新一代kaldi有问题可以在群里面问，我们会写文章去回答，如果这个问题特别好的话。</p>
<img src="/2023/03/14/k2/%E8%A7%86%E9%A2%91%20%E5%9F%BA%E4%BA%8E%E6%96%B0%E4%B8%80%E4%BB%A3kaldi%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B-%E9%83%AD%E7%90%86%E5%8B%87%20%E5%B0%8F%E7%B1%B3/640 (22).png" alt="640 (22)" style="zoom:80%;">





<p>总结一下今天我们简要的分享主要是分享了两个问题。一个是现代kaldi项目包含很多子项目，k2是其中一个主要用于实现fst和fsa算法的子项目。另一个是我们当前主力研发的sherpa子项目，它是用于部署我们训练所得的模型。</p>
]]></content>
      <categories>
        <category>k2</category>
      </categories>
      <tags>
        <tag>k2</tag>
      </tags>
  </entry>
  <entry>
    <title>python 装饰器 decorators</title>
    <url>/2023/02/03/python/python%20%E8%A3%85%E9%A5%B0%E5%99%A8/</url>
    <content><![CDATA[<h1 id="python-装饰器-decorators"><a href="#python-装饰器-decorators" class="headerlink" title="python 装饰器 decorators"></a>python 装饰器 decorators</h1><blockquote>
<p><a href="https://realpython.com/primer-on-python-decorators/">https://realpython.com/primer-on-python-decorators/</a></p>
</blockquote>
<h2 id="装饰器解释"><a href="#装饰器解释" class="headerlink" title="装饰器解释"></a>装饰器解释</h2><blockquote>
<p>术语对照表：<a href="https://docs.python.org/zh-cn/3/glossary.html#term-decorator">https://docs.python.org/zh-cn/3/glossary.html#term-decorator</a></p>
</blockquote>
<p>decorator – 装饰器</p>
<p>返回值为另一个函数的函数，通常使用 <code>@wrapper</code> 语法形式来进行函数变换。 装饰器的常见例子包括 <a href="https://docs.python.org/zh-cn/3/library/functions.html#classmethod"><code>classmethod()</code></a> 和 <a href="https://docs.python.org/zh-cn/3/library/functions.html#staticmethod"><code>staticmethod()</code></a>。</p>
<p>装饰器语法只是一种语法糖，以下两个函数定义在语义上完全等价:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def f(arg):</span><br><span class="line">    ...</span><br><span class="line">f = staticmethod(f)</span><br><span class="line"></span><br><span class="line">@staticmethod</span><br><span class="line">def f(arg):</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<p>同样的概念也适用于类，但通常较少这样使用。有关装饰器的详情可参见 <a href="https://docs.python.org/zh-cn/3/reference/compound_stmts.html#function">函数定义</a> 和 <a href="https://docs.python.org/zh-cn/3/reference/compound_stmts.html#class">类定义</a> 的文档。</p>
<h2 id="chatgpt解释"><a href="#chatgpt解释" class="headerlink" title="chatgpt解释"></a>chatgpt解释</h2><p>Python装饰器是一种可以在不修改函数定义的情况下为函数添加额外功能的方法。装饰器是一种特殊类型的函数，它接收一个函数作为参数并返回一个新函数，新函数在原函数的基础上添加了额外的功能。装饰器的语法在 Python 中是通过 @ 语法实现的，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@decorator</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">function</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>



<p>装饰器可以用来给函数加入缓存、检查函数参数类型、记录函数调用日志等等。</p>
<h2 id="装饰器详解"><a href="#装饰器详解" class="headerlink" title="装饰器详解"></a>装饰器详解</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1Gu411Q7JV/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">【python】装饰器超详细教学，用尽毕生所学给你解释清楚，以后再也不迷茫了！</a></p>
</blockquote>
<p>python里所有东西都是对象，函数也是对象。</p>
<ol>
<li>因此函数也可以当作参数、变量（理解成是<strong>保存着函数对象的变量</strong>），传进其它函数里。</li>
</ol>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">double</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">triple</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calc_number</span>(<span class="params">func, x</span>):</span><br><span class="line">    <span class="built_in">print</span>(func(x))</span><br><span class="line"></span><br><span class="line">calc_number(double, <span class="number">3</span>)</span><br><span class="line">calc_number(triple, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>函数还可以成为一个返回值（函数的返回值可以是一个函数）</li>
</ol>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_multiple_func</span>(<span class="params">n</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">multiple</span>(<span class="params">x</span>):</span><br><span class="line">        <span class="keyword">return</span> n * x</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> multiple</span><br><span class="line"></span><br><span class="line">double = get_multiple_func(<span class="number">2</span>)	<span class="comment"># 这里double变量其实拿到的是multiple这个函数对象，可以把double看作是multiple函数，只不过函数里面的n是2</span></span><br><span class="line">triple = get_multiple_func(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(double(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(triple(<span class="number">3</span>))</span><br></pre></td></tr></table></figure>



<p>函数可被调用的，callable。装饰器是一个callable。</p>
<p>decorator是一个函数，写法是<code>@</code>后面跟着的名字，就是函数名。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dec</span>(<span class="params">f</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@dec</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">double</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 完全等价</span></span><br><span class="line">double = dec(double)</span><br></pre></td></tr></table></figure>



<p>多练习几遍这个写法加深记忆！ double函数上面写一个@dec函数，其实完全等价于这样写：<code>double = dec(double)</code>，输入是double函数，dec的输出传给double变量（函数）</p>
<p>decorator是一个输入和输出都是函数的函数（其实输出不一定是函数，极端情况故意不是函数（没意义），一般写法都是函数的）</p>
<p>举例：（这里先不用看args和kwargs）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">timeit</span>(<span class="params">f</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">x</span>):	<span class="comment"># 参数只有一个，x</span></span><br><span class="line">        start = time.time()</span><br><span class="line">        ret = f(x)</span><br><span class="line">        <span class="built_in">print</span>(time.time() - start)</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@timeit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_func</span>(<span class="params">x</span>):</span><br><span class="line">    time.sleep(x)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="meta">@timeit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">other_func</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">my_func(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(other_func(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>

<p>等价于 my_func &#x3D; timeit(my_func) ， 所以就是wrapper(1)传给左边my_func这个变量。</p>
<p>timeit函数当作decorator来用，输入f是一个函数，返回wrapper还是一个函数。</p>
<p>使用decorator好处：有不同函数时，都可以比较简洁的来完成这件事。</p>
<p>上述wrapper函数的初始形态为（补上args和kwargs）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">timeit</span>(<span class="params">f</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>): </span><br><span class="line">        start = time.time()</span><br><span class="line">        ret = f(*args, **kwargs)</span><br><span class="line">        <span class="built_in">print</span>(time.time() - start)</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br></pre></td></tr></table></figure>



<p>args、kwargs作用：<strong>允许变长的函数参数</strong> ，因此不管装饰的是什么函数，都能用这个装饰器。</p>
<p>还是以上面的例子为例，比如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@timeit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> x + y</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">2</span>,<span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<p>对于两个参数，装饰器timeit也能用。</p>
<p><strong>带参数的decorator</strong>：相当于在等价的过程中，多了一次函数调用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@timeit(<span class="params"><span class="number">10</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">double</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 完全等价</span></span><br><span class="line">double = timeit(<span class="number">10</span>)(double)</span><br></pre></td></tr></table></figure>

<p>先计算timeit(10)，返回一个函数，再用这个函数去调用double（传入double），再返回一个函数。</p>
<p>（之前不带参数的情况是：timeit(double)，直接用timeit这个函数去调用double。）</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">timeit</span>(<span class="params">iteration</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>(<span class="params">f</span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>): </span><br><span class="line">            start = time.time()</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(iteration):</span><br><span class="line">                ret = f(*args, **kwargs)</span><br><span class="line">            <span class="built_in">print</span>(time.time() - start)</span><br><span class="line">            <span class="keyword">return</span> ret</span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line"><span class="meta">@timeit(<span class="params"><span class="number">1000</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">double</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">double(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完全等价</span></span><br><span class="line"><span class="comment"># double = timeit(1000)(double)</span></span><br><span class="line">inner = timeit(<span class="number">1000</span>)</span><br><span class="line">double = inner(double)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python 类装饰器 class decorator</title>
    <url>/2023/02/06/python/python%20%E7%B1%BB%E8%A3%85%E9%A5%B0%E5%99%A8/</url>
    <content><![CDATA[<h1 id="python-类装饰器-class-decorator"><a href="#python-类装饰器-class-decorator" class="headerlink" title="python 类装饰器 class decorator"></a>python 类装饰器 class decorator</h1><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV19U4y1d79C/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">【python】一个公式解决所有复杂的装饰器，理解了它以后任何装饰器都易如反掌！</a></p>
</blockquote>
<h3 id="类装饰器"><a href="#类装饰器" class="headerlink" title="类装饰器"></a>类装饰器</h3><p>举例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Timer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, func</span>):</span><br><span class="line">        self.func = func</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span><br><span class="line">        start = time.time()</span><br><span class="line">        ret = self.func(*args, **kwargs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Time: <span class="subst">&#123;time.time() - start&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="meta">@Timer</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完全等价</span></span><br><span class="line">add = Timer(add)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行该python程序，输出</span></span><br><span class="line">Time: <span class="number">1.1920928955078125e-06</span></span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure>



<p><code>add = Timer(add)</code> 这句话，Timer装饰器，把add从一个函数，变成了<strong>Timer类的对象</strong>（赋给右边add），因为Timer是一个类，相当于创建了一个类的对象。因此创建对象，括号内的add就会传入Timer类的<code>__init__</code>函数里，所以add作为一个参数被保存在了self.func里。然后整个Timer对象被保存在add这个变量名字里。</p>
<p><code>add(2, 3)</code> 执行这句话时，相当于做了对象的调用，因此调用了Timer的<code>__call__</code>函数，因此参数(2, 3)就传入了<code>__call__</code>里，开始执行函数内部，self.func就是原来的add函数。</p>
<h3 id="带参数的类装饰器"><a href="#带参数的类装饰器" class="headerlink" title="带参数的类装饰器"></a>带参数的类装饰器</h3><p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Timer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, prefix</span>):</span><br><span class="line">        self.prefix = prefix</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, func</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">            start = time.time()</span><br><span class="line">            ret = func(*args, **kwargs)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;self.prefix&#125;</span><span class="subst">&#123;time.time() - start&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> ret</span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@Timer(<span class="params">prefix=<span class="string">&quot;curr_time: &quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完全等价</span></span><br><span class="line">add = Timer(prefix=<span class="string">&quot;curr_time: &quot;</span>)(add)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<p>想实现一个功能，先打印一个prefix字符串，再打印时间。</p>
<p>Timer输入参数prefix，返回一个函数，比如把<code>Timer(prefix)</code>记为k，也就是<code>k=Timer(prefix)</code>，这个函数k当call时，也就是<code>k(add)</code>时，也要输出一个函数（再赋给add），因此在Timer类的<code>__call__()</code>方法里return的是一个函数对象，也就是<code>wrapper(*args, **kwargs)</code>。</p>
<p>执行<code>add(2, 3)</code>时，也就是执行<code>wrapper(*args, **kwargs)</code>的函数内部代码。</p>
<h3 id="类的装饰器"><a href="#类的装饰器" class="headerlink" title="类的装饰器"></a>类的装饰器</h3><p>上面更像是装饰器的类，这里介绍类的装饰器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_str</span>(<span class="params">cls</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):  <span class="comment">#通过重载__str__来改变它print的值</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(self.__dict__)</span><br><span class="line">    cls.__str__ = __str__</span><br><span class="line">    <span class="keyword">return</span> cls</span><br><span class="line"></span><br><span class="line"><span class="meta">@add_str</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyObject</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, a, b</span>):</span><br><span class="line">        self.a = a</span><br><span class="line">        self.b = b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完全等价</span></span><br><span class="line"><span class="comment"># MyObject = add_str(MyObject)</span></span><br><span class="line"></span><br><span class="line">o = MyObject(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(o)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure>

<p>在python里面，一个自定义类class的对象，当 print 它时，它不会打印出什么，只会打印出这个对象是一个什么类。</p>
<p><strong>可以通过重载它的<code>__str__</code>函数，来改变它print出来的结果</strong>。</p>
<p>但是每个class都改很麻烦，于是写一个装饰类的装饰器。</p>
<p>上面的例子中，<code>add_str</code>输入是一个class，返回也是这个class（同一个class），只不过重载了它的print方法，把cls的<code>__str__</code>函数替换成了自定义的<code>__str__</code>函数。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python下划线</title>
    <url>/2023/02/09/python/python%E4%B8%8B%E5%88%92%E7%BA%BF/</url>
    <content><![CDATA[<h1 id="python下划线"><a href="#python下划线" class="headerlink" title="python下划线"></a>python下划线</h1><h2 id="python代码里的-下划线"><a href="#python代码里的-下划线" class="headerlink" title="python代码里的_ 下划线"></a>python代码里的_ 下划线</h2><blockquote>
<p><a href="https://cloud.tencent.com/developer/article/1582867">我终于把Python中下划线的含义弄清楚了（憋了很久了）</a></p>
</blockquote>
<h3 id="1-前单下划线：-var"><a href="#1-前单下划线：-var" class="headerlink" title="1. 前单下划线： _var"></a>1. 前单下划线： <code>_var</code></h3><h4 id="变量或方法名加-单下划线："><a href="#变量或方法名加-单下划线：" class="headerlink" title="变量或方法名加 单下划线："></a>变量或方法名加 单下划线：</h4><p>变量或方法名加 单下划线 时，向其他程序员的<em>提示</em>，即以单个下划线开头的变量或方法供内部使用（表示私有），这不是Python强制执行的，直接访问也是可以访问的。</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Test</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.foo = <span class="number">11</span></span><br><span class="line">        self._bar = <span class="number">23</span></span><br></pre></td></tr></table></figure>

<p>如果你实例化这个类并试图访问它的构造函数中定义的foo和_bar属性，会发生什么?让我们来看看:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; t = Test()</span><br><span class="line">&gt;&gt;&gt; t.foo</span><br><span class="line">11</span><br><span class="line">&gt;&gt;&gt; t._bar</span><br><span class="line">23</span><br></pre></td></tr></table></figure>

<p>看到_bar中的前一个下划线并没有阻止我们“进入”类并访问该变量的值。</p>
<p>这是因为Python中的单个下划线前缀仅仅是一种约定。</p>
<h4 id="函数单下划线-从模块导入："><a href="#函数单下划线-从模块导入：" class="headerlink" title="函数单下划线 从模块导入："></a>函数单下划线 从模块导入：</h4><p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This is my_module.py:</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">external_func</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="number">23</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_internal_func</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="number">42</span></span><br></pre></td></tr></table></figure>

<p>现在，如果使用通配符导入来从模块中导入所有名称，Python将不会导入带有前导下划线的名称(除非模块定义了覆盖此行为的_all__列表):</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; from my_module import *</span><br><span class="line">&gt;&gt;&gt; external_func()</span><br><span class="line">23</span><br><span class="line">&gt;&gt;&gt; _internal_func()</span><br><span class="line">NameError: <span class="string">&quot;name &#x27;_internal_func&#x27; is not defined&quot;</span></span><br></pre></td></tr></table></figure>

<p>顺便说一下，应该避免通配符导入，因为它们使名称空间中出现的名称变得不清楚。</p>
<p>与通配符导入不同，常规导入不受主要的单下划线命名约定的影响:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; import my_module</span><br><span class="line">&gt;&gt;&gt; my_module.external_func()</span><br><span class="line">23</span><br><span class="line">&gt;&gt;&gt; my_module._internal_func()</span><br><span class="line">42</span><br></pre></td></tr></table></figure>

<p>单下划线是一种Python命名约定，表示某个名称是供内部使用的。它通常不是由Python解释器强制执行的，只是对程序员的提示。</p>
<h3 id="2-后单下划线：-var"><a href="#2-后单下划线：-var" class="headerlink" title="2. 后单下划线： var_"></a>2. 后单下划线：<code> var_</code></h3><p>有时候，一个变量最合适的名字已经被一个关键字代替了。因此，类或def之类的名称在Python中不能用作变量名。在这种情况下，你可以添加一个下划线打破命名冲突:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; def make_object(name, class):</span><br><span class="line">SyntaxError: <span class="string">&quot;invalid syntax&quot;</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; def make_object(name, class_):</span><br><span class="line">...     pass</span><br></pre></td></tr></table></figure>

<p>总之，惯例使用单个尾划线(后缀)来避免与Python关键字的命名冲突。在PEP 8中解释了这种约定。</p>
<h3 id="3-前双下划线：-var"><a href="#3-前双下划线：-var" class="headerlink" title="3.前双下划线： __var"></a>3.前双下划线： <code>__var</code></h3><p>这个比较特殊！python会改变其 <strong>变量、方法</strong> 名！</p>
<p>双下划线前缀导致Python解释器重写属性名，以避免子类中的命名冲突。</p>
<p>这也叫做名字拼写——解释器改变变量的名字的方式使得在以后扩展类时很难产生冲突。</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">XHX</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.foo = <span class="number">11</span></span><br><span class="line">        self._bar = <span class="number">23</span></span><br><span class="line">        self.__baz = <span class="number">23</span></span><br></pre></td></tr></table></figure>

<p>让我们看看这个对象的属性使用内置的dir()函数:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="built_in">dir</span>(XHX())</span><br><span class="line">[<span class="string">&#x27;_XHX__baz&#x27;</span>, <span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dict__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__init_subclass__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;__weakref__&#x27;</span>, <span class="string">&#x27;_bar&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>这会给我们一个带有对象属性的列表。让我们看看这个列表：</p>
<p><code>self.foo</code>在属性列表中，foo变量显示为未修改的foo。</p>
<p><code>self._bar</code>的行为方式是一样的，它在类中显示为_bar。就像我之前说的，前导下划线只是一种惯例。给程序员的提示。</p>
<p><code>self.__baz</code>看起来有点不同。当在该列表中搜索_baz时，将看到没有具有该名称的变量。它变成了 <code>_XHX__baz</code>！也就是 <code>_类名__变量名</code></p>
<p>前面多了一个类名了！这是Python解释器应用的命名混乱。这样做是为了保护变量不被子类覆盖。</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ManglingTest</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.__mangled = <span class="string">&#x27;hello&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_mangled</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__mangled</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ManglingTest().get_mangled()</span><br><span class="line"><span class="string">&#x27;hello&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ManglingTest().__mangled	<span class="comment"># 应该用：ManglingTest()._ManglingTest__mangled</span></span><br><span class="line">AttributeError: <span class="string">&quot;&#x27;ManglingTest&#x27; object has no attribute &#x27;__mangled&#x27;&quot;</span></span><br></pre></td></tr></table></figure>

<p>如果这里没有用下划线，假设变量名叫 self.mangled，<code>ManglingTest().mangled</code>就可以正常返回的。</p>
<p>并且不止是变量，方法（函数）也会变！</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MangledMethod</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__method</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">42</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call_it</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__method()</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>MangledMethod().__method()	<span class="comment"># 应该用：MangledMethod()._MangledMethod__method()</span></span><br><span class="line">AttributeError: <span class="string">&quot;&#x27;MangledMethod&#x27; object has no attribute &#x27;__method&#x27;&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>MangledMethod().call_it()</span><br><span class="line"><span class="number">42</span></span><br></pre></td></tr></table></figure>



<h3 id="4-前后双下划线-var"><a href="#4-前后双下划线-var" class="headerlink" title="4. 前后双下划线__var__"></a>4. 前后双下划线<code>__var__</code></h3><p>表示由Python语言定义的特殊方法。避免为自己的属性使用此命名方案。</p>
<p>也叫“魔法函数”，也就是<strong>python内置的函数</strong>，尽量避免自己写函数时写这种前后双下划线的形式。</p>
<h2 id="python调用C-的-下划线"><a href="#python调用C-的-下划线" class="headerlink" title="python调用C++的_ 下划线"></a>python调用C++的_ 下划线</h2><p>import一个下划线的包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> _wenet</span><br></pre></td></tr></table></figure>

<p>这是在C++里写了这个module模块，python绑定了这个C++模块，在python里import时用的是加下划线的写法。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python 迭代器  iterators</title>
    <url>/2023/02/02/python/python%20%E8%BF%AD%E4%BB%A3%E5%99%A8/</url>
    <content><![CDATA[<h1 id="python-迭代器-iterators"><a href="#python-迭代器-iterators" class="headerlink" title="python 迭代器  iterators"></a>python 迭代器  iterators</h1><blockquote>
<p><a href="https://pymotw.com/3/itertools/index.html">https://pymotw.com/3/itertools/index.html</a></p>
<p><a href="https://docs.python.org/3/library/itertools.html">https://docs.python.org/3/library/itertools.html</a></p>
<p><a href="http://realpython.cn/tutorials/topics/python-iterators/">http://realpython.cn/tutorials/topics/python-iterators/</a></p>
<p>解释：<a href="https://docs.python.org/zh-cn/3/glossary.html#term-iterator">https://docs.python.org/zh-cn/3/glossary.html#term-iterator</a></p>
</blockquote>
<h2 id="python迭代器解释"><a href="#python迭代器解释" class="headerlink" title="python迭代器解释"></a>python迭代器解释</h2><blockquote>
<p>python术语对照表：<a href="https://docs.python.org/zh-cn/3/glossary.html#term-iterator">https://docs.python.org/zh-cn/3/glossary.html#term-iterator</a></p>
</blockquote>
<h4 id="iterator-–-迭代器"><a href="#iterator-–-迭代器" class="headerlink" title="iterator – 迭代器"></a>iterator – 迭代器</h4><p><strong>用来表示一连串数据流的对象</strong>。重复调用迭代器的 <a href="https://docs.python.org/zh-cn/3/library/stdtypes.html#iterator.__next__"><code>__next__()</code></a> 方法（或将其传给内置函数 <a href="https://docs.python.org/zh-cn/3/library/functions.html#next"><code>next()</code></a>）将逐个返回流中的项。当没有数据可用时则将引发 <a href="https://docs.python.org/zh-cn/3/library/exceptions.html#StopIteration"><code>StopIteration</code></a> 异常。到这时迭代器对象中的数据项已耗尽，继续调用其 <code>__next__()</code> 方法只会再次引发 <a href="https://docs.python.org/zh-cn/3/library/exceptions.html#StopIteration"><code>StopIteration</code></a> 异常。迭代器必须具有 <code>__iter__()</code> 方法用来返回该迭代器对象自身，因此迭代器必定也是可迭代对象，可被用于其他可迭代对象适用的大部分场合。一个显著的例外是那些会多次重复访问迭代项的代码。容器对象（例如 <a href="https://docs.python.org/zh-cn/3/library/stdtypes.html#list"><code>list</code></a>）在你每次向其传入 <a href="https://docs.python.org/zh-cn/3/library/functions.html#iter"><code>iter()</code></a> 函数或是在 <a href="https://docs.python.org/zh-cn/3/reference/compound_stmts.html#for"><code>for</code></a> 循环中使用它时都会产生一个新的迭代器。如果在此情况下你尝试用迭代器则会返回在之前迭代过程中被耗尽的同一迭代器对象，使其看起来就像是一个空容器。</p>
<h4 id="iterable-–-可迭代对象"><a href="#iterable-–-可迭代对象" class="headerlink" title="iterable – 可迭代对象"></a>iterable – 可迭代对象</h4><p>可以一个一个返回成员的对象。<strong>An object capable of returning its members one at a time.</strong> Examples of iterables include all sequence types (such as <a href="https://docs.python.org/zh-cn/3/library/stdtypes.html#list"><code>list</code></a>, <a href="https://docs.python.org/zh-cn/3/library/stdtypes.html#str"><code>str</code></a>, and <a href="https://docs.python.org/zh-cn/3/library/stdtypes.html#tuple"><code>tuple</code></a>) and some non-sequence types like <a href="https://docs.python.org/zh-cn/3/library/stdtypes.html#dict"><code>dict</code></a>, <a href="https://docs.python.org/zh-cn/3/glossary.html#term-file-object">file objects</a>, and objects of any classes you define with an <code>__iter__()</code> method or with a <code>__getitem__()</code> method that implements <a href="https://docs.python.org/zh-cn/3/glossary.html#term-sequence">sequence</a> semantics.</p>
<p>可迭代对象被可用于 <a href="https://docs.python.org/zh-cn/3/reference/compound_stmts.html#for"><code>for</code></a> 循环（for loop）以及许多其他需要一个序列的地方（<a href="https://docs.python.org/zh-cn/3/library/functions.html#zip"><code>zip()</code></a>、<a href="https://docs.python.org/zh-cn/3/library/functions.html#map"><code>map()</code></a> …）。当一个可迭代对象作为参数传给内置函数 <a href="https://docs.python.org/zh-cn/3/library/functions.html#iter"><code>iter()</code></a> 时，它会返回该对象的迭代器。这种迭代器适用于对值集合的一次性遍历。在使用可迭代对象时，你通常不需要调用 <a href="https://docs.python.org/zh-cn/3/library/functions.html#iter"><code>iter()</code></a> 或者自己处理迭代器对象。<code>for</code> 语句会为你自动处理那些操作，创建一个临时的未命名变量用来在循环期间保存迭代器。参见 <a href="https://docs.python.org/zh-cn/3/glossary.html#term-iterator">iterator</a>、<a href="https://docs.python.org/zh-cn/3/glossary.html#term-sequence">sequence</a> 以及 <a href="https://docs.python.org/zh-cn/3/glossary.html#term-generator">generator</a>。</p>
<h2 id="python迭代器概念"><a href="#python迭代器概念" class="headerlink" title="python迭代器概念"></a>python迭代器概念</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1ca411t7A9/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">【python】对迭代器一知半解？看完这个视频就会了。涉及的每个概念，都给你讲清楚！</a></p>
</blockquote>
<h4 id="iterable和iterator区别："><a href="#iterable和iterator区别：" class="headerlink" title="iterable和iterator区别："></a>iterable和iterator区别：</h4><p>iterable更像是数据的保存者，一个container，可以不知道迭代器数到哪里了，没有状态，需要有能力产生一个iterator。</p>
<p>iterator是有状态的，但它并不需要实现一个container，内部知道它代表的iterable里面是什么数据，不用实现一个interface接口来修改这个iterable里面的数据。（？？）</p>
<p>从实现上看，iterable要么有 <strong><code>__iter__()</code>方法</strong>，要么它就是一个sequence，然后有**<code>__getitem__()</code>方法**，这两者都是为了保证可迭代对象可以在iter()这个函数的作用下返回一个迭代器。</p>
<p>iterator必须要有**<code>__next__</code>方法**，这个method保证它在被next()作用下可以返回下一个iterable里面的值。</p>
<p>具体python内部实现过程：for循环里，是从栈顶的iterable里，拿出这个iterable所对应的iterator。</p>
<p>例子，用iterable实现一个链表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NodeIter</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, Node</span>):   <span class="comment"># 这里self是自己的nodeiter对象，node是传进来的node对象</span></span><br><span class="line">        self.curNode = Node</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.curNode:</span><br><span class="line">            <span class="keyword">raise</span> StopIteration</span><br><span class="line">        node, self.curNode = self.curNode, self.curNode.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Node</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> NodeIter(self)   <span class="comment"># 把自己这个Node对象传进去</span></span><br><span class="line"></span><br><span class="line">node1 = Node(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">node2 = Node(<span class="string">&quot;b&quot;</span>)</span><br><span class="line">node3 = Node(<span class="string">&quot;c&quot;</span>)</span><br><span class="line"></span><br><span class="line">node1.<span class="built_in">next</span> = node2</span><br><span class="line">node2.<span class="built_in">next</span> = node3</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> node1:</span><br><span class="line">    <span class="built_in">print</span>(node.name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果想从第二个开始打印：</span></span><br><span class="line">it = <span class="built_in">iter</span>(node1)</span><br><span class="line">first = <span class="built_in">next</span>(it)    <span class="comment"># 或者写 it.__next__()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> it:</span><br><span class="line">    <span class="built_in">print</span>(node.name)</span><br></pre></td></tr></table></figure>





<h2 id="python迭代器语法"><a href="#python迭代器语法" class="headerlink" title="python迭代器语法"></a>python迭代器语法</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV18R4y1t7Hg/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">『教程』几分钟听懂迭代器</a></p>
</blockquote>
<p>放在for里的对象必须要是可迭代（iterable）的，不然会报错。</p>
<p>有 iter() 方法就是可迭代的。</p>
<img src="/2023/02/02/python/python%20%E8%BF%AD%E4%BB%A3%E5%99%A8/image-20230202180415065.png" alt="image-20230202180415065" style="zoom: 33%;">

<p>&#x3D;&#x3D;对于可迭代对象，for语句会先调用<code>__iter__()</code>方法，然后把<code>__iter__()</code>方法的返回值当成一个对象（obj），并且调用这个对象的<code>__next__()</code>方法（<code>obj.__next__()</code>）。&#x3D;&#x3D;</p>
<p>迭代器（iterator）：可迭代对象具有<code>__next__()</code>方法，称为迭代器。或者说，一个对象，有<code>__iter__()</code>方法，也有<code>__next__()</code>方法，则是迭代器。</p>
<p>python中的内置函数<code>iter()</code>，可以得到<strong>可迭代对象</strong>的迭代器（如果有的话）。</p>
<p>对于迭代器，可直接调用next()方法，来查看每一次的返回值。</p>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=<span class="number">2233</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> e <span class="keyword">in</span> a:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(e)</span><br><span class="line">...</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: <span class="string">&#x27;int&#x27;</span> <span class="built_in">object</span> <span class="keyword">is</span> <span class="keyword">not</span> iterable</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterable</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(a, Iterable)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lstTest = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(lstTest, Iterable)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections.abc <span class="keyword">import</span> Iterator</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(lstTest, Iterator)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xd = <span class="built_in">iter</span>(lstTest)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(xd, Iterator)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(xd, Iterable)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xd</span><br><span class="line">&lt;list_iterator <span class="built_in">object</span> at <span class="number">0x7f1c07b0c3a0</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xd.__next__()</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xd.__next__()</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(xd)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(xd)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure>



<p>为什么for循环里不会出现StopIteration异常报错呢？因为for循环里写了自动捕捉这个异常，并把它当作遍历结束的标志：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 所以一个for循环：</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> seq:</span><br><span class="line">    do_something_to(i)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实际上是这样工作的：</span></span><br><span class="line">fetch = <span class="built_in">iter</span>(seq)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        i = fetch.<span class="built_in">next</span>()</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>



<h3 id="让自己的类支持迭代："><a href="#让自己的类支持迭代：" class="headerlink" title="让自己的类支持迭代："></a>让自己的类支持迭代：</h3><p>只需要：</p>
<ol>
<li>给类加入<code>__iter__()</code>方法</li>
<li>上述方法返回的对象具有<code>__next__()</code>方法</li>
</ol>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Reverse</span>:</span><br><span class="line">    <span class="comment"># 例子：可把字符串反序输出的迭代器</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data</span>):</span><br><span class="line">        self.data = data</span><br><span class="line">        self.index = <span class="built_in">len</span>(data)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 把字符串挨个儿反序输出</span></span><br><span class="line">        <span class="keyword">if</span> self.index == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> StopIteration</span><br><span class="line">        self.index = self.index - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> self.data[self.index]</span><br><span class="line"></span><br><span class="line">r = Reverse(abc)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(r))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(r))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(r))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者用遍历：</span></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> r:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="comment"># c</span></span><br><span class="line"><span class="comment"># b</span></span><br><span class="line"><span class="comment"># a</span></span><br></pre></td></tr></table></figure>

<p>不知道iter里写什么，就填返回自己（self）。</p>
<p>&#x3D;&#x3D;<strong>迭代器特点：用多少取多少</strong>&#x3D;&#x3D;。这里Reverse(abc)对象只包含abc这三个字符，但每次迭代时只返回【<strong>一个</strong>】字符，假如这里是三千万个字符，要实现反转的功能，每次迭代时仍然可以只返回一个字符。只要用很少的内存就可以存放和处理！也不需要开辟一个很大的内存空间，来一次性接收这三千万个字符！</p>
<p>又称为“惰性加载”。</p>
<hr>
<blockquote>
<p>realpython教程 <a href="https://realpython.com/python-itertools/">Itertools in Python 3, By Example</a></p>
</blockquote>
<p><code>[1, 2, 3]</code>and 和<code>[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</code>所有列表一样，是可迭代的，这意味着它们可以一次返回一个元素。</p>
<p>从技术上讲，任何实现<code>.__iter__()</code>或<code>.__getitem__()</code>方法的 Python 对象都是可迭代的。</p>
<hr>
<blockquote>
<p>runoob <a href="https://www.runoob.com/python3/python3-iterator-generator.html">Python3 迭代器与生成器</a></p>
</blockquote>
<p>迭代是访问集合元素的一种方式。</p>
<p>迭代器是一个可以记住遍历的位置的对象。</p>
<p>迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。</p>
<p>迭代器有两个基本的方法：<strong>iter()</strong> 和 **next()**。</p>
<p>字符串，列表或元组对象都可用于创建迭代器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>it = <span class="built_in">iter</span>(<span class="built_in">list</span>)    <span class="comment"># 创建迭代器对象</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> (<span class="built_in">next</span>(it))   <span class="comment"># 输出迭代器的下一个元素</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> (<span class="built_in">next</span>(it))</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure>



<p>迭代器对象可以使用常规for语句进行遍历：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">list</span>=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">it = <span class="built_in">iter</span>(<span class="built_in">list</span>)    <span class="comment"># 创建迭代器对象</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> it:</span><br><span class="line">    <span class="built_in">print</span> (x, end=<span class="string">&quot; &quot;</span>)</span><br></pre></td></tr></table></figure>

<p>执行以上程序，输出结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 2 3 4</span><br></pre></td></tr></table></figure>



<p>也可以使用 next() 函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys         <span class="comment"># 引入 sys 模块</span></span><br><span class="line"> </span><br><span class="line"><span class="built_in">list</span>=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">it = <span class="built_in">iter</span>(<span class="built_in">list</span>)    <span class="comment"># 创建迭代器对象</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span> (<span class="built_in">next</span>(it))</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        sys.exit()</span><br></pre></td></tr></table></figure>

<p>执行以上程序，输出结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td></tr></table></figure>



<hr>
<blockquote>
<p>简书 <a href="https://www.jianshu.com/p/efaa19594cf4">python 黑科技之迭代器、生成器、装饰器</a></p>
</blockquote>
<h2 id="可迭代对象"><a href="#可迭代对象" class="headerlink" title="可迭代对象"></a>可迭代对象</h2><p>先说下上面三者的基础：可迭代对象（Iterable Object），简单的来理解就是可以使用 <code>for</code> 来循环遍历的对象。比如常见的 list、set和dict。可以用以下方法来测试对象是否是可迭代</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Iterable</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="string">&#x27;abc&#x27;</span>, Iterable)     <span class="comment"># 判断str是否可迭代</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], Iterable)   <span class="comment"># list是否可迭代</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="number">123</span>, Iterable)       <span class="comment"># 整数是否可迭代</span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>



<h2 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h2><p>对所有的可迭代对象调用 <code>dir()</code> 方法时，会发现他们都实现了 <code>__iter__</code> 方法。这样就可以通过 <code>iter(object)</code> 来返回一个迭代器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = <span class="built_in">iter</span>(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;list&#x27;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(y)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;list_iterator&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>

<p>可以看到调用 <code>iter()</code> 之后，变成了一个 <code>list_iterator</code> 的对象。会发现增加了 <code>__next__</code> 方法。所有实现了 <code>__iter__</code> 和 <code>__next__</code> 两个方法的对象，都是迭代器。</p>
<p>迭代器是带状态的对象，它会记录当前迭代所在的位置，以方便下次迭代的时候获取正确的元素。<code>__iter__</code>返回迭代器自身，<code>__next__</code>返回容器中的下一个值，如果容器中没有更多元素了，则抛出StopIteration异常。</p>
<hr>
<blockquote>
<p>我问chatgpt：python中的迭代器</p>
</blockquote>
<p>在 Python 中，迭代器是一种对象，它可以遍历一个集合中的元素，每次返回一个元素，直到元素全部返回或遍历完毕。一个对象是一个迭代器当且仅当它实现了 <strong>iter</strong> 方法，该方法返回一个实现了 <strong>next</strong> 方法的对象。 <strong>next</strong> 方法返回下一个元素，如果没有更多的元素，则抛出 StopIteration 异常。</p>
<p>通过内置函数 iter() 可以将一个对象转换成一个迭代器，通过内置函数 next() 可以从迭代器中返回下一个元素。常见的内置类型如列表、元组、字符串都可以被视为一个迭代器。</p>
<p>以下是一个简单的例子，演示如何创建一个自定义的迭代器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyIterator</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line">        self.current = start</span><br><span class="line">        self.end = end</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.current &gt;= self.end:</span><br><span class="line">            <span class="keyword">raise</span> StopIteration</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.current += <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> self.current - <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> MyIterator(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<hr>
<p>待看：</p>
<blockquote>
<p><a href="https://www.bilibili.com/video/BV1BT4y1P7nn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=5e9891722f2b62adca440a5e92121b5b">https://www.bilibili.com/video/BV1BT4y1P7nn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=5e9891722f2b62adca440a5e92121b5b</a></p>
</blockquote>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python调用C++——ctypes</title>
    <url>/2023/02/13/python/python%E8%B0%83%E7%94%A8C++%E2%80%94%E2%80%94ctypes/</url>
    <content><![CDATA[<h1 id="python调用C-——ctypes"><a href="#python调用C-——ctypes" class="headerlink" title="python调用C++——ctypes"></a>python调用C++——ctypes</h1><h2 id="python3调用cpp的方法——python调用so"><a href="#python3调用cpp的方法——python调用so" class="headerlink" title="python3调用cpp的方法——python调用so"></a>python3调用cpp的方法——python调用so</h2><blockquote>
<p>csdn：<a href="https://blog.csdn.net/springlustre/article/details/101177282">python3调用cpp的方法——python调用so</a></p>
</blockquote>
<p>python中使用ctypes模块可以在python中直接调用C&#x2F;C++。<br>首先要将C&#x2F;C++编译成动态库（.so)，之后python中调用即可</p>
<p>特别注意：<strong>在调用C++函数需要在函数声明时，加入前缀<code>extern “C” </code>，这是由于C++支持函数重载功能，在编译时会更改函数名。在函数声明时，前缀extern “C”则确保按C的方式编译。</strong></p>
<p>一定要有函数输入输出类型的声明，int型不用转换，float和double类型需要进行转换，ctypes中的变量类型与C中对应如下：</p>
<table>
<thead>
<tr>
<th>ctypes数据类型</th>
<th>C数据类型</th>
</tr>
</thead>
<tbody><tr>
<td>c_char</td>
<td>char</td>
</tr>
<tr>
<td>c_short</td>
<td>short</td>
</tr>
<tr>
<td>c_int</td>
<td>int</td>
</tr>
<tr>
<td>c_long</td>
<td>long</td>
</tr>
<tr>
<td>c_float</td>
<td>float</td>
</tr>
<tr>
<td>c_double</td>
<td>double</td>
</tr>
<tr>
<td>c_void_p</td>
<td>void</td>
</tr>
<tr>
<td>c_uint8</td>
<td>unsigned char</td>
</tr>
</tbody></table>
<p>使用步骤：</p>
<h4 id="1、编写c-代码"><a href="#1、编写c-代码" class="headerlink" title="1、编写c++代码"></a>1、编写c++代码</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Test</span>&#123;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="type">double</span> _calculate(<span class="type">int</span> a, <span class="type">double</span> b);</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="type">double</span> <span class="title">calculate</span><span class="params">(<span class="type">int</span> a, <span class="type">double</span> b, <span class="type">char</span> c[], <span class="type">int</span> * d, <span class="type">double</span> * e, <span class="type">char</span> ** f)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">double</span> Test::_calculate(<span class="type">int</span> a, <span class="type">double</span> b)&#123;</span><br><span class="line">    <span class="type">double</span> res = a+b;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;res: &quot;</span>&lt;&lt;res&lt;&lt;std::endl;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">Test::calculate</span><span class="params">(<span class="type">int</span> a, <span class="type">double</span> b, <span class="type">char</span> c[], <span class="type">int</span> * d, <span class="type">double</span> * e, <span class="type">char</span> ** f)</span></span>&#123;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;a: &quot;</span>&lt;&lt;a&lt;&lt;std::endl;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;b: &quot;</span>&lt;&lt;b&lt;&lt;std::endl;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;c: &quot;</span>&lt;&lt;c&lt;&lt;std::endl;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;d: &quot;</span>&lt;&lt;d[<span class="number">0</span>]&lt;&lt;d[<span class="number">1</span>]&lt;&lt;std::endl;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;e: &quot;</span>&lt;&lt;e[<span class="number">0</span>]&lt;&lt;e[<span class="number">1</span>]&lt;&lt;std::endl;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;f: &quot;</span>&lt;&lt;f[<span class="number">0</span>]&lt;&lt;f[<span class="number">1</span>]&lt;&lt;std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>-&gt;_calculate(a, b);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 封装C接口</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span>&#123;</span><br><span class="line"><span class="comment">// 创建对象</span></span><br><span class="line">    <span class="function">Test* <span class="title">test_new</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Test;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">double</span> <span class="title">my_calculate</span><span class="params">(Test* t, <span class="type">int</span> a, <span class="type">double</span> b, <span class="type">char</span> c[], <span class="type">int</span> * d, <span class="type">double</span> * e, <span class="type">char</span> ** f)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> t-&gt;<span class="built_in">calculate</span>(a, b,c,d,e,f);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、将cpp编译成so"><a href="#2、将cpp编译成so" class="headerlink" title="2、将cpp编译成so"></a>2、将cpp编译成so</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">g++ -shared -Wl,-soname,test -o test.so -fPIC test.cpp</span><br></pre></td></tr></table></figure>

<p>其中test为cpp的名称</p>
<h4 id="3、使用python调用即可"><a href="#3、使用python调用即可" class="headerlink" title="3、使用python调用即可"></a>3、使用python调用即可</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> ctypes</span><br><span class="line"><span class="comment"># 指定动态链接库</span></span><br><span class="line">lib = ctypes.cdll.LoadLibrary(<span class="string">&#x27;./test.so&#x27;</span>)</span><br><span class="line"><span class="comment">#需要指定返回值的类型，默认是int</span></span><br><span class="line">lib.my_calculate.restype = ctypes.c_double</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Test</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 动态链接对象</span></span><br><span class="line">        self.obj = lib.test_new()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">calculate</span>(<span class="params">self, a, b,c,d,e,f</span>):</span><br><span class="line">        res = lib.my_calculate(self.obj, a, b,c,d,e,f)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="comment">#将python类型转换成c类型，支持int, float,string的变量和数组的转换</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_type</span>(<span class="params"><span class="built_in">input</span></span>):</span><br><span class="line">    ctypes_map = &#123;<span class="built_in">int</span>:ctypes.c_int,</span><br><span class="line">              <span class="built_in">float</span>:ctypes.c_double,</span><br><span class="line">              <span class="built_in">str</span>:ctypes.c_char_p</span><br><span class="line">              &#125;</span><br><span class="line">    input_type = <span class="built_in">type</span>(<span class="built_in">input</span>)</span><br><span class="line">    <span class="keyword">if</span> input_type <span class="keyword">is</span> <span class="built_in">list</span>:</span><br><span class="line">        length = <span class="built_in">len</span>(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">if</span> length==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;convert type failed...input is &quot;</span>+<span class="built_in">input</span>)</span><br><span class="line">            <span class="keyword">return</span> null</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            arr = (ctypes_map[<span class="built_in">type</span>(<span class="built_in">input</span>[<span class="number">0</span>])] * length)()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">                arr[i] = <span class="built_in">bytes</span>(<span class="built_in">input</span>[i],encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">if</span> (<span class="built_in">type</span>(<span class="built_in">input</span>[<span class="number">0</span>]) <span class="keyword">is</span> <span class="built_in">str</span>) <span class="keyword">else</span> <span class="built_in">input</span>[i]</span><br><span class="line">            <span class="keyword">return</span> arr</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> input_type <span class="keyword">in</span> ctypes_map:</span><br><span class="line">            <span class="keyword">return</span> ctypes_map[input_type](<span class="built_in">bytes</span>(<span class="built_in">input</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">if</span> <span class="built_in">type</span>(<span class="built_in">input</span>) <span class="keyword">is</span> <span class="built_in">str</span> <span class="keyword">else</span> <span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;convert type failed...input is &quot;</span>+<span class="built_in">input</span>)</span><br><span class="line">            <span class="keyword">return</span> null</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t = Test()</span><br><span class="line">    A1	= <span class="number">123</span>;</span><br><span class="line">    A2	= <span class="number">0.789</span>;</span><br><span class="line">    A3	= <span class="string">&quot;C789&quot;</span>;</span><br><span class="line">    A4	= [<span class="number">456</span>,<span class="number">789</span>];</span><br><span class="line">    A5	= [<span class="number">0.123</span>,<span class="number">0.456</span>];</span><br><span class="line">    A6	= [<span class="string">&quot;A123&quot;</span>, <span class="string">&quot;B456&quot;</span>];</span><br><span class="line">    <span class="built_in">print</span>(t.calculate(convert_type(A1), convert_type(A2), convert_type(A3),convert_type(A4),convert_type(A5),convert_type(A6)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注意看这里的convert_type</p>
<h2 id="Python-C-x2F-C-联合编程实战-Python-CTypes访问C-x2F-C-动态链接库"><a href="#Python-C-x2F-C-联合编程实战-Python-CTypes访问C-x2F-C-动态链接库" class="headerlink" title="Python C&#x2F;C++联合编程实战-Python CTypes访问C&#x2F;C++动态链接库"></a>Python C&#x2F;C++联合编程实战-Python CTypes访问C&#x2F;C++动态链接库</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV17y4y1W7BY/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">Python C&#x2F;C++联合编程实战-Python CTypes访问C&#x2F;C++动态链接库</a></p>
</blockquote>
<h3 id="windows版本："><a href="#windows版本：" class="headerlink" title="windows版本："></a>windows版本：</h3><p>需要：</p>
<ul>
<li>dll动态链接库、</li>
<li><code>__declspec(dllexport)</code> 要导出函数名，才可以生成dll；</li>
<li><code>extern &quot;C&quot;</code> 在C++代码里加这一行，编译成C的函数。这是因为python支持的是C语言，而C语言不支持重载，因此要把C++代码里写一个extern C，表示变成C语言名称，不要自己多加一些函数名这个意思（C++编译时，函数名会加上参数，因此可以区分出不一样的函数（重载））。</li>
<li>库在系统目录或当前执行目录下（要把库放在哪边，因为执行脚本时要调用这个库）</li>
<li>与python库查找路径无关 sys.path</li>
</ul>
<p>举例：</p>
<p>在visual studio里新建项目，选择dll</p>
<p>然后新建一个cpp文件：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;pch.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> __declspec(dllexport) <span class="function"><span class="type">void</span> <span class="title">TestCtypes</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;In C testctypes\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>然后选菜单的 “生成” —— “生成解决方案”，就会导出一个dll文件</p>
<p>注意，这里的dll是32位还是64位，要与后面python的32位或64位一致。比如我的python是64位（查看python是几位，通过在powershell里输入python得知）那么导出的dll就要是64位，否则会报 <code>OSError: [WinError 193] %1 不是有效的 Win32 应用程序。</code> 错误。</p>
<p>dll设置位64位：</p>
<img src="/2023/02/13/python/python%E8%B0%83%E7%94%A8C++%E2%80%94%E2%80%94ctypes/image-20230213124938001.png" alt="image-20230213124938001" style="zoom:67%;">

<p>选择 x64.</p>
<p>或者在visual studio的 侧边栏 解决方案 项目名 右键——属性——（右上）配置管理器——活动解决方案平台，选择x64.</p>
<p>新建一个python文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> *</span><br><span class="line">lib = CDLL(<span class="string">&quot;testctypes&quot;</span>)</span><br><span class="line">lib.TestCtypes()</span><br></pre></td></tr></table></figure>

<p>这里的 testctypes，是导出的 dll名称，这里不需要填 testctypes.dll后缀，只要写前面名称就好。</p>
<p>然后在windows里的powershell执行python文件。</p>
<p><strong>注意，如果python文件的路径和dll路径不一致。有三种解决方法：</strong></p>
<ol>
<li>复制dll到python文件所在目录；</li>
<li>python文件里写上相对路径，比如：<code>lib = CDLL(&quot;x64/Debug/testctypes&quot;)</code></li>
<li>dll文件导出时写相对路径：visual studio的侧边栏 解决方案 项目名 右键——属性——链接器——输出文件，比如把<code>$(OutDir)$(TargetName)$(TargetExt)</code> 改成 <code>..\$(TargetName)$(TargetExt)</code> 就是上一级目录（比如python文件在上一级目录下）</li>
</ol>
<h3 id="Linux版本："><a href="#Linux版本：" class="headerlink" title="Linux版本："></a>Linux版本：</h3><ul>
<li>so动态链接库 64位（链接库 也叫 目标程序），目标程序位数要和平台相关</li>
<li>代码字符集 utf-8（在windows的visual studio是gbk编码），</li>
<li><code>g++ -fPIC -shared -o $@ $&lt; -finput-charset=&#39;gbk&#39;</code>  编译出一个动态链接库 文件。比如：<code>g++ -fPIC -shared -o a a.cpp </code><ul>
<li>-fPIC：使得动态链接库位置无关？</li>
<li>-shared：对应的动态链接库版本</li>
<li>-finput-charset&#x3D;’gbk’ ：指定的输出格式</li>
</ul>
</li>
<li>so库在 <code>/usr/lib</code> 或者环境变量路径</li>
<li><strong>如果要在当前路径调用库，<code>export LD_LIBRARY_PATH ./</code> 要把库的路径export进库path里。（windows就不需要，windows找库路径时，会去找当前路径下有没有这个库，而linux只会找<code>LD_LIBRARY_PATH</code> 和 <code>/usr/lib</code>里有没有这个库）</strong></li>
</ul>
<p>这里cpp文件是（比如 a.cc）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">TestCtypes</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;In C testctypes\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里就不像windows里的写法那样，需要<code> __declspec(dllexport)</code> ， 这里不需要。</p>
<p>另一种写法：通过 <strong>宏</strong> 来判断是linux系统或者windows系统。一次到位，就不用对不同系统写不同cpp代码了。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> _WIN32	<span class="comment">// win32 win64</span></span></span><br><span class="line">	<span class="meta">#<span class="keyword">define</span> XIB __declspec(dllexport)</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span>	<span class="comment">// MAC linux</span></span></span><br><span class="line">	<span class="meta">#<span class="keyword">define</span> XIB</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">XIB</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">TestCtypes</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;In C testctypes\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>执行<code>g++ -fPIC -shared -o a a.cc</code> 或者 <code>g++ -fPIC -shared -o a a.cpp</code> 或者 <code>g++ -fPIC -shared -o a.so a.cc</code></p>
<p><code>ldd a.so</code> 看一看。</p>
<p>python文件是（比如a.py）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ctypes</span><br><span class="line">lib=ctypes.CDLL(<span class="string">&#x27;./a.so&#x27;</span>)</span><br><span class="line"></span><br><span class="line">lib.TestCtypes()</span><br></pre></td></tr></table></figure>

<p>执行 <code>python a.py</code></p>
<p>关于路径问题，可以把每次编译完了之后的so文件，都复制到 <code>/usr/lib</code>路径下，就没有路径问题了（写一个shell每次自动复制过去，或者写一个makefile），或者export进lib path里 <code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/mnt/k/c_practice</code> 。</p>
<p>写一个makefile：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">a.so:a.cc</span></span><br><span class="line">	g++ -fPIC -shared -o <span class="variable">$@</span> <span class="variable">$&lt;</span></span><br><span class="line">	cp <span class="variable">$@</span> /usr/lib</span><br></pre></td></tr></table></figure>

<p>这里 <code>$@</code> 指的 <code>a.so</code>， <code>$&lt;</code> 指的 <code>a.cc</code>。</p>
<p>然后命令行 <code>make</code> </p>
<h3 id="mac版本"><a href="#mac版本" class="headerlink" title="mac版本"></a>mac版本</h3><ul>
<li>与linux基本一致，但不支持代码GBK</li>
<li>演示用g++</li>
<li>VS代码格式改为utf-8</li>
</ul>
<p>改成utf-8的方法：</p>
<ol>
<li>用notepad++打开cpp文件，菜单栏——编码——utf-8</li>
<li>打开Visual Studio项目，菜单栏——文件——高级保存选项——Unicode(UTF-8 无签名)</li>
</ol>
<h3 id="ctypes类型对应"><a href="#ctypes类型对应" class="headerlink" title="ctypes类型对应"></a>ctypes类型对应</h3><p>64位的程序，对指针的存放要特别关注。因为指针用64位（8个字节）地址，如果变成运行在32位系统，则会丢失一部分信息（只读写了32位，剩下没读写完）。</p>
<h3 id="传递数字参数"><a href="#传递数字参数" class="headerlink" title="传递数字参数"></a>传递数字参数</h3><ul>
<li>传递float和int</li>
<li>c_int() c_float()</li>
<li>v&#x3D;c_int(101)</li>
<li>print(v.value)</li>
</ul>
<p>ctypes整数和浮点数类型参数传递代码示例和异常处理：</p>
<p>举例：</p>
<p>c++代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> _WIN32	<span class="comment">// win32 win64</span></span></span><br><span class="line">	<span class="meta">#<span class="keyword">define</span> XIB __declspec(dllexport)</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span>	<span class="comment">// MAC linux</span></span></span><br><span class="line">	<span class="meta">#<span class="keyword">define</span> XIB</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">XIB</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">numbers</span><span class="params">(<span class="type">int</span> x, <span class="type">float</span> y, <span class="type">bool</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;In C testctypes %d %f %d\n&quot;</span>,x, y, b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>make一下，生成 a.so。</p>
<p>python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> *</span><br><span class="line">lib = CDLL(<span class="string">&#x27;./a.so&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    lib.numbers(<span class="number">101</span>, c_float(<span class="number">99.1</span>), <span class="literal">True</span>)	<span class="comment"># 99.1是python里的float型，要传给c里的函数，要转成c的格式（通过c_float()函数转）</span></span><br><span class="line"></span><br><span class="line">    p2 = c_int(<span class="number">102</span>)</span><br><span class="line">    <span class="built_in">print</span>(p2)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(p2))</span><br><span class="line">    <span class="built_in">print</span>(p2.value)</span><br><span class="line">    lib.numbers(p2,c_float(<span class="number">99.1</span>),<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;error&quot;</span>, ex)</span><br></pre></td></tr></table></figure>



<p><code>python a.py</code> 输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n C testctypes <span class="number">101</span> <span class="number">99.099998</span> <span class="number">1</span></span><br><span class="line">c_int(<span class="number">102</span>)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;ctypes.c_int&#x27;</span>&gt;</span><br><span class="line"><span class="number">102</span></span><br><span class="line">In C testctypes <span class="number">102</span> <span class="number">99.099998</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>











<h2 id="ctypes类型对应-1"><a href="#ctypes类型对应-1" class="headerlink" title="ctypes类型对应"></a>ctypes类型对应</h2><p>传参，要把python类型转成c语言支持的；返回值，要把c语言类型转成python支持的。</p>
<blockquote>
<p><a href="https://docs.python.org/zh-cn/3/library/ctypes.html">https://docs.python.org/zh-cn/3/library/ctypes.html</a></p>
</blockquote>
<p><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#module-ctypes"><code>ctypes</code></a> 定义了一些和C兼容的基本数据类型：</p>
<p>这里ctypes类型都看作函数，<strong>转换函数</strong>，把python类型转成c类型的<strong>转换函数</strong>。</p>
<table>
<thead>
<tr>
<th align="left">ctypes 类型</th>
<th align="left">C 类型</th>
<th align="left">Python 类型</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_bool"><code>c_bool</code></a></td>
<td align="left">_Bool</td>
<td align="left">bool (1)</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_char"><code>c_char</code></a></td>
<td align="left">char</td>
<td align="left">单字符字节串对象（一个字节存放一个字符）</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_wchar"><code>c_wchar</code></a></td>
<td align="left">wchar_t</td>
<td align="left">单字符字符串（两个字节存放一个字符，宽字节，unsigned short）</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_byte"><code>c_byte</code></a></td>
<td align="left">char</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_ubyte"><code>c_ubyte</code></a></td>
<td align="left">unsigned char</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_short"><code>c_short</code></a></td>
<td align="left">short</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_ushort"><code>c_ushort</code></a></td>
<td align="left">unsigned short</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_int"><code>c_int</code></a></td>
<td align="left">int</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_uint"><code>c_uint</code></a></td>
<td align="left">unsigned int</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_long"><code>c_long</code></a></td>
<td align="left">long</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_ulong"><code>c_ulong</code></a></td>
<td align="left">unsigned long</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_longlong"><code>c_longlong</code></a></td>
<td align="left">__int64 or long long</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_ulonglong"><code>c_ulonglong</code></a></td>
<td align="left">unsigned __int64 or unsigned long long</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_size_t"><code>c_size_t</code></a></td>
<td align="left">size_t</td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_ssize_t"><code>c_ssize_t</code></a></td>
<td align="left">ssize_t or <a href="https://docs.python.org/zh-cn/3/c-api/intro.html#c.Py_ssize_t">Py_ssize_t</a></td>
<td align="left">int</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_float"><code>c_float</code></a></td>
<td align="left">float</td>
<td align="left">float</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_double"><code>c_double</code></a></td>
<td align="left">double</td>
<td align="left">float</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_longdouble"><code>c_longdouble</code></a></td>
<td align="left">long double</td>
<td align="left">float</td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_char_p"><code>c_char_p</code></a></td>
<td align="left">char* (NUL terminated)</td>
<td align="left">字节串对象或 <code>None</code></td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_wchar_p"><code>c_wchar_p</code></a></td>
<td align="left">wchar_t* (NUL terminated)</td>
<td align="left">字符串或 <code>None</code></td>
</tr>
<tr>
<td align="left"><a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_void_p"><code>c_void_p</code></a></td>
<td align="left">void*</td>
<td align="left">int 或 <code>None</code></td>
</tr>
</tbody></table>
<ol>
<li>构造函数接受任何具有真值的对象。</li>
</ol>
<p>所有这些类型都可以通过使用正确类型和值的可选初始值调用它们来创建:</p>
<p><code>from ctypes import *</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>c_int()</span><br><span class="line">    c_long(<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c_wchar_p(<span class="string">&quot;Hello, World&quot;</span>)</span><br><span class="line">c_wchar_p(<span class="number">140018365411392</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c_ushort(-<span class="number">3</span>)</span><br><span class="line">c_ushort(<span class="number">65533</span>)</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>



<p>由于这些类型是可变的，它们的值也可以在以后更改:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>i = c_int(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(i)</span><br><span class="line">c_long(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(i.value)</span><br><span class="line"><span class="number">42</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>i.value = -<span class="number">99</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(i.value)</span><br><span class="line">-<span class="number">99</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>



<p>当给指针类型的对象 <a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_char_p"><code>c_char_p</code></a>, <a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_wchar_p"><code>c_wchar_p</code></a> 和 <a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.c_void_p"><code>c_void_p</code></a> 等赋值时，将改变它们所指向的 <em>内存地址</em>，而 <em>不是</em> 它们所指向的内存区域的 <em>内容</em> (这是理所当然的，因为 Python 的 bytes 对象是不可变的):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = <span class="string">&quot;Hello, World&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c_s = c_wchar_p(s)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c_s)</span><br><span class="line">c_wchar_p(<span class="number">139966785747344</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c_s.value)</span><br><span class="line">Hello World</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c_s.value = <span class="string">&quot;Hi, there&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c_s)              <span class="comment"># the memory location has changed</span></span><br><span class="line">c_wchar_p(<span class="number">139966783348904</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c_s.value)</span><br><span class="line">Hi, there</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(s)                <span class="comment"># first object is unchanged</span></span><br><span class="line">Hello, World</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>



<p>但你要注意不能将它们传递给会改变指针所指内存的函数。如果你需要可改变的内存块，ctypes 提供了 <a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.create_string_buffer"><code>create_string_buffer()</code></a> 函数，它提供多种方式创建这种内存块。当前的内存块内容可以通过 <code>raw</code> 属性存取，如果你希望将它作为NUL结束的字符串，请使用 <code>value</code> 属性:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> ctypes <span class="keyword">import</span> *</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = create_string_buffer(<span class="number">3</span>)            <span class="comment"># create a 3 byte buffer, initialized to NUL bytes</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(sizeof(p), <span class="built_in">repr</span>(p.raw))</span><br><span class="line"><span class="number">3</span> <span class="string">b&#x27;\x00\x00\x00&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = create_string_buffer(<span class="string">b&quot;Hello&quot;</span>)     <span class="comment"># create a buffer containing a NUL terminated string</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(sizeof(p), <span class="built_in">repr</span>(p.raw))</span><br><span class="line"><span class="number">6</span> <span class="string">b&#x27;Hello\x00&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">repr</span>(p.value))</span><br><span class="line"><span class="string">b&#x27;Hello&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = create_string_buffer(<span class="string">b&quot;Hello&quot;</span>, <span class="number">10</span>) <span class="comment"># create a 10 byte buffer</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(sizeof(p), <span class="built_in">repr</span>(p.raw))</span><br><span class="line"><span class="number">10</span> <span class="string">b&#x27;Hello\x00\x00\x00\x00\x00&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.value = <span class="string">b&quot;Hi&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(sizeof(p), <span class="built_in">repr</span>(p.raw))</span><br><span class="line"><span class="number">10</span> <span class="string">b&#x27;Hi\x00lo\x00\x00\x00\x00\x00&#x27;</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

<p>The <a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.create_string_buffer"><code>create_string_buffer()</code></a> function replaces the old <code>c_buffer()</code> function (which is still available as an alias). To create a mutable memory block containing unicode characters of the C type wchar_t, use the <a href="https://docs.python.org/zh-cn/3/library/ctypes.html#ctypes.create_unicode_buffer"><code>create_unicode_buffer()</code></a> function.</p>
<h2 id="chatgpt回答"><a href="#chatgpt回答" class="headerlink" title="chatgpt回答"></a>chatgpt回答</h2><blockquote>
<p>以下回答来自chatgpt：</p>
</blockquote>
<p>Python 可以通过 Cython、ctypes、SWIG 等方式与 C++ 进行交互。</p>
<ul>
<li>Cython 可以把 Python 代码编译为 C++ 代码，它的语法是 Python 的语法的扩展，可以直接调用 C++ 代码；</li>
<li>ctypes 可以直接加载并调用动态链接库，并且可以很容易地调用 C 函数；</li>
<li>SWIG 可以自动生成 Python 接口，方便地从 Python 中调用 C++ 代码。</li>
</ul>
<ol>
<li>使用Cython或SWIG：这些工具可以让你编写接口代码，它们会把这些代码编译成可以在Python环境下运行的代码。</li>
<li>使用ctypes或cffi：这些库可以动态加载C++代码作为C函数，从而在Python代码中调用。</li>
</ol>
<p>下面是一个使用ctypes的例子：</p>
<p>c++：（a.cc）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// a.cc</span></span><br><span class="line"><span class="meta"># <span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a + b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>python：(a.py)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># a.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ctypes</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the shared library</span></span><br><span class="line">lib = ctypes.CDLL(<span class="string">&#x27;./libexample.so&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Call the add function in the C++ code</span></span><br><span class="line">result = lib.add(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># 8</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>把c++编译成 libexample.so：<code>g++ -shared -fPIC -o libexample.so a.cc</code></p>
<p>然后执行代码：<code>python a.py</code> 。就能得到结果了。</p>
<p>这是一个简单的例子，它仅仅是说明了如何调用C++代码。请注意，这只是一种方法，具体应用取决于您的需求和使用场景。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python调用C++——pybind11</title>
    <url>/2023/02/15/python/python%E8%B0%83%E7%94%A8C++%E2%80%94%E2%80%94pybind11/</url>
    <content><![CDATA[<h1 id="python调用C-——pybind11"><a href="#python调用C-——pybind11" class="headerlink" title="python调用C++——pybind11"></a>python调用C++——pybind11</h1><blockquote>
<p>官方：<a href="https://pybind11.readthedocs.io/en/stable/">https://pybind11.readthedocs.io/en/stable/</a> ；中文翻译：<a href="https://github.com/charlotteLive/pybind11-Chinese-docs">https://github.com/charlotteLive/pybind11-Chinese-docs</a></p>
</blockquote>
<p>也是一种python调用c++的方式。</p>
<p>具体做法是 在C++代码里要写上要绑定的C++函数，封装、编译成某个python也能用的.so库，供给python代码import进这个库。</p>
<p>编译，可以用cmake。</p>
<p>例子，看官方文档就可以。</p>
<h1 id="模型部署入门教程（四）阅读笔记一之Pybind11-保姆级教程"><a href="#模型部署入门教程（四）阅读笔记一之Pybind11-保姆级教程" class="headerlink" title="模型部署入门教程（四）阅读笔记一之Pybind11 保姆级教程"></a>模型部署入门教程（四）阅读笔记一之Pybind11 保姆级教程</h1><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1L341137NP/?spm_id_from=333.337.search-card.all.click">模型部署入门教程（四）阅读笔记一之Pybind11 保姆级教程</a> </p>
<p>该视频的例子来自youtube：<a href="https://www.youtube.com/watch?v=FIoGJCUFV4M&ab_channel=CppMonk">Setting up CMake, Pybind11 and QtCreator [Part 3A, Understand &amp; Code a Kalman Filter]</a></p>
</blockquote>
<h4 id="第0步-放第三方库"><a href="#第0步-放第三方库" class="headerlink" title="第0步 放第三方库"></a>第0步 放第三方库</h4><p>新建文件夹，记为<code>thirdparty</code>，里面放第三方库，分别放了 <code>eigen</code> 和 <code>pybind11</code> （分别是到官网<code>https://eigen.tuxfamily.org/index.php?title=Main_Page </code>下载 eigen-3.4.0.zip 解压到该路径，和 <code>git clone https://github.com/pybind/pybind11.git</code>）</p>
<p>（eigen是一个矩阵代数库）</p>
<h4 id="第1步-创建-CMakeLists-txt，内容为："><a href="#第1步-创建-CMakeLists-txt，内容为：" class="headerlink" title="第1步 创建 CMakeLists.txt，内容为："></a>第1步 创建 <code>CMakeLists.txt</code>，内容为：</h4><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 项目名称</span></span><br><span class="line">project(kf_code)</span><br><span class="line"><span class="comment"># cmake最低版本</span></span><br><span class="line">cmake_minimum_required (VERSION 3.0)</span><br><span class="line"><span class="comment"># 添加子目录</span></span><br><span class="line">add_subdirectory(thirdparty/pybind11)</span><br><span class="line"><span class="comment"># 添加库</span></span><br><span class="line">include_directories(thirdparty/engen-3.4.0) </span><br><span class="line"><span class="comment"># 编译成动态库，名字叫 kf_cpp，动态库的源文件的 wrappers.cpp</span></span><br><span class="line">pybind11_add_module(kf_cpp wrappers.cpp)</span><br></pre></td></tr></table></figure>

<p>（这里kf来自一个kalman filter项目）</p>
<h4 id="第2步-创建-wrapper-cpp-文件，内容为："><a href="#第2步-创建-wrapper-cpp-文件，内容为：" class="headerlink" title="第2步 创建 wrapper.cpp 文件，内容为："></a>第2步 创建 <code>wrapper.cpp</code> 文件，内容为：</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> j)</span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;start&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PYBIND11_MODULE(kf_cpp, m)&#123;</span><br><span class="line">    m.doc() = <span class="string">&quot;pybind11 example plugin&quot;</span>;</span><br><span class="line">    m.def(<span class="string">&quot;add&quot;</span>, &amp;add, <span class="string">&quot;a add funciton&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，这里cpp文件名叫wrapper，编译出的名称叫kf_cpp，不一样，如果一样就省事，如果不一样，则需要cmake编译</p>
<h4 id="第3步-make，生成-kf-cpp-可执行动态库。"><a href="#第3步-make，生成-kf-cpp-可执行动态库。" class="headerlink" title="第3步 make，生成 kf_cpp 可执行动态库。"></a>第3步 make，生成 <code>kf_cpp</code> 可执行动态库。</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>生成 <code>kf_cpp.cpython-39-x86_64-linux-gnu.so</code></p>
<ul>
<li><p>如果修改了 <code>wrapper.cpp</code> 文件，修改后，重新执行 <code>make</code> 一下就好。</p>
</li>
<li><p>如果一直cmake不好（比如修改过cmakelist.txt），就把build文件夹删除，重新创建一次。</p>
</li>
</ul>
<h4 id="第4步-python里测试"><a href="#第4步-python里测试" class="headerlink" title="第4步 python里测试"></a>第4步 python里测试</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> kf_cpp</span><br><span class="line"></span><br><span class="line">kf_cpp.add(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出 3</span></span><br></pre></td></tr></table></figure>







<h2 id="Setting-up-CMake-Pybind11-and-QtCreator-Part-3A-Understand-amp-Code-a-Kalman-Filter"><a href="#Setting-up-CMake-Pybind11-and-QtCreator-Part-3A-Understand-amp-Code-a-Kalman-Filter" class="headerlink" title="Setting up CMake, Pybind11 and QtCreator [Part 3A, Understand &amp; Code a Kalman Filter]"></a>Setting up CMake, Pybind11 and QtCreator [Part 3A, Understand &amp; Code a Kalman Filter]</h2><blockquote>
<p>youtube：<a href="https://www.youtube.com/watch?v=FIoGJCUFV4M&ab_channel=CppMonk">Setting up CMake, Pybind11 and QtCreator [Part 3A, Understand &amp; Code a Kalman Filter]</a></p>
<p>youtube：<a href="https://www.youtube.com/watch?v=74yr6hEV-fQ&ab_channel=CppMonk">Python Wrappers for C++ with Pybind11 [Part 3B, Understand &amp; Code a Kalman Filter]</a></p>
<p>youtube：<a href="https://www.youtube.com/watch?v=NFth5v38NHc&ab_channel=CppMonk">Kalman Filter in C++ (and Pybind11) [Part 3C, Understand &amp; Code a Kalman Filter]</a></p>
<p>全系列为：<a href="https://www.youtube.com/playlist?list=PLvKAPIGzFEr8n7WRx8RptZmC1rXeTzYtA">https://www.youtube.com/playlist?list=PLvKAPIGzFEr8n7WRx8RptZmC1rXeTzYtA</a></p>
<p>github：<a href="https://github.com/cbecker/kalman_python_cpp">kalman_python_cpp</a></p>
</blockquote>
<p>第一个视频和上面的b站视频基本一致。</p>
<ol>
<li>set up CMake, Eigen &amp; Pybind11</li>
<li>C++ Skeleton and integrate w&#x2F;tests</li>
<li>populate KF code in C++ Skeleton</li>
</ol>
<p>第二、三个视频：</p>
<p>验证python里调用C++执行的结果，和python自己的函数执行的结果是否一致。用了命令行指令 <code>pytest</code> （pytest 自动会测试以 <code>test_</code>开头&#x2F;结尾的文件，测试类以<code>Test</code>开头，并且不能带有 init 方法，测试函数以<code>test_</code>开头）</p>
<p>用一个wrapper.cpp作为绑定到python的中间人，里面写进其它cpp&#x2F;h的类、函数，通过这个cpp来建立python和其它cpp&#x2F;h之间的绑定：</p>
<p>wrapper.cpp</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kf.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(kf_cpp, m)</span><br><span class="line">&#123;</span><br><span class="line">    m.<span class="built_in">doc</span>() = <span class="string">&quot;C++ KF implementation wrappers&quot;</span>;  <span class="comment">// optional module docstring</span></span><br><span class="line"></span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;add&quot;</span>, &amp;add, <span class="string">&quot;A function which adds two numbers&quot;</span>);</span><br><span class="line"></span><br><span class="line">    pybind11::<span class="built_in">class_</span>&lt;KF&gt;(m, <span class="string">&quot;KF&quot;</span>)</span><br><span class="line">        .<span class="built_in">def</span>(pybind11::<span class="built_in">init</span>&lt;<span class="type">double</span>, <span class="type">double</span>, <span class="type">double</span>&gt;())</span><br><span class="line">        .<span class="built_in">def</span>(<span class="string">&quot;predict&quot;</span>, &amp;KF::predict)</span><br><span class="line">        .<span class="built_in">def</span>(<span class="string">&quot;update&quot;</span>, &amp;KF::update)</span><br><span class="line">        .<span class="built_in">def_property_readonly</span>(<span class="string">&quot;cov&quot;</span>, &amp;KF::cov)</span><br><span class="line">        .<span class="built_in">def_property_readonly</span>(<span class="string">&quot;mean&quot;</span>, &amp;KF::mean)</span><br><span class="line">        .<span class="built_in">def_property_readonly</span>(<span class="string">&quot;pos&quot;</span>, &amp;KF::pos)</span><br><span class="line">        .<span class="built_in">def_property_readonly</span>(<span class="string">&quot;vel&quot;</span>, &amp;KF::vel);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中，类KF来自 <code>kf.h  </code> 。</p>
<p>这里参考的是pybind11官方教程里的写法：</p>
<blockquote>
<p><a href="https://pybind11.readthedocs.io/en/stable/classes.html">https://pybind11.readthedocs.io/en/stable/classes.html</a></p>
</blockquote>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">py::<span class="built_in">class_</span>&lt;Pet&gt;(m, <span class="string">&quot;Pet&quot;</span>)</span><br><span class="line">    .<span class="built_in">def</span>(py::<span class="built_in">init</span>&lt;<span class="type">const</span> std::string &amp;&gt;())</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;setName&quot;</span>, &amp;Pet::setName)</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;getName&quot;</span>, &amp;Pet::getName)</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;__repr__&quot;</span>,</span><br><span class="line">        [](<span class="type">const</span> Pet &amp;a) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;&lt;example.Pet named &#x27;&quot;</span> + a.name + <span class="string">&quot;&#x27;&gt;&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>







<h1 id="Python-Bindings-Calling-C-or-C-From-Python"><a href="#Python-Bindings-Calling-C-or-C-From-Python" class="headerlink" title="Python Bindings: Calling C or C++ From Python"></a>Python Bindings: Calling C or C++ From Python</h1><blockquote>
<p><a href="https://realpython.com/python-bindings-overview/">https://realpython.com/python-bindings-overview/</a> </p>
<p>翻译：<a href="https://bbs.huaweicloud.com/blogs/281506">Python 绑定:从 Python 调用 C 或 C++ |【生长吧！Python!】</a></p>
</blockquote>
<p>Python 绑定:从 Python 调用 C 或 C++。</p>
<p>这篇没看很懂，有点乱。</p>
<h4 id="编写绑定"><a href="#编写绑定" class="headerlink" title="编写绑定"></a>编写绑定</h4><p>在C++代码中，创建一些代码来告诉该工具如何构建您的 Python 绑定：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pybind11_wrapper.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cppmult.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(pybind11_example, m) &#123;</span><br><span class="line">    m.<span class="built_in">doc</span>() = <span class="string">&quot;pybind11 example plugin&quot;</span>; <span class="comment">// Optional module docstring</span></span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">&quot;cpp_function&quot;</span>, &amp;add, <span class="string">&quot;A function that multiplies two numbers&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意这里，一般 <code>PYBIND11_MODULE</code> 的第一个参数 模块名，和这个cpp文件的名称相同最好？？，就不需要自己写一个init了。</p>
<p>（上面这个代码例子，第一个参数模块名是<code>pybind11_example</code>，但是cpp文件名称是<code>pybind11_wrapper</code>）</p>
<p>让我们一次一个地看，因为<code>PyBind11</code>将大量信息打包成几行。</p>
<p>前两行包括<code>pybind11.h</code> C++ 库的文件和头文件<code>cppmult.hpp</code> 之后，你就有了<code>PYBIND11_MODULE</code>宏。这将扩展为<code>PyBind11</code>源代码中详细描述的 C++ 代码块：</p>
<blockquote>
<p>此宏创建入口点，当 Python 解释器导入扩展模块时将调用该入口点。模块名称作为第一个参数给出，不应用引号引起来。第二个宏参数定义了一个<code>py::module</code>可用于初始化模块的类型变量。（<a href="https://github.com/pybind/pybind11/blob/1376eb0e518ff2b7b412c84a907dd1cd3f7f2dcd/include/pybind11/detail/common.h#L267">来源</a>）</p>
</blockquote>
<p>在本例中，您正在&#x3D;&#x3D;创建一个名为<code>pybind11_example</code>的模块，其余代码将<code>m</code>用作<code>py::module</code>对象的名称&#x3D;&#x3D;。在下一行，在您定义的 C++ 函数中，您为模块创建一个文档字符串。虽然这是可选的，但让您的模块更加Pythonic是一个不错的选择。</p>
<p>你有<code>m.def()</code>call。这将定义一个由您的新 Python 绑定导出的函数，这意味着它将在 Python 中可见。在此示例中，您将传递三个参数：</p>
<ul>
<li>**<code>cpp_function</code>**是您将在 Python 中使用的函数的导出名称。如本例所示，它不需要匹配 C++ 函数的名称。（后面python调用函数，用的这个名称）</li>
<li><strong><code>&amp;add</code></strong> 获取要导出的函数的地址。（C++函数名的地址）（这里是<code>cppmult.hpp</code>里定义的一个函数<code>add</code>）</li>
<li><strong><code>&quot;A function...&quot;</code></strong> 是函数的可选文档字符串。</li>
</ul>
<p>现在您已经有了 Python 绑定的代码，接下来看看如何将其构建到 Python 模块中。</p>
<p>这里<code>cppmult.hpp</code>是：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> CPPMULT_HPP</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CPPMULT_HPP</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">add</span><span class="params">()</span></span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> </span></span><br></pre></td></tr></table></figure>

<p>这里<code>cppmult.cpp</code>是：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cppmult.hpp&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">add</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="构建-Python-绑定"><a href="#构建-Python-绑定" class="headerlink" title="构建 Python 绑定"></a>构建 Python 绑定</h4><p>用于构建 Python 绑定的工具<code>PyBind11</code>是 C++ 编译器本身。您可能需要修改编译器和操作系统的默认值。</p>
<p>首先，您必须构建要为其创建绑定的 C++ 库。对于这么小的示例，您可以将<code>cppmult</code>库直接构建到 Python 绑定库中。但是，对于大多数实际示例，您将有一个要包装的预先存在的库，因此您将<code>cppmult</code>单独构建该库。构建是对编译器的标准调用以构建共享库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tasks.py</span></span><br><span class="line"><span class="keyword">import</span> invoke</span><br><span class="line">invoke.run(</span><br><span class="line">    <span class="string">&quot;g++ -O3 -Wall -Werror -shared -std=c++11 -fPIC cppmult.cpp &quot;</span></span><br><span class="line">    <span class="string">&quot;-o libcppmult.so &quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>运行这个<code>invoke build-cppmult</code>产生<code>libcppmult.so</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ invoke build-cppmult</span><br><span class="line">==================================================</span><br><span class="line">= Building C++ Library</span><br><span class="line">* Complete</span><br></pre></td></tr></table></figure>

<p>另一方面，Python 绑定的构建需要一些特殊的细节：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># tasks.py</span></span><br><span class="line">invoke.run(</span><br><span class="line">    <span class="string">&quot;g++ -O3 -Wall -Werror -shared -std=c++11 -fPIC &quot;</span></span><br><span class="line">    <span class="string">&quot;`python3 -m pybind11 --includes` &quot;</span></span><br><span class="line">    <span class="string">&quot;-I /usr/include/python3.7 -I .  &quot;</span></span><br><span class="line">    <span class="string">&quot;&#123;0&#125; &quot;</span></span><br><span class="line">    <span class="string">&quot;-o &#123;1&#125;`python3-config --extension-suffix` &quot;</span></span><br><span class="line">    <span class="string">&quot;-L. -lcppmult -Wl,-rpath,.&quot;</span>.<span class="built_in">format</span>(cpp_name, extension_name)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>让我们逐行浏览一下。<strong>第 3 行</strong>包含相当标准的 C++ 编译器标志，指示几个细节，包括您希望捕获所有警告并将其视为错误、您需要共享库以及您使用的是 C++11。</p>
<p><strong>第 4 行</strong>是魔法的第一步。它调用<code>pybind11</code>模块使其<code>include</code>为<code>PyBind11</code>. 您可以直接在控制台上运行此命令以查看它的作用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python3 -m pybind11 --includes</span><br><span class="line">-I/mnt/k/anaconda3/include/python3<span class="number">.9</span> -I/mnt/k/anaconda3/lib/python3<span class="number">.9</span>/site-packages/pybind11/include</span><br></pre></td></tr></table></figure>

<p>您的输出应该相似但显示不同的路径。</p>
<p>在编译调用的<strong>第 5 行</strong>，您可以看到您还添加了 Python dev 的路径<code>includes</code>。虽然建议您<em>不要</em>链接 Python 库本身，但源代码需要一些代码<code>Python.h</code>才能发挥其魔力。幸运的是，它使用的代码在 Python 版本中相当稳定。</p>
<p>第 5 行还用于<code>-I .</code>将当前目录添加到<code>include</code>路径列表中。这允许<code>#include &lt;cppmult.hpp&gt;</code>解析包装器代码中的行。</p>
<p><strong>第 6 行</strong>指定源文件的名称，即<code>pybind11_wrapper.cpp</code>. 然后，在<strong>第 7 行，</strong>您会看到更多的构建魔法正在发生。此行指定输出文件的名称。Python 在模块命名上有一些特别的想法，包括 Python 版本、机器架构和其他细节。Python 还提供了一个工具来帮助解决这个问题<code>python3-config</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python3-config --extension-suffix</span><br><span class="line">.cpython-<span class="number">39</span>-x86_64-linux-gnu.so</span><br></pre></td></tr></table></figure>

<p>如果您使用的是不同版本的 Python，则可能需要修改该命令。如果您使用不同版本的 Python 或在不同的操作系统上，您的结果可能会发生变化。</p>
<p>构建命令的最后一行，<strong>第 8 行</strong>，将链接器指向<code>libcppmult</code>您之前构建的库。该<code>rpath</code>部分告诉链接器向共享库添加信息以帮助操作系统<code>libcppmult</code>在运行时查找。最后，您会注意到此字符串的格式为<code>cpp_name</code>和<code>extension_name</code>。<code>Cython</code>在下一节中构建 Python 绑定模块时，您将再次使用此函数。</p>
<p>运行此命令以构建绑定：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ invoke build-pybind11</span><br><span class="line">==================================================</span><br><span class="line">= Building C++ Library</span><br><span class="line">* Complete</span><br><span class="line">==================================================</span><br><span class="line">= Building PyBind11 Module</span><br><span class="line">* Complete</span><br></pre></td></tr></table></figure>

<p>就是这样！您已经使用<code>PyBind11</code>. 是时候测试一下了！</p>
<h4 id="调用你的函数"><a href="#调用你的函数" class="headerlink" title="调用你的函数"></a>调用你的函数</h4><p>与<code>CFFI</code>上面的示例类似，一旦您完成了创建 Python 绑定的繁重工作，调用您的函数看起来就像普通的 Python 代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pybind11_test.py</span></span><br><span class="line"><span class="keyword">import</span> pybind11_example</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># Sample data for your call</span></span><br><span class="line">    x, y = <span class="number">6</span>, <span class="number">2.3</span></span><br><span class="line"></span><br><span class="line">    answer = pybind11_example.cpp_function(x, y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;    In Python: int: <span class="subst">&#123;x&#125;</span> float <span class="subst">&#123;y:<span class="number">.1</span>f&#125;</span> return val <span class="subst">&#123;answer:<span class="number">.1</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>由于您<code>pybind11_example</code>在<code>PYBIND11_MODULE</code>宏中用作模块的名称，因此这就是您导入的名称。在<code>m.def()</code>您告诉<code>PyBind11</code>将<code>cppmult</code>函数导出为 的调用中<code>cpp_function</code>，这就是您用来从 Python 调用它的方法。</p>
<p>你也可以测试它<code>invoke</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ invoke test-pybind11</span><br><span class="line">==================================================</span><br><span class="line">= Testing PyBind11 Module</span><br><span class="line">    In cppmul: int: 6 <span class="built_in">float</span> 2.3 returning  13.8</span><br><span class="line">    In Python: int: 6 <span class="built_in">float</span> 2.3 <span class="built_in">return</span> val 13.8</span><br></pre></td></tr></table></figure>

<p>这就是<code>PyBind11</code>看起来的样子。接下来，您将了解何时以及为何<code>PyBind11</code>是适合该工作的工具。</p>
<h3 id="长处和短处"><a href="#长处和短处" class="headerlink" title="长处和短处"></a>长处和短处</h3><p><code>PyBind11</code>专注于 C++ 而不是 C，这使得它不同于<code>ctypes</code>和<code>CFFI</code>。它有几个特性使其对 C++ 库非常有吸引力：</p>
<ul>
<li>它支持<strong>类</strong>。</li>
<li>它处理<strong>多态子类化</strong>。</li>
<li>它允许您从 Python 和许多其他工具向对象添加<strong>动态属性</strong>，而使用您检查过的基于 C 的工具很难做到这一点。</li>
</ul>
<p>话虽如此，您需要进行大量设置和配置才能<code>PyBind11</code>启动和运行。正确安装和构建可能有点挑剔，但一旦完成，它似乎相当可靠。此外，<code>PyBind11</code>要求您至少使用 C++11 或更高版本。对于大多数项目来说，这不太可能是一个很大的限制，但它可能是您的一个考虑因素。</p>
<p>最后，创建 Python 绑定需要编写的额外代码是用 C++ 编写的，而不是用 Python 编写的。这可能是也可能不是你的问题，但它<em>是</em>比你在这里看到的其他工具不同。在下一节中，您将继续讨论<code>Cython</code>，它采用完全不同的方法来解决这个问题。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>联合调试python/C++</title>
    <url>/2023/02/15/python/%E8%81%94%E5%90%88%E8%B0%83%E8%AF%95pythonC++/</url>
    <content><![CDATA[<h1 id="联合调试python-x2F-C"><a href="#联合调试python-x2F-C" class="headerlink" title="联合调试python&#x2F;C++"></a>联合调试python&#x2F;C++</h1><p>我想实现在vscode里调试python代码，遇到extern的C++代码，也能跳进C++函数里。</p>
<p>或者说python调试过程中，想跳入C++代码，要如何实现呢？</p>
<h3 id="生成支持debug的链接库"><a href="#生成支持debug的链接库" class="headerlink" title="生成支持debug的链接库"></a>生成支持debug的链接库</h3><p><strong>首先python代码中 import 的库，需要能够支持debug</strong>，不支持debug的库(.so)无法调试。</p>
<p>于是要在make的时候加入信息，让它make出来的链接库要可以debug。</p>
<p>有两种方法：</p>
<ol>
<li>**用<code>cmake</code>**，来把cpp编译成python可以import的库 的时候，加入debug选项。（cmakelists.txt里是<code>pybind11_add_module</code>）</li>
</ol>
<p>CMakeLists.txt中加入：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) </span><br><span class="line"></span><br><span class="line">SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;)</span><br><span class="line">SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</span><br></pre></td></tr></table></figure>

<p>重新编译：在build里：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cmake clean ..</span></span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug ..</span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug --build .</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>生成支持debug的动态链接库.so。（路径在build&#x2F;下）</p>
<p>（cmake方法参考的 <a href="https://www.bilibili.com/video/BV1L341137NP/?spm_id_from=333.337.search-card.all.click">模型部署入门教程（四）阅读笔记一之Pybind11 保姆级教程</a> ，并在上面做了修改）</p>
<ol start="2">
<li>**用<code>python setup.py</code>**，来把cpp编译成python可以import的库 的时候，加入debug选项</li>
</ol>
<p>命令行执行：<code>python3 setup.py build_ext --debug install</code> </p>
<p>（setup方法参考的  <a href="https://blog.csdn.net/wq_0708/article/details/121229527">VSCode 联合调试Python&#x2F;C++</a>  ，并在上面做了修改，以及 <a href="https://stackoverflow.com/questions/61692952/how-to-pass-debug-to-build-ext-when-invoking-setup-py-install">How to pass –debug to build_ext when invoking setup.py install?</a> ）</p>
<h3 id="联合调试"><a href="#联合调试" class="headerlink" title="联合调试"></a>联合调试</h3><p>这里介绍的是 python代码里用到C++代码的情况，也就是调试python代码时 跳入C++代码的调试方法。</p>
<p>调试方法有两种：</p>
<ol>
<li><strong>命令行 gdb&#x2F;cgdb调试</strong> ，直接通过命令行的 <code>gdb --args python XX.py</code> 进行调试，在cpp代码里打断点，比如 <code>b myadd.cpp:7</code> ，然后 <code>r</code> 执行，就会跳转到cpp文件的断点位置。</li>
</ol>
<p>这里更标准的写法是：</p>
<p>先打cpp代码的断点，然后<code>gdb -ex r --args python script.py args</code> （args是传入python的参数）；</p>
<p>如果想同时查看python脚本，则用混合模式 <code>gdb -ex r --args python -m pdb script.py</code> 。</p>
<p>（gdb调试参考的 <a href="https://blog.csdn.net/wq_0708/article/details/121229527">VSCode 联合调试Python&#x2F;C++</a> 、<a href="https://stackoverflow.com/questions/51537967/how-to-debug-python-script-in-c-level-using-gdb-give-me-a-simple-example-for-th">How to debug python script in C level using GDB. Give me a simple example for this</a>）</p>
<ol start="2">
<li><strong>用VSCode调试</strong>，通过VSCode的attach功能调试</li>
</ol>
<p>具体做法为：修改 <code>launch.json</code></p>
<p>选添加配置：</p>
<img src="/2023/02/15/python/%E8%81%94%E5%90%88%E8%B0%83%E8%AF%95pythonC++/image-20230215180432615.png" alt="image-20230215180432615" style="zoom: 67%;">

<p>选(gdb)附加：</p>
<img src="/2023/02/15/python/%E8%81%94%E5%90%88%E8%B0%83%E8%AF%95pythonC++/image-20230215180522052.png" alt="image-20230215180522052" style="zoom: 67%;">

<p>在命令行敲 <code>which python</code> 得到 比如 <code>/mnt/k/anaconda3/bin/python</code> ， 然后把这一行写在配置的 <code>program</code> 里：</p>
<img src="/2023/02/15/python/%E8%81%94%E5%90%88%E8%B0%83%E8%AF%95pythonC++/image-20230215180708634.png" alt="image-20230215180708634" style="zoom:67%;">

<p>最终的 <code>launch.json</code>长这样：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// 使用 IntelliSense 了解相关属性。 </span></span><br><span class="line">    <span class="comment">// 悬停以查看现有属性的描述。</span></span><br><span class="line">    <span class="comment">// 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;(gdb) 附加&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cppdbg&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;attach&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/mnt/k/anaconda3/bin/python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;MIMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;setupCommands&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;为 gdb 启用整齐打印&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-enable-pretty-printing&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;将反汇编风格设置为 Intel&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-gdb-set disassembly-flavor intel&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python: 当前文件&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;file&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;justMyCode&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>然后 <code>ctrl+p</code> 输入 <code>&gt;developer:reload window</code> 回车。</p>
<p>在python文件打端点，在cpp文件里打断点。开始调试python文件，当执行到断点处时，选择<code>(gdb)附加</code> （原本是<code>python:当前文件</code>），然后点绿色箭头），</p>
<p><img src="/2023/02/15/python/%E8%81%94%E5%90%88%E8%B0%83%E8%AF%95pythonC++/image-20230215180923473.png" alt="image-20230215180923473"></p>
<p>弹出 附加到进程 ，输入python文件名，选择下面那个。</p>
<img src="/2023/02/15/python/%E8%81%94%E5%90%88%E8%B0%83%E8%AF%95pythonC++/image-20230215182152138.png" alt="image-20230215182152138" style="zoom:67%;">

<p>或者在命令行里敲 <code>ps aux |grep python</code>，查看进程号，敲进去。</p>
<p><img src="/2023/02/15/python/%E8%81%94%E5%90%88%E8%B0%83%E8%AF%95pythonC++/image-20230215182453382.png" alt="image-20230215182453382"></p>
<p>连接上之后（红色插头），敲F5继续，就可以看见跳进C++代码了。</p>
<img src="/2023/02/15/python/%E8%81%94%E5%90%88%E8%B0%83%E8%AF%95pythonC++/image-20230215182635255.png" alt="image-20230215182635255" style="zoom: 67%;">

<p>（vscode调试参考的 <a href="https://www.bilibili.com/video/BV1ja4y1W7o7/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b%EF%BC%89">【C++编程系列】如何利用vscode调试pytorch源码(python&#x2F;c++)</a> ）</p>
<h2 id="chatgpt回答"><a href="#chatgpt回答" class="headerlink" title="chatgpt回答"></a>chatgpt回答</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>在Python和C++联合调试时，您可以使用以下方法：</p>
<ol>
<li>使用共享库：将C++代码编译为共享库，然后在Python中使用ctypes模块加载库。这样，您可以使用Python代码来调用C++代码，并在C++代码中使用gdb或其他调试器进行调试。（分开调试）</li>
<li>使用调试器：在C++代码中设置断点，并在Python代码中使用subprocess模块运行C++程序。这将在C++代码中触发断点，允许您检查C++代码中的变量和执行路径。</li>
<li>使用调试服务器：在C++代码中添加调试服务器，并在Python代码中使用Python的内置pdb模块连接到该服务器。这将使您能够在C++代码中调试，并使用Python代码来查看和修改C++变量。</li>
</ol>
<p>无论您选择哪种方法，都需要确保您的Python和C++代码之间的接口正确地定义了数据结构，以便在两个语言之间传递数据。</p>
<p>要在VS Code中调试Python代码并跳进C++代码，您可以使用以下步骤：</p>
<ol>
<li><p>确保您的C++代码被编译为共享库，以便Python可以加载它。如果您的C++代码没有编译为共享库，请按照操作系统和编译器的指示进行操作。</p>
</li>
<li><p>在VS Code中打开Python文件，并按照常规方式启动调试器。这将启动Python调试器，并暂停在您的Python代码中的第一行。</p>
</li>
<li><p>在VS Code中的调试控制台中输入以下命令，以确保您的共享库路径已被添加到Python的sys.path中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;/path/to/your/shared/library&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>这将允许Python找到并加载您的C++共享库。</p>
</li>
<li><p>在您的Python代码中使用ctypes模块加载C++共享库，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ctypes</span><br><span class="line">mylib = ctypes.CDLL(<span class="string">&#x27;/path/to/your/shared/library/mylib.so&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>这将加载名为mylib.so的共享库，并使其可用于Python。</p>
</li>
<li><p>在您的Python代码中调用C++代码，并使用VS Code的调试功能中的“跳过”或“跳进”命令进入C++代码。如果您在C++代码中设置了断点，VS Code调试器将暂停在该断点处，允许您检查C++代码的变量和执行路径。</p>
</li>
</ol>
<p>请注意，为了使C++和Python代码之间的接口正确地定义数据结构和函数签名，您需要仔细编写并编译您的C++代码，并使用正确的ctypes函数调用C++函数。这可能需要一些实践和调试，以确保正确的交互。</p>
<h2 id="待看"><a href="#待看" class="headerlink" title="待看"></a>待看</h2><blockquote>
<p>visual studio 官方教程：<a href="https://learn.microsoft.com/zh-cn/visualstudio/python/debugging-mixed-mode-c-cpp-python-in-visual-studio?view=vs-2022">一起调试 Python 和 C++</a></p>
<p><a href="https://www.cnblogs.com/yemanxiaozu/p/8269638.html">调试Python调用的C++共享库</a></p>
<p><a href="https://blog.51cto.com/u_12890843/5356871">python gdb</a></p>
<p><a href="https://www.bilibili.com/video/BV1wV4y1p7Ak/?spm_id_from=333.337.search-card.all.click&amp;vd_source=5e9891722f2b62adca440a5e92121b5b">https://www.bilibili.com/video/BV1wV4y1p7Ak/?spm_id_from=333.337.search-card.all.click&amp;vd_source=5e9891722f2b62adca440a5e92121b5b</a></p>
<p><a href="https://www.bilibili.com/video/BV1kP4y1K7Eo/?spm_id_from=333.337.search-card.all.click&amp;vd_source=5e9891722f2b62adca440a5e92121b5b">https://www.bilibili.com/video/BV1kP4y1K7Eo/?spm_id_from=333.337.search-card.all.click&amp;vd_source=5e9891722f2b62adca440a5e92121b5b</a></p>
</blockquote>
<ul>
<li><input disabled type="checkbox"> subprocess</li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>api_main.cc</title>
    <url>/2023/03/03/wenetruntime/api_main.cc/</url>
    <content><![CDATA[<h1 id="api-main-cc"><a href="#api-main-cc" class="headerlink" title="api_main.cc"></a>api_main.cc</h1><p>可执行文件路径在：<code>wenet/runtime/libtorch/build/bin</code></p>
<p>想编译出这个可执行文件，需要在 <code>runtime/core/bin/CMakeLists.txt</code> 里添加：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">add_executable</span>(api_main api_main.cc)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(api_main PUBLIC wenet_api)</span><br><span class="line"></span><br><span class="line"><span class="comment">#或者把官方注释打开</span></span><br><span class="line"><span class="keyword">if</span>(TORCH)</span><br><span class="line">  <span class="keyword">add_executable</span>(api_main api_main.cc)</span><br><span class="line">  <span class="keyword">target_link_libraries</span>(api_main PUBLIC wenet_api)</span><br><span class="line"><span class="keyword">endif</span>()</span><br></pre></td></tr></table></figure>

<p>然后在命令行窗口执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">cmake --build .</span><br></pre></td></tr></table></figure>



<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd wenet/runtime/libtorch</span></span><br><span class="line">./build/bin/api_main --model_dir /mnt/k/wenet/model/20220506_u2pp_conformer_libtorch/ --wav_path test.wav</span><br></pre></td></tr></table></figure>



<h3 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd libtorch</span></span><br><span class="line">cgdb ./build/bin/api_main</span><br><span class="line"><span class="comment"># 打断点</span></span><br><span class="line">run --model_dir /mnt/k/wenet/model/20220506_u2pp_conformer_libtorch/ --wav_path test.wav</span><br><span class="line">run --model_dir /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/ --wav_path test.wav</span><br></pre></td></tr></table></figure>

<p>这里 <code>chunk_size</code> 用的默认值（16）（<code>core/decoder/asr_decoder.h</code>）</p>
<h3 id="代码解释"><a href="#代码解释" class="headerlink" title="代码解释"></a>代码解释</h3><p>另一个版本的可执行文件 <code>decoder_main</code> 里，用的是<code>AsrDecoder</code>基类，<code>wenet::AsrDecoder decoder(feature_pipeline, g_decode_resource, *g_decode_config);</code></p>
<p>这里 <code>api_main</code> 用的是 <code>core/api/wenet_api.cc </code>里的 <code>Recognizer</code> 类，里面也是有<code>feature_pipeline</code>_、<code>resource_</code>、<code>model</code>等成员。</p>
<p>这里直接把 model 固定为<code>TorchAsrModel</code>类型，只是可以选用libtorch的gpu运行还是cpu运行模型：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// core/api/wenet_api.cc</span></span><br><span class="line"><span class="keyword">auto</span> model = <span class="built_in">std</span>::make_shared&lt;wenet::TorchAsrModel&gt;();</span><br><span class="line">model-&gt;Read(model_path);</span><br></pre></td></tr></table></figure>





<p><code>core/api/wenet_api.cc</code> 一些函数过程和 <code>core/decoder/params.h</code> 很像。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">`wenet::TorchAsrModel::InitEngineThreads();`</span><br></pre></td></tr></table></figure>

<p>没有像<code>core/bin/decoder_main.cc</code>用线程池解码。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>可执行文件<code>api_main</code> ，可以看作是走libtorch模型的语音识别命令。代码相比decoder_main简化了，删去一些判断，用新的类（Recognizer）有做封装。</p>
]]></content>
      <categories>
        <category>wenetruntime</category>
      </categories>
      <tags>
        <tag>wenetruntime</tag>
      </tags>
  </entry>
  <entry>
    <title>libtorch下的main脚本 decoder_main</title>
    <url>/2023/03/03/wenetruntime/libtorch%E4%B8%8B%E7%9A%84decoder_main.cc/</url>
    <content><![CDATA[<h1 id="libtorch下的main脚本-decoder-main"><a href="#libtorch下的main脚本-decoder-main" class="headerlink" title="libtorch下的main脚本 decoder_main"></a>libtorch下的main脚本 decoder_main</h1><p>路径：<code>wenet/runtime/libtorch/core/bin/decoder_main.cc</code></p>
<h3 id="编译："><a href="#编译：" class="headerlink" title="编译："></a>编译：</h3><p>首先之前编译cmake时，没有加可选debug的选项，因此不可调试，在<strong>CMakeLists.txt</strong>加入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cd</span> wenet/runtime/libtorch</span></span><br><span class="line"></span><br><span class="line">SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) </span><br><span class="line"></span><br><span class="line">SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;)</span><br><span class="line">SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</span><br></pre></td></tr></table></figure>

<p>重新编译：在build里：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cd</span> wenet/runtime/libtorch/build</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cmake clean ..</span></span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug ..</span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug --build .</span><br><span class="line">make</span><br></pre></td></tr></table></figure>



<p>编译出的可执行文件叫 <code>decoder_main</code>，路径在<code>build/bin/decoder_main</code>，是通过cmake编译整个工程得到的，运行于<code>x86</code>平台。</p>
<h4 id="不可调试版本的编译"><a href="#不可调试版本的编译" class="headerlink" title="不可调试版本的编译"></a>不可调试版本的编译</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build &amp;&amp; cmake .. &amp;&amp; cmake --build .</span><br></pre></td></tr></table></figure>



<h3 id="调试："><a href="#调试：" class="headerlink" title="调试："></a>调试：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd  wenet/runtime/libtorch</span></span><br><span class="line"></span><br><span class="line">cgdb ./build/bin/decoder_main </span><br><span class="line"></span><br><span class="line"><span class="comment"># 打断点</span></span><br><span class="line"></span><br><span class="line">run --chunk_size -1 --wav_path test.wav --model_path /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/final.zip --unit_path /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/units.txt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">run --chunk_size -1 --wav_path test.wav --model_path /mnt/k/wenet/model/20220506_u2pp_conformer_libtorch/final.zip --unit_path /mnt/k/wenet/model/20220506_u2pp_conformer_libtorch/units.txt --output_nbest <span class="literal">true</span></span><br></pre></td></tr></table></figure>



<h3 id="非调试"><a href="#非调试" class="headerlink" title="非调试"></a>非调试</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> GLOG_logtostderr=1</span><br><span class="line"><span class="built_in">export</span> GLOG_v=2</span><br><span class="line"></span><br><span class="line">./build/bin/decoder_main --chunk_size -1 --wav_path test.wav --model_path /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/final.zip --unit_path /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/units.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure>






<h3 id="代码解释："><a href="#代码解释：" class="headerlink" title="代码解释："></a>代码解释：</h3><p>这里的代码可能有借鉴了：<a href="https://github.com/opencv/opencv/blob/4.x/modules/dnn/src/model.cpp">https://github.com/opencv/opencv/blob/4.x/modules/dnn/src/model.cpp</a></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// wenet/runtime/core/decoder/params.h ：</span></span><br><span class="line"> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;DecodeResource&gt; <span class="title function_">InitDecodeResourceFromFlags</span><span class="params">()</span> &#123;&#125; </span><br><span class="line"><span class="comment">// 该函数是初始化解码需要的资源，新建一个放资源的对象resource（函数return的对象），要存放的资源分别是：</span></span><br><span class="line"><span class="comment">// 分别是新建一个模型对象（指针），把某路径的模型文件加载进来，模型是用来语音识别的声学模型，模型类型不同（在cmakelists里确定是哪种模型（可选libtorch、onnx、xpu、bpu））不同模型类型是派生类，都继承自 AsrModel，这里新建的对象是基类，基类都加了virtual，就可以用派生类成员函数（派生类不用加virtual，只基类加就行）。</span></span><br><span class="line"><span class="comment">// 我这里用的模型类型是 TorchAsrModel 继承自 AsrModel</span></span><br><span class="line"><span class="comment">// 新建一个字表unit_table对象（指针），把某路径的字表文件加载进来，字表是将声学模型输出类别映射到字</span></span><br><span class="line"><span class="comment">// 如果有传入语言模型fst文件，则新建一个fst，把某路径的lm fst加载进来，用来ctc出来beam search过程加入语言模型分数？，传入fst还要传入dict表，是词表，放在symbol_table里</span></span><br><span class="line"><span class="comment">// 如果有传入上下文表context，则把某路径的上下文词表文件加载进来，用来增加某些词的权重，上下文词要构建成上下文词图，</span></span><br><span class="line"><span class="comment">// 新建后处理模块</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// wenet/runtime/core/bin/decoder_main.cc</span></span><br><span class="line"><span class="comment">// 用线程池  // pool.enqueue(decode, wav, false); 第一个参数是一个函数，第二个参数是某一条音频（音频名 音频路径 的pair），不断入队列</span></span><br><span class="line"><span class="comment">// 每个线程一个锁</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 跳入decode()函数</span></span><br><span class="line">feature_pipeline-&gt;AcceptWaveform(wav_reader.data(), num_samples);计算特征</span><br><span class="line">feature_pipeline-&gt;set_input_finished(); <span class="comment">// feature_pipeline里有一个成员mutex， 用的阻塞队列feature_queue_，这个队列里没有特征 或 输入没全给完时，就不再进行read操作了（read也就是从队列里拿数据去给声学模型识别解码）</span></span><br><span class="line"><span class="comment">// feature_queue_ 的容量是这条音频的长度？？</span></span><br><span class="line"></span><br><span class="line">wenet::AsrDecoder <span class="title function_">decoder</span><span class="params">(feature_pipeline, g_decode_resource, *g_decode_config)</span>; </span><br><span class="line"><span class="comment">// 新建一个 AsrDecoder对象，里面的参数有特征管道，声学模型资源，解码参数配置</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// wenet/runtime/core/decoder/asr_decoder.cc</span></span><br><span class="line">DecodeState <span class="title function_">AsrDecoder::AdvanceDecoding</span><span class="params">(<span class="type">bool</span> block)</span>&#123;&#125; <span class="comment">//在这里函数中进行识别解码</span></span><br><span class="line"><span class="keyword">if</span> (!feature_pipeline_-&gt;Read(num_required_frames, &amp;chunk_feats)) &#123;&#125; <span class="comment">// read进特征，把刚才计算得到的fbank特征都进来，read的时候也上锁</span></span><br><span class="line"></span><br><span class="line">model_-&gt;ForwardEncoder(chunk_feats, &amp;ctc_log_probs); <span class="comment">// 跳入coredecoder/asr_model.cc</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// core/decoder/asr_model.cc</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">AsrModel::ForwardEncoder</span><span class="params">()</span> <span class="comment">// 跳入函数，计算经过模型的输出，这里用的基类，函数内部会跳入不同的派生类</span></span><br><span class="line">this-&gt;<span class="title function_">ForwardEncoderFunc</span><span class="params">(chunk_feats, ctc_prob)</span>; <span class="comment">//这里类型是基类AsrModel，但是指向的是派生类，我这里的派生类是TorchAsrModel类，因此跳进的是派生类的ForwardEncoderFunc和CacheFeature函数</span></span><br><span class="line">this-&gt;CacheFeature(chunk_feats);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// core/decoder/torch_asr_model.cc</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">TorchAsrModel::ForwardEncoderFunc</span><span class="params">()</span> <span class="comment">// 函数，计算经过识别模型的输出概率 前向计算</span></span><br><span class="line">torch::Tensor feats = torch::zeros(&#123;<span class="number">1</span>, num_frames, feature_dim&#125;, torch::kFloat); <span class="comment">//新建tensor类型对象</span></span><br><span class="line">torch::from_blob(const_cast&lt;<span class="type">float</span>*&gt;(chunk_feats[i].data()), &#123;feature_dim&#125;, torch::kFloat).clone(); </span><br><span class="line"><span class="comment">// 把vector&lt;vector&lt;float&gt;&gt;类型特征转成tensor，每次读入一帧</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">auto</span> outputs = model_-&gt;get_method(<span class="string">&quot;forward_encoder_chunk&quot;</span>)(inputs).toTuple()-&gt;elements(); <span class="comment">// 经过模型的输出，三维</span></span><br><span class="line">torch::Tensor chunk_out = outputs[<span class="number">0</span>].toTensor(); <span class="comment">// 就是conformer编码器的输出？？</span></span><br><span class="line">att_cache_ = outputs[<span class="number">1</span>].toTensor();	<span class="comment">// transformer/conformer attention cache，就是attention解码器的输出</span></span><br><span class="line">cnn_cache_ = outputs[<span class="number">2</span>].toTensor();	<span class="comment">// conformer-only conv_module cache，编码器后接简单解码器的输出概率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 跳回  core/decoder/asr_model.cc</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">AsrModel::CacheFeature</span><span class="params">()</span> <span class="comment">//函数，Cache feature for next chunk   。。。[todo]</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment">// 跳回 core/decoder/asr_decoder.cc</span></span><br><span class="line">searcher_-&gt;<span class="title function_">Search</span><span class="params">(ctc_log_probs)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里又用了基类和派生类，searcher_是SearchInterface基类的智能指针，派生类是CtcPrefixBeamSearch和CtcWfstBeamSearch两种类型，</span></span><br><span class="line"><span class="comment">// 这里用哪一种派生类是在初始化AsrDecoder对象时 确定的（decoder_main.cc里的`AsrDecoder decoder`代码）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 跳入 core/decoder/ctc_prefix_beam_search.cc</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">CtcPrefixBeamSearch::Search</span><span class="params">(<span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">float</span>&gt;&gt;&amp; logp)</span> &#123;&#125; <span class="comment">//函数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h4 id="ctc-prefix-beam-search-解码过程："><a href="#ctc-prefix-beam-search-解码过程：" class="headerlink" title="ctc_prefix_beam_search 解码过程："></a>ctc_prefix_beam_search 解码过程：</h4><p><code> core/decoder/ctc_prefix_beam_search.cc </code></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Please refer https://robin1001.github.io/2020/12/11/ctc-search</span></span><br><span class="line"><span class="comment">// for how CTC prefix beam search works, and there is a simple graph demo in</span></span><br><span class="line"><span class="comment">// it.</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">CtcPrefixBeamSearch::Search</span><span class="params">(<span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">float</span>&gt;&gt;&amp; logp)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (logp.size() == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line">  <span class="type">int</span> first_beam_size =</span><br><span class="line">      <span class="built_in">std</span>::min(static_cast&lt;<span class="type">int</span>&gt;(logp[<span class="number">0</span>].size()), opts_.first_beam_size); <span class="comment">// 万一输出类别没有beam多</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> t = <span class="number">0</span>; t &lt; logp.size(); ++t, ++abs_time_step_) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">float</span>&gt;&amp; <span class="type">logp_t</span> = logp[t];</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;, PrefixScore, PrefixHash&gt; next_hyps; <span class="comment">//key 是路径id序列，规整字符串，保存的规整字符串的集合</span></span><br><span class="line">    <span class="comment">// 1. First beam prune, only select topk candidates</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">float</span>&gt; topk_score;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int32_t</span>&gt; topk_index;</span><br><span class="line">    TopK(<span class="type">logp_t</span>, first_beam_size, &amp;topk_score, &amp;topk_index); </span><br><span class="line">    <span class="comment">//选topk的，堆排序，优先级队列，小根堆，概率大的前beam个，其中概率小的在堆顶</span></span><br><span class="line">    <span class="comment">// topk_score：beam个，概率大的在前；</span></span><br><span class="line">    <span class="comment">// 2. Token passing</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; topk_index.size(); ++i) &#123;</span><br><span class="line">      <span class="type">int</span> id = topk_index[i];</span><br><span class="line">      <span class="keyword">auto</span> prob = topk_score[i];</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; it : cur_hyps_) &#123; <span class="comment">//cur_hyps_初始化在 void CtcPrefixBeamSearch::Reset() &#123;&#125;函数里，有一个cur_hyps_[empty] = prefix_score;</span></span><br><span class="line">        <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&amp; prefix = it.first;   <span class="comment">// 引用 这里就是规整后的路径（id序列，id也就是输出字符，路径也就是字符串）</span></span><br><span class="line">        <span class="type">const</span> PrefixScore&amp; prefix_score = it.second; <span class="comment">// 引用</span></span><br><span class="line">        <span class="comment">// If prefix doesn&#x27;t exist in next_hyps, next_hyps[prefix] will insert</span></span><br><span class="line">        <span class="comment">// PrefixScore(-inf, -inf) by default, since the default constructor</span></span><br><span class="line">        <span class="comment">// of PrefixScore will set fields s(blank ending score) and</span></span><br><span class="line">        <span class="comment">// ns(none blank ending score) to -inf, respectively.</span></span><br><span class="line">        <span class="keyword">if</span> (id == opts_.blank) &#123;</span><br><span class="line">          <span class="comment">// Case 0: *a + ε =&gt; *a</span></span><br><span class="line">          PrefixScore&amp; next_score = next_hyps[prefix]; <span class="comment">//对map类型的next_hyps添加元素prefix（作为key），如果不存在就是添加，如果存在就读？</span></span><br><span class="line">          next_score.s = LogAdd(next_score.s, prefix_score.score() + prob); <span class="comment">// 更新next_score.s，这里要加原本的next_score.s，以blank结尾的，前缀无论以blank还是非blank结尾的分数（prefix_score.score()），加上声学模型输出后验概率prob</span></span><br><span class="line">          next_score.v_s = prefix_score.viterbi_score() + prob;</span><br><span class="line">          next_score.times_s = prefix_score.times();</span><br><span class="line">          <span class="comment">// Prefix not changed, copy the context from prefix.</span></span><br><span class="line">          <span class="keyword">if</span> (context_graph_ &amp;&amp; !next_score.has_context) &#123;</span><br><span class="line">            next_score.CopyContext(prefix_score);</span><br><span class="line">            next_score.has_context = <span class="literal">true</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!prefix.empty() &amp;&amp; id == prefix.back()) &#123;</span><br><span class="line">          <span class="comment">// Case 1: *a + a =&gt; *a</span></span><br><span class="line">          PrefixScore&amp; next_score1 = next_hyps[prefix]; <span class="comment">// 规整字符串不变，还是这个prefix</span></span><br><span class="line">          next_score1.ns = LogAdd(next_score1.ns, prefix_score.ns + prob);</span><br><span class="line">          <span class="keyword">if</span> (next_score1.v_ns &lt; prefix_score.v_ns + prob) &#123;</span><br><span class="line">            next_score1.v_ns = prefix_score.v_ns + prob;</span><br><span class="line">            <span class="keyword">if</span> (next_score1.cur_token_prob &lt; prob) &#123;</span><br><span class="line">              next_score1.cur_token_prob = prob;</span><br><span class="line">              next_score1.times_ns = prefix_score.times_ns;</span><br><span class="line">              CHECK_GT(next_score1.times_ns.size(), <span class="number">0</span>);</span><br><span class="line">              next_score1.times_ns.back() = abs_time_step_;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (context_graph_ &amp;&amp; !next_score1.has_context) &#123;</span><br><span class="line">            next_score1.CopyContext(prefix_score);</span><br><span class="line">            next_score1.has_context = <span class="literal">true</span>;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Case 2: *aε + a =&gt; *aa</span></span><br><span class="line">          <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; <span class="title function_">new_prefix</span><span class="params">(prefix)</span>;</span><br><span class="line">          new_prefix.emplace_back(id);</span><br><span class="line">          PrefixScore&amp; next_score2 = next_hyps[new_prefix]; <span class="comment">// 规整字符串变了，也就是原规整字符串后接一个相同字符</span></span><br><span class="line">          next_score2.ns = LogAdd(next_score2.ns, prefix_score.s + prob);</span><br><span class="line">          <span class="keyword">if</span> (next_score2.v_ns &lt; prefix_score.v_s + prob) &#123;</span><br><span class="line">            next_score2.v_ns = prefix_score.v_s + prob;</span><br><span class="line">            next_score2.cur_token_prob = prob;</span><br><span class="line">            next_score2.times_ns = prefix_score.times_s;</span><br><span class="line">            next_score2.times_ns.emplace_back(abs_time_step_);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (context_graph_ &amp;&amp; !next_score2.has_context) &#123;</span><br><span class="line">            <span class="comment">// Prefix changed, calculate the context score.</span></span><br><span class="line">            next_score2.UpdateContext(context_graph_, prefix_score, id,</span><br><span class="line">                                      prefix.size());</span><br><span class="line">            next_score2.has_context = <span class="literal">true</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// Case 3: *a + b =&gt; *ab, *aε + b =&gt; *ab</span></span><br><span class="line">          <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; new_prefix(prefix);</span><br><span class="line">          new_prefix.emplace_back(id);    <span class="comment">//规整字符串要变了，变成后接新字符的新规整字符串</span></span><br><span class="line">          PrefixScore&amp; next_score = next_hyps[new_prefix]; <span class="comment">//引用，之后next_score更新了，这里next_hyps里面的值也会更新 这个代码是对map类型的next_hyps做了一个插入 添加元素操作，添加一个元素，元素key是new_prefix</span></span><br><span class="line">          next_score.ns = LogAdd(next_score.ns, prefix_score.score() + prob);</span><br><span class="line">          <span class="keyword">if</span> (next_score.v_ns &lt; prefix_score.viterbi_score() + prob) &#123;</span><br><span class="line">            next_score.v_ns = prefix_score.viterbi_score() + prob;</span><br><span class="line">            next_score.cur_token_prob = prob;</span><br><span class="line">            next_score.times_ns = prefix_score.times();</span><br><span class="line">            next_score.times_ns.emplace_back(abs_time_step_);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (context_graph_ &amp;&amp; !next_score.has_context) &#123;</span><br><span class="line">            <span class="comment">// Calculate the context score.</span></span><br><span class="line">            next_score.UpdateContext(context_graph_, prefix_score, id,</span><br><span class="line">                                     prefix.size());</span><br><span class="line">            next_score.has_context = <span class="literal">true</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 二次剪枝，只保留second_beam_size条路径</span></span><br><span class="line">    <span class="comment">// 3. Second beam prune, only keep top n best paths</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">pair</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;, PrefixScore&gt;&gt; arr(next_hyps.begin(),</span><br><span class="line">                                                              next_hyps.end());</span><br><span class="line">    <span class="type">int</span> second_beam_size =</span><br><span class="line">        <span class="built_in">std</span>::min(static_cast&lt;<span class="type">int</span>&gt;(arr.size()), opts_.second_beam_size);</span><br><span class="line">    <span class="built_in">std</span>::nth_element(arr.begin(), arr.begin() + second_beam_size, arr.end(),</span><br><span class="line">                     PrefixScoreCompare);</span><br><span class="line">    arr.resize(second_beam_size);</span><br><span class="line">    <span class="built_in">std</span>::sort(arr.begin(), arr.end(), PrefixScoreCompare);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. Update cur_hyps_ and get new result</span></span><br><span class="line">    UpdateHypotheses(arr);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p><code>core/utils/utils.cc</code> ：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">template &lt;typename T&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ValueComp</span> &#123;</span></span><br><span class="line">  <span class="type">bool</span> <span class="title function_">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T, <span class="type">int32_t</span>&gt;&amp; lhs,</span></span><br><span class="line"><span class="params">                  <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T, <span class="type">int32_t</span>&gt;&amp; rhs)</span> <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> lhs.first &gt; rhs.first ||</span><br><span class="line">           (lhs.first == rhs.first &amp;&amp; lhs.second &lt; rhs.second);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// We refer the pytorch topk implementation</span></span><br><span class="line"><span class="comment">// https://github.com/pytorch/pytorch/blob/master/caffe2/operators/top_k.cc</span></span><br><span class="line">template &lt;typename T&gt;</span><br><span class="line"><span class="type">void</span> <span class="title function_">TopK</span><span class="params">(<span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;T&gt;&amp; data, <span class="type">int32_t</span> k, <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;T&gt;* values,</span></span><br><span class="line"><span class="params">          <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;* indices)</span> &#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T, <span class="type">int32_t</span>&gt;&gt; heap_data;</span><br><span class="line">  <span class="type">int</span> n = data.size();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; k &amp;&amp; i &lt; n; ++i) &#123;</span><br><span class="line">    heap_data.emplace_back(data[i], i); <span class="comment">// 类别概率 和 所在第几个类 先存前beam个</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">priority_queue</span>&lt;<span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T, <span class="type">int32_t</span>&gt;, <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">pair</span>&lt;T, <span class="type">int32_t</span>&gt;&gt;,</span><br><span class="line">                      ValueComp&lt;T&gt;&gt;</span><br><span class="line">      pq(ValueComp&lt;T&gt;(), <span class="built_in">std</span>::move(heap_data)); <span class="comment">// 重建堆，，把概率最小的往上挪，堆顶的概率最小，小根堆</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int32_t</span> i = k; i &lt; n; ++i) &#123; <span class="comment">// 每次和其它剩余类的概率比较，和堆顶比较，比堆顶概率大，就替换</span></span><br><span class="line">    <span class="keyword">if</span> (pq.top().first &lt; data[i]) &#123;</span><br><span class="line">      pq.pop();</span><br><span class="line">      pq.emplace(data[i], i); <span class="comment">// 插入的过程会重建堆</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  values-&gt;resize(<span class="built_in">std</span>::min(k, n));</span><br><span class="line">  indices-&gt;resize(<span class="built_in">std</span>::min(k, n));</span><br><span class="line">  <span class="type">int32_t</span> cur = values-&gt;size() - <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (!pq.empty()) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; item = pq.top();</span><br><span class="line">    (*values)[cur] = item.first;</span><br><span class="line">    (*indices)[cur] = item.second;</span><br><span class="line">    pq.pop();</span><br><span class="line">    cur -= <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">next_hyps:<span class="built_in">map</span>类型  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; PrefixScore</span><br><span class="line">prefix：<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;</span><br><span class="line">next_hyps[prefix] <span class="comment">//就是查找 prefixscore，这个是一个结构体，它内部成员（分数）初始化的时候都是负无穷大</span></span><br><span class="line"></span><br><span class="line">next_hyps：</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">unordered_map</span> with <span class="number">1</span> element = &#123;[<span class="built_in">std</span>::<span class="built_in">vector</span> of length <span class="number">0</span>, capacity <span class="number">0</span>] = &#123;s = <span class="number">-3.40282347e+38</span>, ns = <span class="number">-3.40282347e+38</span>, v_s = <span class="number">-3.40282347e+38</span>, v_ns = <span class="number">-3.40282347e+38</span>,</span><br><span class="line">    cur_token_prob = <span class="number">-3.40282347e+38</span>, times_s = <span class="built_in">std</span>::<span class="built_in">vector</span> of length <span class="number">0</span>, capacity <span class="number">0</span>, times_ns = <span class="built_in">std</span>::<span class="built_in">vector</span> of length <span class="number">0</span>, capacity <span class="number">0</span>, has_context = <span class="literal">false</span>, context_state = <span class="number">0</span>,</span><br><span class="line">   context_score = <span class="number">0</span>, start_boundaries = <span class="built_in">std</span>::<span class="built_in">vector</span> of length <span class="number">0</span>, capacity <span class="number">0</span>, end_boundaries = <span class="built_in">std</span>::<span class="built_in">vector</span> of length <span class="number">0</span>, capacity <span class="number">0</span>&#125;&#125;    </span><br></pre></td></tr></table></figure>







<p>继续主代码<code>decoder_main.cc</code></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 做attention rescore，就要过一遍 attention(transformer) decoder的模型，此时encoder的输出和nbest ctc output作为attention model的输入，因此要转成torch格式</span></span><br><span class="line">model_-&gt;AttentionRescoring(hypotheses, opts_.reverse_weight, &amp;rescoring_score);</span><br><span class="line"><span class="comment">//跳入 core/decoder/torch_asr_model.cc //这里用的是libtorch派生类</span></span><br><span class="line"></span><br><span class="line">searcher_-&gt;FinalizeSearch();	</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> outputs = model_-&gt;run_method(<span class="string">&quot;forward_attention_decoder&quot;</span>, hyps_tensor,hyps_length, encoder_out, reverse_weight).toTuple()-&gt;elements();<span class="comment">//这里是在模型的python文件中（wenet/transformer/asr_model.py），有这样写这个函数，然后把模型导出torch.jlt.export，就能通过run_method找到这个函数</span></span><br><span class="line"><span class="comment">// 参考的https://discuss.pytorch.org/t/how-to-get-model-attribute-using-c-api/41486/3</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>多线程解码，在线程池里，默认都做了rescoring。</p>
]]></content>
      <categories>
        <category>wenetruntime</category>
      </categories>
      <tags>
        <tag>wenetruntime</tag>
      </tags>
  </entry>
  <entry>
    <title>websocket_client_main.cc</title>
    <url>/2023/03/09/wenetruntime/websocket_client_main.cc/</url>
    <content><![CDATA[<h1 id="websocket-client-main-cc"><a href="#websocket-client-main-cc" class="headerlink" title="websocket_client_main.cc"></a>websocket_client_main.cc</h1><p>可执行文件路径：wenet&#x2F;runtime&#x2F;libtorch&#x2F;build&#x2F;bin&#x2F;websocket_client_main</p>
<h3 id="直接执行"><a href="#直接执行" class="headerlink" title="直接执行"></a>直接执行</h3><p>与前一篇《websocket_server_main.cc》相同。</p>
<h3 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd runtime/libtorch</span></span><br><span class="line"><span class="built_in">export</span> GLOG_logtostderr=1</span><br><span class="line"><span class="built_in">export</span> GLOG_v=2</span><br><span class="line"><span class="comment"># 在一个命令行窗口，执行</span></span><br><span class="line">bash websocket_server.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在另一个命令行窗口，执行</span></span><br><span class="line">cgdb ./build/bin/websocket_client_main </span><br><span class="line"><span class="comment"># 打断点  比如 b core/websocket/websocket_client.cc:55</span></span><br><span class="line">run --hostname 127.0.0.1 --port 10086 --wav_path test.wav</span><br></pre></td></tr></table></figure>



<h3 id="过程解释"><a href="#过程解释" class="headerlink" title="过程解释"></a>过程解释</h3><p>client建立与server的连接（发起请求）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// core/websocket/websocket_client.cc:</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">WebSocketClient::Connect</span><span class="params">()</span> &#123;</span><br><span class="line">  tcp::resolver resolver&#123;ioc_&#125;;</span><br><span class="line">  <span class="comment">// Look up the domain name</span></span><br><span class="line">  <span class="keyword">auto</span> <span class="type">const</span> results = resolver.resolve(hostname_, <span class="built_in">std</span>::to_string(port_));</span><br><span class="line">  <span class="comment">// Make the connection on the IP address we get from a lookup</span></span><br><span class="line">  <span class="keyword">auto</span> ep = asio::connect(ws_.next_layer(), results);</span><br><span class="line">  <span class="comment">// Provide the value of the Host HTTP header during the WebSocket handshake.</span></span><br><span class="line">  <span class="comment">// See https://tools.ietf.org/html/rfc7230#section-5.4</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> host = hostname_ + <span class="string">&quot;:&quot;</span> + <span class="built_in">std</span>::to_string(ep.port());	<span class="comment">// 比如 127.0.0.1:10086</span></span><br><span class="line">  <span class="comment">// Perform the websocket handshake</span></span><br><span class="line">  ws_.handshake(host, <span class="string">&quot;/&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后新建子线程，子线程里执行 <code>ReadLoopFunc()</code> 函数，主线程发送开始符给server，是一个text格式的字符串，write写进ws_里，也就是和server发消息（发开始符）（对应函数为 <code>SendTextData(const std::string&amp; data)</code> ， data内容是<code>&#123;\&quot;signal\&quot;:\&quot;start\&quot;,\&quot;nbest\&quot;:1,\&quot;continuous_decoding\&quot;:false&#125;</code>）。主线程接着往下走，读取要识别的音频，然后每隔0.5s发送0.5s的音频数据给server，发送给server了就休息一下，sleep 0.5s，直到把音频数据全发送完，再发送结束符。然后等待子线程里 <code>ReadLoopFunc()</code>函数执行完，主线程也结束。</p>
<p><code>ReadLoopFunc()</code> 函数作用：这个函数作用是验证server返回的消息是不是正常的。</p>
<p><code>ReadLoopFunc()</code>函数流程：（主线程client已经给server发送开始请求了），用 <code>while(true)</code>循环一直在read读取 server返回的消息，确认client接收到消息的status一直是ok的，如果不ok，就会break退出循环。而server端发送不ok的情况就是进入<code>OnError()</code>函数，里面的status会是<code>failed</code>，会发给client非ok的状态，而此时server的代码会执行<code>ws_.close()</code>，也就是断开和client的连接，因此起到验证server返回的消息是否正常的功能。</p>
<p>然后一直到client接收到消息的type是speech_end字符串，也会break退出循环，结束子线程。</p>
]]></content>
      <categories>
        <category>wenetruntime</category>
      </categories>
      <tags>
        <tag>wenetruntime</tag>
      </tags>
  </entry>
  <entry>
    <title>main脚本对比</title>
    <url>/2023/03/01/wenetruntime/main%E8%84%9A%E6%9C%AC%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<h1 id="1-libtorch下的main脚本"><a href="#1-libtorch下的main脚本" class="headerlink" title="1. libtorch下的main脚本"></a>1. libtorch下的main脚本</h1><p>提供了一种调用libtorch模型的识别过程脚本。</p>
<p>路径：<code>wenet/runtime/libtorch/core/bin/decoder_main.cc</code></p>
<h3 id="编译："><a href="#编译：" class="headerlink" title="编译："></a>编译：</h3><p>首先之前编译cmake时，没有加可选debug的选项，因此不可调试，在<strong>CMakeLists.txt</strong>加入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cd</span> wenet/runtime/libtorch</span></span><br><span class="line"></span><br><span class="line">SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) </span><br><span class="line"></span><br><span class="line">SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;)</span><br><span class="line">SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</span><br></pre></td></tr></table></figure>

<p>重新编译：在build里：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cd</span> wenet/runtime/libtorch/build</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cmake clean ..</span></span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug ..</span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug --build .</span><br><span class="line">make</span><br></pre></td></tr></table></figure>



<p>编译出的可执行文件叫 <code>decoder_main</code>，路径在<code>build/bin/decoder_main</code>，是通过cmake编译整个工程得到的，运行于<code>x86</code>平台。</p>
<h3 id="调试："><a href="#调试：" class="headerlink" title="调试："></a>调试：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd  wenet/runtime/libtorch</span></span><br><span class="line"></span><br><span class="line">cgdb ./build/bin/decoder_main </span><br><span class="line"></span><br><span class="line"><span class="comment"># 打断点</span></span><br><span class="line"></span><br><span class="line">run --chunk_size -1 --wav_path test.wav --model_path /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/final.zip --unit_path /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/units.txt</span><br></pre></td></tr></table></figure>



<h1 id="2-WebSocket、gRPC、http、docker进行识别"><a href="#2-WebSocket、gRPC、http、docker进行识别" class="headerlink" title="2. WebSocket、gRPC、http、docker进行识别"></a>2. WebSocket、gRPC、http、docker进行识别</h1><blockquote>
<p><a href="https://github.com/wenet-e2e/wenet/blob/main/runtime/libtorch/README.md">https://github.com/wenet-e2e/wenet/blob/main/runtime/libtorch/README.md</a></p>
</blockquote>
<p>就是在<code>CmakeLists.txt</code> 里打开一些参数，除了这些客户端服务端，还支持不同模型，也是打开<code>CmakeLists.txt</code> 参数。</p>
<p>具体的参考libtorch下的readme。</p>
<p>然后main函数在core&#x2F;bin下不同文件。</p>
<p>[TODO]</p>
<h1 id="3-binding-x2F-python下的main脚本"><a href="#3-binding-x2F-python下的main脚本" class="headerlink" title="3. binding&#x2F;python下的main脚本"></a>3. binding&#x2F;python下的main脚本</h1><p>提供了一种python绑定C++的方法。</p>
<p>main路径在：core&#x2F;api&#x2F;wenet_api.cc</p>
<p>编译的路径在：wenet&#x2F;runtime&#x2F;binding&#x2F;python</p>
<p>也能调试C++，因此修改CMakeLists.txt和setup.py</p>
<p>在CMakeLists.txt里添加：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) </span><br><span class="line"></span><br><span class="line">SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;)</span><br><span class="line">SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</span><br></pre></td></tr></table></figure>

<p>在setup.py里修改<code>-DCMAKE_BUILD_TYPE=Release</code> 为 <code>-DCMAKE_BUILD_TYPE=Debug</code></p>
<p>然后在命令行里敲 <code>python3 setup.py build_ext --debug install</code> 进行编译。</p>
<p>每次修改一点代码，要重新python setup ，这个过程非常久。不是增量编译？建议直接用cmake的方法（比如第一种），会更快速，代码都没问题了，如果目标是用python调用C++，那么这会儿再尝试python掉C++的方法也来得及。</p>
]]></content>
      <categories>
        <category>wenetruntime</category>
      </categories>
      <tags>
        <tag>wenetruntime</tag>
      </tags>
  </entry>
  <entry>
    <title>websocket_server_main.cc</title>
    <url>/2023/03/08/wenetruntime/websocket_server_main.cc/</url>
    <content><![CDATA[<h1 id="websocket-server-main-cc"><a href="#websocket-server-main-cc" class="headerlink" title="websocket_server_main.cc"></a>websocket_server_main.cc</h1><p>可执行文件路径：wenet&#x2F;runtime&#x2F;libtorch&#x2F;build&#x2F;bin&#x2F;websocket_server_main</p>
<h3 id="直接执行"><a href="#直接执行" class="headerlink" title="直接执行"></a>直接执行</h3><p>在命令行窗口执行： <code>bash websocket_server.sh</code>：</p>
<p>websocket_server.sh：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> GLOG_logtostderr=1</span><br><span class="line"><span class="built_in">export</span> GLOG_v=2</span><br><span class="line">model_dir=/mnt/k/wenet/model/20210601_u2++_conformer_libtorch</span><br><span class="line"><span class="comment">#model_dir=/mnt/k/wenet/model/20220506_u2pp_conformer_libtorch</span></span><br><span class="line"></span><br><span class="line">./build/bin/websocket_server_main \</span><br><span class="line">    --port 10086 \</span><br><span class="line">    --chunk_size 16 \</span><br><span class="line">    --model_path <span class="variable">$model_dir</span>/final.zip \</span><br><span class="line">    --unit_path <span class="variable">$model_dir</span>/units.txt 2&gt;&amp;1 | <span class="built_in">tee</span> server.log</span><br></pre></td></tr></table></figure>



<p>在另一个命令行窗口执行：<code>bash websocket_client.sh</code></p>
<p>websocket_client.sh：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> GLOG_logtostderr=1</span><br><span class="line"><span class="built_in">export</span> GLOG_v=2</span><br><span class="line">wav_path=test.wav</span><br><span class="line"></span><br><span class="line">./build/bin/websocket_client_main \</span><br><span class="line">    --hostname 127.0.0.1 --port 10086 \</span><br><span class="line">    --wav_path <span class="variable">$wav_path</span> 2&gt;&amp;1 | <span class="built_in">tee</span> client.log</span><br></pre></td></tr></table></figure>





<h3 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd runtime/libtorch</span></span><br><span class="line"><span class="built_in">export</span> GLOG_logtostderr=1</span><br><span class="line"><span class="built_in">export</span> GLOG_v=2</span><br><span class="line"></span><br><span class="line">cgdb ./build/bin/websocket_server_main </span><br><span class="line"><span class="comment"># 打断点  比如 b core/websocket/websocket_server.cc:125</span></span><br><span class="line">run --port 10086 --chunk_size 16 --model_path /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/final.zip --unit_path /mnt/k/wenet/model/20210601_u2++_conformer_libtorch/units.txt </span><br><span class="line"></span><br><span class="line"><span class="comment"># 在另一个命令行窗口，执行</span></span><br><span class="line">bash websocket_client.sh</span><br></pre></td></tr></table></figure>



<h3 id="过程解释"><a href="#过程解释" class="headerlink" title="过程解释"></a>过程解释</h3><p>server监听来自client的消息，接收到client消息就新开一个线程，在子线程里进行通信。通信的类叫<code>websocket::stream&lt;tcp::socket&gt;</code>，客户端写数据消息 write进这个类对象 <code>ws_</code>里，服务器端read消息。</p>
<p>子线程具体通信过程（下面把“当前这个子线程”叫“主线程”，因为这个子线程里面又会新开线程）：</p>
<p>client先发一个text作为开始通信的表示，server接收，server通过连续三个判断（接收的字符串里有三个字段，分别是<code>signal == &quot;start&quot;</code>、<code>obj.find(&quot;nbest&quot;) != obj.end()</code>、<code>obj.find(&quot;continuous_decoding&quot;) != obj.end()</code>）确认它是想开始通信。</p>
<p>然后进入<code>OnSpeechStart()</code>函数，server告诉client接收到了，发送给client（发送，也就是<code>ws.write</code>）ok的状态，server准备好了。</p>
<p>新建一个线程类型的共享指针，子线程内执行的函数是 <code>DecodeThreadFunc()</code>函数。于是子线程<code>decode_thread_</code>去执行 <code>DecodeThreadFunc()</code>函数，原来的线程继续执行，新一轮for循环会执行到 <code>OnSpeechData()</code> 函数，读入音频数据，<code>feature_pipeline_-&gt;AcceptWaveform(pcm_data, num_samples);</code>，计算成fbank特征，放进特征队列里，等待解码器的解码。音频数据全部读完后，break退出for循环，程序来到 <code>decode_thread_-&gt;join();</code>，主线程等待子线程 <code>decode_thread_</code> 程序执行完毕。</p>
<p><code>DecodeThreadFunc()</code>函数流程：用了<code>while(true)</code>循环，直到遇到end结束符就break，否则一直循环，执行<code>state = decoder_-&gt;Decode()</code>，<code>decoder_-&gt;Decode()</code> 具体操作是：从特征队列里读取read特征，存放在chunk_feat 里，送入模型 <code>model_-&gt;ForwardEncoder</code> 识别，再做CtcPrefixBeamSearch。</p>
<p>根据解码返回状态 state 决定接下去的步骤：</p>
<ul>
<li>状态为 “解码完所有音频特征 kEndFeats 时”，说明所有音频解码完了，进行rescore，结果保存在json中，写入ws_，也就是传结果这个消息给客户端，然后break出去；</li>
<li>状态为“检测到端点 kEndpoint 时”，说明遇到端点，进行rescore，结果保存在json中，写入ws_，也就是传结果这个消息给客户端，然后根据初始参数设置的是要连续解码还是非连续解码，进行不同的后续步骤。如果设定为要连续解码，则虽然遇到端点了，还是要接着下一轮循环继续解码，把decoder清空历史内存，reset各种状态，重新开始解码；如果设定为非连续解码，则遇到端点，视为结束，传结束符给client，break出去。</li>
<li>状态为“kEndBatch或kWaitFeats时”，输出部分结果，告诉client部分结果，接着下一轮循环。</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DecodeThreadFunc()：</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">      DecodeState state = decoder_-&gt;Decode();</span><br><span class="line">      <span class="keyword">if</span> (state == DecodeState::kEndFeats) &#123;</span><br><span class="line">        decoder_-&gt;Rescoring();</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">string</span> result = SerializeResult(<span class="literal">true</span>);</span><br><span class="line">        OnFinalResult(result);</span><br><span class="line">        OnFinish();</span><br><span class="line">        stop_recognition_ = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (state == DecodeState::kEndpoint) &#123;</span><br><span class="line">        decoder_-&gt;Rescoring();</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">string</span> result = SerializeResult(<span class="literal">true</span>);</span><br><span class="line">        OnFinalResult(result);</span><br><span class="line">        <span class="comment">// If it&#x27;s not continuous decoding, continue to do next recognition</span></span><br><span class="line">        <span class="comment">// otherwise stop the recognition</span></span><br><span class="line">        <span class="keyword">if</span> (continuous_decoding_) &#123;</span><br><span class="line">          decoder_-&gt;ResetContinuousDecoding();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          OnFinish();</span><br><span class="line">          stop_recognition_ = <span class="literal">true</span>;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (decoder_-&gt;DecodedSomething()) &#123;</span><br><span class="line">          <span class="built_in">std</span>::<span class="built_in">string</span> result = SerializeResult(<span class="literal">false</span>);</span><br><span class="line">          OnPartialResult(result);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>wenetruntime</category>
      </categories>
      <tags>
        <tag>wenetruntime</tag>
      </tags>
  </entry>
  <entry>
    <title>第一篇hexo博客</title>
    <url>/2022/11/03/%E5%85%B6%E4%BB%96/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p>今天学习用hexo建立自己的博客网站，在github服务器上发布。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>推荐语音识别入门书籍</title>
    <url>/2023/01/19/%E5%85%B6%E4%BB%96/%E6%8E%A8%E8%8D%90%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%85%A5%E9%97%A8%E4%B9%A6%E7%B1%8D/</url>
    <content><![CDATA[<p>图书馆借的书要到期了，花了一周回顾了一下语音识别基础原理知识，查缺补漏，看了洪青阳老师的《语音识别原理与应用》，写的清楚明了，系统全面，在博文视点网站 <a href="http://www.broadview.com.cn/book/6084">http://www.broadview.com.cn/book/6084</a> 里下载的PPT中，还有洪老师上课的录音，非常友好了。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>端到端合成论文——声码器——Melgan</title>
    <url>/2022/11/25/%E5%90%88%E6%88%90/Melgan%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="端到端合成论文——声码器——Melgan"><a href="#端到端合成论文——声码器——Melgan" class="headerlink" title="端到端合成论文——声码器——Melgan"></a>端到端合成论文——声码器——Melgan</h1><blockquote>
<p>Kumar, Kundan, et al. “Melgan: Generative adversarial networks for conditional waveform synthesis.” <em>Advances in neural information processing systems</em> 32 (2019). citations：561 Lyrebird AI  、蒙特利尔大学</p>
<p>github：<a href="https://github.com/descriptinc/melgan-neurips">https://github.com/descriptinc/melgan-neurips</a>  </p>
<p>试听音频：<a href="https://melgan-neurips.github.io/">https://melgan-neurips.github.io</a>  </p>
<p>相关应用：<a href="https://www.descript.com/overdub">https://www.descript.com/overdub</a>  </p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/291009155">MelGAN解构与分析</a></p>
</blockquote>
<h4 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h4><p>基于GAN的vocoder合成waveform效果不好的问题；</p>
<h4 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h4><p>提出一个基于GAN的vocoder，叫melgan，在语音合成、音乐翻译（music domain translation）和 unconditional 音乐合成领域都有好的效果，说明该vocoder的适用性很广；  </p>
<h4 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h4><p>轻量级架构，全卷积结构；</p>
<p>合成速度快，在GTX 1080Ti GPU上运行是realtime的100倍快，在CPU上运行是realtime的2倍快；</p>
<h4 id="存在什么问题"><a href="#存在什么问题" class="headerlink" title="存在什么问题"></a>存在什么问题</h4><p>音质不够好，MOS&#x3D;3.09；</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>vocoder分三类：</p>
<ol>
<li><p><strong>Pure signal processing approaches</strong> </p>
<p>代表为 Griffin-Lim (Griffin &amp; Lim, 1984)  、WORLD vocoder (MORISE et al., 2016)  ，world vocoder是attention based的RNN结构，用于Char2Wav 等模型；</p>
</li>
<li><p><strong>Autoregressive neural-networks-based models</strong>  </p>
<p>代表为 WaveNet (Van Den Oord et al., 2016)  、SampleRNN (Mehri et al., 2016)   、WaveRNN (Kalchbrenner et al., 2018)  、FFTNet（wavnenet的改进）</p>
</li>
<li><p><strong>Non autoregressive models</strong>   </p>
<ol>
<li>flow-based：Parallel Wavenet (Oord et al., 2017)   、Clarinet (Ping et al., 2018) ，蒸馏一个自回归教师模型，基于flow的卷积学生模型，loss为学生教师分布之间的KL散度； </li>
<li>based on Glow  ：WaveGlow (Prenger et al., 2019)  基于Glow的flow-based生成模型，模型较大；</li>
</ol>
</li>
</ol>
<p>这篇论文提出之前的GAN用于合成vocoder的做法：有使用GANs通过建模STFT的幅值和相位角来生成音乐音色，而不是直接建模原始波形、有用GAN映射mel谱到幅度谱、有用GAN蒸馏自回归模型；</p>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><ul>
<li>提出MelGAN，这是第一个成功训练基于GAN输出波形的模型，不需要通过蒸馏手段或感知loss作为辅助；</li>
<li>通过在通用音乐翻译、文本到语音生成和无条件音乐合成方面的实验，我们表明自回归模型可以很容易地被快速并行的MelGAN解码器取代，用于生成原始波形，尽管质量略有下降。</li>
<li>合成速度快，比目前最快的model快10倍；</li>
</ul>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><h4 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h4><p>输入mel谱（mel-spectrogram）s，输出波形x，因为输入维度小于输出维度（时间分辨率低256倍），因此堆叠一堆卷积层进行上采样；</p>
<p>结构全由卷积层构成：转置卷积 👉 残差结构的空洞卷积 ，作为一个block，堆叠N个block；</p>
<p>和传统GAN不同，不是用噪声作为输入，也不是用噪声作为辅助输入，因为发现辅助噪声对波形没帮助，这很反直觉，因为一般合成输入到输出是一到多映射，因此加点噪声有助于合成音频，但是可能因为mel谱信息太丰富，噪声没什么用了；</p>
<h4 id="Induced-receptive-field"><a href="#Induced-receptive-field" class="headerlink" title="Induced receptive field"></a>Induced receptive field</h4><p>在conv神经网络的生成器中，由于诱导感受野之间的高度重叠，存在一种诱导偏差，即空间上靠近的像素点是相关的。我们设计我们的生成器架构，把一个归纳偏差，在音频时间步之间有长范围的相关性。在每个上采样层之后，我们添加了带有膨胀dilated的residual block，以便每个后续层的远端输出激活具有显著的重叠输入。dilated conv layer叠加的感受野随层数呈指数增长。因此，生成器允许有效地增加每个输出时间步的诱导接受野，即在相隔很远的时间步的诱导感受野中有更大的重叠，从而导致更好的长范围相关性。</p>
<h4 id="Checkerboard-artifacts"><a href="#Checkerboard-artifacts" class="headerlink" title="Checkerboard artifacts"></a>Checkerboard artifacts</h4><p>棋盘效应，repeated patterns  会导致高频有嘶嘶声，要小心选择解卷积层的kernel-size和stride、dilated，即kernel-size是stride的整数倍，dilation是kerenl-size的幂次；</p>
<h4 id="Normalization-technique"><a href="#Normalization-technique" class="headerlink" title="Normalization technique"></a>Normalization technique</h4><p>选择不同的归一化方法直接影响合成质量；图像GAN里用的instance normalization，但音频GAN里instance normalization会冲掉pitch信息，使音频听起来像金属声；用谱归一化spectral normalization   效果也不好，用 <strong>Weight normalization</strong> (Salimans &amp; Kingma, 2016)   效果好；Weight normalization通过解耦权重向量的尺度与方向解耦来重新参数化权重矩阵；</p>
<p><img src="/2022/11/25/%E5%90%88%E6%88%90/Melgan%E8%AE%BA%E6%96%87/image-20221123155537151.png" alt="image-20221123155537151"></p>
<h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><h4 id="Multi-Scale-Architecture-多尺度判别器"><a href="#Multi-Scale-Architecture-多尺度判别器" class="headerlink" title="Multi-Scale Architecture  多尺度判别器"></a>Multi-Scale Architecture  多尺度判别器</h4><p>判别器用的MSD，这个在后续工作hifigan中使用了；用的3个子判别器，第一个判别器输入是生成器的输出waveform，第二个判别器输入是下采样（平均池化）2倍的waveform，第三个判别器是下采样（平均池化）4倍后的waveform作为输入；三个输入表示了不同尺度的音频特征，即<strong>不同频带特征</strong>；下采样的后的音频就没有高频了，因此输入是下采样过的子判别器会倾向于学习低频；（由傅里叶变换可知，信号是由无数个正弦波信号叠加而成的，多个子判别器的设置，分别处理不同降采样倍率的信号，以学习音频中不同频段的“模式”，假设采样频率为22k（信号频率最大11k）：第一个MSD判别器能采的信号频率为0 ~ 11K；第二个为0 ~ 5.5K；第三个为0 ~ 2.25K;）</p>
<h3 id="Window-based-objective"><a href="#Window-based-objective" class="headerlink" title="Window-based objective"></a>Window-based objective</h3><p>之前的判别器分类的对象是整条音频样本，而用窗口判别器，分类的是音频片段，窗口是overlap的窗口，每个窗口长度等于判别器的感受野，判别器的特点是卷积层的kernel-size很大（window长度也不短，不然不好分类音频了）（用group conv让卷积层参数量不会很大）；</p>
<p>windows判别器的优势是可以捕捉高频特征？；</p>
<p>结构上也用的weight norm；</p>
<h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>GAN的loss，采用的是 hinge loss 版本的GAN目标，并用的最小二乘 least-squares (LSGAN) 来改善原始的hinge loss；</p>
<h3 id="GAN-loss"><a href="#GAN-loss" class="headerlink" title="GAN loss"></a>GAN loss</h3><p>$$<br>\begin{aligned}<br>&amp;\min <em>{D_k} \mathbb{E}<em>x\left[\min \left(0,1-D_k(x)\right)\right]+\mathbb{E}</em>{s, z}\left[\min \left(0,1+D_k(G(s, z))\right)\right], \forall k&#x3D;1,2,3 \<br>&amp;\min <em>G \mathbb{E}</em>{s, z}\left[\sum</em>{k&#x3D;1,2,3}-D_k(G(s, z))\right]<br>\end{aligned}<br>$$</p>
<p>​		其中 $x$ 表示真实波形，$s$ 表示conditioning information（比如mel谱），$z$ 表示高斯噪声向量；</p>
<h3 id="Feature-Matching"><a href="#Feature-Matching" class="headerlink" title="Feature Matching"></a>Feature Matching</h3><p>feature matching objective用来辅助生成器更新，注意这里和hifi-gan不同，hifi-gan用的是mel谱之间的L1距离（频域），这里用的判别器输出的L1距离，应该算是时域（波形）；但是如果直接用x和G(s)计算L1距离作为辅助loss，合成的音质反而会有噪声，会更差！（这个图像领域的gan的结论相反）因此这里是用判别器输出来计算L1距离；<br>$$<br>\mathcal{L}<em>{FM}(G,D_k)&#x3D;\mathbb{E}</em>{x, s\sim p_{data}}\left[\sum_{i&#x3D;1}^T \frac{1}{N_i}\left|D_k^i(x)-D_k^i(G(s))\right|_1\right]<br>$$</p>
<p>​		其中，$D_k^{(i)}$ 表示第 $k$ 个判别器的第 $i$ 层 feature map输出（中间层）；$N_i$ 表示每层的神经元梳理；Feature matching  和感知loss（perceptual loss）很像；</p>
<h3 id="生成器的Final-loss"><a href="#生成器的Final-loss" class="headerlink" title="生成器的Final loss"></a>生成器的Final loss</h3><p>$$<br>\min <em>G \left(\mathbb{E}</em>{s, z}\left[\sum_{k&#x3D;1,2,3}-D_k(G(s, z))\right]+\lambda\sum_{k&#x3D;1}^3\mathcal L_{FM}(G,D_k) \right)<br>$$</p>
<p>​		其中，$\lambda&#x3D;10$ ；</p>
<h2 id="参数量和推理速度"><a href="#参数量和推理速度" class="headerlink" title="参数量和推理速度"></a>参数量和推理速度</h2><p>在GTX1080 Ti GPU in full precision 上的合成速度为 2500kHz，在CPU上的合成速度为 50kHz</p>
<p>Speed of n kHz means that the model can generate n × 1000 raw audio samples per second.   </p>
<p><img src="/2022/11/25/%E5%90%88%E6%88%90/Melgan%E8%AE%BA%E6%96%87/image-20221125110534986.png" alt="image-20221125110534986"></p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="Ground-truth-mel-spectrogram-inversion"><a href="#Ground-truth-mel-spectrogram-inversion" class="headerlink" title="Ground truth mel-spectrogram inversion"></a>Ground truth mel-spectrogram inversion</h3><h4 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h4><p>数据集 LJ Speech dataset  ，训练 400k次迭代；</p>
<p>MOS分比较：</p>
<p><img src="/2022/11/25/%E5%90%88%E6%88%90/Melgan%E8%AE%BA%E6%96%87/image-20221125110607376.png" alt="image-20221125110607376"></p>
<p>可以看出，有spec norm和L1 loss(audio space)都会影响音质，其中melgan里的Window-based Discriminator  对音质的帮助最大；</p>
<h5 id="根据实验结果有几个结论"><a href="#根据实验结果有几个结论" class="headerlink" title="根据实验结果有几个结论"></a>根据实验结果有几个结论</h5><ol>
<li>生成器没有dilated conv stack，或少了weight norm，会导致高频伪影（high frequency artifacts）；</li>
<li>只使用单个判别器（而不是多尺度判别器）会产生金属声音（metallic audio）（当说话人有呼吸声就会更明显），并且会跳过一些单词没读！</li>
<li>用spec norm或不用window-based 判别器 loss，会很难学到sharp高频pattern，导致音频听起来有明显噪声；</li>
<li>添加波形的L1 loss使得合成音频听起来像金属声，并且有额外的高频伪影 high frequency artifacts（高频伪影可以通过denoiser降噪器去除）；</li>
</ol>
<h4 id="Benchmarking-competing-models"><a href="#Benchmarking-competing-models" class="headerlink" title="Benchmarking competing models"></a>Benchmarking competing models</h4><p>不同的vocoder之间进行比较，输入为真实音频的mel谱，melgan训练了2.5M次迭代：</p>
<img src="/2022/11/25/%E5%90%88%E6%88%90/Melgan%E8%AE%BA%E6%96%87/image-20221125112732176.png" alt="image-20221125112732176" style="zoom: 67%;">

<p>melgan音质相比于wavenet、waveglow来说都差了一些；</p>
<h4 id="Generalization-to-unseen-speakers"><a href="#Generalization-to-unseen-speakers" class="headerlink" title="Generalization to unseen speakers"></a>Generalization to unseen speakers</h4><p>用说话人的数据集训练melgan，模型可以生成训练集没有的说话人声音，该实验表明了melgan可以学到的是说话人不变的（speaker -invariant）mel谱到waveform的映射；</p>
<h3 id="End-to-end-speech-synthesis"><a href="#End-to-end-speech-synthesis" class="headerlink" title="End-to-end speech synthesis"></a>End-to-end speech synthesis</h3><p>用声学模型+不同声码器，验证该声码器效果</p>
<p>MOS分对比如下：</p>
<img src="/2022/11/25/%E5%90%88%E6%88%90/Melgan%E8%AE%BA%E6%96%87/image-20221125113723721.png" alt="image-20221125113723721" style="zoom:67%;">

<p>其中，Text2mel是一个开源的char2wav model；</p>
<p>图上没有wavenet的实验结果，因为text2mel+wavenet的mos为3.4，可能是开源的模型有点问题？</p>
<p>图上的tacotron2+waveglow是开源的，作为对比，并没有实现tacotron2+melgan的实验，感觉这篇论文实验不是很充分；</p>
<h3 id="Non-autoregressive-decoder-for-music-translation"><a href="#Non-autoregressive-decoder-for-music-translation" class="headerlink" title="Non autoregressive decoder for music translation"></a>Non autoregressive decoder for music translation</h3><p>为了表现melgan的普适性，在music translation领域上的表现。</p>
<h3 id="Non-autoregressive-decoder-for-VQ-VAE"><a href="#Non-autoregressive-decoder-for-VQ-VAE" class="headerlink" title="Non-autoregressive decoder for VQ-VAE"></a>Non-autoregressive decoder for VQ-VAE</h3><p>为了进一步表现melgan的普适性，与Vector-Quantized VAEs (van den Oord et al., 2017) 进行对比。</p>
<p>TODO</p>
<p><img src="/2022/11/25/%E5%90%88%E6%88%90/Melgan%E8%AE%BA%E6%96%87/image-20221125115634115.png" alt="image-20221125115634115"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>提出一种条件语音合成（条件指的是mel谱）架构，基于GAN，叫melgan，定性定量分析了它，melgan有以下几个特点：lightweight轻量级，训练在单GPU上也能很快收敛，有较快的推理速度；但它受到时间对齐条件信息要求的限制；</p>
<h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>提出一个基于GAN的vocoder，是一篇改进模型和loss的论文，主要特点我觉得是用了multi-scale判别器，window-based objective，从音质出发，实验了对模型和目标的哪些改变能改进音质，这里音质不好包括了高频伪影、金属声、噪声，我们训练模型时出现了这些问题，可以从文章提出的解决思路去尝试；</p>
]]></content>
      <categories>
        <category>语音合成</category>
      </categories>
      <tags>
        <tag>语音合成</tag>
      </tags>
  </entry>
  <entry>
    <title>端到端合成论文——声学模型——VITS</title>
    <url>/2022/12/12/%E5%90%88%E6%88%90/VITS%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="端到端合成论文——声学模型——VITS"><a href="#端到端合成论文——声学模型——VITS" class="headerlink" title="端到端合成论文——声学模型——VITS"></a>端到端合成论文——声学模型——VITS</h1><blockquote>
<p>&#x3D;&#x3D;Kim, Jaehyeon, Jungil Kong, and Juhee Son. “Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech.” <em>International Conference on Machine Learning</em>. PMLR, 2021.&#x3D;&#x3D; citations: 118 Kakao （和hifi-gan一样的作者）</p>
<p>github: <a href="https://github.com/jaywalnut310/vits">https://github.com/jaywalnut310/vits</a></p>
<p>Demo: <a href="https://jaywalnut310.github.io/vits-demo/index.html">https://jaywalnut310.github.io/vits-demo/index.html</a>  </p>
</blockquote>
<ul>
<li>解决什么问题<ul>
<li>one-stage TTS model合成音质没有two-stage model好的问题。</li>
</ul>
</li>
<li>用了什么方法<ul>
<li>提出VITS（Variational Inference with adversarial learning for end-to-end Text-to-Speech）  ，是一个结合了变分推断、标准化flow、对抗网络的TTS model；</li>
<li>提出了一种从输入文本合成不同韵律语音的随机时长预测器，实现one-to-many。</li>
<li>不同于two-stage tts用mel谱作为中间产物进行声学模型和声码器的串联，vits用的vae的隐变量作为中间物。</li>
</ul>
</li>
<li>效果如何<ul>
<li>比two-stage TTS model音质好，更自然；</li>
<li>多种生成方法结合，改善了生成模型的建模能力；</li>
<li>在LJ Speech数据集达到SOTA，媲美真实声音。</li>
</ul>
</li>
<li>存在什么问题<ul>
<li>VITS输入依然需要文本预处理，研究语言表征的自监督学习可能是消除文本预处理的一个可能的方向。</li>
</ul>
</li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ul>
<li><p>为什么likelihood-based的方法对于序列问题会更好：因为不用去学习text和spectrograms之间的alignment关系，直接通过最大化目标mel谱的似然。（之间用attention-map来得到text和mel的对齐关系，attention-map越好，tts模型性能更好）</p>
</li>
<li><p>two-stage系统有天然的问题，在于：</p>
<ol>
<li>训练vocoder的输入用的是声学模型生成（输出）的样本，声学模型训得很好或不太好，对于后面的vocoder，以及整体的语音合成来说，不确定哪种结合方案是最好的。就是两个模型之间有gap。</li>
<li>依赖于预定义的中间特征，比如mel谱，因此无法应用习得的隐藏表示来获得进一步的性能改进。</li>
</ol>
</li>
</ul>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>提出一个端到端TTS方法，叫VITS，用了CVAE来连接两个模块（vocoder和声学模型），CVAE的隐变量就是两个模块之间的code，中间变量；用了标准化flow来建模条件先验分布；用了对抗学习来训练生成waveform的vocoder模块。CVAE的隐变量能起到一定的one-to-many效果，为了进一步one-to-many的效果，提出stochastic duration predictor  随机时长预测器，合成不同rhythm的语音。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="Variational-Inference"><a href="#Variational-Inference" class="headerlink" title="Variational Inference"></a>Variational Inference</h3><h4 id="OVERVIEW"><a href="#OVERVIEW" class="headerlink" title="OVERVIEW"></a>OVERVIEW</h4><p>CVAE的目标是最大化变分下界variational lower bound  ，也叫做 $\log p_\theta(x \mid c) $ 的 evidence lower bound (ELBO)<br>$$<br>\log p_\theta(x \mid c) \geq \mathbb{E}<em>{q_\phi(z \mid x)}\left[\log p_\theta(x \mid z)-\log \frac{q_\phi(z \mid x)}{p_\theta(z \mid c)}\right]<br>&#x3D;-K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}) | p_\theta(\mathbf{z} \mid \mathbf{c})\right)+\mathbb{E}</em>{q_\phi(\mathbf{z} \mid \mathbf{x})}\left[\log p_\theta(\mathbf{x} \mid \mathbf{z})\right]<br>$$</p>
<p>其中， $p_\theta(z \mid c)$ 是给定条件 $c$ 下隐变量 $z$ 的先验分布； $ p_\theta(x \mid z)$ 是数据点 $x$ 的似然函数； $q_\phi(z \mid x)$ 是<strong>后验概率分布</strong>的近似。</p>
<p>把ELBO取负，则第一项是 $\log q_\phi(z \mid x)$ 和 $\log p_\theta(z \mid c)$ 之间的KL散度，其中  $z \sim q_\phi(z \mid x)$ ；第二项是重构误差 reconstruction loss $-\log p_\theta(x \mid z)$ 。</p>
<p>$x$ 表示mel谱；$c$ 表示<strong>文本信息</strong>和<strong>对齐信息</strong>；$z$ 表示隐含变量，其中，对齐信息是一个&#x3D;&#x3D;硬对齐矩阵，形状为[|text|,|z|]&#x3D;&#x3D;。</p>
<p>文中提到，发现在 $P(z|c)$ 表示成简单的高斯分布之后再加一个flow变换，音质会更好。（这也就解释了为什么要加flow不可，其实不加也可以的）</p>
<h4 id="RECONSTRUCTION-LOSS"><a href="#RECONSTRUCTION-LOSS" class="headerlink" title="RECONSTRUCTION LOSS"></a>RECONSTRUCTION LOSS</h4><p>&#x3D;&#x3D;decoder&#x3D;&#x3D; 。重构误差里的真实数据点x用的是mel谱（不是waveform），用 $x_{mel}$ 表示。采样出来的 $z$ 通过decoder进行上采样，得到  $\hat{y}$ ，将 $\hat{y}$ 转换到mel谱域，得到 $\hat{x}<em>{m e l}$ ，把预测和真实mel谱之间的 $L_1$ loss 作为reconstruction：（这里不是直接最大似然）<br>$$<br>L</em>{\text {recon }}&#x3D;\left|x_{m e l}-\hat{x}_{\text {mel }}\right|_1<br>$$<br>这个步骤只在训练阶段进行，而在推理阶段，不是把整个向量 $z$ 都上采样，而是只把一部分送入decoder，这叫做 windowed generator training  。</p>
<p>这个deocoder也就是基于gan的声码器的生成器。</p>
<h4 id="KL-DIVERGENCE"><a href="#KL-DIVERGENCE" class="headerlink" title="KL-DIVERGENCE"></a>KL-DIVERGENCE</h4><p>我们的目标是为&#x3D;&#x3D;后验编码器 posterior encoder&#x3D;&#x3D;提供更多高分辨率的信息。因此，我们使用目标语音的线性尺度谱 linear-scale spectrogram   $x_{lin}$ 作为输入，而不是mel谱。</p>
<p>因此 KL散度公式为：<br>$$<br>\begin{gathered}<br>L_{k l}&#x3D;\log q_\phi\left(z \mid x_{l i n}\right)-\log p_\theta\left(z \mid c_{\text {text }}, A\right), \<br>z \sim q_\phi\left(z \mid x_{l i n}\right)&#x3D;N\left(z ; \mu_\phi\left(x_{l i n}\right), \sigma_\phi\left(x_{l i n}\right)\right)<br>\end{gathered}<br>$$<br>这里 $x_{lin}$ 作为输入到高斯分布中，输出 $z$ ；</p>
<p>所以说训练时，z来自于x，是后验分布得到的z（推理时就不是通过后验分布得到z，因为推理时没有x）</p>
<p>然后，作者发现增加&#x3D;&#x3D;先验分布&#x3D;&#x3D; $p(z|c)$ 的表达性对于生成样本像不像真实语音来说很重要，因此提出在encoder的先验分布和后验上做factorized normal distribution用标准化flow $f_\theta$    ，可以根据变量变化规则，将简单分布可逆转换为更复杂的分布。（通过简单的jacobian行列式计算就可以映射过去）</p>
<p>这里其实是额外做了一步，没有flow这一步，先验分布也可以表示的，就是特地做的一步，因为实验发现先验分布表达好了，对结果音质会很友好。</p>
<p>先验分布 &#x3D;&#x3D;先验编码器 prior encoder&#x3D;&#x3D;   $ p_\theta(z \mid c)$ 的 factorized normal distribution的表达式为：<br>$$<br>\begin{aligned}<br> p_\theta(z \mid c)&amp;&#x3D;N\left(f_\theta(z) ; \mu_\theta(c), \sigma_\theta(c)\right)\left|\operatorname{det} \frac{\partial f_\theta(z)}{\partial z}\right| \<br>&amp; c&#x3D;\left[c_{\text {text }}, A\right]<br>\end{aligned}<br>$$</p>
<p>其中，先验encoder $c$ 的输入条件是文本中提取的音素 $c_{text}$ 和音素、隐变量和音素之间的对齐矩阵 $A$ 组成。</p>
<p>这里c为输入的高斯分布，高斯分布的输出是 $f_\theta(z)$ ！注意这里输出比较特别是 $f_\theta(z)$ 服从高斯分布，然后再映射到另一个分布（z的分布）（这里如果对应到flow，z的分布就是复杂分布，而f(z)是简单分布）。</p>
<h3 id="Alignment-Estimation"><a href="#Alignment-Estimation" class="headerlink" title="Alignment Estimation"></a>Alignment Estimation</h3><h4 id="MONOTONIC-ALIGNMENT-SEARCH"><a href="#MONOTONIC-ALIGNMENT-SEARCH" class="headerlink" title="MONOTONIC ALIGNMENT SEARCH"></a>MONOTONIC ALIGNMENT SEARCH</h4><p>为了估计输入文本和目标语音之间的对齐关系 $A$，作者采用了单调对齐搜索 Monotonic Alignment Search   (MAS)，这是一种搜索对齐的方法，该方法使标准化flow $f$ 最大化数据的似然值（找在某参数下的A，能够让似然值（这里就不是先验分布了，而是在条件下生成样本）最大，找到对应的参数A）：</p>
<p>这里对齐关系是语音x和c的关系。</p>
<p>$$<br>\begin{aligned}<br>A&amp;&#x3D;\underset{\hat{A}}{\arg \max } \log p_\theta\left(x \mid c_{\text {text }}, \hat{A}\right) \<br>&amp;&#x3D;\underset{\hat{A}}{\arg \max } \log N\left(f(x) ; \mu\left(c_{\text {text }}, \hat{A}\right), \sigma\left(c_{\text {text }}, \hat{A}\right)\right) \quad<br>\end{aligned}<br>$$</p>
<p>这里对齐矩阵A的限制条件为文本和语音都是单调对齐的，并且是non-skipping的。这种求代价最小路径的问题，很容易想出用动态规划求解，但是这里的“代价”，也就是似然值不好求，因为CVAE的目标函数也没直接求似然，而是用的求ELBO代替的。所以作者这里就没有直接用似然值作为动态规划里的“代价”，而是就用的ELBO当作是似然值了。因此MAS公式就变成了，去找ELBO最大时对应的参数A：<br>$$<br>\begin{aligned}<br>A&amp;&#x3D;  \underset{\hat{A}}{\arg \max } \log p_\theta\left(x_{\text {mel }} \mid z\right)-\log \frac{q_\phi\left(z \mid x_{\text {lin }}\right)}{p_\theta\left(z \mid c_{\text {text }}, \hat{A}\right)} \<br>&amp; &#x3D;\underset{\hat{A}}{\arg \max } \log p_\theta\left(z \mid c_{\text {text }}, \hat{A}\right) \<br>&amp; &#x3D;\log N\left(f_\theta(z) ; \mu_\theta\left(c_{\text {text }}, \hat{A}\right), \sigma_\theta\left(c_{\text {text }}, \hat{A}\right)\right)<br>\end{aligned}<br>$$<br>第二行公式是因为矩阵A和 $p(x|z)$ 、 $q(z|x)$ 都无关，因此忽略这两项，只保留有关的 $p(z|c,A)$ 先验分布， 然后要最大化它。</p>
<p>再根据前面的先验分布的flow模块，由于 $\frac{\partial f_\theta(z)}{\partial z}$ 和A无关，行列式为1，log后为0，写成第三行。</p>
<h4 id="DURATION-PREDICTION-FROM-TEXT"><a href="#DURATION-PREDICTION-FROM-TEXT" class="headerlink" title="DURATION PREDICTION FROM TEXT"></a>DURATION PREDICTION FROM TEXT</h4><p>时长预测模型的必要性是因为，推理阶段，先验分布 $p(z|c,A)$ 需要A，如果不知道A就无法得知先验分布，A和音素持续时长有关，因此需要知道音素时长。也就是说这个&#x3D;&#x3D;时长预测模型，是为了推理阶段服务，才提出的&#x3D;&#x3D;。</p>
<p>每个人说不同句子都可能会有不同语速，如果是确定的时长预测器（每个phone固定的预测时长），可能合成出来的不够像真实的人类的韵律。作者提出了一种随机时长预测器，每次从音素时长分布中采样，也就是说，每个音素都有一个时长分布，每次通过采样，得到这次这个音素的时长。结构是一个flow-based的生成模型，生成的东西是“音素时长“，训练目标是最大似然估计，直接用会有点问题，因为时长是离散的整数，而flow对象是连续变量，并且时长是一个标量，一个数值，因为flow的可逆性，输入输出维度相同，都是个标量，就不好做高维变换了。</p>
<p>为了解决用flow做时长预测器会遇到的问题，作者用了variational dequantization   和 variational data augmentation  。</p>
<p>具体做法为：引入两个随机变量 $u$ 和 $v$ （和时长序列 $d$ 的time resolution相同（长度相同）、维度相同），$u$ 限制在 [0,1) 里，因此 $d-u$ 就是一个连续变量 （该方法叫variational dequantization）；$d$ 和 $v$ 做channel-wise拼接，得到更高维的隐变量表示（该方法叫 variational data augmentation）。 $u$ 、 $v$ 是从近似分布（不是真实分布）后验分布 $q_\phi(u, ν|d, c_{text})$ 中采样来的。 </p>
<p>因此，音素时长预测器的目标本来是最大似然估计，这里也用VAE的变分下界代替了，目标表达式为：<br>$$<br>\log p_\theta\left(d \mid c_{\text {text }}\right) \geq \mathbb{E}<em>{q_\phi\left(u, \nu \mid d, c</em>{\text {text }}\right)}\left[\log \frac{p_\theta\left(d-u, \nu \mid c_{\text {text }}\right)}{q_\phi\left(u, \nu \mid d, c_{\text {text }}\right)}\right]<br>$$<br>训练的时候要让时长预测器的梯度不能回传到input，就传到中间层A、$c_{test}$ 就行（通过A矩阵知道每个音素对应多长的语音）。</p>
<p>实际上训练（目标）的是时长预测器的逆，训练的时候，从真实数据中采样的x作为输入，简单的分布采样z作为输出，训练x到z的映射，然后实际用时，时长预测器取逆，输入简单分布z（随机噪声），抽样，输出时长预测结果x，然后转成整数，作为时长；</p>
<h3 id="Adversarial-Training"><a href="#Adversarial-Training" class="headerlink" title="Adversarial Training"></a>Adversarial Training</h3><p>和gan的vocoder一样了，就是额外添加一个判别器模型，对抗网络目标用最小均方loss和特征匹配loss。<br>$$<br>\begin{aligned}<br>L_{a d v}(D) &amp; &#x3D;\mathbb{E}<em>{(y, z)}\left[(D(y)-1)^2+(D(G(z)))^2\right] \<br>L</em>{a d v}(G) &amp; &#x3D;\mathbb{E}<em>z\left[(D(G(z))-1)^2\right] \<br>L</em>{f m}(G) &amp; &#x3D;\mathbb{E}<em>{(y, z)}\left[\sum</em>{l&#x3D;1}^T \frac{1}{N_l}\left|D^l(y)-D^l(G(z))\right|_1\right]<br>\end{aligned}<br>$$<br>特征匹配loss可以视为VAE里的重构误差 reconstruction loss ？</p>
<h3 id="Final-Loss"><a href="#Final-Loss" class="headerlink" title="Final Loss"></a>Final Loss</h3><p>$$<br>L_{vae}&#x3D;L_{recon}+L_{kl}+L_{dur}+L_{adv}(G)+L_{fm}(G)<br>$$</p>
<h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><p>下面介绍VITS中所使用的模块的结构。</p>
<h4 id="POSTERIOR-ENCODER"><a href="#POSTERIOR-ENCODER" class="headerlink" title="POSTERIOR ENCODER"></a>POSTERIOR ENCODER</h4><p>只用于训练阶段，推理不用。结构是non-causal WaveNet residual blocks  。</p>
<p>也就是拟合 $q_\phi(z \mid x)$ 后验概率。</p>
<p>输入 $x_{lin}$ ，输出均值方差，后验概率，再采样出z。</p>
<p>应用于多人模型时，将说话人嵌入向量添加进残差模块。</p>
<p>隐变量z可以理解为声学模型的输出。</p>
<h4 id="PRIOR-ENCODER"><a href="#PRIOR-ENCODER" class="headerlink" title="PRIOR ENCODER"></a>PRIOR ENCODER</h4><p>先验分布 $ p_\theta(z \mid c)$  ，$c&#x3D;\left[c_{\text {text }}, A\right] $  。</p>
<p>结构是transformer encoder + flow结构。transformer encoder目的是将文本变成提高维特征为 $c_{text}$ ， flow目的是进一步变成复杂分布，提高分布的复杂度。</p>
<p>输入是文本，输出是先验分布。</p>
<p>先验编码器作用类似于声学模型，只不过 VITS 是将音素映射为中间表示 z 而不是频谱 。</p>
<p>应用于多人模型时，向标准化流的残差模块中添加说话人嵌入向量。  </p>
<h4 id="DECODER"><a href="#DECODER" class="headerlink" title="DECODER"></a>DECODER</h4><p>$p_\theta(x \mid z)$。从隐变量z中生成波形。</p>
<p>应用于多人模型时，在说话人嵌入向量之后添加一个线性层，拼接到   $f_\theta$ 的输出隐变量 $z$ 。</p>
<h4 id="DISCRIMINATOR"><a href="#DISCRIMINATOR" class="headerlink" title="DISCRIMINATOR"></a>DISCRIMINATOR</h4><p>gan中使用，只用于训练阶段，推理不用。</p>
<h4 id="STOCHASTIC-DURATION-PREDICTOR"><a href="#STOCHASTIC-DURATION-PREDICTOR" class="headerlink" title="STOCHASTIC DURATION PREDICTOR"></a>STOCHASTIC DURATION PREDICTOR</h4><p>基于flow。从条件输入 $h_{text}$  估算音素时长的分布。</p>
<p>应用于多人模型时，在说话人嵌入向量之后添加一个线性层，并将其拼接到文本编码器的输出  $h_{text}$ 。</p>
<p>架构图：</p>
<p><img src="/2022/12/12/%E5%90%88%E6%88%90/VITS%E8%AE%BA%E6%96%87/image-20221212162129315.png" alt="image-20221212162129315"></p>
<h2 id="VITS公式推导"><a href="#VITS公式推导" class="headerlink" title="VITS公式推导"></a>VITS公式推导</h2><blockquote>
<p>b站 <a href="https://www.bilibili.com/video/BV1wU4y1q7po/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">60、基于cVAE+Flow+GAN的效果最好语音合成VITS模型论文精讲</a></p>
</blockquote>
<p>出发点是 $P(z|x)$ 和 $Q(z|x)$ 的关系，注意这里是 $P(z|x)$  ，虽然 $P(x)$ 积分项里是和 $P(x|z)$ 有关。（数据x给定下的叫后验，求数据x的叫似然）。</p>
<p><img src="/2022/12/12/%E5%90%88%E6%88%90/VITS%E8%AE%BA%E6%96%87/image-20221212104145183.png" alt="image-20221212104145183"></p>
<p>发现这里的推导都是从kl散度出发，vae基础上加上条件变量c。</p>
<p><img src="/2022/12/12/%E5%90%88%E6%88%90/VITS%E8%AE%BA%E6%96%87/image-20221212104128108.png" alt="image-20221212104128108"></p>
<h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2>]]></content>
      <categories>
        <category>语音合成</category>
      </categories>
      <tags>
        <tag>语音合成</tag>
      </tags>
  </entry>
  <entry>
    <title>端到端合成论文——声码器——Wavenet</title>
    <url>/2022/11/25/%E5%90%88%E6%88%90/Wavenet%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="端到端合成论文——声码器——Wavenet"><a href="#端到端合成论文——声码器——Wavenet" class="headerlink" title="端到端合成论文——声码器——Wavenet"></a>端到端合成论文——声码器——Wavenet</h1><blockquote>
<p>&#x3D;&#x3D;Oord, Aaron van den, et al. “Wavenet: A generative model for raw audio.” <em>arXiv preprint arXiv:1609.03499</em> (2016).&#x3D;&#x3D;citations：4826 谷歌</p>
<p>试听音频：<a href="https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio">https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio</a></p>
<p><a href="https://www.bilibili.com/video/BV1QE411p7z3/?p=16&vd_source=5e9891722f2b62adca440a5e92121b5b">李宏毅《深度学习人类语言处理》国语课程(2020) P16 Vocoder</a> </p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/285917433">WaveNet结构与推断</a></p>
</blockquote>
<h5 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><p>实现了waveform的生成，在tts里是sota，比参数方法和拼接合成方法听起来自然得多；</p>
<h5 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><p>提出了自回归的神经网络结构生成waveform，叫做wavenet；</p>
<h5 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h5><p>第一个提出生成waveform的神经网络结构；</p>
<p>产生的音频质量开始与真实人类语音相媲美，并且已经在一些完整的TTS系统中得到了应用</p>
<h5 id="存在什么问题"><a href="#存在什么问题" class="headerlink" title="存在什么问题"></a>存在什么问题</h5><p>WaveNet的输入(语言特征，预测log基频(F0)，音素时长)需要大量的领域专业知识来制作，包括复杂的文本分析系统和鲁棒的词典（发音指导）；</p>
<p>sample-level的自回归方法，只能按样本输出，不能逐帧输出，因此输出的实时性不高；</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>提出了自回归的神经网络结构生成waveform，叫做wavenet；</p>
<p>每个预测的音频样本点分布都是在先前一个样本的前提条件下得到的；</p>
<p>每秒能训练成千上万个样本点；</p>
<p>wavenet可以捕捉不同说话人的特征，通过调节说话人id在他们之间切换；</p>
<p>能生成music片段；</p>
<p>wavenet不仅能用于生成式模型，也能用于判别式模型，返回音素识别结果；</p>
<h3 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h3><ul>
<li>wavenet可以生成语音信号，在TTS领域里的主观自然度是sota水平；</li>
<li>因为语音生成需要长时依赖，为了模型能实现的长时依赖功能，设计了名叫dilated casual convolution的新结构，它具有很大的感受野；</li>
<li>在有说话人id为前提条件下，一个单一的模型可以用来生成不同的声音；</li>
<li>wavenet的网络结构，不仅在TTS任务上有效，并且在生成其他语音任务（比如music）也有效；</li>
</ul>
<h2 id="WaveNet模型"><a href="#WaveNet模型" class="headerlink" title="WaveNet模型"></a>WaveNet模型</h2><p>结构用的PixelCNN (van den Oord et al., 2016a;b)  ，生成的波形序列 $x&#x3D;{x_1,…,x_T}$ 的联合概率可以分解为条件概率的乘积<br>$$<br>p(x)&#x3D;\prod_{t&#x3D;1}^Tp(x_t|x_1,..,x_{t-1})<br>$$</p>
<h3 id="DILATED-CAUSAL-CONVOLUTIONS"><a href="#DILATED-CAUSAL-CONVOLUTIONS" class="headerlink" title="DILATED CAUSAL CONVOLUTIONS"></a>DILATED CAUSAL CONVOLUTIONS</h3><p>因果卷积指的是当前层的当前时刻输入，只与之前层的之前时刻到当前时刻有关，不会和未来时刻有关，不依赖于未来时刻；</p>
<h4 id="causal-convolution"><a href="#causal-convolution" class="headerlink" title="causal convolution"></a>causal convolution</h4><p>causal convolutional layers 可视化如下：</p>
<p>图中感受野长度等于5（&#x3D; #layers + filter length - 1  ）</p>
<p><img src="/2022/11/25/%E5%90%88%E6%88%90/Wavenet%E8%AE%BA%E6%96%87/image-20221125151839782.png" alt="image-20221125151839782"></p>
<p>因果卷积和图像里的masked卷积表现是一样的，只不过实现masked conv是通过构造一个mask张量并在应用它之前对这个mask与卷积核进行元素乘法来实现。对于1-D数据，如音频，可以通过将正常卷积的输出移动几个时间步来更容易地实现这一点。</p>
<p>为了增加感受野，提出dilated causal convolution</p>
<h4 id="dilated-causal-convolution"><a href="#dilated-causal-convolution" class="headerlink" title="dilated causal convolution"></a>dilated causal convolution</h4><p>dilated causal convolution也叫a trous 或 convolution with holes，空洞卷积、带洞卷积；就是滤波器作用在特征上时会按某个确定step进行skip再去作用；它等价于一个由原始滤波器用零填充为更大滤波器的卷积；输入输出size相等，</p>
<p>dilated causal convolutional   可视化如下：</p>
<p>图中dilations为1，2，4，8；</p>
<p><img src="/2022/11/25/%E5%90%88%E6%88%90/Wavenet%E8%AE%BA%E6%96%87/image-20221125153158301.png" alt="image-20221125153158301"></p>
<p>Dilated convolutions   不是wavenet提出的，在89年信号处理领域中就提出了，15年图像分割领域也提出过；</p>
<p>本文的空洞率为每层加倍，直到某个限制值，然后重复：$1,2,4,…,512,1,2,4,…,512,1,2,4,…,512$</p>
<p>每个 $1,2,4,…,512$ block 的感受野为1024  </p>
<h3 id="SOFTMAX-DISTRIBUTIONS"><a href="#SOFTMAX-DISTRIBUTIONS" class="headerlink" title="SOFTMAX DISTRIBUTIONS"></a>SOFTMAX DISTRIBUTIONS</h3><p>本来输出是一个一个采样点数值，转成one-hot vector；声音信号一般是16bit表示，如果ont-hot vector则向量长度为65536，太大了，因此要通过某种方法减少向量维度，这里通过 $\mu-law$ 算法，不是直接linear矩阵映射，而是用一个公式进行变换，先把[-32768, 32767]通过linear映射到[-1,1]，再用 $\mu-law$ 算法，因为我们希望映射到比如8bit，即256维，因此$\mu&#x3D;255$；</p>
<p>把16bit（65536）量化到256个可能的值<br>$$<br>f(x_t)&#x3D;\operatorname{sign} (x_t)\frac{ln(1+\mu|x_t|)}{ln(1+\mu)}<br>$$</p>
<p>​	其中 $-1&lt;x_t&lt;1$ ，$\mu&#x3D;255$ ；这种非线性量化产生的重构效果明显优于简单的线性量化方案。特别是对于语音，发现量化后的重构信号听起来与原始信号非常相似。</p>
<img src="/2022/11/25/%E5%90%88%E6%88%90/Wavenet%E8%AE%BA%E6%96%87/image-20221123174942354.png" alt="image-20221123174942354" style="zoom:50%;">



<h3 id="GATED-ACTIVATION-UNITS"><a href="#GATED-ACTIVATION-UNITS" class="headerlink" title="GATED ACTIVATION UNITS"></a>GATED ACTIVATION UNITS</h3><p>门激活函数表达式为：<br>$$<br>\mathbf{z}&#x3D;\tanh \left(W_{f, k} * \mathbf{x}\right) \odot \sigma\left(W_{g, k} * \mathbf{x}\right)<br>$$<br>即x分别经过两个激活函数，再点乘；</p>
<p>其中，$*$ 表示卷积操作，$\odot$ 表示element-wise 乘法，$\sigma(\cdot)$ 表示sigmoid函数，$k$ 是layer系数，$f$ 表示filter，$g$ 表示gate，$W$ 是卷积层滤波器参数，gate激活函数好于relu（因为语音波形有正有负）；</p>
<h3 id="RESIDUAL-AND-SKIP-CONNECTIONS"><a href="#RESIDUAL-AND-SKIP-CONNECTIONS" class="headerlink" title="RESIDUAL AND SKIP CONNECTIONS"></a>RESIDUAL AND SKIP CONNECTIONS</h3><p>残差结构组成的block，每个block输出是下一个block的输入，把所有block输出求和（skip-connections）；</p>
<p>残差结构能加速收敛，让模型能堆得更深；</p>
<img src="/2022/11/25/%E5%90%88%E6%88%90/Wavenet%E8%AE%BA%E6%96%87/image-20221125165445825.png" alt="image-20221125165445825" style="zoom:67%;">



<h3 id="CONDITIONAL-WAVENETS"><a href="#CONDITIONAL-WAVENETS" class="headerlink" title="CONDITIONAL WAVENETS"></a>CONDITIONAL WAVENETS</h3><p>上述过程中只讲述了输入是之前语音序列的情况，模型的输入为序列x， x为时间点t之前的语音序列。实际上我们不能单单通过之前的语音预测下一个点，就比方说如果单独输入一个 “我”字，是无法预测到底是“我吃饭”还是“我睡觉”的，所以还需要添加一个条件(Condition)来限制预测方向。</p>
<p>给额外输入 $h$ ，WaveNets可以对给定输入的音频的条件分布 $p (x|h)$ 进行建模。<br>$$<br>p(x|h)&#x3D;\prod_{t&#x3D;1}^Tp(x_t|x_1,..,x_{t-1},h)<br>$$<br>通过使模型与其他输入变量相适应，我们可以引导WaveNet生成具有所需特征的音频。例如，在多说话人设置中，我们可以通过将说话人身份作为额外输入提供给模型来选择说话人。类似地，对于TTS，我们需要提供关于文本的信息作为额外的输入。</p>
<p>这里在本文中条件指的是频谱特征，一般是mel谱。这个特征以帧为单位变化。这样就可以正确的指定预测方向了。</p>
<p>如何添加Conditon：</p>
<ol>
<li><p><strong>全局条件 global conditioning</strong> ：</p>
<ol>
<li><p>特征是一个单一的潜在表示 $h$   它影响所有时间步的输出分布，比如speaker embedding</p>
</li>
<li><p>门激活函数变为：<br>$$<br>\mathbf{z}&#x3D;\tanh \left(W_{f, k} * \mathbf{x}+V_{f, k}^T \mathbf{h}\right) \odot \sigma\left(W_{g, k} * \mathbf{x}+V_{g, k}^T \mathbf{h}\right)<br>$$</p>
</li>
</ol>
</li>
<li><p><strong>局部条件 local conditioning</strong>  ：</p>
<ol>
<li><p>特征是第二个时间序列 $h_t$ ，可能具有比音频信号更低的采样频率，比如linguistic features</p>
</li>
<li><p>门激活函数变为：<br>$$<br>\mathbf{z}&#x3D;\tanh \left(W_{f, k} * \mathbf{x}+V_{f, k} *\mathbf{y}\right) \odot \sigma\left(W_{g, k} * \mathbf{x}+V_{g, k} *\mathbf{y}\right)<br>$$</p>
</li>
</ol>
</li>
</ol>
<p><img src="/2022/11/25/%E5%90%88%E6%88%90/Wavenet%E8%AE%BA%E6%96%87/v2-e232ed4a4df0644255445d575dcafcf0_720w.webp" alt="img"></p>
<h3 id="CONTEXT-STACKS"><a href="#CONTEXT-STACKS" class="headerlink" title="CONTEXT STACKS"></a>CONTEXT STACKS</h3><p>意思好像是说和网络结构和输入的context长度有关，短一点就叠少一点，长一点就叠多一点？</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>数据集 The North American English dataset  </p>
<p>MOS分：</p>
<p><img src="/2022/11/25/%E5%90%88%E6%88%90/Wavenet%E8%AE%BA%E6%96%87/image-20221125173022187.png" alt="image-20221125173022187"></p>
<p>todo。。。</p>
]]></content>
      <categories>
        <category>语音合成</category>
      </categories>
      <tags>
        <tag>语音合成</tag>
      </tags>
  </entry>
  <entry>
    <title>端到端合成论文——声学模型——Tacotron</title>
    <url>/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/</url>
    <content><![CDATA[<h1 id="端到端合成论文——声学模型——Tacotron"><a href="#端到端合成论文——声学模型——Tacotron" class="headerlink" title="端到端合成论文——声学模型——Tacotron"></a>端到端合成论文——声学模型——Tacotron</h1><blockquote>
<p>&#x3D;&#x3D;Wang, Yuxuan, et al. “Tacotron: Towards end-to-end speech synthesis.” <em>arXiv preprint arXiv:1703.10135</em> (2017).&#x3D;&#x3D; Google  citations: 1430</p>
<p>知乎 <a href="https://zhuanlan.zhihu.com/p/101064153">Tacotron&amp;Tacotron2——基于深度学习的端到端语音合成模型</a></p>
<p>语音合成-从入门到放弃.pdf 第 5 章 声学模型  </p>
</blockquote>
<h5 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><ul>
<li>语音合成有很多组件（pipelines）（前端文本处理、声学模型、声码器）（multi-stage model），通常构建、设计这些组件难度较高。而一个集成的端到端TTS系统（single model）有很多好处：<ul>
<li>可以减轻了费力的特征工程的需要；</li>
<li>可以用更多的属性、特征（比如说话人id特征、语种特征、情感特征），因为可以在模型输入用这些特征，使得整个模型都有这个特征信息，而不是只在某些component用到，其他component没用到；</li>
<li>适应新数据也可能更容易；</li>
<li>multi-stage model的每个component都可能会出错（预测错），只要一个组件错误，就会影响整个系统的，使得整个系统的出错可能性比起single model来得更高；</li>
<li></li>
</ul>
</li>
</ul>
<h5 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><ul>
<li>提出端到端语音合成模型，直接从characters 合成语音，该模型叫 tacotron。只要给&lt;文本，音频&gt;训练对pair，就能训练得到一个效果较好的语音合成器。逐帧生成语音（帧级别），因此比样本级别自回归方法生成语音来得快得多。</li>
</ul>
<h5 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h5><ul>
<li><p>直接输入的是文本characters，直接预测输出的是逐帧的音频谱raw linear spectrogram；</p>
</li>
<li><p>英语MOS分3.82，自然度naturalness方面优于工业上的参数系统；</p>
</li>
<li><p>很好训练，随机初始化去训练就能得到不错的模型；</p>
</li>
<li><p>改进了原始端到端结构（vanilla seq2seq paradigm  ）</p>
</li>
</ul>
<h5 id="存在什么问题"><a href="#存在什么问题" class="headerlink" title="存在什么问题"></a>存在什么问题</h5><ul>
<li>效果相比于wavenet没有明显提升；</li>
</ul>
<h2 id="模型总体结构"><a href="#模型总体结构" class="headerlink" title="模型总体结构"></a>模型总体结构</h2><p>输入文本characters（不是音素序列，是字符序列），输出预测的逐帧的谱 raw linear spectrogram。</p>
<p>模型总体结构包括一个encoder，一个attention-based 的 decoder，一个后处理网络post-processing net；</p>
<p><img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221107153002024.png" alt="image-20221107153002024"></p>
<p><img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221108170533821.png" alt="image-20221108170533821"></p>
<h3 id="ENCODER"><a href="#ENCODER" class="headerlink" title="ENCODER"></a>ENCODER</h3><p>输入文本序列characters，one-hot -&gt; embedding -&gt; pre-net -&gt; CBHG module -&gt; attention</p>
<h3 id="Encoder-pre-net"><a href="#Encoder-pre-net" class="headerlink" title="Encoder pre-net"></a>Encoder pre-net</h3><p>输入character序列，做embedding，经过非线性变换（激活函数），经过dropout，bottleneck层（加速收敛，减少过拟合，提高泛化性）；</p>
<h3 id="CBHG-MODULE"><a href="#CBHG-MODULE" class="headerlink" title="CBHG MODULE"></a>CBHG MODULE</h3><p>CBHG是conv bank highway gru</p>
<p>CBHG模块作为encoder的其中一部分，提取pre-net的输出序列（一些非线性变换后的特征），到更高阶特征；</p>
<p>CBHC模块包括一组一维卷积，然后残差连接，然后highway层，作为双向GRU的输入；</p>
<h4 id="1-D-convolutional-filters-一维卷积"><a href="#1-D-convolutional-filters-一维卷积" class="headerlink" title="1-D convolutional  filters 一维卷积"></a>1-D convolutional  filters 一维卷积</h4><p>作用类似unigram、bigram，K-grams，用来提取上下文信息，提取局部信息；</p>
<p>实现是用$K$个滤波器，其中第$k$个滤波器长度是$k$；举例：$k&#x3D;1$，只卷当前的字符；$k&#x3D;2$，卷前后两个字符；$k&#x3D;K$，卷前后范围$K$个字符，因此就是一组滤波器长度不一样的卷积组；</p>
<p>每个滤波器卷积都对应一个输出（步长为1（保持原始的时间分辨率）），把所有滤波器卷积输出都堆叠（stack）在一起，相当于提取了不同范围上下文信息了（multi-scale那意思）；再沿着时间轴做max-pooling，相当于做了smooth平滑操作，让相邻帧更像一点；</p>
<blockquote>
<p>highway networks (Srivastava et al., 2015)  </p>
</blockquote>
<p><img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221108104125133.png" alt="image-20221108104125133"></p>
<h3 id="DECODER"><a href="#DECODER" class="headerlink" title="DECODER"></a>DECODER</h3><p>自回归</p>
<p><img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221108173745272.png" alt="image-20221108173745272"></p>
<h3 id="Decoder-RNN"><a href="#Decoder-RNN" class="headerlink" title="Decoder RNN"></a>Decoder RNN</h3><p>输入是 Attention RNN的输出 和 context vector 拼接起来的向量，经过GRU，得到输出；</p>
<p>而context vector来自Attention RNN的输出作为query，encoder作为key，做attention操作得到的向量；</p>
<p>预测输出是80维的mel谱。不是直接输出频谱spectrogram，因为波形谱的可能性很多，size很大，256维？生成很耗时，而mel-spectrogram虽然损失了信息，但是相比spectrogram就小了很多，且由于它是针对人耳来设计的，因此对最终生成的波形的质量不会有很多影响。</p>
<p>&#x3D;&#x3D;每个decoder step，不是预测一帧，而是预测多帧！输出多帧，并且是不重叠的帧；&#x3D;&#x3D;这样做的好处是可以大大缩减计算量（不减少的话，一个样本得输出几百帧），并且发现可以加速模型收敛（因为用的RNN预测，RNN对于几百帧的输出不友好，对于较少帧数的输出比较友好，并且帧数长了，产生需要的时间也是线性增加的）；每次预测r帧，decoder的序列长度变为1&#x2F;r长；</p>
<p>&#x3D;&#x3D;推理过程开dropout&#x3D;&#x3D;模拟推理过程可能出错的情况！！不是每次都用RNNR概率最大的那个值，而是需要增加随机性；（其他比如GPT2，是通过在输出的概率分布的采样，来作为输出，来增加随机性）；</p>
<p>怎么知道合成完了？通过一个二分类器（输出一个标量数值，通过阈值判断），每次把RNN输出送进分类器，判断是否结束；</p>
<img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221108174036419.png" alt="image-20221108174036419" style="zoom:50%;">



<h3 id="post-processing-network-and-waveform-synthesis"><a href="#post-processing-network-and-waveform-synthesis" class="headerlink" title="post-processing network  and waveform synthesis"></a>post-processing network  and waveform synthesis</h3><p>输入整个mel谱序列，通过decoder的non casual CBHG生成linear-scale spectrogram，linear spectrogram和waveform相比只少了一个phase信息（只差一个linear transform），因此不用很强的再后处理(vocoder)，只用一个较为简单的Griffin-Lim algorithm，来增加相位信息，输出幅度谱；</p>
<p>用Griffin-Lim algorithm 进行相位估计，然后做逆短时傅里叶变换（STFT）；</p>
<p>decoder CBHG可以替换成其他module来生成其他东西，比如换成wavnet那样的vocoder，就是直接输出波形了；</p>
<p>之所以需要post-processing，而不是靠RNN来输出linear spectrogram，是因为RNN是从前向后的（单向）（预测到某一个step时，可能发现前面预测错了，但是没法改了），然后加一个CBHG，可以看从前向后和从后向前的信息，这样会更好；</p>
<p>两个loss，都要最小化</p>
<img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221108174727511.png" alt="image-20221108174727511" style="zoom:50%;">

<p>这里voceder理解成不在主模型外的，是单独的一个模块（单独训练好的）；</p>
<h2 id="细节参数"><a href="#细节参数" class="headerlink" title="细节参数"></a>细节参数</h2><h3 id="模型参数"><a href="#模型参数" class="headerlink" title="模型参数"></a>模型参数</h3><p><img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221108110927345.png" alt="image-20221108110927345"></p>
<h3 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h3><h3 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h3><p>tacotron相比于wavenet，主要是在输入上需要的信息少了，也能起到好的效果，这对于人们训练一个语音合成系统减少了很多工作量，输入只要字符序列就可以了（训练时只要字符序列和音频pair）；</p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Shen, Jonathan, et al. “Natural tts synthesis by conditioning wavenet on mel spectrogram predictions.” <em>2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>. IEEE, 2018.&#x3D;&#x3D; citations：1958</p>
</blockquote>
<h5 id="解决什么问题-1"><a href="#解决什么问题-1" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><p>- </p>
<h5 id="用了什么方法-1"><a href="#用了什么方法-1" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><ul>
<li>提出Tacotron2，在tacotron基础上输出mel谱，再用改进的wavenet vocoder来生成波形；</li>
</ul>
<h5 id="效果如何-1"><a href="#效果如何-1" class="headerlink" title="效果如何"></a>效果如何</h5><p>- </p>
<p>- </p>
<h5 id="存在什么问题-1"><a href="#存在什么问题-1" class="headerlink" title="存在什么问题"></a>存在什么问题</h5><p>- </p>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>主要有两部分组成，Spectrogram Prediction Network  和 WaveNet Vocoder  。</p>
<p>Spectrogram Prediction Network类似tacotron的结构，然后把tacotron的decoder重的CBHG替换成了wavenet vocoder；</p>
<img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221108123420015.png" alt="image-20221108123420015" style="zoom:67%;">

<img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221109102922783.png" alt="image-20221109102922783" style="zoom: 67%;">

<h3 id="Spectrogram-Prediction-Network"><a href="#Spectrogram-Prediction-Network" class="headerlink" title="Spectrogram Prediction Network"></a>Spectrogram Prediction Network</h3><p>可以理解为声学模型</p>
<h4 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h4><p>输入字符序列 👉 embedding(512维) 👉 固定滤波器长度的卷积(512个滤波器，滤波器长度5*1，3层卷积，(每次看5个character)) 👉 BN ReLu 👉 BLSTM</p>
<p>这里没有采用tacotron1中的CHBG模块，也能取得好效果，看来卷积滤波器长度变化不是特别重要？</p>
<p>再送入注意力机制生成编码向量，这里用的是location-sensitive attention(LSA)位置敏感注意力，该注意力机制的对齐函数为：<br>$$<br>\operatorname{score}\left(s_{i-1}, h_j\right)&#x3D;v_a^T \tanh \left(W s_{i-1}+V h_j+U f_{i, j}+b\right)<br>$$<br>其中, $v_a, W, V, U$ 为待训练参数, $b$ 是偏置值, $s_{i-1}$ 为上一时间步 $i-1$ 的解码器隐状态, $h_j$ 为当前时间步 $j$ 的编码器隐状态, $f_{i, j}$ 为上一个解码步的注意力权重 $\alpha_{i-1}$ 经卷积获得的位置特征, 如下式<br>$$<br>f_{i, j}&#x3D;F * \alpha_{i-1}<br>$$</p>
<p>其中，$\alpha_{i-1}$是经过 softmax 的注意力权重的累加和。  </p>
<h4 id="decoder"><a href="#decoder" class="headerlink" title="decoder"></a>decoder</h4><p>自回归循环神经网络，每个step输出<strong>一帧</strong>；</p>
<p><strong>pre-net</strong> ：2层FC + relu，作为信息瓶颈对学习注意力至关重要；</p>
<p>pre-net输出 和 attention context进行拼接，作为LSTM的输入；</p>
<p>LSTM输出再与 attention context进行拼接，通过线性变换进行投影，来预测一帧的target谱；</p>
<p>LSTM 的输出用来计算新的编码向量，最后新计算出来的编码向量与 LSTM 输出做拼接，送入映射层以计算输出。  ？</p>
<p>（attention context在decoder中用了两次）</p>
<p>输出有两种形式，一种是频谱帧，另一种是停止符的概率，后者是一个简单二分类问题，决定解码过程是否结束。为了能够有效加速计算，减小内存占用，引入缩减因子 r（Reduction Factor），即每一个时间步允许解码器预测 r 个频谱帧进行输出。解码完成后，送入后处理网络处理以生成最终的梅尔频谱；<br>$$<br>s_{f i n a l}&#x3D;s_i+s_i^{\prime}<br>$$<br>其中, $s_i$ 是解码器输出, $s_{\text {final }}$ 表示最终输出的梅尔频谱, $s_i^{\prime}$ 是后处理网络的输出, 解码器的输出经过后处 理网络之后获得 $s_i^{\prime}$ ；</p>
<p>预测的target谱（mel谱）经过post-net(5层卷积)，生成频谱帧；</p>
<img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221109104613410.png" alt="image-20221109104613410" style="zoom:67%;">

<p>推理时，对decoder的pre-net开dropout！（本来网络里这个地方没有加dropout的，但是在推理过程中加了！）目的是为了在推理时输出能有变化；</p>
<p>没有用tacotron1中的reduction factor  （$r$）</p>
<h3 id="WaveNet-vocoder"><a href="#WaveNet-vocoder" class="headerlink" title="WaveNet vocoder"></a>WaveNet vocoder</h3><p>在 Tacotron-2 原始论文中，直接将梅尔频谱送入声码器 WaveNet 生成最终的时域波形。但是 WaveNet 计算复杂度过高，几乎无法实际使用，因此可以使用其它声码器，比如 Griffin-Lim、 HiFiGAN 等 。</p>
<ul>
<li><input disabled type="checkbox"> [TODO] [声码器还不是很懂，这块还要再看一下]</li>
</ul>
<h3 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h3><ol>
<li>进入后处理网络 post-net **前后 **的平方损失mse loss：</li>
</ol>
<p>$$<br>MselLoss &#x3D;\frac{1}{n} \sum_{i&#x3D;1}^n\left(y_{\text {real }, i}^{\text {mel }}-y_{b e f \text { ore }, i}^{\text {mel }}\right)^2+\frac{1}{n} \sum_{i&#x3D;1}^n\left(y_{\text {real }, i}^{\text {mel }}-y_{a f \text { ter }, i}^{\text {mel }}\right)^2<br>$$</p>
<p>​	其中，$y_{\text {real }, i}^{\text {mel }}$ 表示从音频中提取的真实频谱  ，$y_{b e f \text { ore }, i}^{\text {mel }}$， $y_{a f \text { ter }, i}^{\text {mel }}$ 分别为进入后处理网络前、后的解码器输出，$n$  为每批的样本数。  </p>
<ol start="2">
<li>从 CBHG 模块中输出<strong>线性谱</strong>的平方损失：</li>
</ol>
<p>$$<br>LinearLoss &#x3D;\frac{1}{n} \sum_{i&#x3D;1}^n\left(y_{\text {real }, i}^{\text {linear }}-y_i^{\text {linear }}\right)^2<br>$$</p>
<p>​	其中, $y_{\text {real }, i}^{\text {linear }}$ 是从真实语音中计算获得的线性谱, $y_i^{\text {linear }}$ 是从 CBHG 模块输出的线性谱。</p>
<ol start="3">
<li><p>停止符交叉熵<br>$$<br>StopTokenLoss &#x3D;-[y \cdot \log (p)+(1-y) \cdot \log (1-p)]<br>$$</p>
<p>其中，$y$为停止符真实概率分布，  $p$ 是解码器线性映射输出的预测分布。  </p>
</li>
<li><p>$L2$ 正则化？？<br>$$<br>RegulationLoss $&#x3D;\frac{1}{K} \sum_{k&#x3D;1}^K w_k^2<br>$$<br>其中$K$ 为参数总数, $w_k$为模型中的参数，这里排除偏置值、 RNN 以及线性映射中的参数。</p>
<p>最终的损失函数为上述 4 个部分的损失之和，如下式：</p>
</li>
</ol>
<p>$$<br>Loss &#x3D; MelLoss + LinearLoss + StopTokenLoss + RegulationLoss<br>$$</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>wavenet最好是用tacotron产生的谱作为输入进行训练，会比用真实谱进行训练的效果好（让wavenet知道tacotron产生的谱长什么样，才能得到最好的结果）；</p>
<img src="/2022/11/14/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(1)/image-20221108175319842.png" alt="image-20221108175319842" style="zoom: 67%;">

]]></content>
      <categories>
        <category>语音合成</category>
      </categories>
      <tags>
        <tag>语音合成</tag>
      </tags>
  </entry>
  <entry>
    <title>端到端合成论文——声学模型——FastSpeech</title>
    <url>/2022/11/16/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(4)/</url>
    <content><![CDATA[<h1 id="端到端合成论文——声学模型——FastSpeech"><a href="#端到端合成论文——声学模型——FastSpeech" class="headerlink" title="端到端合成论文——声学模型——FastSpeech"></a>端到端合成论文——声学模型——FastSpeech</h1><blockquote>
<p>&#x3D;&#x3D;Ren, Yi, et al. “Fastspeech: Fast, robust and controllable text to speech.” <em>Advances in Neural Information Processing Systems</em> 32 (2019).&#x3D;&#x3D;citations：575 浙大和微软</p>
<p>github：<a href="https://github.com/ming024/FastSpeech2">https://github.com/ming024/FastSpeech2</a></p>
<p>试听音频：<a href="https://speechresearch.github.io/fastspeech/">https://speechresearch.github.io/fastspeech/</a></p>
</blockquote>
<ul>
<li><p>解决什么问题</p>
<p>相比于拼接和统计参数的合成方法，神经网络的端到端合成方法的有几个问题：</p>
<ul>
<li><ol>
<li><strong>推理过程中mel谱生成的速度慢</strong>，这是因为mel谱产生是自回归方式；</li>
</ol>
</li>
<li><ol start="2">
<li><strong>合成语音不够鲁棒</strong>（一些词会跳读、重复读），这是因为error会传播、text和语音之间错误的attention alignments；</li>
</ol>
</li>
<li><ol start="3">
<li><strong>缺少可控性</strong>（语速控制或韵律控制），这是因为自回归的方法一帧帧生成mel谱，没有利用整条文本和整条语音之间的对齐关系；</li>
</ol>
</li>
</ul>
</li>
<li><p>用了什么方法</p>
<ul>
<li><p>以文本和语音是单调对齐作为出发点，提出一种输入文本（音素）序列，<strong>非自回归</strong>产生mel谱序列的方法（并行），解决了上面的问题1；</p>
</li>
<li><p>为了解决音素序列和mel谱序列不等长问题，根据每个音素的时长对相应的mel谱进行上采样，来扩大mel谱长度；调整每个音素时长length regulator的基础是音素时长预测器，它预测每个音素的时长；<strong>Phoneme duration predictor</strong> 和之前的 attention alignments一旦不好就会影响合成质量 很不同，因此解决了上面的问题2；</p>
</li>
<li><p>通过调整length regulator，很容易调整语速，还可以通过在相邻音素之间添加break来控制部分韵律，解决了上面的问题3；</p>
</li>
</ul>
</li>
<li><p>效果如何</p>
<ul>
<li>该并行模型在语音质量方面与自回归模型相匹配，几乎消除了特别困难情况下的跳过和重复的问题，并能平稳地调整语音速度。</li>
<li>主要特点是合成速度快，使得端到端语音合成快了38倍，是mel谱生成快了270倍，因此叫 FastSpeech；</li>
</ul>
</li>
<li><p>存在什么问题</p>
<ul>
<li>根据时长直接复制特征扩展特征长度，会不会一个音素的时长里特征都是一模一样的？</li>
<li>要额外训练一个教师模型，比较耗时；</li>
<li>从教师模型抽取的时长信息不是一定准确的；</li>
<li>因为是用的模型蒸馏，教师模型生成的语音mel谱作为target，因为不是用真实音频提取的mel谱，因此丢失了一些音高、能量、韵律等变化信息，比训练数据中用真实音频相比简单得多，多样性也少得多。</li>
</ul>
</li>
</ul>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Non-Autoregressive-Sequence-Generation"><a href="#Non-Autoregressive-Sequence-Generation" class="headerlink" title="Non-Autoregressive Sequence Generation"></a>Non-Autoregressive Sequence Generation</h3><p>非自回归序列生成的应用：</p>
<p>neural machine translation  ：</p>
<blockquote>
<p>Jiatao Gu, James Bradbury, Caiming Xiong, Victor OK Li, and Richard Socher. Non-autoregressive neural machine translation. arXiv preprint arXiv:1711.02281, 2017.  </p>
<p>Junliang Guo, Xu Tan, Di He, Tao Qin, Linli Xu, and Tie-Yan Liu. Non-autoregressive neural machine translation with enhanced decoder input. In AAAI, 2019.  </p>
<p>Yiren Wang, Fei Tian, Di He, Tao Qin, ChengXiang Zhai, and Tie-Yan Liu. Non-autoregressive machine translation with auxiliary regularization. In AAAI, 2019  </p>
</blockquote>
<p>audio synthesis  ：</p>
<blockquote>
<p>Aaron van den Oord, Yazhe Li, Igor Babuschkin, Karen Simonyan, Oriol Vinyals, Koray Kavukcuoglu, George van den Driessche, Edward Lockhart, Luis C Cobo, Florian Stimberg, et al. Parallel wavenet: Fast high-fidelity speech synthesis. arXiv preprint arXiv:1711.10433, 2017.  </p>
<p>Wei Ping, Kainan Peng, and Jitong Chen. Clarinet: Parallel wave generation in end-to-end text-to-speech. In International Conference on Learning Representations, 2019.  </p>
<p>Ryan Prenger, Rafael Valle, and Bryan Catanzaro. Waveglow: A flow-based generative network for speech synthesis. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3617–3621. IEEE, 2019.  </p>
</blockquote>
<p>上面都是在推理阶段用非自回归，但是训练阶段还是自回归；</p>
<p>非自回归vocoder：</p>
<blockquote>
<p>Parallel WaveNet [16]</p>
<p>ClariNet [18] </p>
<p>WaveGlow [20]   </p>
</blockquote>
<p>这些方法输入mel谱到输出waveform过程是并行的（非自回归），但是由于生成mel谱过程是自回归的，因此总的来说还是自回归的；</p>
<p>完全非自回归的：</p>
<blockquote>
<p>Kainan Peng, Wei Ping, Zhao Song, and Kexin Zhao. Parallel neural text-to-speech. arXiv preprint arXiv:1905.08459, 2019.  </p>
</blockquote>
<p>这个和fastspeech一样都是完全自回归的，但是参数量比fastspeech大，因此推理速度没fastspeech快；</p>
<h2 id="FastSpeech模型结构"><a href="#FastSpeech模型结构" class="headerlink" title="FastSpeech模型结构"></a>FastSpeech模型结构</h2><p>用了教师模型（相当于蒸馏）模型较小；</p>
<p>训练和推理都是非自回归生成mel谱，mel谱到waveform也是并行的（非自回归）；</p>
<p>模型总体结构：</p>
<p>由FFT层、时长规整器、FFT、线性层堆叠而来，结构相比于tacotron来说简单很多，没有用到RNN，只有attention+conv就足够！</p>
<p>FFT是先attention再conv；dutation predictor是只用conv；</p>
<p>时长预测器比较巧妙，我们不知道音素实际时长groundtruth，可能可以通过识别方法获得，但是文章采用的是一个attention-based的合成模型获得，去学习音素和谱的时长关系，然后直接把特征复制几份，扩展特征长度了；</p>
<p><img src="/2022/11/16/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(4)/image-20221109181229366.png"></p>
<h3 id="Feed-Forward-Transformer"><a href="#Feed-Forward-Transformer" class="headerlink" title="Feed-Forward Transformer"></a>Feed-Forward Transformer</h3><p>每个FFT Block组成：音素embedding输入 👉 multi-head attention 👉 conv 1D 👉 输出（最后是mel谱输出）</p>
<p>多个FFT Block串联起来；</p>
<p>multi-head attention作用：抽取cross-position information，抽取不同位置之间的关系信息；</p>
<p>使用卷积的原因是：在语音任务中，相邻hidden state的字符&#x2F;音素和mel-谱图序列中很相关。</p>
<h3 id="Length-Regulator"><a href="#Length-Regulator" class="headerlink" title="Length Regulator"></a>Length Regulator</h3><p>输入不同音素时长，复制对应帧数那么多份的变换函数</p>
<p>length regulator  $\mathcal{L} \mathcal{R}$ 表示为：<br>$$<br>\mathcal{H}<em>{m e l}&#x3D;\mathcal{L} \mathcal{R}\left(\mathcal{H}</em>{p h o}, \mathcal{D}, \alpha\right)<br>$$<br>举例：音素序列的隐状态为 $$\mathcal{H}_{p h o}&#x3D;\left[h_1, h_2, h_3, h_4\right]$$  ，</p>
<ol>
<li><p>在没有加速减速(normal speed) 的情况下（$\alpha &#x3D; 1$ ）：对应的音素持续时长序列为 $$\mathcal{D}&#x3D;[2,2,3,1]$$（所有持续时长加起来的和等于mel谱序列长度），扩展序列 $\mathcal{H}_{m e l}$ 变成$$\left[h_1, h_1, h_2, h_2, h_3, h_3, h_3, h_4\right]$$；</p>
</li>
<li><p>在减速（slow speed）情况下（$\alpha&#x3D;1.3$）：对应的音素持续时长序列为 $$\mathcal{D}_{\alpha&#x3D;1.3}&#x3D;[2.6,2.6,3.9,1.3] \approx [3,3,4,1]$$ ，扩展序列变成 $$\left[h_1, h_1, h_1, h_2,h_2, h_2, h_3, h_3,h_3,h_3, h_4\right]$$；</p>
</li>
<li><p>在加速（fast speed）情况下（$\alpha&#x3D;0.5$）：对应的音素持续时长序列为 $$\mathcal{D}_{\alpha&#x3D;0.5}&#x3D;[1,1,1.5,0.5] \approx[1,1,2,1]$$，扩展序列变成 $$\left[h_1, h_2, h_3, h_3, h_4\right]$$；</p>
</li>
</ol>
<p>可以通过调整空格字符的持续时长，来调整单词之间的停顿。比如增加单词间的停顿，就在音素持续时长序列里增加空格这个字符的持续时长，这样子很容易就能调整发音波形的韵律了！</p>
<h3 id="Duration-Predictor"><a href="#Duration-Predictor" class="headerlink" title="Duration Predictor"></a>Duration Predictor</h3><p>预测时长和标签时长之间的均方误差作为loss之一，预测的时长是取log的时长；</p>
<p>标签时长来自于自回归的教师模型；</p>
<ol>
<li><p>首先先训练一个自回归的encoder-attention-decoder TTS模型</p>
</li>
<li><p>得到attention alignment</p>
<p>decoder和encoder之间用attention连接，这个attention是multi-head attention，不是每个head都能有好的alignement，因此对多头里的每个头都计算attention alignment，选一个focus fate最大的作为对齐序列；</p>
<p>这里把注意力对齐效果好坏（对齐结果越接近对角线越好） 用focus rate $F$来表示：$$F&#x3D;\frac{1}{S} \sum_{s&#x3D;1}^S \max <em>{1 \leq t \leq T} a</em>{s, t}$$</p>
<p>其中，$S$是标签谱的时长，$T$是音素的时长，$\alpha_{s,t}$ 是注意力矩阵里第$s$行（谱），第$t$列（音素）的元素；注意力矩阵横坐标是decoder的谱（帧），纵坐标是encoder的音素序列，每次遍历音素序列，找到第s帧对应注意力最大值的音素，认为是该帧的音素，然后遍历所有帧，就能得到每一帧对应的音素，以及平均注意力值，叫做focus rate；（理想情况，一般在注意力矩阵作图看上去像对角线）</p>
</li>
<li><p>得到attention alignments之后，可以通过抽取每个音素的时长 $d_i&#x3D;\sum_{s&#x3D;1}^S[\arg \max_t\alpha_{s,t}&#x3D;i]$，因此得知音素序列持续时长 phoneme duration sequence $$\mathcal{D}&#x3D;[d_1,d_2,…,d_n]$$ 。一个音素的持续时间是根据上述步骤中选择的注意头关注到它的mel-谱图的数量。</p>
</li>
</ol>
<h3 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h3><p>loss1：预测的时长和教师target的时长之间的mse loss；</p>
<p>loss2：mel谱的，是教师模型（teacher模型）预测的mel谱作为fastspech模型（student模型）的target；（模型蒸馏）</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>todo</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>用了很特别的方法来解决文本和音频长度不匹配的问题，不是用自回归的，也许我们可能可以想到用一个时长预测器，来复制特征以扩大特征长度，但是用attention来对齐获得时长的方法还是比较巧妙。FastSpeech最巧妙的是时长预测器，我们不知道音素实际时长groundtruth，可能可以通过识别方法获得，但是文章采用的是一个attention-based的合成模型获得，去学习音素和谱的时长关系，然后直接把特征复制几份，扩展特征长度了；</p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Ren, Yi, et al. “Fastspeech 2: Fast and high-quality end-to-end text to speech.” <em>arXiv preprint arXiv:2006.04558</em> (2020).&#x3D;&#x3D;citations：481 浙大和微软</p>
<p>试听音频：<a href="https://speechresearch.github.io/fastspeech2">https://speechresearch.github.io/fastspeech2</a></p>
</blockquote>
<ul>
<li>解决什么问题<ul>
<li>解决one-to-many mapping问题中存在的问题；</li>
<li>自回归TTS唯一的输入信息是文本，这不足以完全预测语音中的方差。在这种情况下，模型容易对训练集中目标语音的变化进行过拟合，导致泛化能力较差。（语音太复杂 变化，只输入文本容易过拟合）</li>
</ul>
</li>
<li>用了什么方法<ul>
<li>提出<strong>fastspeech2</strong>模型，直接用ground-truth目标训练时长模型（fastspeech1是用教师模型）；</li>
<li>不仅只预测时长duration（时长预测器），还训练了pitch 预测器、energy预测器。推理时，模型预测出波形的duration、pitch、energy，使得生成的语音波形更真实；</li>
<li>提出fastspeech 2s模块，训练中有一个分支是直接输出波形的，（不使用mel-谱图作为中间输出），在推理中直接从文本生成语音波形，推理延迟低。</li>
</ul>
</li>
<li>效果如何<ul>
<li>通过简化训练pipeline，训练比fastspeech快三倍；推理比fastspeech更快；</li>
<li>音质超过fastspeech、也超过自回归方法的合成模型；</li>
<li>解决了TTS中的一对多映射问题，实现了更好的语音质量；</li>
<li>fastspeech 2s 更进一步简化推理pipeline，直接从text产生waveform；</li>
</ul>
</li>
<li>存在什么问题<ul>
<li>音素的持续时长groundtruth来自识别强制对齐，这基于一个已训练好的识别模型，因此还要先训练一个识别模型（或者用预训练模型）；</li>
</ul>
</li>
</ul>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>总体结构很简单，输入是<strong>音素序列</strong>，做embedding，然后encoder抽取高级特征，经过提取不同特征的模块variance adaptor，于positional encoding相加，经过decoder，输出波形和mel谱；</p>
<p>输出不仅输出mel谱，同时也送入waveform decoder输出波形，这个模块称为FastSpeech 2s，在推理阶段就直接用这里的输出波形，使得合成速度很快，推理延迟低；</p>
<img src="/2022/11/16/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(4)/image-20221110112621377.png" alt="image-20221110112621377" style="zoom:67%;">

<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>feed-forward Transformer block，就是self-attention和1D-conv的结构堆好几层；</p>
<h3 id="Variance-adaptor"><a href="#Variance-adaptor" class="headerlink" title="Variance adaptor"></a>Variance adaptor</h3><p>由duration predictor、pitch predictor、energy predictor组成，对input分别抽取三类信息，然后再特征相加，相当于把input分离出它的某些特征分量，重视了这些特征，然后得到一个很容易就能起作用的特征，相当于人为帮带有冗余信息的input提了有用的稀疏特征；</p>
<p>PS. 文章虽然只用了这三种特征，但提到将来的研究中可以用其他的特征，比如emotion、style、speaker。</p>
<p>variance adaptor中的每个predictor都是由2层1维卷积、relu激活、layer norm dropout组成的；</p>
<h4 id="duration-predictor"><a href="#duration-predictor" class="headerlink" title="duration predictor"></a>duration predictor</h4><p>音素持续时长的标签来自于强制对齐（识别方法）（Montreal forced alignment (MFA) (McAuliffe et al., 2017)  ），这比用attention map得到的更准；</p>
<p>输出是log域的音素时长序列；</p>
<p>MSE loss；</p>
<h4 id="pitch-predictor"><a href="#pitch-predictor" class="headerlink" title="pitch predictor"></a>pitch predictor</h4><p>prosody中pitch特征很重要，考虑到时间轴一长，pitch变化很大，使用连续小波变换（continuous wavelet transform (CWT)  ）将pitch轮廓转换为pitch谱图(Suni et al., 2013; Hirose &amp; Tao, 2015)   ，并且在频域里预测（之前的方法是直接预测pitch包络，但是预测出来的和groundtruth区别很大）；</p>
<p>输出pitch spectrogram；</p>
<p>MSE loss；</p>
<p>推理时，pitch predictor预测出pitch spectrogram，再利用连续小波反变换(iCWT)将其进一步转换回pitch包络。</p>
<p><strong>pitch值</strong>：训练和推理过程中的groundtruth、predict的pitch $F_0$特征都要进行量化，量化到256个可能的数值（8bit表示？），该pitch值再embedding成向量vector $v$，然后加到之前特征里；</p>
<h4 id="Energy-Predictor"><a href="#Energy-Predictor" class="headerlink" title="Energy Predictor"></a>Energy Predictor</h4><p>逐帧进行快速傅里叶变换STFT，求功率（模方），L2-norm ， 量化到256个可能的值，再embedding成向量vector $e$，然后加到之前特征里；</p>
<p>注意，predictor输出是未量化的功率！然后才对输出进行量化的；</p>
<p>MSE loss；</p>
<h3 id="FASTSPEECH-2S"><a href="#FASTSPEECH-2S" class="headerlink" title="FASTSPEECH 2S"></a>FASTSPEECH 2S</h3><p>直接预测waveform会遇到几个问题：</p>
<ol>
<li>波形比mel谱包含更多变化的信息（比如phase），输出信息量越多，只凭简单的输入想要预测该输出就更难；</li>
<li>每帧的波形向量很大，如果波形一长的话，输出矩阵就很大，很难训练，因此一般就只训练音频片段，但是这样会失去一些上下文关系；</li>
</ol>
<p>本文提出的解决方法：</p>
<ol>
<li>因为相位很难预测，因此要用更难一点的训练方法，本文用的在waveform decoder中引入对抗训练，(Yamamoto et al., 2020).  </li>
<li>利用同一个模型预测的mel谱作为输入；？？</li>
</ol>
<h4 id="waveform-decoder结构"><a href="#waveform-decoder结构" class="headerlink" title="waveform decoder结构"></a>waveform decoder结构</h4><p>类似wavenet，非因果卷积、gate激活；</p>
<p>输入是短音频片段，上采样为和输出一样长的音频片段（通过一维卷积上采样），输出是groundtruth音频片段；</p>
<p>对抗网络中的判别器discriminator 的结构和Parallel WaveGAN(Yamamoto et al., 2020)   一样，包含10层的非因果空洞1维卷积，leaky relu激活；</p>
<p>loss是multi-resolution STFT 和 LSGAN discriminator loss；</p>
<p>推理阶段不需要mel谱，只使用waveform decoder来合成波形；</p>
<h3 id="MODELING-PITCH-WITH-CONTINUOUS-WAVELET-TRANSFORM"><a href="#MODELING-PITCH-WITH-CONTINUOUS-WAVELET-TRANSFORM" class="headerlink" title="MODELING PITCH WITH CONTINUOUS WAVELET TRANSFORM"></a>MODELING PITCH WITH CONTINUOUS WAVELET TRANSFORM</h3><p>公式的目的是得到pitch谱，这个pitch谱才是我们想要的特征，也就是pitch提取器的输出groundtruth，和预测的对象；</p>
<p>因此我们有了pitch包络，先变换到pitch谱，作为pitch特征；</p>
<p>具体计算公式如下：</p>
<p>给一个连续pitch包络函数 $F_0$ ，用(Tuteur, 1988; Grossmann &amp; Morlet, 1984)转换成pitch谱 $W(\tau,t)$：<br>$$<br>W(\tau,t)&#x3D;\tau^{-1&#x2F;2}\int_{-\infty}^{+\infty}F_0(x)\psi(\frac{x-t}{\tau})dx<br>$$<br> 其中，$\psi$ 是Mexican hat mother wavelet，$F_0(x)$是位置$x$的pitch值（位置？），$\tau$ 是wavelet的scale，$t$ 是wavelet的position（第 $t$ 帧）；</p>
<p>而原始的pitch包络也能从pitch谱中恢复（通过inverse continuous wavelet transform (iCWT)），他们是可以互相转换的；<br>$$<br>F_0(t)&#x3D;\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}W(\tau,t)\tau^{-5&#x2F;2}\psi(\frac{x-t}{\tau}) dxd\tau<br>$$<br>（不知道这公式怎么来的，先不管？）</p>
<p>假设把$F_0$分解为10个scales，</p>
<img src="/2022/11/16/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(4)/image-20221116162902354.png" alt="image-20221116162902354" style="zoom: 67%;">

<h4 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h4><blockquote>
<p><a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder">https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder</a>  </p>
</blockquote>
<p>使用PyWorldVocoder提取pitch包络，但先做一些预处理工作：</p>
<ol>
<li>由于CWT算法对不连续信号很敏感，因此先对清音（unvoiced）（没有pitch的）帧进行线性插值，插出pitch来；</li>
<li>对提取的pitch包络转到log域；</li>
<li>对每个句子归一化到 $\mu&#x3D;0,\delta&#x3D;1$，保留原始均值方差，为了重建pitch 包络；</li>
<li>用CWT公式把归一化的pitch包络变换到pitch谱，作为groundtruth；</li>
</ol>
<p>训练阶段，pitch predictor预测的是pitch谱和pitch包络的均值方差，整个pitch模块输入给下一个模块的是groundtruth的pitch包络；pitch谱来自于groundtruth的pitch包络通过CWT得到；</p>
<p>推理阶段，pitch predictor预测了pitch谱和pitch包络的均值方差后，通过iCWT转换为pitch包络，作为下一个模块的输入特征之一；</p>
<img src="/2022/11/16/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(4)/image-20221116155025671.png" alt="image-20221116155025671" style="zoom:67%;">

<h2 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h2><p>TODO</p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>核心在于用了一些“物理”特征，先验地认为这几个物理量和合成效果最相关，然后训练这几个物理量的生成器，结果产生了很不错的效果；说明合成也许就和这几个物理量最相关，这几个物理量生成得好，合成效果自然就好；</p>
<p>这几个物理量和合成最相关也许之前的研究者也很清楚，但是都没怎么用到，输入的只有文本，标签只有音频，让模型自己训，fastspeech2有点像是减轻模型工作量的思路，减轻模型训练的难度，先提取一些分别的物理量，让模型去训练，各个模块都有点分开的意思，再得到一个总体的模型；</p>
<p>因此，从这个角度出发，如果能找到这几个物理量哪些性质对于合成韵律最重要，进一步抽取这些性质，也许能进一步减轻模型训练的难度；比方说pitch的变化大？短时周期性？等等，看看哪一个性质对韵律影响最大，进一步分别抽取，也许能合成出更好的音质；</p>
<p>直接生成waveform的结构也比较巧妙，考虑到waveform很难预测好，输入不是像其他预测器一样只用来自文本的特征（或者说encoder），而是用的预测的mel谱作为特征；并且因为很难预测好，没有用简单的结构+mseloss，而是用了GAN的训练策略；</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>合成是一个一对多的过程，输入（文本）相比于输出（变化的音频）来说很简单，在这种输入输出复杂度不对等的前提下，思考如何设计模型这个问题，可以转化成思考如何缩小输入和输出之间的gap这个问题；问题解决方法之一是输出太复杂了，那把输出特征多利用一点，多榨干一点，音频重要的特征全都分解出来，让输入一一去拟合它们，有点化简（文本特征）为繁（多个特征）的意思；有点欠拟合的意思？需要从输入增加特征，才能把模型训练好；</p>
<p>而识别，是一个多对一的过程，和合成反过来，输入很复杂，输出很简单，于是也有一个输入输出之间存在gap的问题，因此是不是可以把输入删掉一些特征，不要那么多输入特征信息，从而减少这个gap（特征工程来删除冗余特征）；或者说输入分解很多个特征，让输出一一拟合他们；所以识别模型容易过拟合？所以识别模型可以往简单地靠，可能参数量越多层数越多反而效果越不好？</p>
]]></content>
      <categories>
        <category>语音合成</category>
      </categories>
      <tags>
        <tag>语音合成</tag>
      </tags>
  </entry>
  <entry>
    <title>使用互斥锁实现线程同步</title>
    <url>/2023/02/23/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E4%BD%BF%E7%94%A8%E4%BA%92%E6%96%A5%E9%94%81%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<h1 id="使用互斥锁实现线程同步"><a href="#使用互斥锁实现线程同步" class="headerlink" title="使用互斥锁实现线程同步"></a>使用互斥锁实现线程同步</h1><blockquote>
<p>c语言中文网：<a href="http://c.biancheng.net/thread/vip_8615.html">使用互斥锁实现线程同步</a></p>
</blockquote>
<p>互斥锁实现多线程同步的核心思想是：有线程访问进程空间中的公共资源时，该线程执行“加锁”操作（将资源“锁”起来），阻止其它线程访问。访问完成后，该线程负责完成“解锁”操作，将资源让给其它线程。当有多个线程想访问资源时，谁最先完成“加锁”操作，谁就最先访问资源。</p>
<blockquote>
<p>当有多个线程想访问“加锁”状态下的公共资源时，它们只能等待资源“解锁”，所有线程会排成一个&#x3D;&#x3D;等待（阻塞）队列&#x3D;&#x3D;。资源解锁后，&#x3D;&#x3D;操作系统会唤醒等待队列中的所有线程，第一个访问资源的线程会率先将资源“锁”起来，其它线程则继续等待。&#x3D;&#x3D;</p>
</blockquote>
<p>本质上，<strong>互斥锁就是一个全局变量</strong>，它只有 “lock” 和 “unlock” 两个值，含义分别是：</p>
<ul>
<li>“unlock” 表示当前资源可以访问，第一个访问资源的线程负责将互斥锁的值改为 “lock”，访问完成后再重置为“unlock”；</li>
<li>“lock” 表示有线程正在访问资源，其它线程需等待互斥锁的值为 “unlock” 后才能开始访问。</li>
</ul>
<p>通过对资源进行 “加锁（lock）”和 “解锁（unlock）”，可以确保同一时刻最多有 1 个线程访问该资源，从根本上避免了“多线程抢夺资源”的情况发生。</p>
<p>再次强调，对资源进行“加锁”和“解锁”操作的必须是同一个线程。换句话说，哪个线程对资源执行了“加锁”操作，那么“解锁”操作也必须由该线程负责。</p>
<h2 id="互斥锁的用法"><a href="#互斥锁的用法" class="headerlink" title="互斥锁的用法"></a>互斥锁的用法</h2><p>POSIX 标准规定，用 pthread_mutex_t 类型的变量来表示一个互斥锁，该类型以结构体的形式定义在<code>&lt;pthread.h&gt;</code>头文件中。举个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">pthread_mutex_t</span> myMutex;</span><br></pre></td></tr></table></figure>

<p>我们成功地定义了一个名为 myMutex 的互斥锁，但要想使用它，还要进行初始化操作。</p>
<h4 id="1-互斥锁的初始化"><a href="#1-互斥锁的初始化" class="headerlink" title="1) 互斥锁的初始化"></a>1) 互斥锁的初始化</h4><p>初始化 pthread_mutex_t 变量的方式有两种，分别为：</p>
<ol>
<li>使用特定的宏 <code>PTHREAD_MUTEX_INITIALIZER</code></li>
<li>调用初始化的函数 <code>pthread_mutex_init()</code></li>
</ol>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、使用特定的宏</span></span><br><span class="line"><span class="type">pthread_mutex_t</span> myMutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2、调用初始化的函数</span></span><br><span class="line"><span class="type">pthread_mutex_t</span> myMutex;</span><br><span class="line">pthread_mutex_init(&amp;myMutex , <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure>

<p>以上两种初始化方式是完全等价的，PTHREAD_MUTEX_INITIALIZER 宏和 pthread_mutex_init() 函数都定义在 &lt;pthread.h&gt; 头文件中，它们的主要区别在于：</p>
<ul>
<li>pthread_mutex_init() 函数可以自定义互斥锁的属性（具体自定义的方法，这里不再进行讲解）。</li>
<li>对于调用 malloc() 函数分配动态内存的互斥锁，只能以第 2 种方法完成初始化；</li>
</ul>
<p>pthread_mutex_init() 函数专门用于初始化互斥锁，语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_mutex_init</span><span class="params">(<span class="type">pthread_mutex_t</span> *mutex, <span class="type">const</span> <span class="type">pthread_mutexattr_t</span> *attr)</span>;</span><br></pre></td></tr></table></figure>

<p>mutex 参数表示要初始化的互斥锁；attr 参数用于自定义新建互斥锁的属性，attr 的值为 NULL 时表示以默认属性创建互斥锁。</p>
<p>pthread_mutex_init() 函数成功完成初始化操作时，返回数字 0；如果初始化失败，函数返回非零数。</p>
<blockquote>
<p>注意，不能对一个已经初始化过的互斥锁再进行初始化操作，否则会导致程序出现无法预料的错误。</p>
</blockquote>
<h4 id="2-互斥锁的“加锁”和“解锁”"><a href="#2-互斥锁的“加锁”和“解锁”" class="headerlink" title="2) 互斥锁的“加锁”和“解锁”"></a>2) 互斥锁的“加锁”和“解锁”</h4><p>对于互斥锁的“加锁”和“解锁”操作，常用的函数有以下 3 种：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_mutex_lock</span><span class="params">(<span class="type">pthread_mutex_t</span>* mutex)</span>;   <span class="comment">//实现加锁</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_mutex_trylock</span><span class="params">(<span class="type">pthread_mutex_t</span>* mutex)</span>;  <span class="comment">//实现加锁</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_mutex_unlock</span><span class="params">(<span class="type">pthread_mutex_t</span>* mutex)</span>;   <span class="comment">//实现解锁</span></span><br></pre></td></tr></table></figure>

<p>参数 mutex 表示我们要操控的互斥锁。函数执行成功时返回数字 0，否则返回非零数。</p>
<p>pthread_mutex_unlock() 函数用于对指定互斥锁进行“解锁”操作，pthread_mutex_lock() 和 pthread_mutex_trylock() 函数都用于实现“加锁”操作，不同之处在于当互斥锁已经处于“加锁”状态时：</p>
<ul>
<li><p>执行 pthread_mutex_lock() 函数会使线程进入等待（阻塞）状态，直至互斥锁得到释放；</p>
</li>
<li><p>执行 pthread_mutex_trylock() 函数不会阻塞线程，直接返回非零数（表示加锁失败）。</p>
</li>
</ul>
<h4 id="3-互斥锁的销毁"><a href="#3-互斥锁的销毁" class="headerlink" title="3) 互斥锁的销毁"></a>3) 互斥锁的销毁</h4><p>对于使用动态内存创建的互斥锁，例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">pthread_mutex_t</span> myMutex = (<span class="type">pthread_mutex_t</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">pthread_mutex_t</span>));pthread_mutex_init(&amp;myMutex , <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure>

<p>手动释放 myMutex 占用的内存（调用 free() 函数）之前，必须先调用 pthread_mutex_destory() 函数销毁该对象。</p>
<p>pthread_mutex_destory() 函数用于销毁创建好的互斥锁，语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_mutex_destroy</span><span class="params">(<span class="type">pthread_mutex_t</span> *mutex)</span>;</span><br></pre></td></tr></table></figure>

<p>参数 mutex 表示要销毁的互斥锁。如果函数成功销毁指定的互斥锁，返回数字 0，反之返回非零数。</p>
<p>对于这个例子，销毁操作为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> res;</span><br><span class="line">res = pthread_mutex_destroy(&amp;myMutex);</span><br></pre></td></tr></table></figure>



<blockquote>
<p>注意，对于用 PTHREAD_MUTEX_INITIALIZER 或者 pthread_mutex_init() 函数直接初始化的互斥锁，无需调用 pthread_mutex_destory() 函数手动销毁。</p>
<p>只有malloc新建互斥锁对象的需要销魂</p>
</blockquote>
<h2 id="互斥锁的实际应用"><a href="#互斥锁的实际应用" class="headerlink" title="互斥锁的实际应用"></a>互斥锁的实际应用</h2><p>接下来，我们使用互斥锁对《<a href="http://c.biancheng.net/thread/vip_8614.html">线程同步机制</a>》一节中模拟“4 个售票员卖 10 张票”的程序进行改良，如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> ticket_sum = <span class="number">10</span>;</span><br><span class="line"><span class="comment">//创建互斥锁</span></span><br><span class="line"><span class="type">pthread_mutex_t</span> myMutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"><span class="comment">//模拟售票员卖票</span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">sell_ticket</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    <span class="comment">//输出当前执行函数的线程 ID</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;当前线程ID：%u\n&quot;</span>, pthread_self());</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="type">int</span> islock = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//当前线程“加锁”</span></span><br><span class="line">        islock = pthread_mutex_lock(&amp;myMutex);</span><br><span class="line">        <span class="comment">//如果“加锁”成功，执行如下代码</span></span><br><span class="line">        <span class="keyword">if</span> (islock == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">//如果票数 &gt;0 ,开始卖票</span></span><br><span class="line">            <span class="keyword">if</span> (ticket_sum &gt; <span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                sleep(<span class="number">1</span>);</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%u 卖第 %d 张票\n&quot;</span>, pthread_self(), <span class="number">10</span> - ticket_sum + <span class="number">1</span>);</span><br><span class="line">                ticket_sum--;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//当前线程模拟完卖票过程，执行“解锁”操作</span></span><br><span class="line">            pthread_mutex_unlock(&amp;myMutex);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> flag;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="type">void</span> *ans;</span><br><span class="line">    <span class="comment">//创建 4 个线程，模拟 4 个售票员</span></span><br><span class="line">    <span class="type">pthread_t</span> tids[<span class="number">4</span>];</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        flag = pthread_create(&amp;tids[i], <span class="literal">NULL</span>, &amp;sell_ticket, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="keyword">if</span> (flag != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败!&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    sleep(<span class="number">10</span>);   <span class="comment">//等待 4 个线程执行完成</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//阻塞主线程，确认 4 个线程执行完成</span></span><br><span class="line">        flag = pthread_join(tids[i], &amp;ans);</span><br><span class="line">        <span class="keyword">if</span> (flag != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;tid=%d 等待失败！&quot;</span>, tids[i]);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">当前线程ID：149493504</span><br><span class="line">当前线程ID：170473216</span><br><span class="line">当前线程ID：159983360</span><br><span class="line">当前线程ID：139003648</span><br><span class="line">149493504 卖第 1 张票</span><br><span class="line">149493504 卖第 2 张票</span><br><span class="line">149493504 卖第 3 张票</span><br><span class="line">139003648 卖第 4 张票</span><br><span class="line">139003648 卖第 5 张票</span><br><span class="line">139003648 卖第 6 张票</span><br><span class="line">139003648 卖第 7 张票</span><br><span class="line">139003648 卖第 8 张票</span><br><span class="line">159983360 卖第 9 张票</span><br><span class="line">159983360 卖第 10 张票</span><br></pre></td></tr></table></figure>

<p>程序中共创建了 4 个线程，每个线程“开始卖票”前都会进行“加锁”操作（第 17 行），“卖票结束”后再执行“解锁”操作（第 28 行）。通过执行结果可以看到，互斥锁很好地解决了“线程间竞争资源”的问题，实现了线程同步。</p>
<h2 id="chatgpt：C-互斥锁教程"><a href="#chatgpt：C-互斥锁教程" class="headerlink" title="chatgpt：C++互斥锁教程"></a>chatgpt：C++互斥锁教程</h2><blockquote>
<p>chatgpt：C++互斥锁教程</p>
</blockquote>
<p>在 C++ 中使用互斥锁（mutex）可以保证线程安全，避免竞态条件和数据竞争等问题。下面是一个简单的互斥锁使用示例：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::mutex g_mutex;  <span class="comment">// 全局互斥锁</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">print</span><span class="params">(<span class="type">int</span> num)</span></span><br><span class="line">&#123;</span><br><span class="line">    g_mutex.lock();  <span class="comment">// 上锁</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;Thread &quot;</span> &lt;&lt; num &lt;&lt; <span class="string">&quot; is printing.&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    g_mutex.unlock();  <span class="comment">// 解锁</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">std</span>::thread <span class="title function_">t1</span><span class="params">(print, <span class="number">1</span>)</span>;</span><br><span class="line">    <span class="built_in">std</span>::thread <span class="title function_">t2</span><span class="params">(print, <span class="number">2</span>)</span>;</span><br><span class="line">    t1.join();</span><br><span class="line">    t2.join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这个例子中，我们定义了一个全局互斥锁 <code>g_mutex</code>，并在 <code>print</code> 函数中使用了它来保护输出操作。在 <code>print</code> 函数中，先调用 <code>g_mutex.lock()</code> 上锁，执行输出操作，最后调用 <code>g_mutex.unlock()</code> 解锁。</p>
<p>在 <code>main</code> 函数中，我们创建了两个线程 <code>t1</code> 和 <code>t2</code>，分别调用 <code>print</code> 函数，并使用 <code>join()</code> 函数等待线程结束。</p>
<p>使用互斥锁时需要注意以下事项：</p>
<ol>
<li>互斥锁的生命周期应该尽量短，以避免锁的持有时间过长，影响程序性能。</li>
<li>在需要共享数据的线程中，需要使用相同的互斥锁来保护共享数据。</li>
<li>在使用互斥锁时，要注意避免死锁和饥饿等问题。</li>
<li>可以使用 RAII 技术来管理互斥锁，以避免忘记解锁而导致的死锁问题。</li>
<li>C++11 中提供了更加灵活和高效的锁，如 <code>std::unique_lock</code>、<code>std::shared_lock</code> 和 <code>std::lock_guard</code> 等，可以根据实际情况选择适合的锁类型。</li>
</ol>
<p>这是互斥锁的简单介绍，如果需要更深入的了解，可以参考 C++ 的相关文档或教程。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>使用C++11进行多线程编程</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E4%BD%BF%E7%94%A8C++11%E8%BF%9B%E8%A1%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="使用C-11进行多线程编程"><a href="#使用C-11进行多线程编程" class="headerlink" title="使用C++11进行多线程编程"></a>使用C++11进行多线程编程</h1><blockquote>
<p>C语言中文网：<a href="http://c.biancheng.net/thread/vip_8622.html">使用C++11进行多线程编程</a>   </p>
</blockquote>
<p>前面章节中，我们借助操作系统提供的接口实现了 C 语言多线程程序的编写。C++ 11 标准中新引入了与多线程编程相关的多个头文件，包括 <thread>、<mutex>、<future>、<condition_variable> 和 <atomic>。</atomic></condition_variable></future></mutex></thread></p>
<p>当我们在 Linux 环境中编写 C++ 的多线程程序时，既可以借助 POSIX 标准提供的 &lt;pthread.h&gt; 实现，也可以借助 C++11 标准提供的头文件实现。本节，我们就给大家详细地讲解如何利用 C++11 标准编写多线程程序。</p>
<h2 id="线程的创建和使用"><a href="#线程的创建和使用" class="headerlink" title="线程的创建和使用"></a>线程的创建和使用</h2><p>C++11 标准中，<code>&lt;thread&gt;</code>头文件提供了 thread 类（位于 std 命令空间中），专门用来完成线程的创建和使用。</p>
<p><code>thread.h</code> 比 <code>pthread.h</code> 常用的多！</p>
<h4 id="1-创建线程"><a href="#1-创建线程" class="headerlink" title="1) 创建线程"></a>1) 创建线程</h4><p>一个线程可以用 thread 类的对象来表示，thread类中重载了多种构造函数，最常用的有以下两个：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、Fn 表示线程要执行的函数，args 表示向 Fn 传递的多个参数，此构造函数支持泛型</span></span><br><span class="line">template &lt;<span class="class"><span class="keyword">class</span> <span class="title">Fn</span>, <span class="title">class</span>... <span class="title">Args</span>&gt;</span></span><br><span class="line">explicit <span class="title function_">thread</span> <span class="params">(Fn&amp;&amp; fn, Args&amp;&amp;... args)</span>;</span><br><span class="line"><span class="comment">//2、移动构造函数</span></span><br><span class="line">thread (thread&amp;&amp; x) noexcept;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意，thread 类只提供了移动构造函数，未提供拷贝构造函数。这意味着，我们不能直接将一个事先定义好的 thread 对象赋值给另一个 thread 对象，但可以将临时的（匿名的）thread 对象赋值给另一个 thread 对象。有关移动构造函数，读者可阅读《<a href="http://c.biancheng.net/view/7847.html">C++11移动构造函数详解</a>》一文做详细了解。</p>
</blockquote>
<p>POSIX 标准中，线程所执行函数的参数和返回值都必须为 void* 类型。而 thread 类创建的线程可以执行任意的函数，即不对函数的参数和返回值做具体限定。</p>
<p>举个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">threadFun1</span><span class="params">(<span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;---thread1 running\n&quot;</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;n=&quot;</span> &lt;&lt; n &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">threadFun2</span><span class="params">(<span class="type">const</span> <span class="type">char</span> * url)</span> &#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;---thread2 running\n&quot;</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;url=&quot;</span> &lt;&lt; url &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//调用第 1 种构造函数</span></span><br><span class="line">    thread <span class="title function_">thread1</span><span class="params">(threadFun1,<span class="number">10</span>)</span>;</span><br><span class="line">    <span class="comment">//调用移动构造函数</span></span><br><span class="line">    thread thread2 = <span class="built_in">std</span>::thread(threadFun2,<span class="string">&quot;http://c.biancheng.net&quot;</span>);</span><br><span class="line">    <span class="comment">//阻塞主线程，等待 thread1 线程执行完毕</span></span><br><span class="line">    thread1.join();</span><br><span class="line">    <span class="comment">//阻塞主线程，等待 thread2 线程执行完毕</span></span><br><span class="line">    thread2.join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序执行结果为（不唯一）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---thread1 running</span><br><span class="line">n=10</span><br><span class="line">---thread2 running</span><br><span class="line">url=http://c.biancheng.net</span><br></pre></td></tr></table></figure>



<p>程序中，我们分别调用两种构造函数创建了两个线程，它们分别执行 threadFun1() 和 threadFun2() 函数。我们在主线程（main() 函数）中调用了 thread 类提供的 join() 成员函数，以 thread1.join() 为例，它的功能是阻塞主线程，直至 thread1 线程执行完毕后，主线程才能继续执行。</p>
<h4 id="2-线程的使用"><a href="#2-线程的使用" class="headerlink" title="2) 线程的使用"></a>2) 线程的使用</h4><p>除了 join() 成员函数外，thread 类还提供有很多实用的成员函数，表 1 给大家列出了几个最常用的函数：</p>
<p>表 1 thread 类的常用成员函数：</p>
<table>
<thead>
<tr>
<th>成员函数</th>
<th>功 能</th>
</tr>
</thead>
<tbody><tr>
<td>get_id()</td>
<td>获取当前 thread 对象的线程 ID。</td>
</tr>
<tr>
<td>joinable()</td>
<td>判断当前线程是否支持调用 join() 成员函数。</td>
</tr>
<tr>
<td>join()</td>
<td>阻塞当前 thread 对象所在的线程，直至 thread 对象表示的线程执行完毕后，所在线程才能继续执行。</td>
</tr>
<tr>
<td>detach()</td>
<td>将当前线程从调用该函数的线程中分离出去，它们彼此独立执行。</td>
</tr>
<tr>
<td>swap()</td>
<td>交换两个线程的状态。</td>
</tr>
</tbody></table>
<p>注意，每个thread 对象在调用析构函数销毁前，要么调用 join() 函数令主线程等待子线程执行完成，要么调用 detach() 函数将子线程和主线程分离，两者比选其一，否则程序可能存在以下两个问题：</p>
<ul>
<li>&#x3D;&#x3D;线程占用的资源将无法全部释放，造成内存泄漏；&#x3D;&#x3D;</li>
<li>&#x3D;&#x3D;当主线程执行完成而子线程未执行完时，程序执行将引发异常。&#x3D;&#x3D;</li>
</ul>
<p>举个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">threadFun1</span><span class="params">(<span class="type">int</span> n)</span> &#123;</span><br><span class="line">    sleep(<span class="number">5</span>);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;---thread1 running\n&quot;</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;n=&quot;</span> &lt;&lt; n &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">threadFun2</span><span class="params">(<span class="type">const</span> <span class="type">char</span> * url)</span> &#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;---thread2 running\n&quot;</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;url=&quot;</span> &lt;&lt; url &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//调用第 1 种构造函数</span></span><br><span class="line">    thread <span class="title function_">thread1</span><span class="params">(threadFun1, <span class="number">10</span>)</span>;</span><br><span class="line">    <span class="comment">//输出 thread1 线程的 ID</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;thread1 ID:&quot;</span> &lt;&lt; thread1.get_id() &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">//调用移动构造函数</span></span><br><span class="line">    thread thread2 = <span class="built_in">std</span>::thread(threadFun2, <span class="string">&quot;http://c.biancheng.net&quot;</span>);</span><br><span class="line">    <span class="comment">//输出 thread2 线程的 ID</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;thread2 ID:&quot;</span> &lt;&lt; thread2.get_id() &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">//将 thread1 与主线程分离开，thread1 线程独立执行。</span></span><br><span class="line">    thread1.detach();</span><br><span class="line">    <span class="comment">//判断 thread2 线程是否可以调用 join() 函数</span></span><br><span class="line">    <span class="keyword">if</span> (thread2.joinable()) &#123;</span><br><span class="line">        <span class="comment">//阻塞主线程，直至 thread2 线程执行完毕。</span></span><br><span class="line">        thread2.join();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;main finished&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.cpp 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># g++ thread.cpp -o thread.exe -std=c++11 -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">thread1 ID:140278776624896</span><br><span class="line">thread2 ID:140278768232192</span><br><span class="line">---thread2 running</span><br><span class="line">url=http://c.biancheng.net</span><br><span class="line">main finished</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果在 Windows 环境中运行，将程序中引入的 &lt;unistd.h&gt; 头文件改为 &lt;Windows.h&gt;，将第 6 行的 sleep(5); 语句改为 Sleep(5); 语句即可。</p>
</blockquote>
<p>程序中创建了 2 个线程，通过调用 get_id() 成员函数分别获得了它们的线程 ID，其中 thread1 线程独立执行，thread2 线程先于主线程执行完成。通过执行结果可以看到，thread1 线程的执行结果并没有显示到屏幕上，这是因为 thread1 线程还未执行输出语句，主线程就已经执行结束（整个进程也执行结束），thread1 线程无法将执行结果输出到屏幕上。</p>
<p><code>&lt;thread&gt;</code>头文件中不仅定义了 thread 类，还提供了一个名为 this_thread 的命名空间，此空间中包含一些功能实用的函数，如表 2 所示</p>
<p>表 2 this_thread命名空间常用函数：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>功 能</th>
</tr>
</thead>
<tbody><tr>
<td>get_id()</td>
<td>获得当前线程的 ID。</td>
</tr>
<tr>
<td>yield()</td>
<td>阻塞当前线程，直至条件成熟。</td>
</tr>
<tr>
<td>sleep_until()</td>
<td>阻塞当前线程，直至某个时间点为止。</td>
</tr>
<tr>
<td>sleep_for()</td>
<td>阻塞当前线程指定的时间（例如阻塞 5 秒）。</td>
</tr>
</tbody></table>
<blockquote>
<p>有关表 2 中这些函数的用法，我们不再一一举例，感兴趣的读者可查阅 C++ 函数手册。</p>
</blockquote>
<h2 id="实现线程同步"><a href="#实现线程同步" class="headerlink" title="实现线程同步"></a>实现线程同步</h2><p>C++ 11 标准为解决“线程间抢夺公共资源”提供了多种方案，其中就包括我们前面讲到的互斥锁和条件变量。</p>
<h4 id="1-互斥锁"><a href="#1-互斥锁" class="headerlink" title="1) 互斥锁"></a>1) 互斥锁</h4><blockquote>
<p>有关互斥锁实现线程同步的原理，这里不再赘述，您可以阅读《<a href="http://c.biancheng.net/thread/vip_8615.html">Linux互斥锁实现线程同步</a>》一文做详细了解。</p>
</blockquote>
<p>考虑到不同场景的需要，C++ 11 标准提供有多种互斥锁，比如递归互斥锁、定时互斥锁，自动“加锁”和“解锁”的互斥锁等。本节我们以普通的互斥锁为例，给大家讲解互斥锁的基本用法。</p>
<p>C++11标准规定，互斥锁用 mutex 类（位于 std 命名空间中）的对象表示，该类定义在<code>&lt;mutex&gt;</code>头文件中。mutex 类提供有 lock() 和 unlock() 成员函数，分别完成“加锁”和“解锁”功能。</p>
<p>举个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span>          <span class="comment">// std::mutex</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;chrono&gt;</span>         <span class="comment">// std::chrono::seconds()</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">int</span>  n = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">std</span>::mutex mtx;           <span class="comment">// 定义一个 mutex 类对象，创建一个互斥锁</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">threadFun</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">while</span>(n&lt;<span class="number">10</span>)&#123;</span><br><span class="line">        <span class="comment">//对互斥锁进行“加锁”</span></span><br><span class="line">        mtx.lock();</span><br><span class="line">        n++;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;ID&quot;</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">&quot; n = &quot;</span>&lt;&lt; n &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="comment">//对互斥锁进行“解锁”</span></span><br><span class="line">        mtx.unlock();</span><br><span class="line">        <span class="comment">//暂停 1 秒</span></span><br><span class="line">        <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    thread <span class="title function_">th1</span><span class="params">(threadFun)</span>;</span><br><span class="line">    thread <span class="title function_">th2</span><span class="params">(threadFun)</span>;</span><br><span class="line">    th1.join();</span><br><span class="line">    th2.join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序执行结果为（不唯一）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ID16064 n = 1</span><br><span class="line">ID1956 n = 2</span><br><span class="line">ID16064 n = 3</span><br><span class="line">ID1956 n = 4</span><br><span class="line">ID16064 n = 5</span><br><span class="line">ID1956 n = 6</span><br><span class="line">ID16064 n = 7</span><br><span class="line">ID1956 n = 8</span><br><span class="line">ID16064 n = 9</span><br><span class="line">ID1956 n = 10</span><br></pre></td></tr></table></figure>



<p>程序中，访问公共变量 n 的线程有 2 个，为了避免它们之间竞争资源，我们对 threadFun() 函数中访问 n 变量的过程引入了互斥锁机制。</p>
<h4 id="2-条件变量"><a href="#2-条件变量" class="headerlink" title="2) 条件变量"></a>2) 条件变量</h4><p>有关条件变量实现线程同步的原理，这里不再赘述，您可以阅读《<a href="http://c.biancheng.net/thread/vip_8617.html">Linux条件变量实现线程同步</a>》一文做详细了解。</p>
<p>C++ 11标准提供了两种表示条件变量的类，分别是 condition_variable 和 condition_variable_any，它们都定义在<code>&lt;condition_variable&gt;</code>头文件中。我们知道，为了避免线程间抢夺资源，条件变量通常和互斥锁搭配使用，condition_variable 类表示的条件变量只能和 unique_lock 类表示的互斥锁（可自行加锁和解锁）搭配使用，而 condition_variable_any 类表示的条件变量可以和任意类型的互斥锁搭配使用（例如递归互斥锁、定时互斥锁等）。</p>
<p>这里我们以 condition_variable_any 为例，给大家讲解 C++11 标准中条件变量的基本用法。每个 condition_variable_any 类的对象都表示一个条件变量，该类提供的成员函数如表 3 所示。</p>
<p>表 3 条件变量常用函数：</p>
<table>
<thead>
<tr>
<th>成员函数</th>
<th>功 能</th>
</tr>
</thead>
<tbody><tr>
<td>wait()</td>
<td>阻塞当前线程，等待条件成立。</td>
</tr>
<tr>
<td>wait_for()</td>
<td>阻塞当前线程的过程中，该函数会自动调用 unlock() 函数解锁互斥锁，从而令其他线程使用公共资源。当条件成立或者超过了指定的等待时间（比如 3 秒），该函数会自动调用 lock() 函数对互斥锁加锁，同时令线程继续执行。</td>
</tr>
<tr>
<td>wait_until()</td>
<td>和 wait_for() 功能类似，不同之处在于，wait_until() 函数可以设定一个具体时间点（例如 2021年4月8日 的某个具体时间），当条件成立或者等待时间超过了指定的时间点，函数会自动对互斥锁加锁，同时线程继续执行。</td>
</tr>
<tr>
<td>notify_one()</td>
<td>向其中一个正在等待的线程发送“条件成立”的信号。</td>
</tr>
<tr>
<td>notify_all()</td>
<td>向所有等待的线程发送“条件成立”的信号。</td>
</tr>
</tbody></table>
<p>举个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;thread&gt;             // std::thread</span><br><span class="line">#include &lt;mutex&gt;              // std::mutex, std::unique_lock</span><br><span class="line">#include &lt;condition_variable&gt; // std::condition_variable_any</span><br><span class="line">#include &lt;chrono&gt;         // std::chrono::seconds()</span><br><span class="line">//创建一个互斥锁</span><br><span class="line">std::mutex mtx;</span><br><span class="line">//创建一个条件变量</span><br><span class="line">std::condition_variable_any cond;</span><br><span class="line">void print_id() &#123;</span><br><span class="line">    mtx.lock();</span><br><span class="line">    //阻塞线程，直至条件成立</span><br><span class="line">    cond.wait(mtx);</span><br><span class="line">    std::cout &lt;&lt; &quot;----threadID &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt;&quot; run&quot; &lt;&lt; std::endl;</span><br><span class="line">    //等待 2 秒</span><br><span class="line">    std::this_thread::sleep_for(std::chrono::seconds(2));</span><br><span class="line">    mtx.unlock();</span><br><span class="line">&#125;</span><br><span class="line">void go() &#123;</span><br><span class="line">    std::cout &lt;&lt; &quot;go running\n&quot;;</span><br><span class="line">    //阻塞线程 2 秒钟</span><br><span class="line">    std::this_thread::sleep_for(std::chrono::seconds(2));</span><br><span class="line">    //通知所有等待的线程条件成立</span><br><span class="line">    cond.notify_all();</span><br><span class="line">&#125;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    //创建 4 个线程执行 print_id() 函数</span><br><span class="line">    std::thread threads[4];</span><br><span class="line">    for (int i = 0; i &lt; 4; ++i)</span><br><span class="line">        threads[i] = std::thread(print_id);</span><br><span class="line">    //创建 1 个线程执行 go() 函数</span><br><span class="line">    std::thread goThread(go);</span><br><span class="line">    //等待所有线程执行结果后，主线程才能继续执行</span><br><span class="line">    goThread.join();</span><br><span class="line">    for (auto&amp; th : threads) &#123;</span><br><span class="line">        th.join();</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>执行结果为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">go running</span><br><span class="line">----threadID 11416 run</span><br><span class="line">----threadID 18696 run</span><br><span class="line">----threadID 11268 run</span><br><span class="line">----threadID 16824 run</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>端到端合成论文——声码器——HiFi-GAN</title>
    <url>/2022/11/23/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(7)/</url>
    <content><![CDATA[<h1 id="端到端合成论文——声码器——HiFi-GAN"><a href="#端到端合成论文——声码器——HiFi-GAN" class="headerlink" title="端到端合成论文——声码器——HiFi-GAN"></a>端到端合成论文——声码器——HiFi-GAN</h1><blockquote>
<p>Kong, Jungil, Jaehyeon Kim, and Jaekyoung Bae. “Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis.” <em>Advances in Neural Information Processing Systems</em> 33 (2020): 17022-17033. citations：476 韩国的kakao多音通讯</p>
<p>github：<a href="https://github.com/jik876/hifi-gan">https://github.com/jik876/hifi-gan</a></p>
<p>试听音频：<a href="https://jik876.github.io/hifi-gan-demo/">https://jik876.github.io/hifi-gan-demo/</a></p>
<p>声码器HiFiGAN的结构和训练.pptx</p>
</blockquote>
<h4 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h4><ul>
<li>解决了之前基于GAN生成波形的vocoder，效果不如基于自回归或基于flow的vocoder的问题；</li>
</ul>
<h4 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h4><ul>
<li>提出了HiFi-GAN语音合成声码器，基于GAN，输出高保真音质，合成计算效率高，速度快；</li>
<li>由于语音由具有不同周期的正弦信号组成，证明了建模音频的周期模式对提高音质至关重要；用了多周期的判别器，并用多尺度判别器进行平滑，也是学习不同频段；</li>
</ul>
<h4 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h4><ul>
<li><p>合成质量优于基于自回归的wavenet和基于flow的waveglow；</p>
</li>
<li><p>合成速度在V100 CPU上为3.7MHz；</p>
</li>
<li><p>输入噪声，能合成出训练集没有的说话人音色；</p>
</li>
<li><p>小模型的前提下（0.92M 参数量），相同模型下能达到自回归方法的相同音质，并且在CPU上的合成速度比自回归快十几倍；</p>
</li>
<li><p>使用相同的判别器D和学习机制可以训练不同配置的生成器G，这表明可以根据目标配置灵活选择生成器配置，而不需要对判别器进行耗时的超参数搜索。也就是说判别器很通用，训好一个就可以适用于多个生成器，节省了判别器的训练时间，以及GAN整体的训练时间；</p>
</li>
</ul>
<h4 id="还有什么问题"><a href="#还有什么问题" class="headerlink" title="还有什么问题"></a>还有什么问题</h4><ul>
<li>这么多loss好收敛吗？</li>
<li>音质还能提高吗？</li>
<li>训练多久才能训好？</li>
<li>感受野多大，有延迟吗？</li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>之前的vocoder模型有基于自回归的wavenet，但是自回归方法合成速度慢；然后是基于flow的生成模型parallel wavenet（IAF model）、waveglow；然后是基于GAN的生成模型melgan、clarinet、GAN-TTS，但基于GAN的这几个模型音质没有基于自回归或flow来得好；</p>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>提出一个基于GAN的vocoder，计算效率高，合成音频质量优于自回归或flow的方法；</p>
<p>相比于之前相近的 MelGAN，改进点在于：</p>
<ol>
<li>引入了多周期判别器（Multi-Period Discriminator， MPD）。 HiFiGAN 同时拥有多尺度判别器（Multi-Scale Discriminator， MSD）和多周期判别器，尽可能增强 GAN 判别器甄别合成或真实音频的能力，从而提升合成音质。</li>
<li>生成器中提出了多感受野融合模块。 WaveNet 为了增大感受野，叠加带洞卷积，音质虽然很好，但是也使得模型较大，推理速度较慢。 HiFiGAN 则提出了一种残差结构，交替使用带洞卷积和普通卷积增大感受野，保证合成音质的同时，提高推理速度。</li>
</ol>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>考虑到语音是由多个不同周期的正弦波组成的，因此把GAN的判别器用一组子判别器组成，每个子判别器负责一部分周期信号的建模（对音频抽取不同周期分量，每个判别器只判别其中一个分量）；GAN的生成器结构是由不同长度的残差块组成，不同长度的输出对应到不同的判别器；</p>
<p>HiFiGAN由一个生成器和两类判别器组成，两类判别器分别是多尺度（multi-scale）和多周期（multi-period）判别器；</p>
<h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>输入mel谱，噪声不作为额外输入；结构全用卷积组成，通过 **transposed convolutions **进行上采样（帧-&gt;采样点），直到输出序列的长度与原始波形的时间分辨率相匹配；transposed convolution 后接多融合感受野（multi-receptive field fusion (MRF)）  模块；</p>
<p>生成器结构：</p>
<p><img src="/2022/11/23/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(7)/image-20221122160018783.png" alt="image-20221122160018783"></p>
<h4 id="转置卷积-Transposed-convolutions"><a href="#转置卷积-Transposed-convolutions" class="headerlink" title="转置卷积 Transposed convolutions"></a>转置卷积 Transposed convolutions</h4><p>转置卷积我的理解是python的broadcast过程，每个点都和卷积核乘一遍，得到对应位置的卷积核大小的矩阵，再求和；它的输入输出长度关系和普通卷积的输入输出长度关系反过来；</p>
<p>输入比如[80,1]维mel谱（一帧），输出比如[1,256]的波形，输出256个采样点？那么给生成器的输入是按帧送入，还是可以多帧一起送入？TODO？；</p>
<p>mel长度*帧移 &#x3D; 音频长度；帧移(hopsize)大小设置为256， 那么对应的mel长度需要上采样 256倍；</p>
<p>如果需要完成张量[80,1]到[1,256]上采样256倍，可以依次执行ConvTranspose1d(80, 1, kernel_size&#x3D;(32,), stride&#x3D;(16,), padding&#x3D;(8,)) 输出[1,16]、ConvTranspose1d(1, 1, kernel_size&#x3D;(32,), stride&#x3D;(16,), padding&#x3D;(8,)) 输出[1,256]；</p>
<h4 id="多融合感受野-Multi-Receptive-Field-Fusion-（MRF）"><a href="#多融合感受野-Multi-Receptive-Field-Fusion-（MRF）" class="headerlink" title="多融合感受野 Multi-Receptive Field Fusion  （MRF）"></a>多融合感受野 Multi-Receptive Field Fusion  （MRF）</h4><p>残差块residual block中的kernel sizes 和 dilation rates 都是不同的（为了得到不同的感受野），然后求和；多个MRF再求和；</p>
<p>多融合感受野(MRF)对于波形生成的作用：</p>
<ol>
<li>残差网络中不同的kernel_size，意义在于用不同大小的窗口去提取mel-spectrogram的原始信息；</li>
<li>带洞卷积使得即使是在时间步上较远距离的输出，也有更多的相同输入，解决较长时间步长上数据的依赖性（使用带洞卷积增大感受野，较长时间步长上数据的依赖性：例如一个音素的时长为100ms时，就会使得2200个采样点具有较高的相关性）；</li>
</ol>
<p><img src="/2022/11/23/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(7)/image-20221122171756674.png" alt="image-20221122171756674"></p>
<p>伪代码：</p>
<p><img src="/2022/11/23/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(7)/image-20221122181229640.png" alt="image-20221122181229640"></p>
<h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><h4 id="多周期判别器-multi-period-discriminator（MPD）"><a href="#多周期判别器-multi-period-discriminator（MPD）" class="headerlink" title="多周期判别器 multi-period discriminator（MPD）"></a>多周期判别器 multi-period discriminator（MPD）</h4><p>音频的不同部分分别送入子判别器中；多周期，设置周期为[2, 3, 5, 7, 11] ，预先对其按照参数period进行等距分组； 将1维的长度为T的音频reshape到2维，高度height为T&#x2F;p，weight长度为p，其实是把1维数据转成2维了；作为判别器的输入；</p>
<p>MPD对不同范围内的频段进行学习。通过等距分组，相当于对原始信号进行了降采样，从而不同的子判别器对应不同的频率范围，假设采样频率为22k的信号（信号频率最大11k），<strong>各个子判别器对应的可学习频率范围</strong>：</p>
<p>period &#x3D; 2: 0 ~ 5.5k，period &#x3D; 3: 0 ~ 3.7k，period &#x3D; 5: 0 ~ 2.2k，period &#x3D; 7:  0 ~ 1.57k，period &#x3D; 11: 0 ~ 1k；</p>
<p>子判别器的结构为conv2d，2D卷积，卷积核weight&#x3D;1；</p>
<p>如下图，周期为3，第一行抽取的采样点为原始序列的第[1,4,7,…]，第二行抽取的采样点为原始序列的第[2,5,8,…]，第三行抽取的采样点为原始序列的第[3,6,9,…]；</p>
<p><img src="/2022/11/23/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(7)/image-20221122174539348.png" alt="image-20221122174539348"></p>
<p>还是比较巧妙的，多次利用了输入，把输入进行不同的reshape，然后放进不同的判别器中，如果我去做，可能会只会放进同一个判别器中，因此这里还有一个很重要的思路是分开了子判别器，把一个网络结构拆成多个网络，每个网络负责一部分，这个思路；而不是像我想的把网络减轻负担，输入进行拆分，然后堆叠，然后送入网络；</p>
<h4 id="多尺度判别器multi-scale-discriminator-MSD"><a href="#多尺度判别器multi-scale-discriminator-MSD" class="headerlink" title="多尺度判别器multi-scale discriminator (MSD)"></a>多尺度判别器multi-scale discriminator (MSD)</h4><p>由于MPD中的每个子鉴别器只接受不连续的样本，我们添加MSD来连续评估音频序列。提出MSD的是来自于MelGan；</p>
<p>MSD也是由多个子判别器组成，每个判别器的输入尺度不同，分别是<strong>raw audio, ×2 average-pooled audio, and ×4 average-pooled audio</strong>；</p>
<p>网络结构中归一化用的是谱归一化spectral normalization (Miyato et al., 2018)   ，使得训练更稳定；</p>
<p>可以把多尺度判别器的作用理解为平滑波形，因为多周期判别器的输出是不连续的波形，就需要进行平滑，多尺度判别器就扮演了这一角色；</p>
<p>由傅里叶变换可知，信号是由无数个正弦波信号叠加而成的，多个子判别器的设置，分别处理不同降采样倍率的信号，以学习音频中不同频段的“模式”，假设采样频率为22k（信号频率最大11k）：</p>
<p>第一个MSD判别器能采的信号频率为0 ~ 11K；第二个为0 ~ 5.5K；第三个为0 ~ 2.25K;</p>
<p>这里能改进，能做成带通滤波器吗？？</p>
<h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>主要是GAN的loss，还有两个辅助loss</p>
<ol>
<li><strong>GAN Loss</strong> 。LS-GAN，non-vanishing gradient flows  的最小二乘loss，相比于原始GAN loss，它不会有梯度消失的问题；</li>
</ol>
<p>$$<br>\mathcal{L}<em>{Adv}(D;G)&#x3D;\mathbb{E}</em>{(x,s)}\left[(D(x)-1)^2+(D(G(s)))^2\right]<br>$$</p>
<p>$$<br>\mathcal{L}_{Adv}(G;D)&#x3D;\mathbb{E}_s\left[(D(G(s))-1)^2\right]<br>$$<br>​		</p>
<p>其中，$x$ 是真实音频； $s$ 表示输入条件，即真实音频的mel谱；</p>
<ol start="2">
<li><p><strong>Mel-Spectrogram Loss</strong>  。在生成器的损失中添加mel谱loss，以提高生成器的训练效率和生成音频的保真度，因为mel谱是频域信息，添加该loss有助于捕捉时频分布，并且由于人类听觉系统的特点，也可以预期会有更侧重于提高感知质量的效果。</p>
<p>用生成器合成的波形提取的mel谱与真实波形提取的mel谱计算L1距离</p>
</li>
</ol>
<p>$$<br>\mathcal{L}<em>{Mel}(G)&#x3D;\mathbb{E}</em>{(x,s)}\left[|\phi(x)-\phi(G(s))|_1\right]<br>$$</p>
<ol start="3">
<li><strong>Feature Matching Loss</strong>   。在生成器的损失中添加 特征匹配loss，该特征来自于判别器，在判别器的网络中的每层输出（中间特征），认为具有样本的一定特征，可以进行特征的相似度度量；</li>
</ol>
<p>$$<br>\mathcal{L}<em>{FM}(G;D)&#x3D;\mathbb{E}</em>{(x, s)}\left[\sum_{i&#x3D;1}^T \frac{1}{N_i}\left|D^i(x)-D^i(G(s))\right|_1\right]<br>$$</p>
<p>​		其中，$T$ 表示判别器层数，$D^i$ 表示判别器第 $i$ 层的特征，$N_i$ 表示判别器第 $i$ 层的特征数量；</p>
<ol start="4">
<li><strong>Final Loss</strong>。 生成器和判别器的总loss组成为</li>
</ol>
<p>$$<br>\mathcal L_G &#x3D; \mathcal L_{Adv}(G; D) + λ_{fm} \mathcal L_{FM}(G; D) + λ_{mel}\mathcal L_{Mel}(G)<br>$$</p>
<p>$$<br>\mathcal L_D&#x3D;\mathcal L_{Adv}(D;G)<br>$$</p>
<p>​		设置 $\lambda_{fm}&#x3D;2$ ，$\lambda_{mel}&#x3D;45$ ；因为判别器是由一系列的子判别器MPD、MSD组成，上式可以写成子判别器的形式：<br>$$<br>\mathcal{L}<em>G &#x3D;\sum</em>{k&#x3D;1}^K\left[\mathcal{L}<em>{Adv}\left(G ; D_k\right)+\lambda</em>{f m} \mathcal{L}<em>{F M}\left(G ; D_k\right)\right]+\lambda</em>{\text {mel }} \mathcal{L}_{\text {Mel }}(G)<br>$$</p>
<p>$$<br>\mathcal{L}<em>D &#x3D;\sum</em>{k&#x3D;1}^K \mathcal{L}_{\text {Adv}}\left(D_k;G\right)<br>$$</p>
<p>​		其中，$D_k$ 表示MPD和MSD的第 $k$ 个子判别器；</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>LJSpeech  数据集</p>
<p>MOS分，合成速度：</p>
<p><img src="/2022/11/23/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(7)/image-20221123141018713.png" alt="image-20221123141018713"></p>
<p>消融实验</p>
<p><img src="/2022/11/23/%E5%90%88%E6%88%90/%E5%90%88%E6%88%90%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0(7)/image-20221123141124756.png" alt="image-20221123141124756"></p>
<p>可以看出MPD起作用要大于MSD；</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>HiFiGAN的特点：</p>
<ol>
<li>生成器上采样后采用了MRF模块，使用不同大小的卷积核提取mel-spectrogram的原始信息，对于数据中所存在的较长时间步上的依赖（一个音素涉及可能到上千的采样点），采用堆叠的带洞卷积进一步增大感受野，提升信号的生成质量。</li>
<li>相对于MelGAN, HiFiGAN在损失函数上增加了mel-spectrogram损失项，使得训练更稳定，获得了更好的音频质量。</li>
<li>语音信号由不同周期的正弦波组成，需要对不同频率尺度的信号进行建模，HiFiGAN提出了MPD模块对信号中的不同频率范围的信号进行建模，MPD会对原始信号按一定的规则进行分组，使得数据长度有所减小，所以同时使用MSD对连续的数据中存在的周期模式进行建模，从而更好的捕捉到信号中不同的周期信息。</li>
</ol>
<h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>提出一种基于GAN的vocoder，主要改进在于判别器用了多周期判别器，发现了特征的特点，就是波形是由多个正弦波组成，不同周期的正弦波直接影响音质，那么如果对每个周期正弦波都能建模好，最后音质肯定也好，出于这个角度用了多尺度和多周期判别器，比较巧妙。此外，每个判别器都是由子判别器们组成，每个子判别器都是不同的输入，这个子判别器的思路也是比较巧妙的；</p>
]]></content>
      <categories>
        <category>语音合成</category>
      </categories>
      <tags>
        <tag>语音合成</tag>
      </tags>
  </entry>
  <entry>
    <title>使用读写锁实现线程同步</title>
    <url>/2023/02/23/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E4%BD%BF%E7%94%A8%E8%AF%BB%E5%86%99%E9%94%81%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<h1 id="使用读写锁实现线程同步"><a href="#使用读写锁实现线程同步" class="headerlink" title="使用读写锁实现线程同步"></a>使用读写锁实现线程同步</h1><blockquote>
<p>C语言中文网：<a href="http://c.biancheng.net/thread/vip_8618.html">使用读写锁实现线程同步</a> </p>
</blockquote>
<p>前面章节中，我们依次介绍了使用<a href="http://c.biancheng.net/thread/vip_8615.html">互斥锁</a>、<a href="http://c.biancheng.net/thread/vip_8616.html">信号量</a>和<a href="http://c.biancheng.net/thread/vip_8617.html">条件变量</a>实现线程同步，本节讲解如何通过「读写锁」实现线程同步。</p>
<p>多线程程序中，&#x3D;&#x3D;如果仅有少数线程会对共享数据进行修改（写），多数线程只是读取共享数据的值（读），就适合用读写锁解决“线程间抢夺资源”的问题。&#x3D;&#x3D;</p>
<p>读写锁的核心思想是：将线程访问共享数据时发出的请求分为两种，分别是：</p>
<ul>
<li>读请求：只读取共享数据，不做任何修改；</li>
<li>写请求：存在修改共享数据的行为。</li>
</ul>
<p>当有多个线程发出读请求时，这些线程可以同时执行，也就是说，共享数据的值可以同时被多个发出读请求的线程获取；当有多个线程发出写请求时，这些线程只能一个一个地执行（同步执行）。此外，当发出读请求的线程正在执行时，发出写请求的线程必须等待前者执行完后才能开始执行；当发出写请求的线程正在执行时，发出读请求的线程也必须等待前者执行完后才能开始执行。</p>
<p>本质上，读写锁就是一个全局变量，发出读请求和写请求的线程都可以访问它。为了区别线程发出的请求类别，当读写锁被发出读请求的线程占用时，我们称它为“<strong>读锁</strong>”；当读写锁被发出写请求的线程占用时，称它为“<strong>写锁</strong>”。</p>
<p>为了让您更清楚地了解读写锁在多线程程序中发挥的作用，我们制作了下面这张表格：</p>
<p>表 1 读写锁的作用：</p>
<table>
<thead>
<tr>
<th>当前读写锁的状态</th>
<th>线程发出“读”请求</th>
<th>线程发出“写”请求</th>
</tr>
</thead>
<tbody><tr>
<td>无锁</td>
<td>允许占用</td>
<td>允许占用</td>
</tr>
<tr>
<td>读锁</td>
<td>允许占用</td>
<td>阻塞线程执行</td>
</tr>
<tr>
<td>写锁</td>
<td>阻塞线程执行</td>
<td>阻塞线程执行</td>
</tr>
</tbody></table>
<p>从上表可以看出，不同状态下的读写锁会以不同的方式处理发出读请求或写请求的线程：</p>
<ol>
<li><p>当读写锁未被任何线程占用时，发出读请求和写请求的线程都可以占用它。注意，由于读请求和写请求的线程不能同时执行，读写锁默认会优先分配给发出读请求的线程。</p>
</li>
<li><p>当读写锁的状态为“读锁”时，表明当前执行的是发出读请求的线程（可能有多个）。此时如果又有线程发出读请求，该线程不会被阻塞，但如果有线程发出写请求，它就会被阻塞，直到读写锁状态改为“无锁”。</p>
</li>
<li><p>当读写锁状态为“写锁”时，表明当前执行的是发出写请求的线程（只能有 1 个）。此时无论其它线程发出的是读请求还是写请求，都必须等待读写锁状态改为“无锁”后才能执行。</p>
</li>
</ol>
<p>总的来说，对于进程空间中的共享资源，读写锁允许发出“读”请求的线程共享资源，发出“写”请求的线程必须独占资源，进而实现线程同步。</p>
<h2 id="读写锁的具体用法"><a href="#读写锁的具体用法" class="headerlink" title="读写锁的具体用法"></a>读写锁的具体用法</h2><p>POSIX 标准中，读写锁用 pthread_rwlock_t 类型的变量表示，此类型定义在<code>&lt;pthread.h&gt;</code>头文件中。举个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">pthread_rwlock_t</span> myRWLock;</span><br></pre></td></tr></table></figure>

<p>由此，我们就成功创建了一个读写锁。但要想使用 myRWLock 读写锁，还需要进行初始化操作。</p>
<h4 id="1-初始化读写锁"><a href="#1-初始化读写锁" class="headerlink" title="1) 初始化读写锁"></a>1) 初始化读写锁</h4><p>初始化读写锁的方法有两种，一种是直接将 PTHREAD_RWLOCK_INITIALIZER 宏赋值给读写锁变量，例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">pthread_rwlock_t</span> myRWLock = PTHREAD_RWLOCK_INITIALIZER;</span><br></pre></td></tr></table></figure>



<p>还可以借助 pthread_rwlock_init() 函数初始化读写锁，此函数的语法格式为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_rwlock_init</span><span class="params">(<span class="type">pthread_rwlock_t</span> *rwlock, <span class="type">const</span> <span class="type">pthread_rwlockattr_t</span> *attr)</span>;</span><br></pre></td></tr></table></figure>

<p>rwlock 参数用于指定要初始化的读写锁变量；attr 参数用于自定义读写锁变量的属性，置为 NULL 时表示以默认属性初始化读写锁。</p>
<p>当 pthread_rwlock_init() 函数初始化成功时，返回数字 0，反之返回非零数。</p>
<blockquote>
<p>当 attr 参数为 NULL 时，以上两种初始化方式完全等价。</p>
</blockquote>
<h4 id="2-线程发出“读锁”请求"><a href="#2-线程发出“读锁”请求" class="headerlink" title="2) 线程发出“读锁”请求"></a>2) 线程发出“读锁”请求</h4><p>通过以下两个函数，线程可以向读写锁发出“读锁”请求：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_rwlock_rdlock</span><span class="params">(<span class="type">pthread_rwlock_t</span>* rwlock)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_rwlock_tryrdlock</span><span class="params">(<span class="type">pthread_rwlock_t</span>* rwlock)</span>;</span><br></pre></td></tr></table></figure>

<p>其中，rwlock 参数指的是初始化好的读写锁。</p>
<p>当读写锁处于“无锁”或者“读锁”状态时，以上两个函数都能成功获得读锁；当读写锁处于“写锁”状态时：</p>
<ul>
<li>pthread_rwlock_rdlock() 函数会阻塞当前线程，直至读写锁被释放；</li>
<li>pthread_rwlock_tryrdlock() 函数不会阻塞当前线程，直接返回 EBUSY。</li>
</ul>
<p>以上两个函数如果能成功获得读锁，函数返回数字 0，反之返回非零数。</p>
<h4 id="3-线程发出“写锁”请求"><a href="#3-线程发出“写锁”请求" class="headerlink" title="3) 线程发出“写锁”请求"></a>3) 线程发出“写锁”请求</h4><p>通过以下两个函数，线程可以向读写锁发出“写锁”请求：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_rwlock_wrlock</span><span class="params">(<span class="type">pthread_rwlock_t</span>* rwlock)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_rwlock_trywrlock</span><span class="params">(<span class="type">pthread_rwlock_t</span>* rwlock)</span>; </span><br></pre></td></tr></table></figure>

<p>rwlock 参数指的是初始化好的读写锁。</p>
<p>当读写锁处于“无锁”状态时，两个函数都能成功获得写锁；当读写锁处于“读锁”或“写锁”状态时：</p>
<ul>
<li>pthread_rwlock_wrlock() 函数将阻塞线程，直至读写锁被释放；</li>
<li>pthread_rwlock_trywrlock() 函数不会阻塞线程，直接返回 EBUSY。</li>
</ul>
<p>以上两个函数如果能成功获得写锁，函数返回数字 0，反之返回非零数。</p>
<h4 id="4-释放读写锁"><a href="#4-释放读写锁" class="headerlink" title="4) 释放读写锁"></a>4) 释放读写锁</h4><p>无论是处于“无锁”、“读锁”还是“写锁”的读写锁，都可以使用如下函数释放读写锁：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_rwlock_unlock</span> <span class="params">(<span class="type">pthread_rwlock_t</span>* rwlock)</span>;</span><br></pre></td></tr></table></figure>

<p>rwlock 参数表示要释放的读写锁。</p>
<p>当函数成功释放读写锁时，返回数字 0，反之则返回非零数。注意，由于多个线程可以同时获得“读锁”状态下的读写锁，这种情况下一个线程释放读写锁后，读写锁仍处于“读锁”状态，直至所有线程都释放读写锁，读写锁的状态才为“无锁”状态。</p>
<h4 id="5-销毁读写锁"><a href="#5-销毁读写锁" class="headerlink" title="5) 销毁读写锁"></a>5) 销毁读写锁</h4><p>当读写锁不再使用时，我们可以借助如下函数将它销毁：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_rwlock_destroy</span><span class="params">(<span class="type">pthread_rwlock_t</span>* rwlock)</span>;</span><br></pre></td></tr></table></figure>

<p>参数 rwlock 表示要销毁的目标读写锁。</p>
<p>如果函数成功销毁指定的读写锁，返回数字 0，反之则返回非零数。</p>
<h2 id="读写锁的实际应用"><a href="#读写锁的实际应用" class="headerlink" title="读写锁的实际应用"></a>读写锁的实际应用</h2><p>接下来通过一个实例，给您演示读写锁的用法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> x = <span class="number">0</span>;</span><br><span class="line"><span class="comment">//创建读写锁变量</span></span><br><span class="line"><span class="type">pthread_rwlock_t</span> myrwlock;</span><br><span class="line"><span class="type">void</span>* <span class="title function_">read_thread</span><span class="params">(<span class="type">void</span>* args)</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;------%u read_thread ready\n&quot;</span>,pthread_self());</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//请求读锁</span></span><br><span class="line">        pthread_rwlock_rdlock(&amp;myrwlock);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;read_thread: %u,x=%d\n&quot;</span>, pthread_self(), x);</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//释放读写锁</span></span><br><span class="line">        pthread_rwlock_unlock(&amp;myrwlock);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span>* <span class="title function_">write_thread</span><span class="params">(<span class="type">void</span>* param)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;------%u write_thread ready!\n&quot;</span>,pthread_self());</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 请求写锁</span></span><br><span class="line">        pthread_rwlock_wrlock(&amp;myrwlock);</span><br><span class="line">        ++x;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;write_thread: %u,x=%d\n&quot;</span>, pthread_self(), x);</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//释放读写锁</span></span><br><span class="line">        pthread_rwlock_unlock(&amp;myrwlock);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="comment">//初始化读写锁</span></span><br><span class="line">    pthread_rwlock_init(&amp;myrwlock, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">//创建 3 个读 x 变量的线程</span></span><br><span class="line">    <span class="type">pthread_t</span> readThread[<span class="number">3</span>];</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">3</span>; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        pthread_create(&amp;readThread[i], <span class="literal">NULL</span>, read_thread, <span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//创建 1 个修改 x 变量的线程</span></span><br><span class="line">    <span class="type">pthread_t</span> writeThread;</span><br><span class="line">    pthread_create(&amp;writeThread, <span class="literal">NULL</span>, write_thread, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">//等待各个线程执行完成</span></span><br><span class="line">    pthread_join(writeThread, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        pthread_join(readThread[i], <span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//销毁读写锁</span></span><br><span class="line">    pthread_rwlock_destroy(&amp;myrwlock);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./mythread.exe</span></span><br><span class="line">------1134741248 read_thread ready</span><br><span class="line">------1113761536 read_thread ready</span><br><span class="line">------1103271680 write_thread ready!</span><br><span class="line">------1124251392 read_thread ready</span><br><span class="line">read_thread: 1124251392,x=0</span><br><span class="line">read_thread: 1113761536,x=0</span><br><span class="line">read_thread: 1134741248,x=0</span><br><span class="line">write_thread: 1103271680,x=1</span><br><span class="line">read_thread: 1134741248,x=1</span><br><span class="line">read_thread: 1124251392,x=1</span><br><span class="line">read_thread: 1113761536,x=1</span><br><span class="line">write_thread: 1103271680,x=2</span><br><span class="line">read_thread: 1124251392,x=2</span><br><span class="line">read_thread: 1113761536,x=2</span><br><span class="line">read_thread: 1134741248,x=2</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意，此程序会一直执行，按 “Ctrl+Z” 组合键可以使程序停止。</p>
</blockquote>
<p>程序中共创建了 4 个子线程，其中 3 个线程用于读取 x 变量的值，读取变量前会先获得“读锁”。剩余的 1 个线程用于修改 x 变量的值，修改前先获得“写锁”。</p>
<p>通过执行结果不难看到，3 个读取 x 变量的线程总是能够同时获取到 x 变量的值，因为它们能够同时获得“读锁”并同时执行。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>使用条件变量实现线程同步</title>
    <url>/2023/02/23/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E4%BD%BF%E7%94%A8%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<h1 id="使用条件变量实现线程同步"><a href="#使用条件变量实现线程同步" class="headerlink" title="使用条件变量实现线程同步"></a>使用条件变量实现线程同步</h1><blockquote>
<p>C语言中文网：<a href="http://c.biancheng.net/thread/vip_8617.html">使用条件变量实现线程同步</a> </p>
</blockquote>
<p>假设一个进程中包含多个线程，这些线程共享变量 x，我们希望某个（或某些）线程等待 “x&#x3D;&#x3D;10’ 条件成立后再执行后续的代码，该如何实现呢？</p>
<p>您可能想到用 while 循环实现，例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span>* <span class="title function_">threadFun</span><span class="params">(<span class="type">void</span> * args)</span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(x != <span class="number">10</span>)&#123;</span><br><span class="line">        sleep(<span class="number">5</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 待条件成立后，执行后续的代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当线程执行此函数时，会判断 x 的值是否等于 10，如果不等则间隔 5 秒后再重复判断，直到 x 的值等于 10 ，线程才能执行后续的代码。</p>
<p>直观上看，while 循环确实能够阻塞线程，但这种方法存在严重的效率问题。当线程因条件不成立进入等待状态时，如果此时恰好有另一个线程将 x 的值改为 10，该线程必须等待 5 秒后才能继续执行。如果我们将等待时间缩短（或者直接将 sleep(5) 注释掉），线程将反复判断 x 的值是否等于 10，它可能会一直霸占着 CPU 资源，导致其它线程无法执行，x 变量的值会出现“长时间不改变”的情况。</p>
<p>针对类似的场景，我们推荐您用<strong>条件变量</strong>来实现。和互斥锁、信号量类似，&#x3D;&#x3D;条件变量本质也是一个全局变量，它的功能是阻塞线程，直至接收到“条件成立”的信号后，被阻塞的线程才能继续执行。&#x3D;&#x3D;</p>
<p><strong>一个条件变量可以阻塞多个线程，这些线程会组成一个等待队列。当条件成立时，条件变量可以解除线程的“被阻塞状态”。</strong>也就是说，条件变量可以完成以下两项操作：</p>
<ul>
<li>阻塞线程，直至接收到“条件成立”的信号；</li>
<li>向等待队列中的一个或所有线程发送“条件成立”的信号，解除它们的“被阻塞”状态。</li>
</ul>
<p>为了避免多线程之间发生“抢夺资源”的问题，条件变量在使用过程中必须和一个互斥锁搭配使用。</p>
<h2 id="条件变量的具体用法"><a href="#条件变量的具体用法" class="headerlink" title="条件变量的具体用法"></a>条件变量的具体用法</h2><p>POSIX 标准中，条件变量用 pthread_cond_t 类型的变量表示，此类型定义在<code>&lt;pthread.h&gt;</code>头文件中。举个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="type">pthread_cond_t</span> myCond;</span><br></pre></td></tr></table></figure>

<p>由此，我们就成功创建了一个条件变量。要想使用 myCond 条件变量，还需要进行初始化操作。</p>
<h4 id="1-初始化条件变量"><a href="#1-初始化条件变量" class="headerlink" title="1) 初始化条件变量"></a>1) 初始化条件变量</h4><p>初始化条件变量的方式有两种，一种是直接将 PTHREAD_COND_INITIALIZER 赋值给条件变量，例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">pthread_cond_t</span> myCond = PTHREAD_COND_INITIALIZER;</span><br></pre></td></tr></table></figure>



<p>还可以借助 pthread_cond_init() 函数初始化条件变量，语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_cond_init</span><span class="params">(<span class="type">pthread_cond_t</span> * cond, <span class="type">const</span> <span class="type">pthread_condattr_t</span> * attr)</span>;</span><br></pre></td></tr></table></figure>

<p>参数 cond 用于指明要初始化的条件变量；参数 attr 用于自定义条件变量的属性，通常我们将它赋值为 NULL，表示以系统默认的属性完成初始化操作。</p>
<p>pthread_cond_init() 函数初始化成功时返回数字 0，反之函数返回非零数。</p>
<blockquote>
<p>当 attr 参数为 NULL 时，以上两种初始化方式完全等价。</p>
</blockquote>
<h4 id="2-阻塞当前线程，等待条件成立"><a href="#2-阻塞当前线程，等待条件成立" class="headerlink" title="2) 阻塞当前线程，等待条件成立"></a>2) 阻塞当前线程，等待条件成立</h4><p>当条件不成立时，条件变量可以阻塞当前线程，所有被阻塞的线程会构成一个等待队列。</p>
<p>阻塞线程可以借助以下两个函数实现：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_cond_wait</span><span class="params">(<span class="type">pthread_cond_t</span>* cond, <span class="type">pthread_mutex_t</span>* mutex)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_cond_timedwait</span><span class="params">(<span class="type">pthread_cond_t</span>* cond, <span class="type">pthread_mutex_t</span>* mutex, <span class="type">const</span> <span class="keyword">struct</span> timespec* abstime)</span>; </span><br></pre></td></tr></table></figure>

<p>cond 参数表示已初始化好的条件变量；mutex 参数表示与条件变量配合使用的互斥锁；abstime 参数表示阻塞线程的时间。</p>
<blockquote>
<p>注意，abstime 参数指的是绝对时间，例如您打算阻塞线程 5 秒钟，那么首先要得到当前系统的时间，然后再加上 5 秒，最终得到的时间才是传递的实参值。</p>
</blockquote>
<p>调用两个函数之前，我们必须先创建好一个互斥锁并完成“加锁”操作，然后才能作为实参传递给 mutex 参数。两个函数会完成以下两项工作：</p>
<ul>
<li>阻塞线程，直至接收到“条件成立”的信号；</li>
<li>当线程被添加到等待队列上时，将互斥锁“解锁”。</li>
</ul>
<p>也就是说，函数尚未接收到“条件成立”的信号之前，它将一直阻塞线程执行。注意，当函数接收到“条件成立”的信号后，它并不会立即结束对线程的阻塞，而是先完成对互斥锁的“加锁”操作，然后才解除阻塞。</p>
<blockquote>
<p>两个函数都以“原子操作”的方式完成“阻塞线程+解锁”或者“重新加锁+解除阻塞”这两个过程。所谓“原子操作”，即当有多个线程执行相同的某个过程时，虽然它们都会访问互斥锁和条件变量，但之间不会相互干扰。</p>
</blockquote>
<p>以上两个函数都能用来阻塞线程，它们的区别在于：</p>
<ul>
<li>pthread_cond_wait() 函数可以永久阻塞线程，直到条件变量成立的那一刻；</li>
<li>pthread_cond_timedwait() 函数只能在 abstime 参数指定的时间内阻塞线程，超出时限后，该函数将重新对互斥锁执行“加锁”操作，并解除对线程的阻塞，函数的返回值为 ETIMEDOUT。</li>
</ul>
<p>如果函数成功接收到了“条件成立”的信号，重新对互斥锁完成了“加锁”并使线程继续执行，函数返回数字 0，反之则返回非零数。</p>
<blockquote>
<p>POSIX 标准规定，pthread_cond_wait() 和 pthread_cond_timedwait() 函数是可以作为“取消点”的函数。当线程接收到“强制终止执行”的信号后，执行到这两个函数时，线程就会终止执行。有关强制终止执行线程和“取消点”的具体含义，您可以阅读《<a href="http://c.biancheng.net/thread/vip_8613.html">线程间相互终止执行，这个坑千万别踩！</a>》一文。</p>
</blockquote>
<h4 id="3-解除线程的“阻塞”状态"><a href="#3-解除线程的“阻塞”状态" class="headerlink" title="3) 解除线程的“阻塞”状态"></a>3) 解除线程的“阻塞”状态</h4><p>对于被 pthread_cond_wait() 或 pthread_cond_timedwait() 函数阻塞的线程，我们可以借助如下两个函数向它们发送“条件成立”的信号，解除它们的“被阻塞”状态：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_cond_signal</span><span class="params">(<span class="type">pthread_cond_t</span>* cond)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_cond_broadcast</span><span class="params">(<span class="type">pthread_cond_t</span>* cond)</span>;</span><br></pre></td></tr></table></figure>

<p>cond 参数表示初始化好的条件变量。当函数成功解除线程的“被阻塞”状态时，返回数字 0，反之返回非零数。</p>
<p>两个函数都能解除线程的“被阻塞”状态，区别在于：</p>
<ul>
<li>pthread_cond_signal() 函数至少解除一个线程的“被阻塞”状态，如果等待队列中包含多个线程，优先解除哪个线程将由操作系统的线程调度程序决定；</li>
<li>pthread_cond_broadcast() 函数可以解除等待队列中所有线程的“被阻塞”状态。</li>
</ul>
<p>由于互斥锁的存在，解除阻塞后的线程也不一定能立即执行。当互斥锁处于“加锁”状态时，解除阻塞状态的所有线程会组成等待互斥锁资源的队列，等待互斥锁“解锁”。</p>
<h4 id="4-销毁条件变量"><a href="#4-销毁条件变量" class="headerlink" title="4) 销毁条件变量"></a>4) 销毁条件变量</h4><p>对于初始化好的条件变量，我们可以调用 pthread_cond_destory() 函数销毁它。</p>
<p>pthread_cond_destory() 函数的语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_cond_destroy</span><span class="params">(<span class="type">pthread_cond_t</span> *cond)</span>;</span><br></pre></td></tr></table></figure>

<p>cond 参数表示要销毁的条件变量。如果函数成功销毁 cond 参数指定的条件变量，返回数字 0，反之返回非零数。</p>
<p>值得一提的是，销毁后的条件变量还可以调用 pthread_cond_init() 函数重新初始化后使用。</p>
<h2 id="条件变量的实际应用"><a href="#条件变量的实际应用" class="headerlink" title="条件变量的实际应用"></a>条件变量的实际应用</h2><p>接下来，通过一个实例给您演示条件变量的具体用法。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="comment">//初始化互斥锁</span></span><br><span class="line"><span class="type">pthread_mutex_t</span> myMutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"><span class="comment">//初始化条件变量</span></span><br><span class="line"><span class="type">pthread_cond_t</span> myCond = PTHREAD_COND_INITIALIZER;</span><br><span class="line"><span class="comment">//设置全局变量</span></span><br><span class="line"><span class="type">int</span> x = <span class="number">0</span>;</span><br><span class="line"><span class="comment">//线程执行的函数</span></span><br><span class="line"><span class="type">void</span> * <span class="title function_">waitForTrue</span><span class="params">(<span class="type">void</span> *args)</span> &#123;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="comment">//条件变量阻塞线程之前，先对互斥锁执行“加锁”操作</span></span><br><span class="line">    res = pthread_mutex_lock(&amp;myMutex);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;waitForTrue 加锁失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;------等待 x 的值为 10\n&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (pthread_cond_wait(&amp;myCond, &amp;myMutex) == <span class="number">0</span>) &#123;	<span class="comment">//遇到pthread_cond_wait 就会卡住，直到另一个线程遇到pthread_cond_signal，这里才会执行下一步</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;x = %d\n&quot;</span>, x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//最终将互斥锁解锁</span></span><br><span class="line">    pthread_mutex_unlock(&amp;myMutex);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//线程执行的函数</span></span><br><span class="line"><span class="type">void</span> * <span class="title function_">doneForTrue</span><span class="params">(<span class="type">void</span> *args)</span> &#123;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="keyword">while</span> (x != <span class="number">10</span>) &#123;</span><br><span class="line">        <span class="comment">//对互斥锁执行“加锁”操作</span></span><br><span class="line">        res = pthread_mutex_lock(&amp;myMutex);</span><br><span class="line">        <span class="keyword">if</span> (res == <span class="number">0</span>) &#123;</span><br><span class="line">            x++;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;doneForTrue：x = %d\n&quot;</span>, x);</span><br><span class="line">            sleep(<span class="number">1</span>);</span><br><span class="line">            <span class="comment">//对互斥锁“解锁”</span></span><br><span class="line">            pthread_mutex_unlock(&amp;myMutex);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//发送“条件成立”的信号，解除 mythread1 线程的“被阻塞”状态</span></span><br><span class="line">    res = pthread_cond_signal(&amp;myCond);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;解除阻塞失败\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="type">pthread_t</span> mythread1, mythread2;</span><br><span class="line">    res = pthread_create(&amp;mythread1, <span class="literal">NULL</span>, waitForTrue, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;mythread1线程创建失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    res = pthread_create(&amp;mythread2, <span class="literal">NULL</span>, doneForTrue, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;mythread2线程创建失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//等待 mythread1 线程执行完成</span></span><br><span class="line">    res = pthread_join(mythread1, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;1：等待线程失败\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//等待 mythread2 线程执行完成</span></span><br><span class="line">    res = pthread_join(mythread2, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;2：等待线程失败\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//销毁条件变量</span></span><br><span class="line">    pthread_cond_destroy(&amp;myCond);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">------等待 x 的值为 10</span><br><span class="line">doneForTrue：x = 1</span><br><span class="line">doneForTrue：x = 2</span><br><span class="line">doneForTrue：x = 3</span><br><span class="line">doneForTrue：x = 4</span><br><span class="line">doneForTrue：x = 5</span><br><span class="line">doneForTrue：x = 6</span><br><span class="line">doneForTrue：x = 7</span><br><span class="line">doneForTrue：x = 8</span><br><span class="line">doneForTrue：x = 9</span><br><span class="line">doneForTrue：x = 10</span><br><span class="line">x = 10</span><br></pre></td></tr></table></figure>

<p>程序中共创建了 2 个线程 mythread1 和 mythread2，其中 mythread1 线程借助条件变量实现了“直到变量 x 的值为 10 时，才继续执行后续代码”的功能，mythread1 线程用于将 x 的变量修改为 10，同时向 mythread1 线程发送“条件成立”的信号，唤醒 mythread1 线程并继续执行。</p>
<p>某一个线程遇到pthread_cond_wait 就会卡住，直到另一个线程遇到pthread_cond_signal，前一个线程这里才会继续执行下一步。</p>
<h2 id="std-condition-variable-native-handle"><a href="#std-condition-variable-native-handle" class="headerlink" title="std::condition_variable::native_handle"></a>std::condition_variable::native_handle</h2><blockquote>
<p><a href="https://zh.cppreference.com/w/cpp/thread/condition_variable/native_handle">https://zh.cppreference.com/w/cpp/thread/condition_variable/native_handle</a></p>
</blockquote>
<p>用于linux系统、posix系统</p>
<p>此函数结果的含义和类型是实现定义的。 POSIX 系统上，这可以是 pthread_cond_t* 类型值。 Windows 系统上，这可以是 PCONDITION_VARIABLE 。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>创建线程 pthread_create()</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="创建线程-pthread-create"><a href="#创建线程-pthread-create" class="headerlink" title="创建线程 pthread_create()"></a>创建线程 pthread_create()</h1><blockquote>
<p>c语言中文网：<a href="http://c.biancheng.net/thread/vip_8626.html">创建线程</a></p>
</blockquote>
<p><code>pthread_create()</code> 函数声明在<code>&lt;pthread.h&gt;</code>头文件中，语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_create</span><span class="params">(<span class="type">pthread_t</span> *thread,</span></span><br><span class="line"><span class="params">                   <span class="type">const</span> <span class="type">pthread_attr_t</span> *attr,</span></span><br><span class="line"><span class="params">                   <span class="type">void</span> *(*start_routine) (<span class="type">void</span> *),</span></span><br><span class="line"><span class="params">                   <span class="type">void</span> *arg)</span>;</span><br></pre></td></tr></table></figure>

<p>各个参数的含义是：</p>
<ol>
<li><p><code>pthread_t *thread</code>：传递一个 pthread_t 类型的指针变量，也可以直接传递某个 pthread_t 类型变量的地址。pthread_t 是一种用于表示线程的数据类型，每一个 pthread_t 类型的变量都可以表示一个线程。</p>
</li>
<li><p><code>const pthread_attr_t *attr</code>：用于手动设置新建线程的属性，例如线程的调用策略、线程所能使用的栈内存的大小等。大部分场景中，我们都不需要手动修改线程的属性，将 attr 参数赋值为 NULL，pthread_create() 函数会采用系统默认的属性值创建线程。</p>
<p>pthread_attr_t 类型以结构体的形式定义在<code>&lt;pthread.h&gt;</code>头文件中，此类型的变量专门表示线程的属性。关于线程属性，您可以阅读《<a href="http://c.biancheng.net/thread/vip_8620.html">Linux线程属性详解</a>》一文做详细地了解。</p>
</li>
</ol>
<ol start="3">
<li><p><code>void *(*start_routine) (void *)</code>：以函数指针的方式指明新建线程需要执行的函数，该函数的参数最多有 1 个（可以省略不写），形参和返回值的类型都必须为 void* 类型。&#x3D;&#x3D;void* 类型又称空指针类型，表明指针所指数据的类型是未知的。使用此类型指针时，我们通常需要先对其进行强制类型转换，然后才能正常访问指针指向的数据。&#x3D;&#x3D;（空指针强转其它类型指针是低风险的）</p>
<blockquote>
<p>如果该函数有返回值，则线程执行完函数后，函数的返回值可以由 pthread_join() 函数接收。有关 phtread_join() 函数的用法，我们会在《<a href="http://c.biancheng.net/thread/vip_8627.html">获取线程函数的返回值</a>》一节给大家做详细讲解。</p>
</blockquote>
</li>
</ol>
<ol start="4">
<li>void *arg：指定传递给 start_routine 函数的实参，当不需要传递任何数据时，将 arg 赋值为 NULL 即可。</li>
</ol>
<p>如果成功创建线程，pthread_create() 函数返回数字 0，反之返回非零值。各个非零值都对应着不同的宏，指明创建失败的原因，常见的宏有以下几种：</p>
<ul>
<li>EAGAIN：系统资源不足，无法提供创建线程所需的资源。</li>
<li>EINVAL：传递给 pthread_create() 函数的 attr 参数无效。</li>
<li>EPERM：传递给 pthread_create() 函数的 attr 参数中，某些属性的设置为非法操作，程序没有相关的设置权限。</li>
</ul>
<blockquote>
<p>以上这些宏都声明在 &lt;errno.h&gt; 头文件中，如果程序中想使用这些宏，需提前引入此头文件。</p>
</blockquote>
<p>接下来通过一个样例，给大家演示 pthread_create() 函数的用法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span>   <span class="comment">//调用 sleep() 函数</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span>  <span class="comment">//调用 pthread_create() 函数</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">ThreadFun</span><span class="params">(<span class="type">void</span> *arg)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (arg == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;arg is NULL\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, (<span class="type">char</span>*)arg);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="type">char</span> * url = <span class="string">&quot;http://www.biancheng.net&quot;</span>;</span><br><span class="line">    <span class="comment">//定义两个表示线程的变量（标识符）</span></span><br><span class="line">    <span class="type">pthread_t</span> myThread1,myThread2;</span><br><span class="line">    <span class="comment">//创建 myThread1 线程</span></span><br><span class="line">    res = pthread_create(&amp;myThread1, <span class="literal">NULL</span>, ThreadFun, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sleep(<span class="number">5</span>);  <span class="comment">//令主线程等到 myThread1 线程执行完成</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//创建 myThread2 线程</span></span><br><span class="line">    res = pthread_create(&amp;myThread2, <span class="literal">NULL</span>, ThreadFun,(<span class="type">void</span>*)url);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sleep(<span class="number">5</span>); <span class="comment">// 令主线程等到 mythread2 线程执行完成</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">arg is NULL</span><br><span class="line">http://www.biancheng.net</span><br></pre></td></tr></table></figure>

<p>程序中共创建了 2 个线程，分别命名为 myThread1 和 myThread2。myThread1 和 myThread2 线程执行的都是 threadFun() 函数，不同之处在于，myThread1 线程没有给 threadFun() 函数传递任何数据，而 myThread2 线程向 threadFun() 函数传递了 “<a href="http://www.biancheng.net&quot;/">http://www.biancheng.net&quot;</a> 这个字符串。</p>
<p>从程序的执行过程不难看出， pthread_create() 函数成功创建的线程会自动执行指定的函数，不需要手动开启。此外，为了确保创建的线程能在主线程之前执行完，程序中调用 sleep() 函数延缓了主线程的执行速度。</p>
<blockquote>
<p>您可以尝试将程序中的 sleep() 函数全部注释掉，然后重新编译、执行此程序。整个进程会随着主线程执行结束而立即终止。</p>
<p>&#x3D;&#x3D;由于主线程执行太快，子线程可能尚未执行完就被强制终止。&#x3D;&#x3D;</p>
</blockquote>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>如何避免线程发生死锁？</title>
    <url>/2023/02/23/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E7%BA%BF%E7%A8%8B%E5%8F%91%E7%94%9F%E6%AD%BB%E9%94%81%EF%BC%9F/</url>
    <content><![CDATA[<h1 id="如何避免线程发生死锁？"><a href="#如何避免线程发生死锁？" class="headerlink" title="如何避免线程发生死锁？"></a>如何避免线程发生死锁？</h1><blockquote>
<p>C语言中文网：<a href="http://c.biancheng.net/thread/vip_8619.html">如何避免线程发生死锁？</a>  </p>
</blockquote>
<p>前面章节，我们详细介绍了实现线程同步的 4 种方法，分别是互斥锁、信号量、条件变量和读写锁。很多初学者在使用这些方法的过程中，经常会发生“线程一直被阻塞”的情况，我们习惯将这种情况称为“死锁”。</p>
<p>线程死锁指的是线程需要使用的公共资源一直被其它线程占用，导致该线程一直处于“阻塞”状态，无法继续执行。举个例子，用互斥锁实现线程同步的过程中，初学者经常忘记为“加锁”的线程及时“解锁”，这种情况下就会发生死锁（实例一）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="comment">//创建并初始化互斥锁</span></span><br><span class="line"><span class="type">pthread_mutex_t</span> myMutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">thread_func</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    <span class="type">int</span> islock;</span><br><span class="line">    <span class="comment">//为线程加锁   </span></span><br><span class="line">    islock = pthread_mutex_lock(&amp;myMutex);</span><br><span class="line">    <span class="keyword">if</span> (islock == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程 %u 已加锁\n&quot;</span>, pthread_self());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> flag;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="comment">//创建 4 个线程</span></span><br><span class="line">    <span class="type">pthread_t</span> tids[<span class="number">4</span>];</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        flag = pthread_create(&amp;tids[i], <span class="literal">NULL</span>, thread_func, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="keyword">if</span> (flag == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;线程 %u 创建完成\n&quot;</span>,tids[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i&lt;<span class="number">4</span>;i++)&#123;</span><br><span class="line">        pthread_join(tids[i], <span class="literal">NULL</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程 %u 执行完成\n&quot;</span>,tids[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">线程 3135751936 创建完成</span><br><span class="line">线程 3125262080 创建完成</span><br><span class="line">线程 3114772224 创建完成</span><br><span class="line">线程 3135751936 已加锁</span><br><span class="line">线程 3104282368 创建完成</span><br><span class="line">线程 3135751936 执行完成</span><br><span class="line">                                           &lt;-- 其它 3 个线程发生了死锁</span><br></pre></td></tr></table></figure>

<p>程序中共创建了 4 个线程，它们都执行 thread_func() 函数，该函数内完成了对互斥锁的“加锁”操作，但没有调用 pthread_mutex_unlock() 函数对互斥锁“解锁”。通过程序的执行结果可以看到，4 个线程中仅有 1 个线程成功执行结束，其它 3 个线程一直处于等待互斥锁“解锁”的阻塞状态，发生了死锁。</p>
<p>再举一个例子（实例二）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">pthread_mutex_t</span> mutex;</span><br><span class="line"><span class="type">pthread_mutex_t</span> mutex2;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">func1</span><span class="params">(<span class="type">void</span> *args)</span></span><br><span class="line">&#123;</span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;t1 成功申请 mytex 锁\n&quot;</span>);</span><br><span class="line">    sleep(<span class="number">2</span>);</span><br><span class="line">    pthread_mutex_lock(&amp;mutex2);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;t1 成功申请 mytex2 锁\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%u is running\n&quot;</span>,pthread_self());</span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;------%u done\n&quot;</span>,pthread_self());      </span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">func2</span><span class="params">(<span class="type">void</span> *args)</span></span><br><span class="line">&#123; </span><br><span class="line">    pthread_mutex_lock(&amp;mutex2);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;t2 成功申请 mytex2 锁\n&quot;</span>);</span><br><span class="line">    sleep(<span class="number">2</span>);</span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;t2 成功申请 mytex 锁\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%u is running\n&quot;</span>,pthread_self()); </span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;------%u done\n&quot;</span>,pthread_self());</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> ret;</span><br><span class="line">    <span class="type">pthread_t</span> t1;</span><br><span class="line">    <span class="type">pthread_t</span> t2;</span><br><span class="line">    pthread_mutex_init(&amp;mutex,<span class="literal">NULL</span>);</span><br><span class="line">    pthread_mutex_init(&amp;mutex2,<span class="literal">NULL</span>);</span><br><span class="line">    ret = pthread_create(&amp;t1, <span class="literal">NULL</span>, func1, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(ret != <span class="number">0</span>)&#123;</span><br><span class="line">           <span class="built_in">printf</span>(<span class="string">&quot;create t1 fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    ret = pthread_create(&amp;t2, <span class="literal">NULL</span>, func2, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(ret != <span class="number">0</span>)&#123;</span><br><span class="line">           <span class="built_in">printf</span>(<span class="string">&quot;create t2 fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    pthread_join(t1,<span class="literal">NULL</span>);</span><br><span class="line">    pthread_join(t2,<span class="literal">NULL</span>);</span><br><span class="line">    pthread_mutex_destroy(&amp;mutex);</span><br><span class="line">    pthread_mutex_destroy(&amp;mutex2);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">t1 成功申请 mytex 锁</span><br><span class="line">t2 成功申请 mytex2 锁</span><br><span class="line">                                          &lt;-- t1 和 t2 都发生了死锁</span><br></pre></td></tr></table></figure>

<p>程序中创建了 mutex 和 mutex2 两个互斥锁，线程 t1 和 t2 同时执行。从执行结果可以看到，t1 成功申请了 mutex 锁，t2 成功申请了 mutex2 锁，t1 一直等待 t2 释放 mutex2 锁，而 t2 一直等待 t1 释放 mutex 锁，两个线程都因等待对方释放资源产生了死锁。</p>
<p>总的来说，当进程空间中的某公共资源不允许多个线程同时访问时，某线程访问公共资源后不及时释放资源，就很可能产生线程死锁。</p>
<p>就是最好不要锁中锁？锁了一个还没释放就又锁一个？</p>
<p>上面例子把 <code>pthread_mutex_lock</code> 修改为 <code>pthread_mutex_trylock</code> 就可以了。</p>
<p>修改后：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">pthread_mutex_t</span> mutex;</span><br><span class="line"><span class="type">pthread_mutex_t</span> mutex2;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">func1</span><span class="params">(<span class="type">void</span> *args)</span></span><br><span class="line">&#123;</span><br><span class="line">    pthread_mutex_trylock(&amp;mutex);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;t1 成功申请 mytex 锁\n&quot;</span>);</span><br><span class="line">    sleep(<span class="number">2</span>);</span><br><span class="line">    <span class="type">int</span> islock = <span class="number">0</span>;</span><br><span class="line">    islock = pthread_mutex_trylock(&amp;mutex2);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;t1 islock %d\n&quot;</span>, islock);</span><br><span class="line">    <span class="keyword">if</span> (islock == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;t1 成功申请 mytex2 锁\n&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;t1  %u is running\n&quot;</span>,pthread_self());</span><br><span class="line">        pthread_mutex_unlock(&amp;mutex2);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;------t1  %u done\n&quot;</span>,pthread_self());      </span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">func2</span><span class="params">(<span class="type">void</span> *args)</span></span><br><span class="line">&#123; </span><br><span class="line">    pthread_mutex_trylock(&amp;mutex2);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;t2 成功申请 mytex2 锁\n&quot;</span>);</span><br><span class="line">    sleep(<span class="number">3</span>);</span><br><span class="line">    <span class="type">int</span> islock = <span class="number">0</span>;</span><br><span class="line">    islock = pthread_mutex_trylock(&amp;mutex);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;t2 islock %d\n&quot;</span>, islock);</span><br><span class="line">    <span class="keyword">if</span> (islock == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;t2 成功申请 mytex 锁\n&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;t2   %u is running\n&quot;</span>,pthread_self()); </span><br><span class="line">        pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_mutex_unlock(&amp;mutex2);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;------t2  %u done\n&quot;</span>,pthread_self());</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> ret;</span><br><span class="line">    <span class="type">pthread_t</span> t1;</span><br><span class="line">    <span class="type">pthread_t</span> t2;</span><br><span class="line">    pthread_mutex_init(&amp;mutex,<span class="literal">NULL</span>);</span><br><span class="line">    pthread_mutex_init(&amp;mutex2,<span class="literal">NULL</span>);</span><br><span class="line">    ret = pthread_create(&amp;t1, <span class="literal">NULL</span>, func1, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(ret != <span class="number">0</span>)&#123;</span><br><span class="line">           <span class="built_in">printf</span>(<span class="string">&quot;create t1 fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    ret = pthread_create(&amp;t2, <span class="literal">NULL</span>, func2, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(ret != <span class="number">0</span>)&#123;</span><br><span class="line">           <span class="built_in">printf</span>(<span class="string">&quot;create t2 fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    pthread_join(t1,<span class="literal">NULL</span>);</span><br><span class="line">    pthread_join(t2,<span class="literal">NULL</span>);</span><br><span class="line">    pthread_mutex_destroy(&amp;mutex);</span><br><span class="line">    pthread_mutex_destroy(&amp;mutex2);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<h2 id="避免线程死锁的几点建议"><a href="#避免线程死锁的几点建议" class="headerlink" title="避免线程死锁的几点建议"></a>避免线程死锁的几点建议</h2><ol>
<li>使用互斥锁、信号量、条件变量和读写锁实现线程同步时，要注意以下几点：<ul>
<li>占用互斥锁的线程，执行完成前必须及时解锁；</li>
<li>通过 sem_wait() 函数占用信号量资源的线程，执行完成前必须调用 sem_post() 函数及时释放；</li>
<li>当线程因 pthread_cond_wait() 函数被阻塞时，一定要保证有其它线程唤醒此线程；</li>
<li>无论线程占用的是读锁还是写锁，都必须及时解锁。</li>
</ul>
</li>
</ol>
<blockquote>
<p>注意，函数中可以设置多种结束执行的路径，但无论线程选择哪个路径结束执行，都要保证能够将占用的资源释放掉。</p>
</blockquote>
<ol start="2">
<li><p>POSIX 标准中，很多阻塞线程执行的函数都提供有 tryxxx() 和 timexxx() 两个版本，例如 pthread_mutex_lock() 和 pthread_mutex_trylock()、sem_wait() 和 sem_trywait()、pthread_cond_wait() 和 pthread_cond_timedwait() 等，它们可以完成同样的功能，但 tryxxx() 版本的函数不会阻塞线程，timexxx() 版本的函数不会一直阻塞线程。</p>
<p>实际开发中，建议您&#x3D;&#x3D;优先选择 tryxxx() 或者 timexxx() 版本的函数，可以大大降低线程产生死锁的概率。&#x3D;&#x3D;</p>
</li>
<li><p>&#x3D;&#x3D;多线程程序中，多个线程请求资源的顺序最好保持一致&#x3D;&#x3D;。实例二中，线程 t1 先请求 mutex 锁然后再请求 mutex2 锁，而 t2 则是先请求 mutex2 锁然后再请求 mutex 锁，这就是典型的因“请求资源顺序不一致”导致发生了线程死锁的情况。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程 multithreading</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="多线程-multithreading"><a href="#多线程-multithreading" class="headerlink" title="多线程 multithreading"></a>多线程 multithreading</h1><blockquote>
<p>c语言中文网 多线程系列 <a href="http://c.biancheng.net/thread/">多线程编程（C语言+Linux）</a></p>
<p><a href="https://developer.aliyun.com/article/1135034">生产者消费者模式保姆级教程 (阻塞队列解除耦合性) 一文帮你从C语言版本到C++ 版本, 从理论到实现 (一文足以)</a></p>
<p>c语言中文网 <a href="http://c.biancheng.net/view/8631.html">Linux Mutex互斥锁详解</a></p>
<p>cppreference <a href="https://zh.cppreference.com/w/cpp/thread/mutex">std::mutex</a></p>
</blockquote>
<p>提高计算机资源利用率的方法。</p>
<p>多进程编程：让多个程序同时执行。进程指的是正在执行的应用程序。</p>
<p>多线程编程：多核基础上，让多个程序同时执行。线程指的是执行应用程序中的某个具体任务，比如一段程序、一个函数等。</p>
<p>多道批处理系统主要有以下两点优势：</p>
<ul>
<li>它将计算机的内存分成很多区域，每个区域都可以存储一个程序；（一开始给每个程序分配一部分内存，参见《计算机科学速成课（二）》）</li>
<li>当执行的程序执行 I&#x2F;O 操作时（io操作，只是读写操作，cpu没有在计算，因此是空闲的），操作系统会将 CPU 资源分配给其它等待执行的程序。</li>
</ul>
<p>早期的多任务操作系统，以进程为单位管理各个程序的运行以及计算机资源的分配和回收，进一步提高了计算机资源的利用率。但随着计算机硬、软件的发展，人们发现还可以做进一步优化，例如：</p>
<ul>
<li>操作系统将 CPU 资源从一个进程分配给另一个进程时，开销较大；</li>
<li>各个进程占用的内存空间是相互独立的，大大增加了进程间通信的实现难度；</li>
<li>一个进程可能会执行多个任务，当某个任务因 I&#x2F;O 操作暂停执行时，其他任务将无法执行。</li>
</ul>
<p>在计算机软、硬件快速发展，人们计算机运行效率的要求越来越高的大背景下，“线程”应运而生。</p>
<p>每个进程执行前，操作系统都会为其分配所需的资源，包括要执行的程序代码、数据、内存空间、文件资源等。一个进程至少包含 1 个线程，可以包含多个线程，所有线程共享进程的资源，各个线程也可以拥有属于自己的私有资源。</p>
<blockquote>
<p>进程仅负责为各个线程提供所需的资源，真正执行任务的是线程，而不是进程。</p>
</blockquote>
<p>下图描述了进程和线程之间的关系：</p>
<p><img src="/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1K4095H5-0.gif" alt="1K4095H5-0"></p>
<p>如图所示，所有线程共享的进程资源有：</p>
<ul>
<li>代码：即应用程序的代码；</li>
<li>数据：包括全局变量、函数内的静态变量、堆空间的数据等；</li>
<li>进程空间：操作系统分配给进程的内存空间；</li>
<li>打开的文件：各个线程打开的文件资源，也可以为所有线程所共享，例如线程 A 打开的文件允许线程 B 进行读写操作。</li>
</ul>
<p>各个线程也可以拥有自己的私有资源，包括寄存器中存储的数据、线程执行所需的局部变量（函数参数）等。</p>
<h2 id="C-多线程编程要注意什么？"><a href="#C-多线程编程要注意什么？" class="headerlink" title="C++多线程编程要注意什么？"></a>C++多线程编程要注意什么？</h2><blockquote>
<p>chatgpt</p>
</blockquote>
<p>在 C++ 中进行多线程编程时需要注意以下事项：</p>
<ol>
<li>线程安全：在多线程环境中，多个线程可能会同时访问同一个变量或资源。要确保在并发访问时不会出现竞态条件和数据竞争等问题，需要使用互斥量、读写锁、条件变量等同步机制来保证线程安全。</li>
<li>死锁：在使用互斥量等同步机制时，如果线程持有一个锁并试图获取另一个锁，而另一个锁已经被另一个线程占用，则可能发生死锁。要避免死锁，需要避免循环等待、尽量避免使用多个锁等策略。</li>
<li>上下文切换：线程的创建和销毁、线程之间的切换都需要消耗系统资源，因此过多的线程会导致上下文切换频繁，影响性能。需要根据实际情况合理控制线程的数量。</li>
<li>线程间通信：在多线程编程中，线程之间需要进行通信，共享数据或者传递消息等。需要使用同步机制来保证线程间的通信安全。</li>
<li>内存管理：多线程环境中，内存管理也需要注意线程安全问题。例如，线程A分配了一块内存，但是在使用之前被线程B释放，这将导致未定义的行为和程序崩溃。</li>
</ol>
<p>除了上述几点，还需要注意线程的优先级、线程的创建顺序等问题。多线程编程比较复杂，需要仔细考虑各种情况，确保程序的正确性和性能。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>并发、并行、异步、同步</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E5%B9%B6%E5%8F%91%E3%80%81%E5%B9%B6%E8%A1%8C%E3%80%81%E5%BC%82%E6%AD%A5%E3%80%81%E5%90%8C%E6%AD%A5%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h1 id="并发、并行、异步、同步"><a href="#并发、并行、异步、同步" class="headerlink" title="并发、并行、异步、同步"></a>并发、并行、异步、同步</h1><blockquote>
<p>b站 奇乐编程学院 <a href="https://www.bilibili.com/video/BV17V411e7Ua/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">一个视频告诉你“并发、并行、异步、同步”的区别</a></p>
</blockquote>
<p>并发：concurrency</p>
<p>并行：parallelism</p>
<p>异步：asynchronous</p>
<p>同步：synchronous</p>
<ul>
<li>并发：表示计算机能够同时执行多项任务。对单核处理器来说，用的是分配时间片的方法，上下文切换（context switching）（任务1执行一段时间切换到任务2，任务2执行一段时间切换到任务1）；</li>
<li>并行：对多核来说，在不同核心执行不同任务，并行处理多个任务。</li>
<li>同步：编程模型，等到前一个任务执行完成后，才能进行下一个任务，没有并发、并行的概念。</li>
<li>异步：编程模型，不同任务之间不会相互等待、先后执行，运行任务1也可以同时运行任务2。典型实现异步的方式是“多线程”编程（multithreading），python里的asyncio、C++20里的co_await。</li>
</ul>
<p>创建多个线程并启动，在多核环境下每个线程会被分配到独立的核心上运行，实现“并行”，在单核环境下，操作系统会通过分配时间片的方式来执行这些线程，“并发”。</p>
<p>通过“函数回调” function callback机制，实现单线程的并发，比如javascript里的fetch()函数。</p>
<h4 id="多线程编程-VS-（单线程）异步编程："><a href="#多线程编程-VS-（单线程）异步编程：" class="headerlink" title="多线程编程 VS. （单线程）异步编程："></a>多线程编程 VS. （单线程）异步编程：</h4><p>对于I&#x2F;O密集型的应用程序，比如web应用经常执行网络操作，适合使用异步编程。此时如果使用多线程，会浪费系统资源，因为每个线程的绝大多数时间都是在等待这些I&#x2F;O操作，而线程自身会占用额外的内存，线程的切换也会有额外的开销、以及线程资源竞争。</p>
<p>对于计算量密集的应用，适合多线程编程。</p>
<p>对于I&#x2F;O操作密集的应用，大多数时间CPU都是在等待这些IO操作的完成，CPU会处于空闲操作，如果使用多线程等待线程自身还有切换+内存开销，会浪费系统资源。所以服务器程序通常都是1个线程处理一个客户端请求，在“这个”线程中会完成所有的数据库&#x2F;文件系统&#x2F;网络等待操作。</p>
<p>其实没有看很懂。</p>
<h1 id="多线程编程：一次性搞懂线程同步机制"><a href="#多线程编程：一次性搞懂线程同步机制" class="headerlink" title="多线程编程：一次性搞懂线程同步机制"></a>多线程编程：一次性搞懂线程同步机制</h1><blockquote>
<p>b站 奇乐编程学院 <a href="https://www.bilibili.com/video/BV1oQ4y1C73G?vd_source=f543adafa22ae8c737564797f76a2bc0">多线程编程：一次性搞懂线程同步机制</a></p>
</blockquote>
<p>看完感觉不是非常明白。</p>
<h1 id="同步和异步，阻塞和非阻塞"><a href="#同步和异步，阻塞和非阻塞" class="headerlink" title="同步和异步，阻塞和非阻塞"></a>同步和异步，阻塞和非阻塞</h1><blockquote>
<p>b站 <a href="https://www.bilibili.com/video/BV1yr4y1j7mM?vd_source=f543adafa22ae8c737564797f76a2bc0">同步和异步，阻塞和非阻塞-结合一个例子简单说明</a></p>
</blockquote>
<ul>
<li><strong>同步</strong>：<strong>客户端</strong>有一个请求的连接，请求服务器端处理一个数据、返回一个结果，但是服务器端计算这个结果的过程很长，连接就要处于一直等待的状态下。</li>
<li><strong>异步</strong>：<strong>客户端</strong>有一个请求的连接，请求服务器端处理一个数据、返回一个结果，但是服务器端计算这个结果的过程很长，客户端不想等待，直接连接返回（直接返回，此时并没有真正得到服务器端返回的结果），因此还有一个消息，消息回写的接口或服务，用来当服务器端把结果算出来后，通过消息回写把数据给客户端。</li>
</ul>
<p>请求线程：客户端发一个请求给服务端，服务端接收到这个叫请求线程。</p>
<p>处理线程：服务端接收到后，去进行处理数据的过程叫处理线程。（比如处理完的结果再返回给客户端）</p>
<ul>
<li><strong>阻塞：</strong>针对<strong>服务器端</strong>的请求线程、处理线程来说的，线程不能做别的事，请求线程要一直处于等待状态</li>
<li><strong>非阻塞</strong>：针对<strong>服务器端</strong>的请求线程、处理线程来说的，请求线程发出请求给处理线程之后，不用一直等待，这个请求线程可以快速释放回资源池，去处理其它请求。但是这个请求线程每隔10s、或20s，要轮询一下处理线程，去查看处理线程完成了没有。如果完成了，请求线程就拿着结果返回给客户端。</li>
</ul>
<p>消息队列。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>第一个多线程程序</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%A8%8B%E5%BA%8F/</url>
    <content><![CDATA[<h1 id="第一个多线程程序"><a href="#第一个多线程程序" class="headerlink" title="第一个多线程程序"></a>第一个多线程程序</h1><blockquote>
<p>c语言中文网：<a href="http://c.biancheng.net/thread/first-thread.html">第一个多线程程序</a></p>
</blockquote>
<p>为了避免多个程序访问系统资源（包括文件资源、I&#x2F;O 设备、网络等）时产生冲突，操作系统会将可能产生冲突的系统资源保护起来，阻止应用程序直接访问。如果程序中需要访问被操作系统保护起来的资源，需使用操作系统规定的方法（函数、命令），我们习惯将这些调用方法（函数、命令）称为接口（<strong>A</strong>pplication <strong>P</strong>rogramming <strong>I</strong>nterface，简称 API）。（程序要访问资源，需要使用操作系统支持的调用方法，也就是符合操作系统支持的接口（API）来访问）</p>
<p>事实上，无论我们用哪种编程语言编写多线程程序，最终都要借助操作系统预留的接口实现。接下来，我们将为您讲解如何借助 Linux 系统预留的接口编写 C 语言多线程程序。</p>
<h2 id="POSIX标准"><a href="#POSIX标准" class="headerlink" title="POSIX标准"></a>POSIX标准</h2><p>类 UNIX 系统有很多种版本，包括 Linux、FreeBSD、OpenBSD 等，它们预留的系统调用接口各不相同。但幸运的是，几乎所有的类 UNIX 系统都兼容 POSIX 标准。</p>
<p>POSIX 标准全称“<strong>P</strong>ortable <strong>O</strong>perating <strong>S</strong>ystem <strong>I</strong>nterface”，中文译为可移植操作系统接口，最后的字母 X 代指类 UNIX 操作系统。简单地理解，POSIX 标准发布的初衷就是为了统一所有类 UNIX 操作系统的接口，这意味着，只要我们编写的程序严格按照 POSIX 标准调用系统接口，它就可以在任何兼容 POSIX 标准的类 UNIX 系统上运行。</p>
<blockquote>
<p>所谓兼容，很多支持 POSIX 标准的类 UNIX 操作系统并没有从根本上修改自己的 API，它们仅仅通过对现有的 API 进行再封装，生成了一套符合 POSIX 标准的系统接口，进而间接地支持 POSIX 标准。</p>
</blockquote>
<p>值得一提的是，POSIX 标准中规范了与多线程相关的系统接口。我们在 Linux 系统上编写多线程程序，只需在程序中引入<code>&lt;pthread.h&gt;</code>头文件，调用该文件中包含的函数即可实现多线程编程。</p>
<blockquote>
<p>注意，pthread.h 头文件中只包含各个函数的声明部分，具体实现位于 libpthread.a 库中。</p>
</blockquote>
<h2 id="第一个多线程程序-1"><a href="#第一个多线程程序-1" class="headerlink" title="第一个多线程程序"></a>第一个多线程程序</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="comment">// include &lt;iostream&gt; // c++加一行</span></span><br><span class="line"><span class="comment">//定义线程要执行的函数，arg 为接收线程传递过来的数据</span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">Thread1</span><span class="params">(<span class="type">void</span> *arg)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;http://c.biancheng.net\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Thread1成功执行&quot;</span>;	<span class="comment">// C++ 改为：return const_cast&lt;char*&gt;(&quot;Thread1成功执行&quot;);</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//定义线程要执行的函数，arg 为接收线程传递过来的数据</span></span><br><span class="line"><span class="type">void</span>* <span class="title function_">Thread2</span><span class="params">(<span class="type">void</span>* arg)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;C语言中文网\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Thread2成功执行&quot;</span>;	<span class="comment">// C++ 改为：return const_cast&lt;char*&gt;(&quot;Thread2成功执行&quot;);</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="type">pthread_t</span> mythread1, mythread2;</span><br><span class="line">    <span class="type">void</span>* thread_result;</span><br><span class="line">    <span class="comment">/*创建线程</span></span><br><span class="line"><span class="comment">    &amp;mythread:要创建的线程</span></span><br><span class="line"><span class="comment">    NULL：不修改新建线程的任何属性</span></span><br><span class="line"><span class="comment">    ThreadFun:新建线程要执行的任务</span></span><br><span class="line"><span class="comment">    NULL：不传递给 ThreadFun() 函数任何参数</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    返回值 res 为 0 表示线程创建成功，反之则创建失败。</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    res = pthread_create(&amp;mythread1, <span class="literal">NULL</span>, Thread1, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    res = pthread_create(&amp;mythread2, <span class="literal">NULL</span>, Thread2, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    等待指定线程执行完毕</span></span><br><span class="line"><span class="comment">    mtThread:指定等待的线程</span></span><br><span class="line"><span class="comment">    &amp;thead_result:接收 ThreadFun() 函数的返回值，或者接收 pthread_exit() 函数指定的值</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    返回值 res 为 0 表示函数执行成功，反之则执行失败。</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    res = pthread_join(mythread1, &amp;thread_result); <span class="comment">// 令主线程等待 mythread1 线程执行完毕后再执行后续的代码</span></span><br><span class="line">    <span class="comment">//输出线程执行完毕后返回的数据</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, (<span class="type">char</span>*)thread_result);</span><br><span class="line">   </span><br><span class="line">    res = pthread_join(mythread2, &amp;thread_result); <span class="comment">// 令主线程等待 mythread2 线程执行完毕后再执行后续的代码</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, (<span class="type">char</span>*)thread_result);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;主线程执行完毕\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>假设我们将程序编写在 thead.c 文件中，调用 gcc 编译器编译（包含链接）此程序：</p>
<p><code>[root@localhost ~]# gcc thread.c -o thread.exe -lpthread</code>  （C++版则是 <code>g++ thread.cc -o thread.exe -lpthread</code>）</p>
<p>在保证程序没有语法错误的前提下，执行此命令会生成一个名为 thread.exe 的可执行文件。需要强调的是，命令中必须包含 “-lpthread” 参数，否则会导致程序链接失败。</p>
<p>在当前目录下找到新生成的 thread.exe 文件，执行如下命令即可看到程序的执行结果：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># ./thead.exe</span></span><br><span class="line">http://c.biancheng.net</span><br><span class="line">C语言中文网</span><br><span class="line">Thread1成功执行</span><br><span class="line">Thread2成功执行</span><br><span class="line">主线程执行完毕</span><br></pre></td></tr></table></figure>

<p>程序中共存在 3 个线程，包括本就存在的主线程以及两个调用 pthread_create() 函数创建的线程（又称子线程），其中名为 mythread1 的线程负责执行 thread1() 函数，名为 mythread2 的线程负责执行 thread2() 函数。</p>
<p>程序中调用了两次 pthread_join() 函数，第 47 行 pthread_join() 函数的功能是令主线程等待 mythread1 线程执行完毕后再执行后续的代码，第 51 行处 pthread_join() 函数的功能是令主线程等待 mythread2 线程执行完毕后在执行后续的代码。</p>
<p>由此，我们已经学会了如何编写一个简单的多线程程序。</p>
<p>说明：</p>
<ul>
<li><p><code>pthread_t mythread</code> ：创建一个线程对象，线程名称叫<code>mythread</code>，此时线程还没有和要做的任务绑定；</p>
</li>
<li><p><code>pthread_create(&amp;mythread, NULL, Thread1, NULL) ： 创建一个线程，将线程对象和任务绑定，任务名叫</code>Thread1&#96;，任务也就是某个函数。</p>
<ul>
<li>第一个参数：要创建的线程，pthread_t 类型的<strong>指针</strong>变量，因此如果是线程对象，传入的是对象地址。</li>
<li>第二个参数为 NULL时表示：不修改新建线程的任何属性；</li>
<li>第三个参数  ThreadFun：新建线程要执行的任务（函数）；</li>
<li>第四个参数为NULL时表示：不传递给 ThreadFun() 函数任何参数；</li>
<li><code>res = pthread_create(&amp;mythread, NULL, Thread1, NULL);</code> 返回值 res 为 0 表示线程创建成功，反之则创建失败。</li>
</ul>
<p>&#x3D;&#x3D;<code>pthread_create</code>就开始进入线程，开始执行任务了，和主线程并行的，主线程接着往下走，互不影响。&#x3D;&#x3D;</p>
</li>
<li><p><code>pthread_join(mythread, &amp;thread_result)</code>：执行此语句时，表示主线程必须等待指定线程执行完毕，才能继续接着执行主语句。</p>
<ul>
<li>第一个参数：指定等待的线程</li>
<li>第二个参数：接收 ThreadFun() 函数的返回值，或者接收 pthread_exit() 函数指定的值</li>
<li><code>res = pthread_join(mythread, &amp;thread_result);</code> 返回值 res 为 0 表示函数执行成功，反之则执行失败。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>线程同步机制</title>
    <url>/2023/02/23/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h1 id="线程同步机制"><a href="#线程同步机制" class="headerlink" title="线程同步机制"></a>线程同步机制</h1><blockquote>
<p>c语言中文网：<a href="http://c.biancheng.net/thread/vip_8614.html">线程同步机制</a> </p>
</blockquote>
<p>《<a href="http://c.biancheng.net/thread/what-is-thread.html">线程是什么</a>》一节讲过，多线程程序中各个线程除了可以使用自己的私有资源（局部变量、函数形参等）外，还可以共享全局变量、静态变量、堆内存、打开的文件等资源。</p>
<p>不加限制的话，多个线程可以同时访问某一公共资源，就会出错。</p>
<p>举个例子，编写一个多线程程序模拟“4个售票员共同卖 10 张票”的过程，代码如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="comment">//全局变量，模拟总的票数</span></span><br><span class="line"><span class="type">int</span> ticket_sum = <span class="number">10</span>;</span><br><span class="line"><span class="comment">//模拟4个售票员一起售卖票的过程</span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">sell_ticket</span><span class="params">(<span class="type">void</span> *arg)</span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="comment">//4个售票员负责将 10 张票全部卖出</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//直至所有票全部卖出，4 个售票员才算完成任务</span></span><br><span class="line">        <span class="keyword">if</span> (ticket_sum &gt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            sleep(<span class="number">1</span>);</span><br><span class="line">            <span class="comment">//每个线程代表一个售票员</span></span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%u 卖第 %d 张票\n&quot;</span>, pthread_self(), <span class="number">10</span> - ticket_sum + <span class="number">1</span>);</span><br><span class="line">            ticket_sum--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> flag;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="type">void</span> *ans;</span><br><span class="line">    <span class="comment">//创建 4 个线程，代表 4 个售票员</span></span><br><span class="line">    <span class="type">pthread_t</span> tids[<span class="number">4</span>];</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        flag = pthread_create(&amp;tids[i], <span class="literal">NULL</span>, &amp;sell_ticket, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="keyword">if</span> (flag != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败!&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    sleep(<span class="number">10</span>); <span class="comment">// 阻塞主线程，等待所有子线程执行结束</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        flag = pthread_join(tids[i], &amp;ans);</span><br><span class="line">        <span class="keyword">if</span> (flag != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;tid=%d 等待失败！&quot;</span>, tids[i]);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>程序中新建了 4 个子线程，每个线程都可以访问 ticket_sum 全局变量，它们共同执行 sell_ticket() 函数，模拟“4个售票员共同售卖 10 张票”的过程。</p>
<p>假设程序编写在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">3296569088 卖第 1 张票</span><br><span class="line">3265099520 卖第 2 张票</span><br><span class="line">3286079232 卖第 3 张票</span><br><span class="line">3275589376 卖第 4 张票</span><br><span class="line">3286079232 卖第 5 张票</span><br><span class="line">3265099520 卖第 6 张票</span><br><span class="line">3296569088 卖第 7 张票</span><br><span class="line">3275589376 卖第 8 张票</span><br><span class="line">3286079232 卖第 9 张票</span><br><span class="line">3265099520 卖第 10 张票</span><br><span class="line">3275589376 卖第 11 张票</span><br><span class="line">3296569088 卖第 12 张票</span><br><span class="line">3286079232 卖第 13 张票</span><br></pre></td></tr></table></figure>



<p>程序的执行结果并不唯一，还可能输出如下类似的信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1492682496 卖第 1 张票</span><br><span class="line">1503172352 卖第 1 张票</span><br><span class="line">1482192640 卖第 1 张票</span><br><span class="line">1471702784 卖第 1 张票</span><br><span class="line">1503172352 卖第 5 张票</span><br><span class="line">1482192640 卖第 6 张票</span><br><span class="line">1492682496 卖第 6 张票</span><br><span class="line">1471702784 卖第 6 张票</span><br><span class="line">1503172352 卖第 9 张票</span><br><span class="line">1492682496 卖第 9 张票</span><br><span class="line">1471702784 卖第 9 张票</span><br><span class="line">1482192640 卖第 12 张票</span><br><span class="line">1503172352 卖第 13 张票</span><br></pre></td></tr></table></figure>

<p>程序执行过程中，出现了“多个售票员卖出同一张票”以及“4个售票员多卖出 3 张票”的异常情况。造成此类问题的根本原因在于，进程中公有资源的访问权限是完全开放的，各个线程可以随时访问这些资源，程序运行过程中很容易出现“多个线程同时访问某公共资源”的情况。</p>
<p>例如，之所以会出现“多个售票员卖出同一张票”的情况，因为这些线程几乎同一时间访问 ticket_sum 变量，得到的是相同的值。出现“4 个售票员多卖出 3 张票”的原因是：4 个线程访问 ticket_sum 变量得到的都是一个大于 0 的数，每个线程都可以继续执行 if 语句内的代码。由于各个线程先后执行的顺序不同，有的线程先执行<code>ticket_sum--</code>操作，导致其它线程计算<code>10-ticket_sum+1</code>表达式时，读取到的 ticket_num 变量的值为负数，因此表达式的值会出现大于 10 的情况。</p>
<p>我们通常将&#x3D;&#x3D;“多个线程同时访问某一公共资源”的现象称为“线程间产生了资源竞争”或者“线程间抢夺公共资源”，线程间竞争资源往往会导致程序的运行结果出现异常，感到匪夷所思，严重时还会导致程序运行崩溃。&#x3D;&#x3D;</p>
<p>幸运地是，Linux 提供了很多种解决方案，确定各个线程可以同步访问进程提供的公共资源（简称“线程同步”）。所谓&#x3D;&#x3D;线程同步，简单地理解就是：当一个线程访问某公共资源时，其它线程不得访问该资源，它们只能等待此线程访问完成后，再逐个访问该资源。&#x3D;&#x3D;</p>
<h2 id="Linux线程同步的解决方案"><a href="#Linux线程同步的解决方案" class="headerlink" title="Linux线程同步的解决方案"></a>Linux线程同步的解决方案</h2><p>Linux 环境中，实现线程同步的常用方法有 4 种，分别称为<a href="http://c.biancheng.net/thread/vip_8615.html">互斥锁</a>、<a href="http://c.biancheng.net/thread/vip_8616.html">信号量</a>、<a href="http://c.biancheng.net/thread/vip_8617.html">条件变量</a>和<a href="http://c.biancheng.net/thread/vip_8618.html">读写锁</a>。</p>
<ul>
<li><strong>互斥锁（Mutex）</strong>又称互斥量或者互斥体，是最简单也最有效地一种线程同步机制。互斥锁的用法和实际生活中的锁非常类似，当一个线程访问公共资源时，会及时地“锁上”该资源，阻止其它线程访问；访问结束后再进行“解锁”操作，将该资源让给其它线程访问。</li>
<li><strong>信号量</strong>又称“信号灯”，主要用于控制同时访问公共资源的线程数量，当线程数量控制在 ≤1 时，该信号量又称二元信号量，功能和互斥锁非常类似；当线程数量控制在 N（≥2）个时，该信号量又称多元信号量，指的是同一时刻最多只能有 N 个线程访问该资源。</li>
<li><strong>条件变量</strong>的功能类似于实际生活中的门，门有“打开”和“关闭”两种状态，分别对应条件变量的“成立”状态和“不成立”状态。当条件变量“不成立”时，任何线程都无法访问资源，只能等待条件变量成立；一旦条件变量成立，所有等待的线程都会恢复执行，访问目标资源。为了防止各个线程竞争资源，条件变量总是和互斥锁搭配使用。</li>
<li>多线程程序中，如果大多数线程都是对公共资源执行读取操作，仅有少量的线程对公共资源进行修改，这种情况下可以使用<strong>读写锁</strong>解决线程同步问题。</li>
</ul>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>终止线程执行（3种方法）pthread_exit()、pthread_cancel()</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E7%BB%88%E6%AD%A2%E7%BA%BF%E7%A8%8B%E6%89%A7%E8%A1%8C%EF%BC%883%E7%A7%8D%E6%96%B9%E6%B3%95%EF%BC%89/</url>
    <content><![CDATA[<h1 id="终止线程执行（3种方法）pthread-exit-、pthread-cancel"><a href="#终止线程执行（3种方法）pthread-exit-、pthread-cancel" class="headerlink" title="终止线程执行（3种方法）pthread_exit()、pthread_cancel()"></a>终止线程执行（3种方法）pthread_exit()、pthread_cancel()</h1><blockquote>
<p>c语言中文网：<a href="http://c.biancheng.net/thread/vip_8610.html">终止线程执行（3种方法）</a></p>
</blockquote>
<p>多线程程序中，终止线程执行的方式有 3 种，分别是：</p>
<ol>
<li>线程执行完成后，自行终止；</li>
<li>线程执行过程中遇到了 pthread_exit() 或者 return，也会终止执行；</li>
<li>线程执行过程中，接收到其它线程发送的“终止执行”的信号，然后终止执行。</li>
</ol>
<p>三种方式中，第一种很容易理解，本节重点给大家讲解后两种方法。</p>
<h2 id="1、pthread-exit"><a href="#1、pthread-exit" class="headerlink" title="1、pthread_exit()"></a>1、pthread_exit()</h2><p>在 C 语言中，return 关键字用于终止函数执行，必要时还能将函数的执行结果反馈给调用者。return 关键字不仅可以用于普通函数，线程函数中也可以使用它。</p>
<p><code>&lt;pthread.h&gt;</code>头文件中，提供有一个和 return 关键字相同功能的 pthread_exit() 函数。和之前不同，pthread_exit() 函数只适用于线程函数，而不能用于普通函数。</p>
<p>（遇到pthread_exit，视为return来处理）</p>
<p>pthread_exit() 函数的语法格式如下：</p>
<p><code>void pthread_exit(void *retval); </code>（没有返回值，<code>pthread_exit</code>定义在<code>pthread.h</code>里）</p>
<p>retval 是<code>void*</code>类型的指针，可以指向任何类型的数据，它指向的数据将作为线程退出时的返回值。如果线程不需要返回任何数据，将 retval 参数置为<code>NULL</code>即可。</p>
<blockquote>
<p>注意，retval 指针不能指向函数内部的局部数据（比如局部变量）。换句话说，pthread_exit() 函数不能返回一个指向局部数据的指针，否则很可能使程序运行结果出错甚至崩溃。</p>
</blockquote>
<p>通过一个样例，给大家演示 pthread_exit() 函数的用法（样例一）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="comment">//线程要执行的函数，arg 用来接收线程传递过来的数据</span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">ThreadFun</span><span class="params">(<span class="type">void</span> *arg)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//终止线程的执行，将“http://c.biancheng.net”返回</span></span><br><span class="line">    pthread_exit(<span class="string">&quot;http://c.biancheng.net&quot;</span>); <span class="comment">//返回的字符串存储在常量区，并非当前线程的私有资源</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;*****************&quot;</span>);<span class="comment">//此语句不会被线程执行</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="comment">//创建一个空指针</span></span><br><span class="line">    <span class="type">void</span> * thread_result;</span><br><span class="line">    <span class="comment">//定义一个表示线程的变量</span></span><br><span class="line">    <span class="type">pthread_t</span> myThread;</span><br><span class="line">    res = pthread_create(&amp;myThread, <span class="literal">NULL</span>, ThreadFun, <span class="literal">NULL</span>);  <span class="comment">//没有打印第8行</span></span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//等待 myThread 线程执行完成，并用 thread_result 指针接收该线程的返回值</span></span><br><span class="line">    res = pthread_join(myThread, &amp;thread_result);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;等待线程失败&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span>, (<span class="type">char</span>*)thread_result);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序存储在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">http://c.biancheng.net</span><br></pre></td></tr></table></figure>

<p>不难看出，myThread 线程并没有执行 ThreadFun() 函数中最后一个 printf() 语句，从侧面验证了 pthread_exit() 函数的功能。此外，我们通过在主线程（main() 函数）调用 pthread_join() 函数，获取到了 myThread 线程返回的数据。</p>
<blockquote>
<p>有关 pthread_join() 函数的功能和用法，我们会在《<a href="http://c.biancheng.net/thread/vip_8627.html">获取线程函数的返回值</a>》一节中给大家讲解。</p>
</blockquote>
<h4 id="pthread-exit-和return的区别"><a href="#pthread-exit-和return的区别" class="headerlink" title="pthread_exit()和return的区别"></a>pthread_exit()和return的区别</h4><p>修改样例一中的程序，将第 8 行（调用 pthread_exit() ）代码替换成如下语句：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> <span class="string">&quot;http://c.biancheng.net&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>重新编译、执行此程序，会发现程序的执行结果和之前完全相同。这意味着当线程执行结束时，无论是采用 return 语句还是调用 pthread_exit() 函数，主线程中的 pthread_join() 函数都可以接收到线程的返回值。</p>
<p>这就产生了一个问题，既然 return 关键字也适用于线程函数，&lt;pthread.h&gt; 头文件为什么还提供 pthread_exit() 函数，不是多此一举吗？</p>
<p>首先，return 语句和 pthread_exit() 函数的含义不同，return 的含义是返回，它不仅可以用于线程执行的函数，普通函数也可以使用；pthread_exit() 函数的含义是线程退出，它专门用于结束某个线程的执行。</p>
<p>在主线程（main() 函数）中，return 和 pthread_exit() 函数的区别最明显。举个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">ThreadFun</span><span class="params">(<span class="type">void</span> *arg)</span></span><br><span class="line">&#123;</span><br><span class="line">    sleep(<span class="number">5</span>);<span class="comment">//等待一段时间</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;http://c.biancheng.net\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="type">pthread_t</span> myThread;</span><br><span class="line">    </span><br><span class="line">    res = pthread_create(&amp;myThread, <span class="literal">NULL</span>, ThreadFun, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;C语言中文网\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过执行结果可以看到，主线程正常执行结束，myThread 线程并没有输出指定的数据。原因很简单，&#x3D;&#x3D;主线程执行速度很快，主线程最后执行的 return 语句不仅会终止主线程执行，还会终止其它子线程执行&#x3D;&#x3D;。也就是说，myThread 线程还没有执行输出语句就被终止了。</p>
<p>将上面程序中，main() 函数中的<code>return 0;</code>用如下语句替换：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">pthread_exit(<span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure>

<p>重新编译、执行程序，运行结果为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">C语言中文网</span><br><span class="line">http://c.biancheng.net</span><br></pre></td></tr></table></figure>

<p>对比上面两个执行结果，可以得出的结论是：&#x3D;&#x3D;pthread_exit() 函数只会终止当前线程，不会影响其它线程的执行（比如主线程）&#x3D;&#x3D;。</p>
<blockquote>
<p>此外，pthread_exit() 函数还会自动调用线程清理程序（本质是一个由 pthread_cleanup_push() 指定的自定义函数），而 return 不具备这个能力。</p>
</blockquote>
<p>总之，如果实际场景中想终止某个子线程，强烈建议大家使用 pthread_exit() 函数。终止主线程时，return 和 pthread_exit() 函数发挥的功能不同，可以根据需要自行选择。</p>
<h2 id="2、pthread-cancel"><a href="#2、pthread-cancel" class="headerlink" title="2、pthread_cancel()"></a>2、pthread_cancel()</h2><p>多线程程序中，一个线程还可以向另一个线程发送“终止执行”的信号（后续称“Cancel”信号），这时就需要调用 pthread_cancel() 函数。</p>
<p>pthread_cancel() 函数声明在<code>&lt;pthread.h&gt;</code>头文件中，语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_cancel</span><span class="params">(<span class="type">pthread_t</span> thread)</span>;</span><br></pre></td></tr></table></figure>

<p>参数 thread 用于接收 Cancel 信号的目标线程。</p>
<p>如果 pthread_cancel() 函数成功地发送了 Cancel 信号，返回数字 0，否则返回非零数。对于因“未找到目标线程”导致的信号发送失败，函数返回 ESRCH 宏（定义在<code>&lt;errno.h&gt;</code>头文件中，该宏的值为整数 3）。</p>
<blockquote>
<p>注意，pthread_cancel() 函数的功能仅仅是向目标线程发送 Cancel 信号，至于目标线程是否接收该信号，何时响应该信号，全由目标线程决定。我们会在《<a href="http://c.biancheng.net/thread/vip_8613.html">终止线程执行，千万别踩这个坑！</a>》一节给您做详细讲解。</p>
</blockquote>
<p>对于接收 Cancel 信号后结束执行的目标线程，等同于该线程自己执行如下语句：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">pthread_exit(PTHREAD_CANCELED);</span><br></pre></td></tr></table></figure>

<p>也就是说，当一个线程被强制终止执行时，它会返回<code>PTHREAD_CANCELED</code>这个宏（定义在<code>&lt;pthread.h&gt;</code>头文件中）。</p>
<p>接下来通过一个样例，给大家演示 pthread_cancel() 函数的用法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span>     <span class="comment">// sleep() 函数</span></span></span><br><span class="line"><span class="comment">//线程执行的函数</span></span><br><span class="line"><span class="type">void</span> * <span class="title function_">thread_Fun</span><span class="params">(<span class="type">void</span> * arg)</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;新建线程开始执行\n&quot;</span>);</span><br><span class="line">    sleep(<span class="number">10</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pthread_t</span> myThread;</span><br><span class="line">    <span class="type">void</span> * mess;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="comment">//创建 myThread 线程</span></span><br><span class="line">    res = pthread_create(&amp;myThread, <span class="literal">NULL</span>, thread_Fun, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sleep(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">//向 myThread 线程发送 Cancel 信号</span></span><br><span class="line">    res = pthread_cancel(myThread);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;终止 myThread 线程失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//获取已终止线程的返回值</span></span><br><span class="line">    res = pthread_join(myThread, &amp;mess);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;等待线程失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//如果线程被强制终止，其返回值为 PTHREAD_CANCELED</span></span><br><span class="line">    <span class="keyword">if</span> (mess == PTHREAD_CANCELED) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myThread 线程被强制终止\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;error\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">新建线程开始执行</span><br><span class="line">myThread 线程被强制终止</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>线程属性有哪些，如何自定义线程属性？</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E5%B1%9E%E6%80%A7%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%8C%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BA%BF%E7%A8%8B%E5%B1%9E%E6%80%A7%EF%BC%9F/</url>
    <content><![CDATA[<h1 id="线程属性有哪些，如何自定义线程属性？"><a href="#线程属性有哪些，如何自定义线程属性？" class="headerlink" title="线程属性有哪些，如何自定义线程属性？"></a>线程属性有哪些，如何自定义线程属性？</h1><blockquote>
<p>C语言中文网：<a href="http://c.biancheng.net/thread/vip_8620.html">线程属性有哪些，如何自定义线程属性？</a>    </p>
</blockquote>
<p>通过阅读前面章节，我们已经学会了如果创建一个线程，例如：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> * <span class="title function_">threadFun</span><span class="params">(<span class="type">void</span>* args)</span>&#123;</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">pthread_t</span> myThread;</span><br><span class="line">pthread_create(&amp;myThread, <span class="literal">NULL</span>, ThreadFun, <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure>

<p>程序中，pthread_create() 函数需要传递 4 个参数，其中第二个参数 NULL 表示以系统默认的属性创建线程。</p>
<p>那么，线程都有哪些属性，线程的属性又该如何设置或者修改呢？接下来，我们将一一为大家解开这些疑惑。</p>
<h2 id="线程属性的种类"><a href="#线程属性的种类" class="headerlink" title="线程属性的种类"></a>线程属性的种类</h2><p>POSIX 标准中，线程的属性用 pthread_attr_t 类型的变量表示，举个例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="type">pthread_attr_t</span> myAttr;</span><br></pre></td></tr></table></figure>

<p>由此，我们就定义了一个表示线程属性的变量。使用此变量前，必须调用 pthread_attr_init() 函数进行初始化，该函数的语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_init</span><span class="params">(<span class="type">pthread_attr_t</span> * attr)</span>;</span><br></pre></td></tr></table></figure>

<p>此函数定义在 &lt;pthread.h&gt; 头文件中，函数执行成功时，返回数字 0，反之返回非零数。</p>
<p>例如，对 myAttr 变量进行初始化：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">pthread_attr_init(&amp;myAttr);</span><br></pre></td></tr></table></figure>

<p>通过调用 pthread_attr_init() 函数，myAttr 变量就拥有了系统默认的线程属性。在此基础上，我们可以根据需要对 myAttr 变量的属性值进行修改。</p>
<p>pthread_attr_t 是一种结构体类型，内部包含多种线程属性：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">       <span class="type">int</span> __detachstate;</span><br><span class="line">       <span class="type">int</span> __schedpolicy;</span><br><span class="line">       <span class="class"><span class="keyword">struct</span> <span class="title">sched_param</span> __<span class="title">schedparam</span>;</span></span><br><span class="line">       <span class="type">int</span> __inheritsched;</span><br><span class="line">       <span class="type">int</span> __scope;</span><br><span class="line">       <span class="type">size_t</span> __guardsize;</span><br><span class="line">       <span class="type">int</span> __stackaddr_set;</span><br><span class="line">       <span class="type">void</span>* __stackaddr;</span><br><span class="line">       <span class="type">size_t</span> __stacksize;</span><br><span class="line">&#125; <span class="type">pthread_attr_t</span>;</span><br></pre></td></tr></table></figure>

<p>接下来，我们将从中挑选出几个常用的属性，给您讲解它们的功能以及修改的方法。</p>
<h4 id="1-detachstate"><a href="#1-detachstate" class="headerlink" title="1) __detachstate"></a>1) __detachstate</h4><p>我们知道，默认属性的线程在执行完目标函数后，占用的私有资源并不会立即释放，要么执行完 pthread_join() 函数后释放，要么整个进程执行结束后释放。某些场景中，我们并不需要接收线程执行结束后的返回值，如果想让线程执行完后立即释放占用的私有资源，就可以通过修改 __detachstate 属性值来实现。</p>
<p>__detachstate 属性值用于指定线程终止执行的时机，该属性的值有两个，分别是：</p>
<ul>
<li>PTHREAD_CREATE_JOINABLE（默认值）：线程执行完函数后不会自行释放资源；</li>
<li>PTHREAD_CREATE_DETACHED：线程执行完函数后，会自行终止并释放占用的资源。</li>
</ul>
<p>关于 __detachstate 属性，&lt;pthread.h&gt; 头文件中提供了 2 个与它相关的函数，分别是：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_getdetachstate</span><span class="params">(<span class="type">const</span> <span class="type">pthread_attr_t</span> * attr,<span class="type">int</span> * detachstate)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_setdetachstate</span><span class="params">(<span class="type">pthread_attr_t</span> *sttr，<span class="type">int</span> detachstate)</span>;</span><br></pre></td></tr></table></figure>

<p>pthread_attr_getdetachstate() 函数用于获取 __detachstate 属性的值，detachstate 指针用于接收 __detachstate 属性的值；pthread_attr_setdetachstate() 函数用于修改 __detachstate 属性的值，detachstate 整形变量即为新的 __detachstate 属性值。两个函数执行成功时返回数字 0，反之返回非零数。</p>
<p>此外，&lt;pthread.h&gt; 头文件还提供有 pthread_detach() 函数，可以直接将目标线程的 __detachstate 属性改为 PTHREAD_CREATE_DETACHED，语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_detach</span><span class="params">(<span class="type">pthread_t</span> thread)</span>;</span><br></pre></td></tr></table></figure>

<p>函数执行成功时返回数字 0 ，反之返回非零数。</p>
<h4 id="2-schedpolicy"><a href="#2-schedpolicy" class="headerlink" title="2) __schedpolicy"></a>2) __schedpolicy</h4><p>__schedpolicy 属性用于指定系统调度该线程所用的算法，它的值有以下 3 个：</p>
<ul>
<li>SCHED_OTHER（默认值）：分时调度算法；</li>
<li>SCHED_FIFO：先到先得（实时调度）算法；</li>
<li>SCHED_RR：轮转法；</li>
</ul>
<blockquote>
<p>其中，SCHED_OTHER 调度算法不支持为线程设置优先级，而另外两种调度算法支持。</p>
</blockquote>
<p>&lt;pthread.h&gt; 头文件提供了如下两个函数，专门用于访问和修改 __schedpolicy 属性：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_getschedpolicy</span><span class="params">(<span class="type">const</span> <span class="type">pthread_attr_t</span> *, <span class="type">int</span> * policy)</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_setschedpolicy</span><span class="params">(pthread_attr_*, <span class="type">int</span> policy)</span></span><br></pre></td></tr></table></figure>

<p>pthread_attr_getschedpolicy() 函数用于获取当前 __schedpolicy 属性的值；pthread_attr_setschedpolicy() 函数用于修改 __schedpolicy 属性的值。函数执行成功时，返回值为数字 0，反之返回非零数。</p>
<h4 id="3-schedparam"><a href="#3-schedparam" class="headerlink" title="3) __schedparam"></a>3) __schedparam</h4><p>__scheparam 用于设置线程的优先级（默认值为 0），该属性仅当线程的 __schedpolicy 属性为 SCHED_FIFO 或者 SCHED_RR 时才能发挥作用。</p>
<p>&lt;pthread.h&gt; 头文件中提供了如下两个函数，用于获取和修改 __schedparam 属性的值：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_getschedparam</span><span class="params">(<span class="type">const</span> <span class="type">pthread_attr_t</span> *attr, <span class="keyword">struct</span> sched_param *param)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_setschedparam</span><span class="params">(<span class="type">pthread_attr_t</span> *attr, <span class="type">const</span> <span class="keyword">struct</span> sched_param *param)</span>;</span><br></pre></td></tr></table></figure>

<p>其中，param 参数用于接收或者修改 __scheparam 属性的优先级，它是 sched_param 结构体类型的变量，定义在 &lt;sched.h&gt; 头文件中，内部仅有一个 sched_priority 整形变量，用于表示线程的优先级。函数执行成功时返回数字 0，反之返回非零数。</p>
<blockquote>
<p>当需要修改线程的优先级时，我们只需创建一个 sched_param 类型的变量并为其内部的 sched_priority 成员赋值，然后将其传递给 pthrerd_attr_setschedparam() 函数。</p>
</blockquote>
<p>不同的操作系统，线程优先级的值的范围不同，您可以通过调用如下两个系统函数获得当前系统支持的最大和最小优先级的值：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">sched_get_priority_max</span><span class="params">(<span class="type">int</span> policy)</span>;   <span class="comment">//获得最大优先级的值</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">sched_get_priority_min</span><span class="params">(<span class="type">int</span> policy)</span>;   <span class="comment">//获得最小优先级的值</span></span><br></pre></td></tr></table></figure>

<p>其中，policy 的值可以为 SCHED_FIFO、SCHED_RR 或者 SCHED_OTHER，当 policy 的值为 SCHED_OTHER 时，最大和最小优先级的值都为 0。</p>
<h4 id="4-inheritsched"><a href="#4-inheritsched" class="headerlink" title="4) __inheritsched"></a>4) __inheritsched</h4><p>新建线程的调度属性（____schedpolicy 和 __schedparam 属性）默认遵循父线程的属性（谁创建它，谁就是它的父线程），如果我们想自定义线程的调度属性，就需要借助 __inheritsched 属性。</p>
<p>也就是说，新线程的调度属性要么遵循父线程，要么遵循 myAttr 规定的属性，默认情况下 __inheritsched 规定新线程的调度属性遵循父线程，我们也可以修改 __inheritsched 的值，使新线程的调度属性遵循自定义的属性变量（如文章开头定义的 myAttr）规定的值。</p>
<p>&lt;pthread.h&gt; 头文件提供了如下两个函数，分别用于获取和修改 __inheritsched 属性的值：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//获取 __inheritsched 属性的值</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_getinheritsched</span><span class="params">(<span class="type">const</span> <span class="type">pthread_attr_t</span> *attr,<span class="type">int</span> *inheritsched)</span>;</span><br><span class="line"><span class="comment">//修改 __inheritsched 属性的值</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_setinheritsched</span><span class="params">(<span class="type">pthread_attr_t</span> *attr,<span class="type">int</span> inheritsched)</span>;</span><br></pre></td></tr></table></figure>

<p>其中在 pthread_attr_setinheritsched() 函数中，inheritsched 参数的可选值有两个，分别是：</p>
<ul>
<li>PTHREAD_INHERIT_SCHED（默认值）：新线程的调度属性继承自父线程；</li>
<li>PTHREAD_EXPLICIT_SCHED：新线程的调度属性继承自 myAttr 规定的值。</li>
</ul>
<p>以上两个函数执行成功时返回数字 0，反之返回非零数。</p>
<h4 id="5-scope"><a href="#5-scope" class="headerlink" title="5) __scope"></a>5) __scope</h4><p>线程执行过程中，可以只和同进程内的其它线程争夺 CPU 资源，也可以和系统中所有的其它线程争夺 CPU 资源，__scope 属性用于指定目标线程和哪些线程抢夺 CPU 资源。</p>
<p>&lt;pthread.h&gt; 头文件中提供了如下两个函数，分别用于获取和修改 __scope 属性的值：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//获取 __scope 属性的值</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_getscope</span><span class="params">(<span class="type">const</span> <span class="type">pthread_attr_t</span> * attr,<span class="type">int</span> * scope)</span>;</span><br><span class="line"><span class="comment">//修改 __scope 属性的值</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_setscope</span><span class="params">(<span class="type">pthread_attr_t</span> * attr,<span class="type">int</span> * scope)</span>;</span><br></pre></td></tr></table></figure>

<p>当调用 pthread_attr_setscope() 函数时，scope 参数的可选值有两个，分别是：</p>
<ul>
<li>PTHREAD_SCOPE_PROCESS：同一进程内争夺 CPU 资源；</li>
<li>PTHREAD_SCOPE_SYSTEM：系统所有线程之间争夺 CPU 资源。</li>
</ul>
<blockquote>
<p>Linux系统仅支持 PTHREAD_SCOPE_SYSTEM，即所有线程之间争夺 CPU 资源。</p>
</blockquote>
<p>当函数执行成功时，返回值为数字 0，反之返回非零数。</p>
<h4 id="6-stacksize"><a href="#6-stacksize" class="headerlink" title="6) __stacksize"></a>6) __stacksize</h4><p>每个线程都有属于自己的内存空间，通常称为栈（有时也称堆栈、栈空间、栈内存等）。某些场景中，线程执行可能需要较大的栈内存，此时就需要我们自定义线程拥有的栈的大小。</p>
<p>__stacksize 属性用于指定线程所拥有的栈内存的大小。&lt;pthread.h&gt; 提供有以下两个函数，分别用于获取和修改栈空间的大小：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//获取当前栈内存的大小</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_getstacksize</span><span class="params">(<span class="type">const</span> <span class="type">pthread_attr_t</span> * attr,<span class="type">size_t</span> * stacksize)</span>;</span><br><span class="line"><span class="comment">//修改栈内存的大小</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_setsstacksize</span><span class="params">(<span class="type">pthread_attr_t</span> * attr,<span class="type">size_t</span> * stacksize)</span>;</span><br></pre></td></tr></table></figure>

<p>函数执行成功时，返回值为数字 0，反之返回非零数。</p>
<h4 id="7-guardsize"><a href="#7-guardsize" class="headerlink" title="7) __guardsize"></a>7) __guardsize</h4><p>每个线程中，栈内存的后面都紧挨着一块空闲的内存空间，我们通常称这块内存为警戒缓冲区，它的功能是：一旦我们使用的栈空间超出了额定值，警戒缓冲区可以确保线程不会因“栈溢出”立刻执行崩溃。</p>
<p>__guardsize 属性专门用来设置警戒缓冲区的大小，&lt;pthread.h&gt; 头文件中提供了如下两个函数，分别用于获取和修改 __guardsize 属性的值：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_getguardsize</span><span class="params">(<span class="type">const</span> <span class="type">pthread_attr_t</span> *<span class="keyword">restrict</span> attr,<span class="type">size_t</span> *<span class="keyword">restrict</span> guardsize)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_attr_setguardsize</span><span class="params">(<span class="type">pthread_attr_t</span> *attr ,<span class="type">size_t</span> *guardsize)</span>;</span><br></pre></td></tr></table></figure>

<p>pthread_attr_setguardsize() 函数中，设置警戒缓冲区的大小为参数 guardsize 指定的字节数。函数执行成功时返回数字 0，反之返回非零数。</p>
<h2 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h2><p>接下来通过一个样例，给大家演示如何自定义线程的属性：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="comment">//myThread1 线程执行的函数</span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">Thread1</span><span class="params">(<span class="type">void</span> *arg)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Thread1 正在执行\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;http://c.biancheng.net\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Thread1 执行完毕\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//myThread2 线程执行的函数</span></span><br><span class="line"><span class="type">void</span>* <span class="title function_">Thread2</span><span class="params">(<span class="type">void</span>* arg)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Thread2 正在执行\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;C语言中文网\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Thread2 执行完毕\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> num1, num2, res;</span><br><span class="line">    <span class="comment">//创建两个线程</span></span><br><span class="line">    <span class="type">pthread_t</span> mythread1, mythread2;</span><br><span class="line">    <span class="comment">//创建两个表示线程优先级的变量</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span>  <span class="title">sched_param</span> <span class="title">param1</span>, <span class="title">param2</span>;</span></span><br><span class="line">    <span class="comment">//创建两个表示线程属性的变量</span></span><br><span class="line">    <span class="type">pthread_attr_t</span> myAttr1, myAttr2;</span><br><span class="line">    <span class="comment">//接收 2 个整数，用于设定线程的优先级</span></span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">3</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;未向程序传入 2 个表示优先级的数字\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//初始化线程属性</span></span><br><span class="line">    res = pthread_attr_init(&amp;myAttr1);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr1 init Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    res = pthread_attr_init(&amp;myAttr2);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr1 init Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//设置 myAttr1 的 __detachstate 属性值为 PTHREAD_CREATE_DETACHED</span></span><br><span class="line">    <span class="comment">//遵循 myAttr1 属性的线程执行函数完毕后会自行释放占用私有资源，不支持 pthread_join() 函数</span></span><br><span class="line">    res = pthread_attr_setdetachstate(&amp;myAttr1, PTHREAD_CREATE_DETACHED);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr1 set_detachstate Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//设置 myAttr1 的 __scope 属性值为 PTHREAD_SCOPE_SYSTEM</span></span><br><span class="line">    <span class="comment">//遵循 myAttr1 属性的线程将同系统中的所有其它线程争夺 CPU 资源</span></span><br><span class="line">    res = pthread_attr_setscope(&amp;myAttr1, PTHREAD_SCOPE_SYSTEM);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr1 set_scope Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//设置 myAttr2 的 __scope 属性值为 PTHREAD_SCOPE_SYSTEM</span></span><br><span class="line">    <span class="comment">//遵循 myAttr2 属性的线程将同系统中的所有其它线程争夺 CPU 资源</span></span><br><span class="line">    res = pthread_attr_setscope(&amp;myAttr2, PTHREAD_SCOPE_SYSTEM);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr2 set_scope Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//设置 myAttr1 的 __schedpolicy 属性值为 SCHED_FIFO</span></span><br><span class="line">    <span class="comment">//系统会以实时调用的方式执行遵循 myAttr1 属性的线程</span></span><br><span class="line">    res = pthread_attr_setschedpolicy(&amp;myAttr1, SCHED_FIFO);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr1 set_policy Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">//设置 myAttr2 的 __schedpolicy 属性值为 SCHED_FIFO</span></span><br><span class="line">    <span class="comment">//系统会以实时调用的方式执行遵循 myAttr2 属性的线程</span></span><br><span class="line">    res = pthread_attr_setschedpolicy(&amp;myAttr2, SCHED_FIFO);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr2 set_policy Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//设置 myAttr1 的 __inheritsched 属性值为 PTHREAD_EXPLICIT_SCHED</span></span><br><span class="line">    <span class="comment">//myAttr1 属性的线程将遵循自定义的线程属性</span></span><br><span class="line">    res = pthread_attr_setinheritsched(&amp;myAttr1, PTHREAD_EXPLICIT_SCHED);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr1 set_inheritsched fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">//设置 myAttr2 的 __inheritsched 属性值为 PTHREAD_EXPLICIT_SCHED</span></span><br><span class="line">    <span class="comment">//myAttr2 属性的线程将遵循自定义的线程属性</span></span><br><span class="line">    res = pthread_attr_setinheritsched(&amp;myAttr2, PTHREAD_EXPLICIT_SCHED);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myAttr2 set_inheritsched fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//想 argv[] 数组中的字符转换为数字</span></span><br><span class="line">    num1 = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">    num2 = atoi(argv[<span class="number">2</span>]);</span><br><span class="line">    <span class="comment">// 分别将 num1 和 num2 作为线程优先级的值</span></span><br><span class="line">    param1.sched_priority = num1;</span><br><span class="line">    param2.sched_priority = num2;</span><br><span class="line">    <span class="comment">//设置 myAttr1 属性的优先级为 param1</span></span><br><span class="line">    res = pthread_attr_setschedparam(&amp;myAttr1, &amp;param1);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;param1 setscheparam Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//设置 myAttr2 属性的优先级为 param2</span></span><br><span class="line">    res = pthread_attr_setschedparam(&amp;myAttr2, &amp;param2);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;param2 setscheparam Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//创建新线程并遵循 myAttr1 属性</span></span><br><span class="line">    res = pthread_create(&amp;mythread1, &amp;myAttr1, Thread1, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;mythread1 create Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//创建新线程并遵循 myAttr2 属性</span></span><br><span class="line">    res = pthread_create(&amp;mythread2, &amp;myAttr2, Thread2, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;mythread2 create Fail\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    sleep(<span class="number">5</span>);  <span class="comment">//等待 mythread1 和 mythread2 两个线程执行完</span></span><br><span class="line">    <span class="comment">//尝试 pthread_join() 函数等待 mythread1 线程执行结束</span></span><br><span class="line">    res = pthread_join(mythread1, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (res == EINVAL) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;mythread1不支持调用 pthread_join()函数\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//尝试等待 mythread2 线程执行结束</span></span><br><span class="line">    res = pthread_join(mythread2, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;mythread2 has finished\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;主线程执行完毕\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe 30 3</span></span><br><span class="line">Thread1 正在执行</span><br><span class="line">http://c.biancheng.net</span><br><span class="line">Thread1 执行完毕</span><br><span class="line">Thread2 正在执行</span><br><span class="line">C语言中文网</span><br><span class="line">Thread2 执行完毕</span><br><span class="line">mythread1不支持调用 pthread_join()函数</span><br><span class="line">主线程执行完毕</span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe 3 30</span></span><br><span class="line">Thread2 正在执行</span><br><span class="line">C语言中文网</span><br><span class="line">Thread2 执行完毕</span><br><span class="line">Thread1 正在执行</span><br><span class="line">http://c.biancheng.net</span><br><span class="line">Thread1 执行完毕</span><br><span class="line">mythread1不支持调用 pthread_join()函数</span><br><span class="line">主线程执行完毕</span><br></pre></td></tr></table></figure>



<p>上面展示了两组执行结果，分别为 mythread1 和 mythread2 设置了不同的优先级，从运行结果可以看到，哪个线程的优先级高（数值大），哪个线程先执行。</p>
<p>此外，通过程序的执行结果还可以看出，由于 mythread 线程的 __detachstate 属性为 PTHREAD_CREATE_DETACHED，因此该线程执行完 Thread1() 函数后会自行终止并释放占用的私有资源，不需要也不允许在其它线程（比如主线程）中执行 pthread_join(mythread1, NULL) 函数。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>终止线程执行，千万别踩这个坑！</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E7%BB%88%E6%AD%A2%E7%BA%BF%E7%A8%8B%E6%89%A7%E8%A1%8C%EF%BC%8C%E5%8D%83%E4%B8%87%E5%88%AB%E8%B8%A9%E8%BF%99%E4%B8%AA%E5%9D%91%EF%BC%81/</url>
    <content><![CDATA[<h1 id="终止线程执行，千万别踩这个坑！"><a href="#终止线程执行，千万别踩这个坑！" class="headerlink" title="终止线程执行，千万别踩这个坑！"></a>终止线程执行，千万别踩这个坑！</h1><blockquote>
<p>c语言中文网：<a href="http://c.biancheng.net/thread/vip_8613.html">终止线程执行，千万别踩这个坑！</a> </p>
</blockquote>
<p>使用 <code>pthread_cancel()</code>函数，有时候会发生并没有cancel掉子线程的情况，子线程仍然继续运行。</p>
<p>在《<a href="http://c.biancheng.net/thread/vip_8610.html">终止线程执行（3种方法）</a>》一节中，我们对 pthread_cancel() 函数的功能和用法做了详细的介绍。总的来说，通过调用 pthread_cancel() 函数，一个线程可以向同进程内的另一个线程发送“终止执行”的信号（Cancel 信号），使目标线程结束执行。</p>
<p>实际使用 pthread_cancel() 函数时，很多读者会发现“Cancel 信号成功发送，但目标线程并未立即终止执行”等类似的问题举个例子，在 Linux 环境中执行如下程序：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> * <span class="title function_">thread_Fun</span><span class="params">(<span class="type">void</span> * arg)</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;新建线程开始执行\n&quot;</span>);</span><br><span class="line">    <span class="comment">//插入无限循环的代码，测试 pthread_cancel()函数的有效性</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pthread_t</span> myThread;</span><br><span class="line">    <span class="type">void</span> * mess;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    res = pthread_create(&amp;myThread, <span class="literal">NULL</span>, thread_Fun, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sleep(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">//令 myThread 线程终止执行</span></span><br><span class="line">    res = pthread_cancel(myThread);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;终止 myThread 线程失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;等待 myThread 线程执行结束：\n&quot;</span>);</span><br><span class="line">    res = pthread_join(myThread, &amp;mess);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;等待线程失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mess == PTHREAD_CANCELED) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myThread 线程被强制终止\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;error\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">新建线程开始执行</span><br><span class="line">等待 myThread 线程执行结束：</span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<p><code>myThread 线程被强制终止</code>这行并没有出来，就卡在<code>res = pthread_join(myThread, &amp;mess);</code>这步，子线程一直在运行，说明并没有cancel掉。</p>
<p>程序中，主线程（ main() 函数）试图调用 pthread_cancel() 函数终止 myThread 线程执行。从运行结果不难发现，pthread_cancel() 函数成功发送了 Cancel 信号，但目标线程仍在执行。</p>
<p>也就是说，&#x3D;&#x3D;接收到 Cancel 信号的目标线程并没有立即处理该信号，或者说目标线程根本没有理会此信号。&#x3D;&#x3D;解决类似的问题，我们就需要搞清楚目标线程对 Cancel 信号的处理机制。</p>
<h2 id="线程对Cancel信号的处理"><a href="#线程对Cancel信号的处理" class="headerlink" title="线程对Cancel信号的处理"></a>线程对Cancel信号的处理</h2><p>对于默认属性的线程，当有线程借助 pthread_cancel() 函数向它发送 Cancel 信号时，它并不会立即结束执行，而是选择在一个适当的时机结束执行。</p>
<p>所谓适当的时机，POSIX 标准中规定，当线程执行一些特殊的函数时，会响应 Cancel 信号并终止执行，比如常见的 pthread_join()、pthread_testcancel()、sleep()、system() 等，POSIX 标准称此类函数为“cancellation points”（中文可译为“取消点”）。</p>
<blockquote>
<p>POSIX 标准中明确列举了所有可以作为取消点的函数，这里不再一一罗列，感兴趣的读者可以自行查阅 POSIX 标准手册。</p>
</blockquote>
<p>此外，&lt;pthread.h&gt; 头文件还提供有 pthread_setcancelstate() 和 pthread_setcanceltype() 这两个函数，我们可以手动修改目标线程处理 Cancel 信号的方式。</p>
<h4 id="1、pthread-setcancelstate-函数"><a href="#1、pthread-setcancelstate-函数" class="headerlink" title="1、pthread_setcancelstate()函数"></a>1、pthread_setcancelstate()函数</h4><p>借助 pthread_setcancelstate() 函数，我们可以令目标线程处理 Cancal 信号，也可以令目标线程不理会其它线程发来的 Cancel 信号。</p>
<p>pthread_setcancelstate() 函数的语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_setcancelstate</span><span class="params">( <span class="type">int</span> state , <span class="type">int</span> * oldstate )</span>; </span><br></pre></td></tr></table></figure>

<ol>
<li><p>state 参数有两个可选值，分别是：</p>
<ul>
<li>PTHREAD_CANCEL_ENABLE（默认值）：当前线程会处理其它线程发送的 Cancel 信号；</li>
<li>PTHREAD_CANCEL_DISABLE：当前线程不理会其它线程发送的 Cancel 信号，直到线程状态重新调整为 PTHREAD_CANCEL_ENABLE 后，才处理接收到的 Cancel 信号。</li>
</ul>
</li>
<li><p>oldtate 参数用于接收线程先前所遵循的 state 值，通常用于对线程进行重置。如果不需要接收此参数的值，置为 NULL 即可。</p>
</li>
</ol>
<p>pthread_setcancelstate() 函数执行成功时，返回数字 0，反之返回非零数。</p>
<h4 id="2、pthread-setcanceltype-函数"><a href="#2、pthread-setcanceltype-函数" class="headerlink" title="2、pthread_setcanceltype()函数"></a>2、pthread_setcanceltype()函数</h4><p>当线程会对 Cancel 信号进行处理时，我们可以借助 pthread_setcanceltype() 函数设置线程响应 Cancel 信号的时机。</p>
<p>pthread_setcanceltype() 函数的语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_setcanceltype</span><span class="params">( <span class="type">int</span> type , <span class="type">int</span> * oldtype )</span>;</span><br></pre></td></tr></table></figure>

<ol>
<li><p>type 参数有两个可选值，分别是：</p>
<ul>
<li>PTHREAD_CANCEL_DEFERRED（默认值）：当线程执行到某个可作为取消点的函数时终止执行；</li>
<li>PTHREAD_CANCEL_ASYNCHRONOUS：线程接收到 Cancel 信号后立即结束执行。</li>
</ul>
</li>
<li><p>oldtype 参数用于接收线程先前所遵循的 type 值，如果不需要接收该值，置为 NULL 即可。</p>
</li>
</ol>
<p>pthread_setcanceltype() 函数执行成功时，返回数字 0，反之返回非零数。</p>
<p>接下来通过一个实例给大家演示以上两个函数的功能和用法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> * <span class="title function_">thread_Fun</span><span class="params">(<span class="type">void</span> * arg)</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;新建线程开始执行\n&quot;</span>);</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="comment">//设置线程为可取消状态</span></span><br><span class="line">    res = pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;修改线程可取消状态失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>  <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//设置线程接收到 Cancel 信号后立即结束执行</span></span><br><span class="line">    res = pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;修改线程响应 Cancel 信号的方式失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>  <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pthread_t</span> myThread;</span><br><span class="line">    <span class="type">void</span> * mess;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    res = pthread_create(&amp;myThread, <span class="literal">NULL</span>, thread_Fun, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sleep(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">//向 myThread 线程发送 Cancel 信号</span></span><br><span class="line">    res = pthread_cancel(myThread);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;终止 myThread 线程失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//等待 myThread 线程执行结束，获取返回值</span></span><br><span class="line">    res = pthread_join(myThread, &amp;mess);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;等待线程失败\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (mess == PTHREAD_CANCELED) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;myThread 线程被强制终止\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;error\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序编写在 thread.c 文件中，程序执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">新建线程开始执行</span><br><span class="line">myThread 线程被强制终止</span><br></pre></td></tr></table></figure>

<p>和《<a href="http://c.biancheng.net/thread/vip_8610.html">终止线程执行（3种方法）</a>》一节中 pthread_cancel() 函数的演示程序相比，我们仅仅是将 myThread 线程设置为“接收到 Cancel 信号后立即结束执行”。通过对比两个程序的输出结果，很容易就可以体会出 pthread_setcancelstate() 和 pthread_setcanceltype() 函数的功能。</p>
<p>其实就是在要用多线程的函数里多写几句话，设置线程为可取消状态、设置线程接收到 Cancel 信号后立即结束执行。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>获取线程函数的返回值 pthread_join()</title>
    <url>/2023/02/22/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E8%BF%9B%E7%A8%8B/%E8%8E%B7%E5%8F%96%E7%BA%BF%E7%A8%8B%E5%87%BD%E6%95%B0%E7%9A%84%E8%BF%94%E5%9B%9E%E5%80%BC/</url>
    <content><![CDATA[<h1 id="获取线程函数的返回值-pthread-join"><a href="#获取线程函数的返回值-pthread-join" class="headerlink" title="获取线程函数的返回值 pthread_join()"></a>获取线程函数的返回值 pthread_join()</h1><blockquote>
<p>c语言中文网：<a href="http://c.biancheng.net/thread/vip_8627.html">获取线程函数的返回值</a></p>
</blockquote>
<p>阻塞主线程！阻塞主线程！阻塞主线程！</p>
<p>前面提到，如果我们想获取某个线程执行结束时返回的数据，可以调用 pthread_join() 函数来实现。本节，我们就为您详细讲解 pthread_join() 函数的功能和用法。</p>
<p>pthread_join() 函数声明在<code>&lt;pthread.h&gt;</code>头文件中，语法格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_join</span><span class="params">(<span class="type">pthread_t</span> thread, <span class="type">void</span> ** retval)</span>;</span><br></pre></td></tr></table></figure>

<p>thread 参数用于指定接收哪个线程的返回值；retval 参数表示接收到的返回值，如果 thread 线程没有返回值，又或者我们不需要接收 thread 线程的返回值，可以将 retval 参数置为 NULL。</p>
<p>&#x3D;&#x3D;pthread_join() 函数会一直阻塞调用它的线程（调用它的线程指的是，比如主线程），直至目标线程执行结束（接收到目标线程的返回值），阻塞状态才会解除。&#x3D;&#x3D;如果 pthread_join() 函数成功等到了目标线程执行结束（成功获取到目标线程的返回值），返回值为数字 0；反之如果执行失败，函数会根据失败原因返回相应的非零值，每个非零值都对应着不同的宏，例如：</p>
<ul>
<li>EDEADLK：检测到线程发生了死锁。关于线程发生死锁，我们会在《<a href="http://c.biancheng.net/thread/vip_8619.html">Linux如何避免线程发生死锁？</a>》一节中做详细讲解。</li>
<li>EINVAL：分为两种情况，要么目标线程本身不允许其它线程获取它的返回值，要么事先就已经有线程调用 pthread_join() 函数获取到了目标线程的返回值。</li>
<li>ESRCH：找不到指定的 thread 线程。</li>
</ul>
<blockquote>
<p>以上这些宏都声明在 &lt;errno.h&gt; 头文件中，如果程序中想使用这些宏，需提前引入此头文件。</p>
</blockquote>
<p>再次强调，一个线程执行结束的返回值只能由一个 pthread_join() 函数获取，当有多个线程调用 pthread_join() 函数获取同一个线程的执行结果时，哪个线程最先执行 pthread_join() 函数，执行结果就由那个线程获得，其它线程的 pthread_join() 函数都将执行失败。</p>
<p>&#x3D;&#x3D;对于一个默认属性的线程 A 来说，线程占用的资源并不会因为执行结束而得到释放。而通过在其它线程中执行<code>pthread_join(A,NULL);</code>语句，可以轻松实现“及时释放线程 A 所占资源”的目的。&#x3D;&#x3D;</p>
<p>接下来通过一个样例，给大家演示 pthread_join() 函数的用法：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span>   <span class="comment">//使用宏 ESRCH</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="comment">//线程执行的函数</span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">ThreadFun</span><span class="params">(<span class="type">void</span> *arg)</span></span><br><span class="line">&#123;</span><br><span class="line">    pthread_exit(<span class="string">&quot;http://c.biancheng.net&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> res;</span><br><span class="line">    <span class="type">void</span> * thread_result;</span><br><span class="line">    <span class="type">pthread_t</span> myThread;</span><br><span class="line">    <span class="comment">//创建 myThread 线程</span></span><br><span class="line">    res = pthread_create(&amp;myThread, <span class="literal">NULL</span>, ThreadFun, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;线程创建失败&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//阻塞主线程，等待 myThread 线程执行结束</span></span><br><span class="line">    res = pthread_join(myThread, &amp;thread_result);</span><br><span class="line">    <span class="keyword">if</span> (res != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;1：等待线程失败&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//输出获取到的 myThread 线程的返回值</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, (<span class="type">char</span>*)thread_result);</span><br><span class="line">    <span class="comment">//尝试再次获取 myThread 线程的返回值</span></span><br><span class="line">    res = pthread_join(myThread, &amp;thread_result);</span><br><span class="line">    <span class="keyword">if</span> (res == ESRCH) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;2：等待线程失败，线程不存在&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设程序位于 thread.c 文件中，执行过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># gcc thread.c -o thread.exe -lpthread</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ./thread.exe</span></span><br><span class="line">http://c.biancheng.net</span><br><span class="line">2：等待线程失败，线程不存在</span><br></pre></td></tr></table></figure>



<p>在程序的在主线程（main() 函数）中，我们尝试两次调用 pthread_join() 函数获取 myThread 线程执行结束的返回值。通过执行结果可以看到，第一个 pthread_join() 函数成功执行，而第二个 Pthread_join() 函数执行失败。原因很简单，第一个成功执行的 pthread_join() 函数会使 myThread 线程释放自己占用的资源，myThread 线程也就不复存在，所以第二个 pthread_join() 函数会返回 ESRCH。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>C语言中文网</tag>
      </tags>
  </entry>
  <entry>
    <title>Alignment free LF-MMI小结</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/Alignment%20free%20LF-MMI%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<h1 id="Alignment-free-LF-MMI"><a href="#Alignment-free-LF-MMI" class="headerlink" title="Alignment free LF-MMI"></a>Alignment free LF-MMI</h1><blockquote>
<p>&#x3D;&#x3D;Wang Y, Lv H, Povey D, et al. Wake Word Detection with Alignment-Free Lattice-Free MMI[J]. arXiv preprint arXiv:2005.08347, 2020.&#x3D;&#x3D;</p>
<p>&#x3D;&#x3D;Wang, Yiming. <em>WAKE WORD DETECTION AND ITS APPLICATIONS</em>. Diss. Johns Hopkins University, 2021.&#x3D;&#x3D;王一鸣博士论文</p>
<p>&#x3D;&#x3D;github开源代码&#x3D;&#x3D;：The code and recipes are available in Kaldi [24]: <a href="https://github.com/kaldi-asr/kaldi/tree/master/egs/%7Bsnips,mobvoi,mobvoihotwords%7D">https://github.com/kaldi-asr/kaldi/tree/master/egs/{snips,mobvoi,mobvoihotwords}</a>. </p>
<p>&#x3D;&#x3D;github代码&#x3D;&#x3D;：<a href="https://github.com/YiwenShaoStephen/pychain">https://github.com/YiwenShaoStephen/pychain</a></p>
<p>&#x3D;&#x3D;csdn 博客&#x3D;&#x3D;：<a href="https://blog.csdn.net/chenxi910911/article/details/107674366">Wake Word Detection with Alignment-Free Lattice-Free MMI</a></p>
</blockquote>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><ul>
<li>提出alignment free LF-MMI，不需要对齐分子lattice</li>
<li>不把唤醒词里面每个音素建模，而是把整个唤醒词建模 model the whole wake phrase  ，用一个固定状态数的HMM去建模唤醒词（该数量少于唤醒词音素组成数量）</li>
<li>keyword、non-keyword、sil 都各用一个HMM建模</li>
<li>针对唤醒任务，提出alignment free LFMMI，分子不用对齐文本得到分子lattice，由于文本就是keyword&#x2F;non-keyword，文本只有一个HMM，直接遍历HMM所有可能路径，求路径和概率。（直接用文本图上添加自环，让解码更自由，前后向可选的路径更多）</li>
<li>负样本文本一般比较长，一个HMM可能建模不了，因此把负样本切成和正常本长度差不多，每个负样本的训练文本为freetext（一个HMM），就可以去生成egs了</li>
<li>负样本如果不segment，会严重过拟合</li>
<li>该方法能有效改善FAR高</li>
<li>分母图上路径权重：按正负样本比例来分配</li>
</ul>
<p>分子图fst：用一个文本构成（一个文本就是一个单词，一个单词用一个HMM建模）</p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/Alignment%20free%20LF-MMI%E5%B0%8F%E7%BB%93/51e33547d077a96de000bf42d8c40e61.jpg" alt="img" style="zoom: 25%;">

<p>分母图fst：可以理解成word 并联序列，只不过添加了sil（不是loop，不能重复走）</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/Alignment%20free%20LF-MMI%E5%B0%8F%E7%BB%93/image-20211029145733035.png" alt="image-20211029145733035"></p>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><ul>
<li>负样本进行了分块chunk，&#x3D;&#x3D;chunk长度和正样本差不多&#x3D;&#x3D;，	</li>
<li>负样本后继chunk重叠0.3s，使得前一个chunk被截掉的单词有机会在后继chunk全词出现</li>
<li>声学模型：TDNN-F，分解到两个低秩矩阵，前一个矩阵是半正定的，确保高维到低维信息不会丢失</li>
<li>前一层的输入乘上缩放比例0.66与本层输入加和（是add，而不是concatenate）</li>
<li>拼帧结构：把本来要拼在一层的结构 分解到两层会更好，比如第一层拼(-3,0,3)，第二层拼(0)，更好的做法是第一层拼(-3,0)，第二层拼(0,3)</li>
<li>训练了一个alignment-free LF-MMI后，对齐lattice，重新训练一个普通的LF-MMI，效果会更好</li>
<li>alignment-free体现在：<ul>
<li>（雷博）不需要GMM-HMM训练过程，不需要对齐ali文件</li>
<li>不需要对齐训练样本然后统计得到phone-lm</li>
<li>一个没有一点对齐能力的模型（0.mdl）也可以拿来使用的</li>
<li>nnet3-chain-e2e-get-egs分子cegs生成，直接用text构建的fst，找到所有可能的fst中的状态序列求和就是分子，普通的还要由fst构建lattice？（感觉二者差不多）</li>
</ul>
</li>
<li>博士论文中比较了不同topo结构：<ul>
<li>把sil和freetext表示在一个HMM中，该HMM有多种可走的路径，这样就能够表示当训练样本前后是非命令词，中间是静音的情况。结果是增加了训练难度，误拒率很高，只有对齐准确的初始模型可能会得到好一点的误拒率，但是还是不好，因此最好不要把sil和freetext放在一起建模</li>
<li>用5状态建模HMM，效果比3状态好</li>
</ul>
</li>
</ul>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><ul>
<li>雷博说：<ul>
<li>负样本切chunk后，要注意正负样本比例，不要让负样本远远多于正样本。</li>
<li>切割负样本（长文本切到短文本）时，文本不知道对应的是sil还是freetext，不好得知文本，把静音段也视作freeetext会有问题</li>
<li>实验效果好，可能由于数据集较小</li>
</ul>
</li>
</ul>
<h4 id="在线解码"><a href="#在线解码" class="headerlink" title="在线解码"></a>在线解码</h4><ul>
<li>解码FST：其实长得有点像分母图，不同之处在于是起始状态和终止状态在同一个结点，使得可以生成词串，比如生成word后还可以生成freetext，再生成word等等，文本串；而分母图要不然就走freetext，要不然就走word，不能都串行出现。</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/Alignment%20free%20LF-MMI%E5%B0%8F%E7%BB%93/image-20211029150244872.png" alt="image-20211029150244872"></p>
<ul>
<li><p>在线解码：一个chunk一个chunk解码，每次解码了一个chunk后，就去更新immortal token和prev_immortal token（在所有active tok里找公共祖先（emitting[0]，或者说tokenOne），作为immortal tok，把前一次的immortal tok作为prevImmortal tok），每次在两个immortal tokens之间的路径寻找（backtrace）是否有唤醒词，实现了逐chunk搜索。</p>
</li>
<li><p>每处理过一段固定长度的录音后，我们用更新不朽token算法来回溯最近两个“不朽token”中间的这些帧，检查这部分回溯是否包含唤醒词。如果发现唤醒词则停止解码，如果没有唤醒词继续解码。（不朽token是现存激活token的共同祖先）</p>
<p>这个是基于这样一个假设：如果现有的存活的部分假设都是来自于前一个时刻的相同的token（不朽token），同时在这之前的所有的假设都已经压缩到了这一个token上，我们就可以从这个“不朽token”检查是否具有唤醒词 [csdn]</p>
</li>
<li><p>伪代码 online decoding：</p>
</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/Alignment%20free%20LF-MMI%E5%B0%8F%E7%BB%93/image-20211029144006785.png" alt="image-20211029144006785"></p>
<ul>
<li>更新immortal token，用于回溯</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/Alignment%20free%20LF-MMI%E5%B0%8F%E7%BB%93/image-20211029144433677.png" alt="image-20211029144433677"></p>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>The code and recipes are available in Kaldi [24]: <a href="https://github.com/kaldi-asr/kaldi/tree/master/egs/%7Bsnips,mobvoi,mobvoihotwords%7D">https://github.com/kaldi-asr/kaldi/tree/master/egs/{snips,mobvoi,mobvoihotwords}</a>.  </p>
<p>本文中引入了一种不需要对齐（Alignment-free）、不需要词图的（Lattice-Free MMI）鉴别性准则训练的模型<br>相比Lattice-free MMI准则需要额外修改一下发音字典、HMM拓扑结构</p>
<p>1.HMM拓扑结构（KW和freetext）用的是5个状态；silence用的是2个状态，但是保持（Lattice-free MMI）的结构self-loop-pdf和forward-pdf对应两个不同的PDF-id，因此神经网络共82+21&#x3D;18个pdf</p>
<p>2.分子图与分母图<br>分子图和chain的不同点在于：不需要依赖对齐结果生成label对应的图，生成一个非扩展的fst，在训练过程中通过前后向算法更加灵活的学习对齐结果<br>分母图和chain的不同点在于：phone级别的语言模型不再需要通过训练数据训练得到，直接手动生成一个语言模型fst，一共3条路径，关键词路径、freetext、silence，其中关键词和freetext前后都可加silence。每一条路径上的权重受训练数据中正负样本的占比因素影响<br>3.声学模型<br>使用TDNN-F模型（因式分解的TDNN），将一层的参数矩阵分解成两个低秩矩阵、第一个矩阵强制限制为半正定矩阵<br>模型（20层每层80节点）存在跨层连接，前一层的输入乘上缩放比例0.66与本层输入加和。<br>4.数据预处理和增强<br>对于负样本（存在很多样本时长较长）会按照正样本的时长分布，对负样本进行切段，每一段分配一个负样本标签。<br>增强：尽管训练数据很多是在实际场景中录制的，增强后效果仍然后提升<br>5.解码<br>手动构造词级别的解码网络FST，每条路径上的权重生成和分母图的LM-fst图方式是一样的。在开始token和结束token上增加从结束token到开始token的空边，原因是音频中可能存在唤醒词和其他可能的音频交叉现象。<br>在线解码的过程中：每处理过一段固定长度的录音后，我们用更新不朽token算法来回溯最近两个“不朽token”中间的这些帧，检查这部分回溯是否包含唤醒词。如果发现唤醒词则停止解码，如果没有唤醒词继续解码。（不朽token是现存激活token的共同祖先）</p>
<p>这个是基于这样一个假设：如果现有的存活的部分假设都是来自于前一个时刻的相同的token（不朽token），同时在这之前的所有的假设都已经压缩到了这一个token上，我们就可以从这个“不朽token”检查是否具有唤醒词</p>
<h1 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h1><ul>
<li><p>由于freetext只用一个HMM，因此不支持于自定义唤醒词，可应用于小模型的需求。</p>
</li>
<li><p>路径：24.3:&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;mobvoihotwords&#x2F;v1</p>
</li>
<li><p>命令词：<code>sil freetext 上一曲 下一曲 减小音量 增大音量 小源小源 播放 暂停 静音</code></p>
</li>
</ul>
<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><ul>
<li>不用run_e2e.sh脚本里的随机切割得到负样本，而是用对齐信息，得到边界，可以避免把静音对成freetext</li>
<li>&#x3D;&#x3D;把带有关键词的负样本删掉&#x3D;&#x3D;</li>
</ul>
<h3 id="切割长负样本到短负样本"><a href="#切割长负样本到短负样本" class="headerlink" title="切割长负样本到短负样本"></a>切割长负样本到短负样本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">work_dir=/home/storage/speech/kaldi/egs/keyword/s5</span><br><span class="line">bash +x steps/get_train_ctm.sh --print_silence <span class="literal">true</span> <span class="variable">$work_dir</span>/data/mfcc/train_12000 data_hua/lang_normal/ <span class="variable">$work_dir</span>/exp_sil/mfcc_pitch/nnet3_tdnn6layers_8b_relu_ali_train_12000 data_hua/ali_12000</span><br></pre></td></tr></table></figure>

<p>去掉存在长静音段的负样本，然后按与正样本长度差不多的随机切割，这是因为正样本有前后静音，如果负样本只有发音段，不太好，因此把存在小的前后静音段考虑进负样本中</p>
<p>把静音区域大于1s的负样本丢弃：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python <span class="built_in">local</span>/phone2word.py data_hua/ali_12000/ctm &gt; data_hua/ali_12000/output_ctm</span><br><span class="line">sed -i <span class="string">&#x27;/yelong/d&#x27;</span> data_hua/ali_12000/output_ctm</span><br></pre></td></tr></table></figure>

<p>筛选出neg_segments：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">utils/filter_scp.pl data_hua/ali_12000/output_ctm data_hua/data_all_sub2_Xiaoyuan_12000_whole/segments &gt; data_hua/data_all_sub2_Xiaoyuan_12000_whole/neg_segments</span><br></pre></td></tr></table></figure>

<p>筛选出正样本（开头SY、Xiaoyuan、sp的）</p>
<p>按照正样本长度范围切割负样本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">srcdir=data_hua/data_all_sub2_Xiaoyuan_12000</span><br><span class="line"><span class="built_in">local</span>/get_random_subsegments.py --overlap-duration=0.3 --max-remaining-duration=0.3 <span class="variable">$&#123;srcdir&#125;</span>_whole/neg_segments <span class="variable">$&#123;srcdir&#125;</span>_whole/pos_utt2dur | <span class="built_in">cat</span> <span class="variable">$&#123;srcdir&#125;</span>_whole/pos_segments - | <span class="built_in">sort</span> &gt;<span class="variable">$&#123;srcdir&#125;</span>_whole/sub_segments</span><br></pre></td></tr></table></figure>

<p>把长度太短的（小于0.5s）、太长的删掉（大于5.05s）</p>
<p>data_hua&#x2F;data_all_sub2_Xiaoyuan_12000_segmented_e2e_cut：正样本正负样本比例：正样本433万条，负样本1635万条，正负样本比例1：3.7（接近1：4）（不好，应该减少正样本的比例）</p>
<p>2021.11.23新：正样本233w，负样本1635万条，正负样本1：7</p>
<p>2021.11.27新：发现split5测试集的唤醒率不高，原来是没有把9w条Xiaoyuan数据都用了，只用了4.5万条，把9w条需要都加入进去才行，正样本237万，负样本1635万，正负样本1：7【训练出来效果很差，不知道为什么】</p>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul>
<li><p>tdnnf结构，13层，dim&#x3D;80，bottleneck dim&#x3D;20，左拼27帧，右拼27帧，参数量 111388（113k）</p>
</li>
<li><p>74个分类状态（2* (9* 4+1) &#x3D;74），sil：1状态，freetext、keyword：4状态</p>
</li>
<li><p>训练很快</p>
</li>
</ul>
<h3 id="实验测试结果"><a href="#实验测试结果" class="headerlink" title="实验测试结果"></a>实验测试结果</h3><p>- </p>
<h2 id="实验结果分析"><a href="#实验结果分析" class="headerlink" title="实验结果分析"></a>实验结果分析</h2><ul>
<li>正负样本1：4时：<ul>
<li>声学模型输出在同一帧中有很多分类的概率都挺高，说明声学模型效果不好，但是还能得到测试集唤醒率高、误唤醒率低的唤醒词，说明后面接的G还是挺关键的</li>
<li>其他唤醒词误唤醒率很高，不是喊该命令词时，也会唤醒，比如喊小源没唤醒，但是会误唤醒其他唤醒词，因此不能把很多命令词都当作唤醒词，就是即使把命令词放在唤醒词后面唤醒，也很容易出现喊命令词却识别成另一个命令词的情况，我们希望的是即使不唤醒，也别唤醒成别的。对多唤醒词任务不友好。</li>
</ul>
</li>
<li>正负样本1：7时：<ul>
<li>其他唤醒词误唤醒率相较于正负样本1：4的模型下降许多</li>
<li>唤醒率低，容易识别成freetext，考虑通过增加每个HMM的topo状态数来缓解[TODO]</li>
</ul>
</li>
<li>过拟合比较严重，对未见过的样本识别率很低，可能是因为建模单元颗粒度大（词），建模topo结构状态数少</li>
<li>freetext后接keyword的输出很少见，应该是和训练相关。</li>
<li>Alignment-Free当模型为tdnnf，13layer，80_20，参数量100K，状态数30时，很容易过拟合，说明模型太小时，不具备大建模单元（一个词用4状态表示）的建模能力；</li>
</ul>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol>
<li>增加topo建模状态数</li>
<li>alignment free LF-MMI对齐lattice训练regular LF-MMI</li>
</ol>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>NIST F4DE安装</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/nist/</url>
    <content><![CDATA[<h1 id="NIST-F4DE安装"><a href="#NIST-F4DE安装" class="headerlink" title="NIST F4DE安装"></a>NIST F4DE安装</h1><p><strong>零 安装包及依赖包</strong></p>
<p><a href="http://139.155.89.35/tools/F4DE/install.tgz">http://139.155.89.35/tools/F4DE/install.tgz</a> 内含有所有依赖包和安装包</p>
<h1 id="一、自主安装"><a href="#一、自主安装" class="headerlink" title="一、自主安装"></a><strong>一、自主安装</strong></h1><ol>
<li><h2 id="gnuplot安装"><a href="#gnuplot安装" class="headerlink" title="gnuplot安装"></a><strong>gnuplot安装</strong></h2></li>
</ol>
<p>首先安装libgd-2.3.2:</p>
<p>.&#x2F;configure</p>
<p>make -j 8</p>
<p>sudo make install (库最终在&#x2F;usr&#x2F;local&#x2F;lib目录下)</p>
<p>export LD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;lib:$LD_LIBRARY_PATH</p>
<p>安装gnuplot-5.2.8:</p>
<p>.&#x2F;configure</p>
<p>make -j 8</p>
<p>sudo make install</p>
<ol>
<li><h2 id="perl库安装"><a href="#perl库安装" class="headerlink" title="perl库安装"></a><strong>perl库安装</strong></h2></li>
</ol>
<p> Text::CSV</p>
<p> Text::CSV_XS</p>
<p> Class::Accessor</p>
<p> Math::Random::OO</p>
<p> Statistics::Descriptive</p>
<p> Statistics::Descriptive::Discrete,</p>
<p> Statistics::Distributions,</p>
<p> DBI</p>
<p> DBD::SQLite</p>
<p> File::Monitor,</p>
<p> File::Monitor::Object,</p>
<p> Digest::SHA</p>
<p> Digest::SHA::PurePerl</p>
<p> YAML</p>
<p> Data::Dump</p>
<ol>
<li><h2 id="安装F4DE-3-5-0"><a href="#安装F4DE-3-5-0" class="headerlink" title="安装F4DE-3.5.0"></a><strong>安装F4DE-3.5.0</strong></h2></li>
</ol>
<p>make KWSEvalcheck 全部成功后 #（这一步可能会因为有报错，可以先跳过直接安装）</p>
<p>make KWSEvalinstall 即可</p>
<p>export LD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;lib:$LD_LIBRARY_PATH</p>
<p>export PATH&#x3D;yourpath&#x2F;F4DE&#x2F;bin:$PATH</p>
<h1 id="二、tencent安装"><a href="#二、tencent安装" class="headerlink" title="二、tencent安装"></a><strong>二、tencent安装</strong></h1><p>mkdir install #（安装在install目录下）</p>
<p>cd install</p>
<p>echo “Downloading F4DE install package …”</p>
<p>wget <a href="http://139.155.89.35/tools/F4DE/install.tgz">http://139.155.89.35/tools/F4DE/install.tgz</a></p>
<p>tar -zxvf install.tgz</p>
<p>cd install&#x2F;</p>
<p>cd dependencies&#x2F;</p>
<p>bash run.sh #（等待）</p>
<p>export LD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;lib:$LD_LIBRARY_PATH</p>
<p>export PATH&#x3D;yourpath&#x2F;F4DE&#x2F;bin:$PATH</p>
<p>### 安装完后在install&#x2F;install&#x2F;F4DE-3.5.0&#x2F;bin&#x2F;目录下</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>kaldi conv-relu-batchnorm-layer</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/kaldi%20conv-relu-batchnorm-layer/</url>
    <content><![CDATA[<h1 id="conv-relu-batchnorm-layer"><a href="#conv-relu-batchnorm-layer" class="headerlink" title="conv-relu-batchnorm-layer"></a>conv-relu-batchnorm-layer</h1><blockquote>
<p>xconfig&#x2F;convolution.py</p>
<p>src&#x2F;nnet3&#x2F;nnet-convolutional-component.h</p>
<p><a href="https://blog.csdn.net/qq_35742630/article/details/103305313?spm=1001.2014.3001.5501">nnet3-TimeHeightConvolution代码解读</a></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conv-relu-batchnorm-layer name=cnn1 <span class="variable">$cnn_opts</span> height-in=50 height-out=50 time-offsets=-1,0,1 height-offsets=-1,0,1 num-filters-out=64</span><br><span class="line">conv-relu-batchnorm-layer name=cnn3 <span class="variable">$cnn_opts</span> height-in=50 height-out=25 height-subsample-out=2 time-offsets=-1,0,1 height-offsets=-1,0,1 num-filters-out=128</span><br></pre></td></tr></table></figure>



<h2 id="参数解释"><a href="#参数解释" class="headerlink" title="参数解释"></a>参数解释</h2><ul>
<li>height-offsets：卷积核大小，dim方向的卷积（比如dim&#x3D;50）（if height-offsets&#x3D;-1,0,1 then height 10 at the output would take input from heights 9,10,11 at the input.）</li>
<li>num-filters-out：The output dimension of this layer is num-filters-out * height-out，卷积核的数量</li>
<li>num-filters-in 和 height-in：假设上一层的输出是2048，那么这里就会要求num-filters-in × \times× height-in &#x3D;&#x3D; 2048。假设我们设height-in是1024，那么num-filters-in 就是2</li>
<li>height-out 和 height-subsample-out：期望的输出维度，是对于一个height-in来说的。height-subsample-out就是在维度上的一个降采样率。这里会有个限制  height-out ×  height-subsample-out &lt;&#x3D; height-in，这一层最终输出的维度是height-out ×  num-filters-out。</li>
<li>height-offsets, time-offsets: 这就是我们需要的卷积核的样子了。或者如果不想这么定义的话，可以直接定义offsets即可。</li>
<li>required-time-offsets：这个实际上是可以忽略的，一般来说，required-time-offsets和time-offsets是等价的。</li>
</ul>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>tdnn、tdnnf计算量分析</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/tdnn%20tdnnf%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="tdnn、tdnnf计算量分析"><a href="#tdnn、tdnnf计算量分析" class="headerlink" title="tdnn、tdnnf计算量分析"></a>tdnn、tdnnf计算量分析</h1><p>计算量，一般是指的1s内乘法的次数</p>
<p>一帧的计算量，一般就是参数量？</p>
<h2 id="TDNN"><a href="#TDNN" class="headerlink" title="TDNN"></a>TDNN</h2><ul>
<li>tdnn结构：</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">fixed-affine-layer name=lda input=Append(-6,-3,0,3,6) affine-transform-file=<span class="variable">$dir</span>/configs/lda.mat</span><br><span class="line">relu-renorm-layer name=tdnn1 dim=256 input=lda</span><br><span class="line">relu-renorm-layer name=tdnn2 dim=256 input=Append(-3,6)</span><br><span class="line">relu-renorm-layer name=tdnn3 dim=256 input=Append(-6,3)</span><br><span class="line">relu-renorm-layer name=tdnn4 dim=256 input=Append(-9,9)</span><br><span class="line">relu-renorm-layer name=tdnn5 dim=256 input=Append(-15,3)</span><br><span class="line"></span><br><span class="line">relu-renorm-layer name=prefinal-chain input=tdnn5 dim=256 target-rms=0.5</span><br><span class="line">output-layer name=output include-log-softmax=<span class="literal">false</span> dim=<span class="variable">$num_targets</span> max-change=1.5</span><br><span class="line">relu-renorm-layer name=prefinal-xent input=tdnn5 dim=256 target-rms=0.5</span><br><span class="line">output-layer name=output-xent dim=<span class="variable">$num_targets</span> learning-rate-factor=<span class="variable">$learning_rate_factor</span> max-change=1.5</span><br></pre></td></tr></table></figure>

<ul>
<li>tdnn一帧计算量：</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/tdnn%20tdnnf%E5%88%86%E6%9E%90/image-20211123163249337.png" alt="image-20211123163249337" style="zoom: 25%;">

<ul>
<li>tdnn网络图：</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/tdnn%20tdnnf%E5%88%86%E6%9E%90/image-20211123163433352.png" alt="image-20211123163433352"></p>
<p>可以看出，chain的跳帧，作用到最底层的输入，输入也是跳3帧的，相当于虽然左右跨帧27，27，但实际输入，参与计算的只有1&#x2F;3的帧数，相当于速度3倍。</p>
<h2 id="TDNNF"><a href="#TDNNF" class="headerlink" title="TDNNF"></a>TDNNF</h2><ul>
<li>tdnnf结构</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dim=320</span><br><span class="line">bn_dim=32</span><br><span class="line">outbn_dim=48</span><br><span class="line"><span class="comment">#dim=180</span></span><br><span class="line"><span class="comment">#bn_dim=20</span></span><br><span class="line"><span class="comment">#outbn_dim=32</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$0</span>: creating neural net configs using the xconfig parser&quot;</span>;</span><br><span class="line">num_targets=$(tree-info <span class="variable">$tree_dir</span>/tree | grep num-pdfs | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line">learning_rate_factor=$(python3 -c <span class="string">&quot;print(0.5/<span class="variable">$xent_regularize</span>)&quot;</span>)</span><br><span class="line">affine_opts=<span class="string">&quot;l2-regularize=0.01 dropout-proportion=0.0 dropout-per-dim=true dropout-per-dim-continuous=true&quot;</span></span><br><span class="line">tdnnf_opts=<span class="string">&quot;l2-regularize=0.01 dropout-proportion=0.0 bypass-scale=0.66&quot;</span></span><br><span class="line">linear_opts=<span class="string">&quot;l2-regularize=0.01 orthonormal-constraint=-1.0&quot;</span></span><br><span class="line">prefinal_opts=<span class="string">&quot;l2-regularize=0.01&quot;</span></span><br><span class="line">output_opts=<span class="string">&quot;l2-regularize=0.002&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$dir</span>/configs</span><br><span class="line"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; $dir/configs/network.xconfig</span></span><br><span class="line"><span class="string">input dim=50 name=input</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># please note that it is important to have input layer with the name=input</span></span><br><span class="line"><span class="string"># as the layer immediately preceding the fixed-affine-layer to enable</span></span><br><span class="line"><span class="string"># the use of short notation for the descriptor</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">fixed-affine-layer name=lda input=Append(-2,-1,0,1,2) affine-transform-file=$dir/configs/lda.mat</span></span><br><span class="line"><span class="string">relu-batchnorm-dropout-layer name=tdnn1 $affine_opts dim=$dim</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf2 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=1</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf3 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=1</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf4 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=1</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf5 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=1</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf6 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=0</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf7 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=3</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf8 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=3</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf9 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=3</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf10 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=3</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf11 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=3</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf12 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=3</span></span><br><span class="line"><span class="string">tdnnf-layer name=tdnnf13 $tdnnf_opts dim=$dim bottleneck-dim=$bn_dim time-stride=3</span></span><br><span class="line"><span class="string">linear-component name=prefinal-l dim=$outbn_dim $linear_opts</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">prefinal-layer name=prefinal-chain input=prefinal-l $prefinal_opts big-dim=$dim small-dim=$outbn_dim</span></span><br><span class="line"><span class="string">output-layer name=output include-log-softmax=false dim=$num_targets $output_opts</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">prefinal-layer name=prefinal-xent input=prefinal-l $prefinal_opts big-dim=$dim small-dim=$outbn_dim</span></span><br><span class="line"><span class="string">output-layer name=output-xent dim=$num_targets learning-rate-factor=$learning_rate_factor $output_opts</span></span><br></pre></td></tr></table></figure>

<ul>
<li>tdnnf一帧计算量：</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/tdnn%20tdnnf%E5%88%86%E6%9E%90/image-20211123163259275.png" alt="image-20211123163259275" style="zoom: 33%;">

<ul>
<li>tdnnf网络图</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/tdnn%20tdnnf%E5%88%86%E6%9E%90/image-20211123163600244.png" alt="image-20211123163600244"></p>
<p>可以看出，前几层很多1的拼帧，所以虽然最上层输入给decoder的进行了下采样，到了底层，也还是要利用那么多帧，没有起到加速的效果。</p>
<ul>
<li>改进：不用1的拼帧，只用3的拼帧</li>
</ul>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>triplet loss keyword spotting 代码</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/triplet%20loss/</url>
    <content><![CDATA[<h1 id="triplet-loss-keyword-spotting-代码"><a href="#triplet-loss-keyword-spotting-代码" class="headerlink" title="triplet loss keyword spotting 代码"></a>triplet loss keyword spotting 代码</h1><p>以 google speech commands为例</p>
<blockquote>
<p>Vygon, Roman, and Nikolay Mikhaylovskiy. “Learning efficient representations for keyword spotting with triplet loss.” <em>International Conference on Speech and Computer</em>. Springer, Cham, 2021.ciations：12</p>
<p>github：<a href="https://github.com/roman-vygon/triplet_loss_kws"> Learning Efficient Representations for Keyword Spotting with Triplet Loss</a></p>
<p>github：<a href="https://github.com/NVIDIA/NeMo/blob/v0.10.1/examples/asr/notebooks/3_Speech_Commands_using_NeMo.ipynb">https://github.com/NVIDIA/NeMo/blob/v0.10.1/examples/asr/notebooks/3_Speech_Commands_using_NeMo.ipynb</a></p>
<p><a href="https://www.codeleading.com/article/61624664033/">https://www.codeleading.com/article/61624664033/</a></p>
<p><a href="https://bindog.github.io/blog/2019/10/23/why-triplet-loss-works/">https://bindog.github.io/blog/2019/10/23/why-triplet-loss-works/</a></p>
<p>github人脸检测：<a href="https://github.com/kuaikuaikim/DFace">https://github.com/kuaikuaikim/DFace</a></p>
<p>facenet：<a href="https://github.com/davidsandberg/facenet">https://github.com/davidsandberg/facenet</a></p>
</blockquote>
<p>&#x2F;home&#x2F;data&#x2F;yelong&#x2F;triplet_loss_kws&#x2F;loss&#x2F;utils.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">RandomNegativeTripletSelector</span>(<span class="params">margin, cpu=<span class="literal">False</span></span>): <span class="keyword">return</span> FunctionNegativeTripletSelector(margin=margin,</span><br><span class="line">                                                                                             negative_selection_fn=random_hard_negative,</span><br><span class="line">                                                                                             cpu=cpu)</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FunctionNegativeTripletSelector</span>(<span class="title class_ inherited__">TripletSelector</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    For each positive pair, takes the hardest negative sample (with the greatest triplet loss value) to create a triplet</span></span><br><span class="line"><span class="string">    Margin should match the margin used in triplet loss.</span></span><br><span class="line"><span class="string">    negative_selection_fn should take array of loss_values for a given anchor-positive pair and all negative samples</span></span><br><span class="line"><span class="string">    and return a negative index for that pair</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>



<p>找triplet三元组：</p>
<p>方法：找出所有同类a,p对，而a,n对根据不同策略选出不同a,n，我这里用的随机，就是在所有d(a,p)-d(a,n)+margin大于0的组合中，随机选一个a,n作为三元组(a,p,n)的n index</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pdist</span>(<span class="params">vectors</span>):</span><br><span class="line">    distance_matrix = -<span class="number">2</span> * vectors.mm(torch.t(vectors)) + vectors.<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>(dim=<span class="number">1</span>).view(<span class="number">1</span>, -<span class="number">1</span>) + vectors.<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>(</span><br><span class="line">        dim=<span class="number">1</span>).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> distance_matrix</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TripletSelector</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implementation should return indices of anchors, positive and negative samples</span></span><br><span class="line"><span class="string">    return np array of shape [N_triplets x 3]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_triplets</span>(<span class="params">self, embeddings, labels</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_hard_negative</span>(<span class="params">loss_values</span>):</span><br><span class="line">    hard_negatives = np.where(loss_values &gt; <span class="number">0</span>)[<span class="number">0</span>]   <span class="comment">#index</span></span><br><span class="line">    <span class="keyword">return</span> np.random.choice(hard_negatives) <span class="keyword">if</span> <span class="built_in">len</span>(hard_negatives) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FunctionNegativeTripletSelector</span>(<span class="title class_ inherited__">TripletSelector</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    For each positive pair, takes the hardest negative sample (with the greatest triplet loss value) to create a triplet</span></span><br><span class="line"><span class="string">    Margin should match the margin used in triplet loss.</span></span><br><span class="line"><span class="string">    negative_selection_fn should take array of loss_values for a given anchor-positive pair and all negative samples</span></span><br><span class="line"><span class="string">    and return a negative index for that pair</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, margin, negative_selection_fn, cpu=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(FunctionNegativeTripletSelector, self).__init__()</span><br><span class="line">        self.cpu = cpu</span><br><span class="line">        self.margin = margin</span><br><span class="line">        self.negative_selection_fn = negative_selection_fn</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_triplets</span>(<span class="params">self, embeddings, labels</span>):</span><br><span class="line">        <span class="keyword">if</span> self.cpu:</span><br><span class="line">            embeddings = embeddings.cpu()</span><br><span class="line">        distance_matrix = pdist(embeddings)</span><br><span class="line">        distance_matrix = distance_matrix.cpu()</span><br><span class="line"></span><br><span class="line">        labels = labels.cpu().data.numpy()</span><br><span class="line">        triplets = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">set</span>(labels):   <span class="comment">#多少种种类</span></span><br><span class="line">            label_mask = (labels == label)</span><br><span class="line">            label_indices = np.where(label_mask)[<span class="number">0</span>] <span class="comment">#同类的index</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(label_indices) &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            negative_indices = np.where(np.logical_not(label_mask))[<span class="number">0</span>]  <span class="comment">#逻辑非（取反） # 不同类的index</span></span><br><span class="line">            anchor_positives = <span class="built_in">list</span>(combinations(label_indices, <span class="number">2</span>))  <span class="comment"># All anchor-positive pairs    # 列出所有anchor_positives对</span></span><br><span class="line">            anchor_positives = np.array(anchor_positives)</span><br><span class="line"></span><br><span class="line">            ap_distances = distance_matrix[anchor_positives[:, <span class="number">0</span>], anchor_positives[:, <span class="number">1</span>]]  <span class="comment"># 在distance_matrix(batch*batch)里找到(a,p)对的距离</span></span><br><span class="line">            <span class="keyword">for</span> anchor_positive, ap_distance <span class="keyword">in</span> <span class="built_in">zip</span>(anchor_positives, ap_distances):</span><br><span class="line">                loss_values = ap_distance - distance_matrix[</span><br><span class="line">                    torch.LongTensor(np.array([anchor_positive[<span class="number">0</span>]])), torch.LongTensor(negative_indices)] + self.margin <span class="comment">#和所有不同类的距离</span></span><br><span class="line">                loss_values = loss_values.data.cpu().numpy()    <span class="comment"># 一个向量当前a,p和所有不同类a,n的距离</span></span><br><span class="line">                hard_negative = self.negative_selection_fn(loss_values) <span class="comment">#在loss大于0的众多loss中选一个，作为hard_negative</span></span><br><span class="line">                <span class="keyword">if</span> hard_negative <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    hard_negative = negative_indices[hard_negative]</span><br><span class="line">                    triplets.append([anchor_positive[<span class="number">0</span>], anchor_positive[<span class="number">1</span>], hard_negative])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(triplets) == <span class="number">0</span>:</span><br><span class="line">            triplets.append([anchor_positive[<span class="number">0</span>], anchor_positive[<span class="number">1</span>], negative_indices[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">        triplets = np.array(triplets)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.LongTensor(triplets)</span><br><span class="line"></span><br><span class="line">a=FunctionNegativeTripletSelector(margin=<span class="number">0.5</span>,negative_selection_fn=random_hard_negative,cpu=<span class="literal">True</span>)</span><br><span class="line">embeddings=torch.randn(<span class="number">6</span>,<span class="number">3</span>)</span><br><span class="line">labels=torch.Tensor([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">b = a.get_triplets(embeddings,labels)</span><br></pre></td></tr></table></figure>



<p>计算triplet loss</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, margin, triplet_selector</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.margin = margin</span><br><span class="line">        self.triplet_selector = triplet_selector</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_loss</span>(<span class="params">self, embeddings, target</span>):</span><br><span class="line">        embeddings = torch.flatten(embeddings, start_dim=-<span class="number">2</span>)</span><br><span class="line">        triplets = self.triplet_selector.get_triplets(embeddings, target)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> embeddings.is_cuda:</span><br><span class="line">            triplets = triplets.cuda()</span><br><span class="line"></span><br><span class="line">        ap_distances = (embeddings[triplets[:, <span class="number">0</span>]] - embeddings[triplets[:, <span class="number">1</span>]]).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># .pow(.5)</span></span><br><span class="line">        an_distances = (embeddings[triplets[:, <span class="number">0</span>]] - embeddings[triplets[:, <span class="number">2</span>]]).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">1</span>)  <span class="comment"># .pow(.5)</span></span><br><span class="line">        losses = F.relu(ap_distances - an_distances + self.margin)</span><br><span class="line">        </span><br><span class="line">triplet_loss = OnlineTripletLoss(args.margin, RandomNegativeTripletSelector(args.margin))        </span><br><span class="line">encoded = l2_regularizer(embeds=encoded)</span><br><span class="line">train_loss = triplet_loss(embeds=encoded, targets=commands)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>WeKws</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/wekws/</url>
    <content><![CDATA[<h1 id="WeKws"><a href="#WeKws" class="headerlink" title="WeKws"></a>WeKws</h1><blockquote>
<p><a href="https://github.com/wenet-e2e/wekws">https://github.com/wenet-e2e/wekws</a></p>
<p>Mining Effective Negative Training Samples for Keyword Spotting (<a href="https://github.com/jingyonghou/KWS_Max-pooling_RHE">github</a>, <a href="http://lxie.nwpu-aslp.org/papers/2020ICASSP_HJY.pdf">paper</a>)</p>
<p>Max-pooling Loss Training of Long Short-term Memory Networks for Small-footprint Keyword Spotting (<a href="https://arxiv.org/pdf/1705.02411.pdf">paper</a>)</p>
<p>A depthwise separable convolutional neural network for keyword spotting on an embedded system (<a href="https://github.com/PeterMS123/KWS-DS-CNN-for-embedded">github</a>, <a href="https://asmp-eurasipjournals.springeropen.com/track/pdf/10.1186/s13636-020-00176-2.pdf">paper</a>)</p>
<p>Hello Edge: Keyword Spotting on Microcontrollers (<a href="https://github.com/ARM-software/ML-KWS-for-MCU">github</a>, <a href="https://arxiv.org/pdf/1711.07128.pdf">paper</a>)</p>
<p>An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling (<a href="http://github.com/locuslab/TCN">github</a>, <a href="https://arxiv.org/pdf/1803.01271.pdf">paper</a>)</p>
</blockquote>
<h2 id="代码结构梳理"><a href="#代码结构梳理" class="headerlink" title="代码结构梳理"></a>代码结构梳理</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_dataset = Dataset(args.train_data, train_conf)</span><br><span class="line">train_data_loader = DataLoader(train_dataset,</span><br><span class="line">                                   batch_size=<span class="literal">None</span>,</span><br><span class="line">                                   pin_memory=args.pin_memory,</span><br><span class="line">                                   num_workers=args.num_workers,</span><br><span class="line">                                   prefetch_factor=args.prefetch)</span><br></pre></td></tr></table></figure>

<p>其中，kws&#x2F;dataset&#x2F;dataset.py里的Dataset函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Dataset</span>(<span class="params">data_list_file, conf, partition=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Construct dataset from arguments</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        We have two shuffle stage in the Dataset. The first is global</span></span><br><span class="line"><span class="string">        shuffle at shards tar/raw file level. The second is global shuffle</span></span><br><span class="line"><span class="string">        at training samples level.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data_type(str): raw/shard</span></span><br><span class="line"><span class="string">            partition(bool): whether to do data partition in terms of rank</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    lists = read_lists(data_list_file)</span><br><span class="line">    shuffle = conf.get(<span class="string">&#x27;shuffle&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">    dataset = DataList(lists, shuffle=shuffle, partition=partition)</span><br><span class="line">    dataset = Processor(dataset, processor.parse_raw)</span><br><span class="line">    filter_conf = conf.get(<span class="string">&#x27;filter_conf&#x27;</span>, &#123;&#125;)</span><br><span class="line">    dataset = Processor(dataset, processor.<span class="built_in">filter</span>, **filter_conf)</span><br><span class="line"></span><br><span class="line">    resample_conf = conf.get(<span class="string">&#x27;resample_conf&#x27;</span>, &#123;&#125;)</span><br><span class="line">    dataset = Processor(dataset, processor.resample, **resample_conf)</span><br><span class="line"></span><br><span class="line">    speed_perturb = conf.get(<span class="string">&#x27;speed_perturb&#x27;</span>, <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">if</span> speed_perturb:</span><br><span class="line">        dataset = Processor(dataset, processor.speed_perturb)</span><br><span class="line">    feature_extraction_conf = conf.get(<span class="string">&#x27;feature_extraction_conf&#x27;</span>, &#123;&#125;)</span><br><span class="line">    <span class="keyword">if</span> feature_extraction_conf[<span class="string">&#x27;feature_type&#x27;</span>] == <span class="string">&#x27;mfcc&#x27;</span>:</span><br><span class="line">        dataset = Processor(dataset, processor.compute_mfcc,</span><br><span class="line">                            **feature_extraction_conf)</span><br><span class="line">    <span class="keyword">elif</span> feature_extraction_conf[<span class="string">&#x27;feature_type&#x27;</span>] == <span class="string">&#x27;fbank&#x27;</span>:</span><br><span class="line">        dataset = Processor(dataset, processor.compute_fbank,</span><br><span class="line">                            **feature_extraction_conf)</span><br><span class="line">    spec_aug = conf.get(<span class="string">&#x27;spec_aug&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> spec_aug:</span><br><span class="line">        spec_aug_conf = conf.get(<span class="string">&#x27;spec_aug_conf&#x27;</span>, &#123;&#125;)</span><br><span class="line">        dataset = Processor(dataset, processor.spec_aug, **spec_aug_conf)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        shuffle_conf = conf.get(<span class="string">&#x27;shuffle_conf&#x27;</span>, &#123;&#125;)</span><br><span class="line">        dataset = Processor(dataset, processor.shuffle, **shuffle_conf)</span><br><span class="line"></span><br><span class="line">    batch_conf = conf.get(<span class="string">&#x27;batch_conf&#x27;</span>, &#123;&#125;)</span><br><span class="line">    dataset = Processor(dataset, processor.batch, **batch_conf)</span><br><span class="line">    dataset = Processor(dataset, processor.padding)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br></pre></td></tr></table></figure>

<p>给dataset按if添加了很多项，写法比较规范</p>
<p>examples&#x2F;hi_xiaowen&#x2F;s0&#x2F;kws&#x2F;dataset&#x2F;processor.py，有点看不懂这里是怎么jump的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shuffle</span>(<span class="params">data, shuffle_size=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Local shuffle the data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data: Iterable[&#123;key, feat, label&#125;]</span></span><br><span class="line"><span class="string">            shuffle_size: buffer size for shuffle</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Iterable[&#123;key, feat, label&#125;]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    buf = []</span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> data:</span><br><span class="line">        buf.append(sample)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(buf) &gt;= shuffle_size:</span><br><span class="line">            random.shuffle(buf)</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> buf:</span><br><span class="line">                <span class="keyword">yield</span> x</span><br><span class="line">            buf = []</span><br><span class="line">    <span class="comment"># The sample left over</span></span><br><span class="line">    random.shuffle(buf)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> buf:</span><br><span class="line">        <span class="keyword">yield</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch</span>(<span class="params">data, batch_size=<span class="number">16</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Static batch the data by `batch_size`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data: Iterable[&#123;key, feat, label&#125;]</span></span><br><span class="line"><span class="string">            batch_size: batch size</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Iterable[List[&#123;key, feat, label&#125;]]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    buf = []</span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> data:</span><br><span class="line">        buf.append(sample)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(buf) &gt;= batch_size:</span><br><span class="line">            <span class="keyword">yield</span> buf</span><br><span class="line">            buf = []</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(buf) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">yield</span> buf</span><br></pre></td></tr></table></figure>



<h3 id="max-pooling-loss"><a href="#max-pooling-loss" class="headerlink" title="max pooling loss"></a>max pooling loss</h3><p>max_pooling loss是取正样本某帧的最大正类概率值，让这帧概率越大越好，取负样本某帧的最小负类概率值，让这帧的概率越大越好</p>
<ul>
<li><p>二分类时：</p>
<p>target &#x3D; filler时：$loss&#x3D;\min\limits_T(1-P_{keyword})$	（min pooling）</p>
<p>target &#x3D; keyword时：$loss&#x3D;\max\limits_TP_{keyword}$	（max pooling）</p>
</li>
<li><p>三分类时（两个keyword）</p>
<p>target &#x3D; filler时：$loss&#x3D;\min\limits_T(1-P_{keyword1})+\min\limits_T(1-P_{keyword2})$	（min pooling）</p>
<p>target &#x3D; keyword1时：$loss&#x3D;\max\limits_TP_{keyword1}+\min\limits_T(1-P_{keyword2})$	（max pooling）</p>
<p>target &#x3D; keyword2时：$loss&#x3D;\max\limits_TP_{keyword2}+\min\limits_T(1-P_{keyword1})$	（max pooling）</p>
</li>
<li><p>目标：$\max_Wloss$</p>
</li>
<li><p><strong>这里我一开始有个误区，$\min\limits_T(1-P_{keyword})$其实不等价为$\max\limits_T(P_{keyword}-1)$！！！而是$\min\limits_T(1-P_{keyword})&#x3D;-\max\limits_T(P_{keyword}-1)$</strong></p>
</li>
<li><p>最小化loss（代码里取负号后是最小化loss，不取负号是最大化loss，我这里先不取负号进行解释），因此要最大化target&#x3D;keyword时 $P_{keyword}$的概率，因为只要有一帧大于阈值就算唤醒，所以取max-pooling对应最大keyword概率帧的概率，同时也要最小化nonkeyword的概率，这里希望最难训练的一帧nonkeyword也要尽可能小，最难训练一帧对应的min-pooling的$1-P_{nonkeyword}$，使得$\min\limits_T(1-P_{nonkeyword})$尽可能大作为loss function，随着迭代该值能够越来越大，意味着最难训练的nonkeyword的概率越来越小</p>
</li>
<li><p>[&#x3D;&#x3D;TODO&#x3D;&#x3D;]稳定之后，尝试focal loss？尽可能让所有的keyword的概率都要大，试试$\min\limits_TP_{keyword}$使之尽可能大</p>
<p>推理时<strong>只考虑keyword帧是否大于阈值</strong>（只要有一帧大于阈值就算唤醒）</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">max_pooling_loss</span>(<span class="params">logits: torch.Tensor,</span></span><br><span class="line"><span class="params">                     target: torch.Tensor,</span></span><br><span class="line"><span class="params">                     lengths: torch.Tensor,</span></span><br><span class="line"><span class="params">                     min_duration: <span class="built_in">int</span> = <span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Max-pooling loss</span></span><br><span class="line"><span class="string">        For keyword, select the frame with the highest posterior.</span></span><br><span class="line"><span class="string">            The keyword is triggered when any of the frames is triggered.</span></span><br><span class="line"><span class="string">        For none keyword, select the hardest frame, namely the frame</span></span><br><span class="line"><span class="string">            with lowest filler posterior(highest keyword posterior).</span></span><br><span class="line"><span class="string">            the keyword is not triggered when all frames are not triggered.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes:</span></span><br><span class="line"><span class="string">        logits: (B, T, D), D is the number of keywords</span></span><br><span class="line"><span class="string">        target: (B)</span></span><br><span class="line"><span class="string">        lengths: (B)</span></span><br><span class="line"><span class="string">        min_duration: min duration of the keyword</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (float): loss of current batch</span></span><br><span class="line"><span class="string">        (float): accuracy of current batch</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    mask = padding_mask(lengths)</span><br><span class="line">    num_utts = logits.size(<span class="number">0</span>)</span><br><span class="line">    num_keywords = logits.size(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    target = target.cpu()</span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_utts):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_keywords):</span><br><span class="line">            <span class="comment"># Add entropy loss CE = -(t * log(p) + (1 - t) * log(1 - p))</span></span><br><span class="line">            <span class="keyword">if</span> target[i] == j:</span><br><span class="line">                <span class="comment"># For the keyword, do max-polling</span></span><br><span class="line">                prob = logits[i, :, j]</span><br><span class="line">                m = mask[i].clone().detach()</span><br><span class="line">                m[:min_duration] = <span class="literal">True</span></span><br><span class="line">                prob = prob.masked_fill(m, <span class="number">0.0</span>)</span><br><span class="line">                prob = torch.clamp(prob, <span class="number">1e-8</span>, <span class="number">1.0</span>)</span><br><span class="line">                max_prob = prob.<span class="built_in">max</span>()</span><br><span class="line">                loss += -torch.log(max_prob)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># For other keywords or filler, do min-polling</span></span><br><span class="line">                prob = <span class="number">1</span> - logits[i, :, j]</span><br><span class="line">                prob = prob.masked_fill(mask[i], <span class="number">1.0</span>)</span><br><span class="line">                prob = torch.clamp(prob, <span class="number">1e-8</span>, <span class="number">1.0</span>)</span><br><span class="line">                min_prob = prob.<span class="built_in">min</span>()</span><br><span class="line">                loss += -torch.log(min_prob)</span><br><span class="line">    loss = loss / num_utts</span><br></pre></td></tr></table></figure>







<ul>
<li>kws&#x2F;bin&#x2F;average_model.py：把最后保存的N个模型里面的参数求和取平均</li>
<li>kws&#x2F;bin&#x2F;score.py：计算声学模型输出，保存到文件中</li>
<li>kws&#x2F;bin&#x2F;compute_det.py：计算FRR&#x2F;FAR：对于某个分类，看它的分数是否大于阈值，大于就唤醒，小于没唤醒；（而不是在不同分类之间比较大小，从而确定是哪个分类唤醒，这是因为这里的输出没有filler分类，只有keyword分类）</li>
</ul>
<h2 id="hi-xiaowen数据集替换为自己的数据集"><a href="#hi-xiaowen数据集替换为自己的数据集" class="headerlink" title="hi_xiaowen数据集替换为自己的数据集"></a>hi_xiaowen数据集替换为自己的数据集</h2><p>。。。</p>
<h3 id="生成data-list："><a href="#生成data-list：" class="headerlink" title="生成data.list："></a>生成data.list：</h3><p>用shell直接从现有文件中生成了</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">awk &#x27;&#123;print&quot;&#123;\&quot;key\&quot;: \&quot;&quot;$1&quot;\&quot;,&quot;&#125;&#x27; feats.scp &gt; 1</span><br><span class="line">awk &#x27;&#123;print&quot;\&quot;txt\&quot;: &quot;$2&quot;,&quot;&#125;&#x27; text &gt; 2</span><br><span class="line">awk &#x27;&#123;print&quot;\&quot;duration\&quot;: &quot;$2&quot;,&quot;&#125;&#x27; utt2dur &gt; 3</span><br><span class="line">awk &#x27;&#123;print&quot;\&quot;wav\&quot;: \&quot;&quot;$2&quot;\&quot;&#125;&quot;&#125;&#x27; feats.scp &gt; 4</span><br><span class="line">paste -d &#x27; &#x27; 1 2 3 4 &gt; data.list</span><br><span class="line">rm 1 2 3 4</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;print&quot;&#123;\&quot;key\&quot;: \&quot;&quot;$1&quot;\&quot;,&quot;&#125;&#x27;</span> feats_offline_cmvn.scp &gt; 1</span><br><span class="line">awk <span class="string">&#x27;&#123;print&quot;\&quot;txt\&quot;: &quot;$2&quot;,&quot;&#125;&#x27;</span> text &gt; 2</span><br><span class="line">awk <span class="string">&#x27;&#123;print&quot;\&quot;duration\&quot;: &quot;$2&quot;,&quot;&#125;&#x27;</span> utt2dur &gt; 3</span><br><span class="line">awk <span class="string">&#x27;&#123;print&quot;\&quot;wav\&quot;: \&quot;&quot;$2&quot;\&quot;&#125;&quot;&#125;&#x27;</span> feats_offline_cmvn.scp &gt; 4</span><br><span class="line"><span class="built_in">paste</span> -d <span class="string">&#x27; &#x27;</span> 1 2 3 4 &gt; data_after_offline_cmvn.list</span><br><span class="line"><span class="built_in">rm</span> 1 2 3 4</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h4 id="不用代码统计global-cmvn，用kaldi的"><a href="#不用代码统计global-cmvn，用kaldi的" class="headerlink" title="不用代码统计global cmvn，用kaldi的"></a>不用代码统计global cmvn，用kaldi的</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">matrix-sum --binary=false scp:data/train_p400h_n4000h/cmvn.scp - &gt; data/train_p400h_n4000h/global_cmvn.stats</span><br></pre></td></tr></table></figure>



<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>num_worker&#x3D;1</p>
<h3 id="输出模型步长"><a href="#输出模型步长" class="headerlink" title="输出模型步长"></a>输出模型步长</h3><p>之前是一个epoch输出一个模型，现在改成1000次迭代输出一个模型</p>
<h2 id="mdtc-small："><a href="#mdtc-small：" class="headerlink" title="mdtc_small："></a>mdtc_small：</h2><p>dilation：低层到高层的值逐渐增长 1，2，4，8</p>
<p>self.receptive_fields感受野（非kernel size）大小与dilation有关，这个变量是为了给卷积补零用的，统计一共需要多少补零的长度</p>
<p>如果causal&#x3D;True，就不能卷（计算）当前时间帧后面帧的信息，只能给过去帧补零，以达到能够计算的长度</p>
<p>如果causal&#x3D;False，前后帧补零（除以2）$\left\lfloor\frac{\text{len(pad)}}{2}\right\rfloor$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.receptive_fields = dilation * (kernel_size - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>



<p>补零的不计算？：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> self.causal:</span><br><span class="line">    inputs = inputs[:, :, self.receptive_fields:]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    inputs = inputs[:, :, self.</span><br><span class="line">                    half_receptive_fields:-self.half_receptive_fields]</span><br></pre></td></tr></table></figure>





<p>[TODO] 补零，可以用复制代替？？</p>
<p>preprocessor预测里后的特征分别经过stack_num个TCN Stack，得到stack_num个输出 </p>
<p>结构：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">the number of model params: 33201</span><br><span class="line">Receptive Fields: 184</span><br><span class="line">KWSModel(</span><br><span class="line">  (global_cmvn): GlobalCMVN()</span><br><span class="line">  (preprocessing): NoSubsampling()</span><br><span class="line">  (backbone): MDTC(</span><br><span class="line">    (preprocessor): TCNBlock(</span><br><span class="line">      (conv1): DSDilatedConv1d(</span><br><span class="line">        (conv): Conv1d(50, 50, kernel_size=(5,), stride=(1,), <span class="built_in">groups</span>=50)</span><br><span class="line">        (bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">        (pointwise): Conv1d(50, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">      )</span><br><span class="line">      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu1): ReLU()</span><br><span class="line">      (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu2): ReLU()</span><br><span class="line">    )</span><br><span class="line">    (relu): ReLU()</span><br><span class="line">    (blocks): ModuleList(</span><br><span class="line">      (0): TCNStack(</span><br><span class="line">        (res_blocks): Sequential(</span><br><span class="line">          (0): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (1): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(2,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (2): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(4,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (3): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(8,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (1): TCNStack(</span><br><span class="line">        (res_blocks): Sequential(</span><br><span class="line">          (0): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (1): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(2,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (2): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(4,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (3): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(8,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">      (2): TCNStack(</span><br><span class="line">        (res_blocks): Sequential(</span><br><span class="line">          (0): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (1): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(2,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (2): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(4,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">          (3): TCNBlock(</span><br><span class="line">            (conv1): DSDilatedConv1d(</span><br><span class="line">              (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(8,), <span class="built_in">groups</span>=32)</span><br><span class="line">              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">              (pointwise): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            )</span><br><span class="line">            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu1): ReLU()</span><br><span class="line">            (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))</span><br><span class="line">            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">            (relu2): ReLU()</span><br><span class="line">          )</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (classifier): LinearClassifier(</span><br><span class="line">    (linear): Linear(in_features=32, out_features=1, bias=True)</span><br><span class="line">    (quant): QuantStub()</span><br><span class="line">    (dequant): DeQuantStub()</span><br><span class="line">  )</span><br><span class="line">  (activation): Sigmoid()</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>参数图：</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/wekws/image-20220112174511263.png" alt="image-20220112174511263"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/wekws/image-20220112174541188.png" alt="image-20220112174541188"></p>
<h1 id="修改代码"><a href="#修改代码" class="headerlink" title="修改代码"></a>修改代码</h1><h3 id="在log中把train的learning-rate也打印出来"><a href="#在log中把train的learning-rate也打印出来" class="headerlink" title="在log中把train的learning rate也打印出来"></a>在log中把train的learning rate也打印出来</h3><p>在kws&#x2F;utils&#x2F;executor.py中，修改logging代码为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">logging.debug(</span><br><span class="line">    <span class="string">&#x27;TRAIN Batch &#123;&#125;/&#123;&#125; loss &#123;:.8f&#125; acc &#123;:.8f&#125; lr &#123;:.8f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        epoch, batch_idx, loss.item(), acc, optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]))</span><br><span class="line"><span class="comment"># logging.debug(</span></span><br><span class="line"><span class="comment">#     &#x27;TRAIN Batch &#123;&#125;/&#123;&#125; loss &#123;:.8f&#125; acc &#123;:.8f&#125;&#x27;.format(</span></span><br><span class="line"><span class="comment">#         epoch, batch_idx, loss.item(), acc))</span></span><br></pre></td></tr></table></figure>





<h3 id="打印model结构图-x2F-可视化"><a href="#打印model结构图-x2F-可视化" class="headerlink" title="打印model结构图&#x2F;可视化"></a>打印model结构图&#x2F;可视化</h3><h4 id="法一：tensorboard-可视化不太明显"><a href="#法一：tensorboard-可视化不太明显" class="headerlink" title="法一：tensorboard[可视化不太明显]"></a>法一：tensorboard[可视化不太明显]</h4><p>在kws&#x2F;model&#x2F;kws_model.py中，添加代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">   kws_model = KWSModel(input_dim, output_dim, hidden_dim, global_cmvn,</span><br><span class="line">                        preprocessing, backbone, classifier, activation)</span><br><span class="line">   <span class="comment"># 添加：</span></span><br><span class="line">   <span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">dummy_input = torch.rand(<span class="number">128</span>,<span class="number">100</span>,<span class="number">40</span>)</span><br><span class="line">   <span class="keyword">with</span> SummaryWriter(comment=<span class="string">&#x27;KWSModel&#x27;</span>)<span class="keyword">as</span> w:</span><br><span class="line">       w.add_graph(kws_model, (dummy_input,))</span><br></pre></td></tr></table></figure>



<p>在路径runs&#x2F;下，tensorboard打开</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/wekws/image-20220111101914418.png" alt="image-20220111101914418"></p>
<p>可以展开看细节。但是这样可视化程度不是很强。[tensorboard可视化模型结构并不友好]</p>
<h4 id="法二：torchviz"><a href="#法二：torchviz" class="headerlink" title="法二：torchviz"></a>法二：torchviz</h4><p>在kws&#x2F;model&#x2F;kws_model.py中，添加代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchviz <span class="keyword">import</span> make_dot</span><br><span class="line">    kws_model = KWSModel(input_dim, output_dim, hidden_dim, global_cmvn,</span><br><span class="line">                         preprocessing, backbone, classifier, activation)</span><br><span class="line">    <span class="comment"># 添加</span></span><br><span class="line">    x = torch.rand(<span class="number">128</span>,<span class="number">100</span>,<span class="number">40</span>)</span><br><span class="line">    y=kws_model(x)</span><br><span class="line">    <span class="comment"># g = make_dot(y)</span></span><br><span class="line">    g = make_dot(y, params=<span class="built_in">dict</span>(<span class="built_in">list</span>(kws_model.named_parameters()) + [(<span class="string">&#x27;x&#x27;</span>, x)]))</span><br><span class="line">    g.view()</span><br><span class="line">    g.render(<span class="string">&#x27;espnet_model&#x27;</span>, view=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/wekws/image-20220111105457343.png" alt="image-20220111105457343"></p>
<h4 id="法三：tensorwatch"><a href="#法三：tensorwatch" class="headerlink" title="法三：tensorwatch"></a>法三：tensorwatch</h4><p>支持的网络不够多</p>
<p>在kws&#x2F;model&#x2F;kws_model.py中，添加代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorwatch <span class="keyword">as</span> tw</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 这个是debug出来发现发现的</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="keyword">if</span> self.global_cmvn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.global_cmvn(x)</span><br><span class="line">        x = self.preprocessing(x)</span><br><span class="line">        <span class="comment"># 添加一行unsqueeze，在第0维，扩充1维度，维度为1</span></span><br><span class="line">        x = torch.unsqueeze(x, dim=<span class="number">0</span>)</span><br><span class="line">        x, _ = self.backbone(x)</span><br><span class="line">        <span class="comment"># 添加一行squeeze，把维度为1的维度删掉</span></span><br><span class="line">        x = torch.squeeze(x, dim=<span class="number">0</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    kws_model = KWSModel(input_dim, output_dim, hidden_dim, global_cmvn,</span><br><span class="line">                         preprocessing, backbone, classifier, activation)</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 添加</span></span><br><span class="line">    <span class="comment"># 查看参数、计算量、flop等</span></span><br><span class="line">    <span class="comment"># module name、input shape、output shape、parameters、infer memory、MAdd、Flops、MemRead、MemWrite、</span></span><br><span class="line">    a = tw.model_stats(kws_model, [<span class="number">100</span>,<span class="number">50</span>])</span><br><span class="line">    <span class="built_in">print</span>(a)</span><br><span class="line">    <span class="comment"># 保存网络结构</span></span><br><span class="line">    img = tw.draw_model(kws_model, [<span class="number">100</span>,<span class="number">50</span>])	<span class="comment"># 有bug，原因是里头有量化.</span></span><br><span class="line">    img.save(<span class="string">&#x27;./ds_tcn.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure>



<ul>
<li>ds_tcn：以batch size&#x3D;1，time&#x3D;1s，40维特征为例的tensorwatch.model_stats</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/wekws/image-20220111141741028.png" alt="image-20220111141741028"></p>
<h4 id="法四：fvcore"><a href="#法四：fvcore" class="headerlink" title="法四：fvcore"></a>法四：fvcore</h4><blockquote>
<p>csdn <a href="https://blog.csdn.net/qq_37541097/article/details/117691873">详解Transformer中Self-Attention以及Multi-Head Attention</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fvcore.nn <span class="keyword">import</span> FlopCountAnalysis</span><br><span class="line">flops = FlopCountAnalysis(mdtc, (x,lengths))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Multi-Head Attention FLOPs:&quot;</span>, flops.total()) </span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>WeKws（五）基于wekws的多命令词识别</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/wekws%EF%BC%88%E4%BA%94%EF%BC%89%E5%A4%9A%E5%91%BD%E4%BB%A4%E8%AF%8D/</url>
    <content><![CDATA[<h1 id="基于wekws的多命令词识别"><a href="#基于wekws的多命令词识别" class="headerlink" title="基于wekws的多命令词识别"></a>基于wekws的多命令词识别</h1><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>激活函数用gate有提升</p>
<p>far_frj loss有提升</p>
<p>center+orth loss有很大的提升！</p>
<p>end of keyword loss加perturb未有提升</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>单一唤醒词识别模型</title>
    <url>/2022/01/11/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%8D%95%E4%B8%80%E5%94%A4%E9%86%92%E8%AF%8D%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="单一唤醒词识别模型"><a href="#单一唤醒词识别模型" class="headerlink" title="单一唤醒词识别模型"></a>单一唤醒词识别模型</h1><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><ul>
<li>与DNN-HMM的ASR任务相同，逐帧分类，按音素建模，不同的是KWS任务分类数量比ASR任务分类数量更少，只有唤醒词包含的音素，其他通用音素都视为非唤醒词音素，采用一个非唤醒词音素建模（gbg）；音频经过声学模型输出后采用beam search解码，最优路径上判断是否是唤醒词路径。</li>
</ul>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>唤醒Recall高，FAR低</p>
<ul>
<li>提高Recall方法：唤醒数据增广，增加唤醒样本的丰富性，其他未有正向结论；</li>
<li>降低FAR方法：参考Sigtia, Siddharth, et al. “Efficient Voice Trigger Detection for Low Resource Hardware.” <em>INTERSPEECH</em>. 2018. 文章通过加入状态持续时间的约束minimum duration constraint，最小状态帧长的约束，也就是每个状态至少持续n帧，增大帧移，来减少误唤醒。因此实验中在解码过程中进行<strong>下采样</strong>，以及声学模型的拼帧采用较长拼帧，来减少误唤醒。</li>
</ul>
<h2 id="声学模型"><a href="#声学模型" class="headerlink" title="声学模型"></a>声学模型</h2><ul>
<li>输出分类标签：唤醒词“小源小源”对应的音素组成“x、iao、vv、van”、静音“sil”、其他音“gbg”，共6个分类数；</li>
<li>声学模型网络结构为TDNN，结构特点为拼帧较长：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">    <span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; $dir/configs/network.xconfig</span></span><br><span class="line"><span class="string">    input dim=50 name=input</span></span><br><span class="line"><span class="string">    fixed-affine-layer name=lda input=Append(-6,-3,0,3,6) affine-transform-file=$dir/configs/lda.mat</span></span><br><span class="line"><span class="string">    relu-renorm-layer name=tdnn1 dim=256</span></span><br><span class="line"><span class="string">    relu-renorm-layer name=tdnn2 dim=256 input=Append(-3,6)</span></span><br><span class="line"><span class="string">    relu-renorm-layer name=tdnn3 dim=256 input=Append(-6,3)</span></span><br><span class="line"><span class="string">    relu-renorm-layer name=tdnn4 dim=256 input=Append(-9,9)</span></span><br><span class="line"><span class="string">    relu-renorm-layer name=tdnn5 dim=256 input=Append(-15,3)</span></span><br><span class="line"><span class="string">    relu-renorm-layer name=tdnn6 dim=256 input=Append(0)</span></span><br><span class="line"><span class="string">    output-layer name=output dim=$num_targets max-change=1.5</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>



<h2 id="词典"><a href="#词典" class="headerlink" title="词典"></a>词典</h2><ul>
<li>lexicon.txt</li>
</ul>
<h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><ul>
<li><p>words.txt</p>
</li>
<li><p>2gram，srilm.o3g.kn.gz：</p>
</li>
<li><p>语言模型训练通过很多的sil和gbg和几条小源小源、xiao、yuan、xiaoyuan等训练得到，观察测试集中没识别出唤醒词识别成什么文本，观察测试集中误唤醒成什么文本，调节该文本相关语言模型权重；</p>
</li>
<li><p>根据recall和far值，不断微调唤醒词和非唤醒词语言模型权重，使得recall较高下也有较低的far；</p>
</li>
</ul>
<h2 id="声学模型训练过程"><a href="#声学模型训练过程" class="headerlink" title="声学模型训练过程"></a>声学模型训练过程</h2><h3 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h3><ul>
<li>用6w原始数据，5种噪声，加上原来没有加噪的数据，6*6&#x3D;36w条；路径：data&#x2F;train_xiaoyuan</li>
<li>速度扰动 36*3&#x3D;108w条，路径：data&#x2F;train_xiaoyuan_sp（727小时）</li>
<li>108w条提取16维mfcc特征，train_xiaoyuan_sp_mfcc（steps&#x2F;make_mfcc_pitch.sh），做对齐，对齐路径：exp&#x2F;nnet3&#x2F;tdnn_lei&#x2F;ali_train_xiaoyuan_sp</li>
<li>提取50维plp特征</li>
<li>108w条对齐文件 + Xiaoyuan 9w条对齐文件 &#x3D; 117w条，作为小源命令词数据（正样本）</li>
<li>4000小时ASR通用数据，360万条作为非唤醒词数据（负样本）</li>
</ul>
<h3 id="训练标签准备"><a href="#训练标签准备" class="headerlink" title="训练标签准备"></a>训练标签准备</h3><ul>
<li><p>将对齐标签转为6分类（可参考kaldi脚本hi_mia&#x2F;w1&#x2F;run_kws_kf.sh）</p>
<ol>
<li><p>构建phone映射表</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#转换，使得只保留命令词的phone，其他无关phone都用garbage这个phone表示</span></span><br><span class="line">awk -v hotword_phone=data/dict/phones.txt \</span><br><span class="line"><span class="string">&#x27;BEGIN &#123;</span></span><br><span class="line"><span class="string">    while (getline &lt; hotword_phone) &#123;</span></span><br><span class="line"><span class="string">        map[$1] = $2-1</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    if(!match($1, &quot;#&quot;) &amp;&amp; !match($1, &quot;&lt;&quot;)) &#123;</span></span><br><span class="line"><span class="string">        if(match($1, &quot;sil&quot;))</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            printf(&quot;%s %s\n&quot;, $2, 0)</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        else</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            printf(&quot;%s %s\n&quot;, $2, map[$1] != &quot;&quot; ? map[$1] : 1)</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#x27;</span> data/lang/phones.txt &gt; data/phone.map</span><br></pre></td></tr></table></figure>
</li>
<li><p>构建6分类的alignment文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$dir_temp</span></span><br><span class="line">   cur=$(<span class="built_in">cat</span> <span class="variable">$ali</span>/num_jobs)</span><br><span class="line">   <span class="keyword">for</span> x <span class="keyword">in</span> $(<span class="built_in">seq</span> 1 <span class="variable">$cur</span>);<span class="keyword">do</span></span><br><span class="line">       gunzip -c <span class="variable">$ali</span>/ali.<span class="variable">$x</span>.gz |</span><br><span class="line">       ali-to-phones --per-frame=<span class="literal">true</span> exp_sil_ftv/mfcc_pitch/nnet3_tdnn6layers_8b_relu_ali_train_ftv/final.mdl ark:- t,ark:- |</span><br><span class="line">       utils/apply_map.pl -f 2- data/phone.map |</span><br><span class="line">       copy-int-vector t,ark:- ark,scp:<span class="variable">$dir_temp</span>/ali.<span class="variable">$x</span>.ark,<span class="variable">$dir_temp</span>/ali.<span class="variable">$x</span>.scp</span><br><span class="line">   <span class="keyword">done</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h3 id="声学模型训练"><a href="#声学模型训练" class="headerlink" title="声学模型训练"></a>声学模型训练</h3><ul>
<li>steps&#x2F;nnet3&#x2F;train_raw_dnn.py，没有转移概率，生成声学模型final.raw</li>
</ul>
<h3 id="生成final-mdl"><a href="#生成final-mdl" class="headerlink" title="生成final.mdl"></a>生成final.mdl</h3><ul>
<li>生成tree：<ul>
<li>gmm-init-mono –shared-phones&#x3D;data&#x2F;lang_xyxy&#x2F;phones&#x2F;sets.int “–train-feats&#x3D;ark,s,cs:apply-cmvn  –utt2spk&#x3D;ark:data&#x2F;train&#x2F;split10&#x2F;1&#x2F;utt2spk scp:data&#x2F;train&#x2F;split10&#x2F;1&#x2F;cmvn.scp scp:data&#x2F;train&#x2F;split10&#x2F;1&#x2F;feats.scp ark:- | add-deltas  ark:- ark:- | subset-feats –n&#x3D;10 ark:- ark:-|” data&#x2F;lang_xiaoyuan&#x2F;topo 39 0.mdl tree</li>
</ul>
</li>
<li>final.raw生成final.mdl<ul>
<li>nnet3-am-init exp&#x2F;nnet3&#x2F;tdnn_1&#x2F;tree data&#x2F;lang_xyxy&#x2F;topo exp&#x2F;nnet3&#x2F;tdnn_1&#x2F;final.raw exp&#x2F;nnet3&#x2F;tdnn_1&#x2F;final.mdl</li>
</ul>
</li>
</ul>
<h2 id="解码过程"><a href="#解码过程" class="headerlink" title="解码过程"></a>解码过程</h2><ul>
<li>与普通识别模型相同，输出声学模型分数，在事先构建好的解码网络HCLG.fst中搜索最优路径，最优路径有唤醒词则唤醒；</li>
<li>解码长度与触发VAD长度相关；</li>
<li>解码时“–frame-subsampling-factor&#x3D;3”，（即在keyword_lib改为chain model网络结构），跳帧输入解码器&#x2F;cmvn后特征跳帧输入DNN；</li>
</ul>
<h2 id="训练小结"><a href="#训练小结" class="headerlink" title="训练小结"></a>训练小结</h2><ol>
<li>对比负样本音素用一个音素gbg表示与保留唤醒词音素的模型，用一个音素表示造成声学特征下输出gbg的概率和唤醒词音素概率都高，造成区分性不明显，混淆，因此不能将负样本音素用一个音素表示，需要在负样本中保留唤醒词音素；</li>
<li>数据增广的效果：<ol>
<li>对比不同唤醒数据量训练的模型，加噪后用上所有唤醒数据，与加噪后没用上所有唤醒数据相比，没有改善；因此在样本数据有一定数量条件下，单纯只用上所有噪声未带来更加丰富的样本信息。</li>
<li>加噪后用上所有唤醒数据，再加入速度扰动，与加噪后没用上所有唤醒数据相比，能有一些改善；因此速度扰动在该样本集条件下能带来更加丰富的样本信息。</li>
</ol>
</li>
<li>asr和kws联合训练的多任务学习、用训好的asr除最后一层作为初始kws模型，未取得正向结论；训练时asr的accuracy在60%，猜想asr的loss较大可能影响了kws任务。</li>
<li>更改模型结构，crnn、attention结构，未取得正向结论；应该还是没有训练好。</li>
</ol>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><ul>
<li>结果从decode.log获取，不通过lattice得到</li>
</ul>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>唤醒小记</title>
    <url>/2021/06/07/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D/</url>
    <content><![CDATA[<p>我们的命令词检索方法：</p>
<p>用HMM filler model的方法，先识别，识别出一段语音内的phone序列，如果有命令词对应的phone序列，则提取DNN对应命令词起止时间内的后验概率等特征，几十维，送入二级DNN判断，做二分类判断，二次确认是否是命令词。</p>
<p>对于相像的关键词，比如“清洗”、“清洗衣服”，到了“清洗”就唤醒，是不是唤醒了再进行后处理，看看“清洗衣服”是否唤醒，才决定是“请洗衣服”or“清洗”；也就是说，多了一层逻辑</p>
<p>现在的瓶颈在于，说话说着说着突然喊一声唤醒词&#x2F;高噪声环境下喊唤醒词，因为此时VAD很早就工作了，就一直在录音，截一段判断一次，因此可能没截全唤醒词，这时候filler model的分数很高，keyword model的分数不高，因此就容易唤不醒。</p>
<p>雷博说，filler model要做的比较复杂，多个filler model</p>
<p>雷博说：一个企业做的TWS耳机上的命令词（12个命令词）结果：<br>大概是这个水平 -5到0db 67%，0-5db大约80+%，5-10db 85+%，10-15db 94%+，安静97%。<br>误识别大概是44小时新闻联播等说话语料，大概3~5次。</p>
<p>先用端到端（64K，就是个片段分类的模型）做1级，不用解码，全部在深度学习专有芯片上运行，功耗很低。然后二级用了一个TDNN的FST解码的方案，模型也是64K。建模单元是合并的音素，大概有六七十个。<br>由于需要解码必须需要在MCU或者DSP上进行解码。</p>
<p>一些经验；<br>1）端到端的模型虽说识别率比较高，到误识别很难控制。<br>2）使用空洞卷积TDNN，看到更多上下文信息，准备batch的时候，控制好帧级别正负样本比例。我们没有用序列模型，所以训练TDNN并不是给句子，而且按帧（扩展TDNN所需要的上下文帧数）给，控制正负样本比例大概4：1</p>
<p>我的目标：10db 唤醒率95%，误唤醒&lt;1~2次&#x2F;12h，内存300k ~ 500k</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词专利</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/</url>
    <content><![CDATA[<h1 id="命令词专利"><a href="#命令词专利" class="headerlink" title="命令词专利"></a>命令词专利</h1><blockquote>
<p>CN201811475797-语音唤醒方法及装置、处理器、音箱和电视机-申请公开.pdf 阿里巴巴  陈梦喆 薛少飞 雷鸣  2018</p>
</blockquote>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><ul>
<li>前端信号处理和kws串联 训练（前端信号处理、kws都用的网络）</li>
<li>前端信号处理的输出信号与原始信号 一起送入kws的am</li>
</ul>
<h4 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h4><ul>
<li>前端信号处理用网络了，功耗大</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/image-20210629164653786.png" alt="image-20210629164653786" style="zoom: 67%;">

<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/image-20210629164713634.png" alt="image-20210629164713634" style="zoom:67%;">



<hr>
<blockquote>
<p>CN201910094806-唤醒模型的确定方法及装置-审定授权.pdf  声智科技	靳源 陈孝良 冯大航 苏少炜 常乐     2019</p>
</blockquote>
<h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><ul>
<li>由于唤醒模块的建立，一般是特地录制关于唤醒词的语音信息，用于训练神经网络。且在神经网络的训练过程中，更新整个神经网络每一层的各个参数。这样一般花费较多的时间，成本较高，且神经网络的训练运算量太大，容易出现误差，因此，得到的唤醒模型的精确度也不高 。</li>
</ul>
<h4 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h4><ul>
<li>提出一种模型参数更新的方法</li>
<li>将训练集中的任一批次训练唤醒数据输入至一基于神经网络的识别模型，确定所述神经网络的隐层的最后一层的当前状态的参数，所述参数包括权重与偏移量；  （更新了一次iter），对所述识别模型的隐层的最后一层的前一个iter的状态的参数与当前状态的参数进行插值处理，确定一插值，并将所述插值更新为当前状态的参数。</li>
<li>也就是说，更新了iter的模型参数后，没有马上把这个参数用于下一个iter的训练，而是把这个参数与前一次iter的参数进行插值，得到新的参数。</li>
</ul>
<hr>
<blockquote>
<p>CN201910095418-语音唤醒的优化装置及方法-申请公开.pdf 声智科技   冯大航 陈孝良 苏少炜 常乐  2019</p>
</blockquote>
<h4 id="思想-2"><a href="#思想-2" class="headerlink" title="思想"></a>思想</h4><ul>
<li>两个阈值Y1,Y2，客户端一个唤醒模型A，云端一个唤醒模型B，经过A的输出Y：<ul>
<li>Y&lt;Y1：没唤醒</li>
<li>Y&gt;Y2：唤醒</li>
<li>Y1&lt;Y&lt;Y2，送入B，得到Y’：<ul>
<li>Y’&lt;Y1：没唤醒</li>
<li>Y’&gt;Y1：唤醒</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<blockquote>
<p>CN201910815261-一种语音唤醒的识别方法、装置及电子设备-审定授权.pdf  声智科技   陈孝良 靳源 冯大航 常乐  2019</p>
</blockquote>
<h4 id="思想-3"><a href="#思想-3" class="headerlink" title="思想"></a>思想</h4><ul>
<li>检测到唤醒时，取出唤醒词边界，多帧后验概率，送入二分类器，判断是否唤醒</li>
<li>二分类器：基于预先训练的唤醒模型，计算每个目标数据帧属于预设的第一语音段的概率；所述预设的第一语音段为属于语音信号且不包括唤醒词的数据。总概率低于阈值：唤醒；总高率高于阈值：误唤醒</li>
<li>概率：每个目标数据帧的短时能量和过零率  ；第一个字的各个音素的后验概率相加，得到每个数据帧属于所述唤醒词的第一字的后验概率值；</li>
</ul>
<hr>
<blockquote>
<p>CN201910872875-一种语音唤醒方法及装置-申请公开.pdf   声智科技 陈天峰 冯大航 陈孝良 常乐  2019</p>
</blockquote>
<h4 id="思想-4"><a href="#思想-4" class="headerlink" title="思想"></a>思想</h4><ul>
<li>唤醒后，把非唤醒词（<gbg>）的边界抽出，非唤醒词边界内的音频能量和声学特征 送入神经网络，得到一个分数，唤醒词分数和非唤醒词分数，得到一个置信度，再根据阈值判断是否唤醒</gbg></li>
</ul>
<hr>
<blockquote>
<p>CN202010268839-一种命令词识别方法及装置-申请公开.pdf   声智科技  张猛 冯大航 陈孝良   2020</p>
</blockquote>
<h4 id="思想-5"><a href="#思想-5" class="headerlink" title="思想"></a>思想</h4><ul>
<li>构造命令词的解码图进行缩减大小，相同的字进行复用，比如去XX楼，去和楼的状态是复用的，去XX楼，只需在去增加arc到XX，XX增加arc到楼</li>
</ul>
<hr>
<blockquote>
<p>CN202010537664-音频数据的存储方法、装置、终端及存储介质-申请公开.pdf  OPPO   陈喆  2020</p>
</blockquote>
<h4 id="思想-6"><a href="#思想-6" class="headerlink" title="思想"></a>思想</h4><ul>
<li>多级模型，从而得知是哪个地方拦住了唤醒</li>
<li>第一级语音唤醒识别模型筛选后，可以去除采集到的无效音频；  </li>
<li>第二级语音唤醒识别模型用于识别音频数据是否包含完整唤醒词，用于去除包含与唤醒词较接近的其他关键词的音频数据</li>
<li>得到第n级语音唤醒识别模型输出的音频特征向量，与预先设置的标准特征向量进行比较</li>
</ul>
<hr>
<blockquote>
<p>CN202010573699-一种语音唤醒系统及方法-申请公开.pdf  长虹电器  朱海 王昆 周琳岷  2020</p>
</blockquote>
<h4 id="思想-7"><a href="#思想-7" class="headerlink" title="思想"></a>思想</h4><ul>
<li>模型：LSTM、WaveNet、CNN、CRNN  中之一</li>
<li>有三类：激活、待激活、非激活。预测每一帧为非激活、待激活、激活标记的概率，采用滑动窗口，只在激活词的尾部进行唤醒 </li>
<li>正样本末尾特殊标记方式为以尾部端点为中心，在前后各一个窗口大小的范围内标记为激活，其余范围标记为待激活，负样本则全部标记为非激活  </li>
<li>若滑动窗口内平均值大于激活阈值，则判决为唤醒；</li>
<li>若滑动窗口内平均值介于激活阈值与待激活阈值，  并且此后窗口小于待激活阈值，则将待激活的语音帧片段用语音唤醒网络做二次判定，再判决是否唤醒。</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/image-20210630205600129.png" alt="image-20210630205600129"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/image-20210630205636115.png" alt="image-20210630205636115"></p>
<hr>
<blockquote>
<p>CN202010634922-语音唤醒方法及装置-申请公开.pdf  声智科技  杨晓帆 冯大航 陈孝良  2020</p>
</blockquote>
<h4 id="思想-8"><a href="#思想-8" class="headerlink" title="思想"></a>思想</h4><ul>
<li>两个模型，一个命令词模型，输出每帧后验，音素后验和，大于一个阈值，送入第二个模型；第二个模型，图片识别模型，输入边界的语谱图和后验概率图</li>
</ul>
<hr>
<blockquote>
<p>CN202010672496-一种基于多命令词的语音唤醒方法及其系统-申请公开.pdf   芯声智能   王蒙 姜黎 胡奎 付志勇  2020</p>
</blockquote>
<h4 id="思想-9"><a href="#思想-9" class="headerlink" title="思想"></a>思想</h4><ul>
<li>PCEN特征-&gt;神经网络-&gt;每帧概率分数-&gt;概率连续大于阈值20帧-&gt;检测到关键词</li>
<li>神经网络组成：CNN-&gt;GRU-&gt;Attention</li>
<li>CNN：对应特征数量，生成大小固定的等量卷积核；  拼接卷积核内积的结果，得到CNN层的输出特征  </li>
<li>label：命令词&#x2F;非命令词；或者：命令词1&#x2F;命令词2&#x2F;…&#x2F;非命令词</li>
<li>每次送入20帧：获取连续20帧的预测概率值，并解码；  累计预测概率值的大小和次数，当预测概率值连续几帧都大于设定的测试阈值时判定为检测到关键词。这种方案相比与滑窗机制，在预测方面识别率会稍有下降，但是计算量缩小将近百倍</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/image-20210701095859623.png" alt="image-20210701095859623"></p>
<h4 id="存在问题-1"><a href="#存在问题-1" class="headerlink" title="存在问题"></a>存在问题</h4><ul>
<li>20帧就能够判断是否命令词了吗？读一个小源岂不是也能唤醒，误唤醒是否会很高</li>
</ul>
<hr>
<blockquote>
<p>CN202010795017-语音唤醒方法、装置、电子设备和存储介质-申请公开.pdf   小米    张秀云  2020</p>
</blockquote>
<h4 id="思想-10"><a href="#思想-10" class="headerlink" title="思想"></a>思想</h4><ul>
<li>多级唤醒处理，每一级准确度递增，前面几级准确度低，但是功耗低，也能排除一部分，判断为误唤醒就不会进入下一级</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/image-20210701102615617.png" alt="image-20210701102615617"></p>
<hr>
<blockquote>
<p>CN202010801109-一种语音处理方法及装置、存储介质-申请公开.pdf  OPPO  陈喆 曹冰 胡宁宁   2020</p>
</blockquote>
<hr>
<blockquote>
<p>CN202110437391-一种语音唤醒方法及装置-申请公开.pdf 中国科学院声学研究所   黎塔 刘作桢 张鹏远 颜永红   2021</p>
</blockquote>
<ul>
<li>attention的RNN-T，输出每一帧的分类后验，每个音素逐帧概率求和与阈值比较，贪心解码，最小编辑距离</li>
</ul>
<hr>
<blockquote>
<p>CN202110168131-语音唤醒方法、装置、芯片、电子设备及存储介质-申请公开.pdf  汇顶科技  何婷婷 王乐临 王鑫山 朱虎   2021</p>
</blockquote>
<ul>
<li>VAD-&gt;声纹-&gt;唤醒词识别</li>
</ul>
<hr>
<blockquote>
<p>[好]CN202011630785-语音唤醒方法和装置-申请公开.pdf  思必驰   薛少飞   2021</p>
</blockquote>
<ul>
<li><p>sinc函数构造带通滤波器</p>
</li>
<li><p>CNN不适合低功耗唤醒设备的原因：</p>
<ul>
<li>计算量大，一维卷积核长度a，音频长度L，步长1，计算量至少a*L</li>
<li>对时间序列缺乏“ 记忆”：CNN由于结构的限制，对于之前的输入缺乏“ 记忆”功能，当前的输出仅和当前的输入有关。<ul>
<li>对时间序列缺乏“ 记忆”主要是由于CNN网络对时间序列缺乏“ 记忆”是由它的网络结构决定的。一方面，对于卷积层来说，卷积只对卷积核覆盖到的区域进行计算，因此卷积核外的语音信息不会对当前卷积核内语音信息的处理产生影响  </li>
<li>尽管由于全连接层的存在，各卷积核之间的信息仍会相互影响，但这种影响仅限于网络输入的总时长(通常为30ms)以内，无法在较长的时间尺度上进行信息传递。</li>
</ul>
</li>
</ul>
</li>
<li><p>FSMN缺点：无法对原始语音信号直接进行处理，直接用原始语音信号作为模型输入进行训练，效果会很差。  FSMN模型缺乏直接从原始音频数据中学习有用信息的能力，因此通常在使用FSMN模型之前需对原始音频进行特征提取。  </p>
</li>
<li><p>sinc函数来构造带通滤波器，形成一种特殊的卷积层，该滤波器的参数为最高和最低截止频率，而这两个参数的值由网络学习得到</p>
</li>
</ul>
<hr>
<blockquote>
<p>CN202011599330-语音唤醒方法、装置、计算机设备和存储介质-申请公开.pdf 杰理科技  匡勇建  2021</p>
</blockquote>
<ul>
<li>解码完，根据解码分数，提出引入一个建模单元时长相关的惩罚函数，音素常规时长区间以外的音素，乘以惩罚函数，得到新的解码分数，根据分数与阈值判断是否唤醒</li>
<li>惩罚函数，采用gamma曲线函数，$f(t)&#x3D;1,t\geq{t1},and,t\leq{t2}$,   $f(t)&#x3D;Gramma(t),t&lt;t1,or,t&gt;t2$</li>
</ul>
<hr>
<blockquote>
<p>CN202011568957-语音处理方法和电子设备-申请公开.pdf vivo 李俊潓  2021</p>
</blockquote>
<ul>
<li>减少误唤醒方法：唤醒后进行声纹识别</li>
</ul>
<hr>
<blockquote>
<p>CN202011565487-一种唤醒方法、装置及终端-申请公开.pdf 思必驰 王文成 董芳芳 樊冰玉 吴翔   2021</p>
</blockquote>
<ul>
<li>减少误唤醒方法：唤醒后进行周围是否有人检测</li>
<li>周围是否有人检测：距离传感器得到距离，得到声音强度，查找声音强度-距离对应关系表；红外特征信息是否符合人体红外特征信息，查找声音强度‑人体红外特征强度对应关系表</li>
</ul>
<hr>
<blockquote>
<p>CN202011547352-一种命令词识别方法及设备-申请公开.pdf 地平线 单长浩  2021</p>
</blockquote>
<ul>
<li>在声学模型上做文章，TDNN引入残差网络，第二层送入第三层与第五层，第三层送入第四层与第六层</li>
<li>引入注意力机制，多级输出？</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/image-20210922171204879.png" alt="image-20210922171204879"></p>
<hr>
<blockquote>
<p>CN202011453041-语音唤醒方法及装置、可读存储介质、电子设备-申请公开.pdf 单长浩 2021</p>
</blockquote>
<ul>
<li><p>普通的注意力机制训练的模型由于对其学习到的知识过度自信，导致语音唤醒系统的性能相对较低，误唤醒率相对较高  </p>
</li>
<li><p>用识别模型，提取bottlenect特征，无监督？，作为第二个模型的输入，第二个模型结构用了注意力机制，输出字，。。。。</p>
</li>
<li><p>基于多个第一语音特征的时序，通过多个第一语音特征分别对应的音素 概率分布形成音素概率分布序列，之后，确定出该音素概率分布序列中的目标音素序列，基 于该目标音素序列，确定第一唤醒概率。作为一种可能的情况，目标音素序列为唤醒词音素 序列，目标音素序列的概率为第一唤醒概率。举例来说，唤醒词是小爱同学，则唤醒词音素 序列(目标音素序列)为“ x iao3 ai4 t ong2 x ue2”，其中，数字3、4、2分别表示汉语音节 中的三声调、四声调和二声调，确定音素概率分布序列中存在唤醒词音素序列(目标音素序 列)的概率，并将该概率确定为第一唤醒概率。作为另一种可能的情况，针对每个音素概率 分布，确定音素概率分布中最大匹配概率值对应的示例音素，通过每个音素概率分布分别 对应的示例音素组成目标音素序列。作为一种可行的实现方式，计算目标音素序列与唤醒 词音素序列之间的相似度，并将该相似度确定为第一唤醒概率。作为另一种可行的实现方 式，构建词级别的声学模型，其中，词级别的声学模型确定语音波形中每个词的概率，基于 词级别的声学模型，得到目标音素序列对应的词序列，计算词序列与唤醒词序列之间的相 似度，并将该相似度确定为第一唤醒概率，这里，需要将连续多个第一语音特征进行拼接， 将拼接后的特征输入至词级声学模型中进行识别。</p>
</li>
</ul>
<hr>
<blockquote>
<p>CN202011502794-语音唤醒方法、装置、电子设备及可读存储介质-申请公开.pdf 百度 周毅 左声勇  2021</p>
</blockquote>
<ul>
<li>避免误唤醒，常见的方法是：采集能够导致误唤醒的音频，利用该些音频对语音助手中的语音识别模型进行训练，以使得语音助手识别出误唤醒的声音后，不会进入唤醒状态。  但这样效率很低</li>
<li>核心思想：不同的环境音量对应不同的唤醒精度 ，根据环境音量的大小，调整唤醒精度。当前环境越嘈杂，语音助手越难被唤醒。比如，用户想要唤醒语音助手，就得清晰、大声的发出“ 小黑小黑”</li>
</ul>
<hr>
<blockquote>
<p>CN202011474857-一种语音唤醒方法、装置、电子设备及存储介质-申请公开.pdf 有竹居网络（字节跳动）  田垚 姚海涛 蔡猛  2021</p>
</blockquote>
<ul>
<li><p>用RNNT网络，由于RNN‑T中预测网络prediction network 的角色类似于语音识别中语言模型的角色，通过输入上一个字(词)来预测下一个字(词)，由于训练数据中存在非常多唤醒词的数据，这些数据对应的文本都是一样的，会导致预测模型出现过拟合，从而利用模型进行语音唤醒时会出现非常多的误唤醒现象，影响语音唤醒的准确性。</p>
</li>
<li><p>在种子RNN‑T模型的基础上添加前向神经FFNN网络，其中，FFNN（Feed Forward Neural Networks ）网络与编码器网络连接；将种子RNN‑T模型（通用识别数据训）作为第一分支，将FFNN网络和编码器网络（识别数据+唤醒数据训）作为第二分支；根据第一分支和第二分支获得自适应唤醒模型。  loss：加权和，多任务学习。</p>
</li>
<li><p>并不是分两部分走，唤醒数据只用来finetune，先用通用识别数据训一个模型，再用识别数据+唤醒数据进行finetune（自适应）  的多任务学习方法。</p>
</li>
<li><p>在对自适应唤醒模型进行训练时，唤醒词数据不会经过预测网络，从而可以解决由于唤醒词所对应的文本都是一样的，而导致预测网络出现过拟合的情况。  </p>
</li>
<li><p>测试时，得到两个分支概率，概率和和阈值关系判断是否唤醒</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E4%B8%93%E5%88%A9/image-20210924120140454.png" alt="image-20210924120140454"></p>
</li>
</ul>
<hr>
<blockquote>
<p>CN202011436338-命令的识别方法、装置及计算机可读存储介质-申请公开.pdf 鹏城实验室 黄炜 钟晓雄 张伟哲 束建钢  艾建文 黄兴森  2021</p>
</blockquote>
<ul>
<li>google推荐的MnasNet(google搜索建立模型的方法)的最优骨干网络搭建方式，建立由输入端到输出端的网络  </li>
<li>由于矩阵中大部分为负样例，正样本对Loss的贡献度非常的小，这样会导致均值平均精度(mAP，mean Average Precision)训练不充分，为此引入处理正负样本不均衡的方法，将原有的交叉熵损失改进为如下公式，  $CrossEntropy(t,p)&#x3D;-(e^{a(1-p)}<em>t</em>log(p)+(1-t)*log(1-p))$ ，类似Focal Loss  ，为了提高正样本对Loss的贡献，其中α为控制该指数的上升速度，t为对应的标签，p为模型输出的值  </li>
<li>利用了声纹特征</li>
<li>判断特征向量与特征向量库是否匹配</li>
</ul>
<hr>
<blockquote>
<p>CN202011302212-语音唤醒方法及装置-申请公开.pdf 思必驰  王蒙 薛少飞  </p>
</blockquote>
<ul>
<li>在滑动窗口内对所获取的音频数据进行归一化处理，以生成相应的目标特征数据；将所述目标特征数据提供给语音唤醒模型  ，可以避免突变的声场环境因归一化操作而被削弱的影响，有助于提高终端设备在较嘈杂的声学环境中的唤醒率。  这不就是sliding cmvn？</li>
<li>PCEN（Per-Channel Energy Normalization , 单通道能量归一化算法）是一种能量泛化算法，其可以对没有取对数的音频特征进行单通道能量归一化处理，能够替代特征提取部分的取对数运算，具有较强的声学自适应性。此外，通过测试结果显示，在远场测试环境下具有提升唤醒率的效果  </li>
<li>在声音产生突变时，可能导致配置有PCEN算法的语音识别模型无法唤醒的情况，其一般是基于IIR（infinite impulse response , 无限脉冲响应）滤波器的，导致初始状态会一直对当前状态产生影响，而在声场环境突变时，特征的值会产生较大的改变，经过归一化处理后，这个改变被削弱，从而对唤醒结果产生一定影响。</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;CN202011238207-一种语音唤醒方法、装置、介质和设备-申请公开.pdf 声智科技  冯大航 陈孝良 韩赞 常乐   2021&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>每一级唤醒模块确定是否应唤醒智能设备的时长均不大于对应的设定值，从而可以通过负载均衡的方式，减轻每一级唤醒模块的计算量，降低每一级唤醒模块的功耗，避免计算能力不足的问题。</li>
</ul>
<hr>
<blockquote>
<p>[好] &#x3D;&#x3D;CN111816165A-语音识别方法、装置及电子设备.pdf 声智科技 陈孝良 冯大航 郭震  2020&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>提出在不同的语言模型上进行两次解码，一个是命令词的语言模型，一个是通用数据语言模型，得到识别解码序列，根据解码分数，确定解码结果是来自哪个解码网络的结果；</li>
<li>提出识别模型训练方法，用要训练模型的预测概率向量和已训练模型的预测概率向量的KL散度，放进loss函数；</li>
</ul>
<blockquote>
<p>&#x3D;&#x3D;D1-CN112133294A-语音识别方法、装置和系统及存储介质-公开.PDF 标贝 王杰 李秀林 2020&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>不是直接用transformer的beam search输出作为识别结果，而是受语言模型限制，把语言模型构建wfst，用声学分数在里面搜索，才得到识别路径</li>
</ul>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词实验小结</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E5%AE%9E%E9%AA%8C%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<h1 id="命令词实验小结"><a href="#命令词实验小结" class="headerlink" title="命令词实验小结"></a>命令词实验小结</h1><p>总结训练的命令词模型实验</p>
<h2 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h2><p>两组训练数据：</p>
<ol>
<li>负样本4000小时（370万），正样本550小时（92万条），正负时长比例1：7，正负数量比例1：4</li>
<li>负样本12000小时（1111万条），正样本2000小时（380万条），正负时长比例1：6，正负数量比例1：3</li>
</ol>
<p>模型类似时（tdnn、5layer、256结点，左27右27拼帧、LF-MMI、1M参数）：</p>
<ol>
<li>训练数据1结果：<ul>
<li>小源recall：70.5%（split1，1.2w）；far：0.0504%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）；</li>
<li>多命令词recall：75.98%（test1w，1w），far：0.9335%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）（左13右9模型）</li>
</ul>
</li>
<li>训练数据2结果：<ul>
<li>小源recall：70.7%（split1，1.2w）；far：0.0279%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）；（但在其他测试集far比1高）</li>
<li>多命令词recall：73.60%（test1w，1w），far：0.6293%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）</li>
<li>该结果是调节解码网络HCLG中G的权重，平衡recall和far后的结果，再提高recall会造成far显著提高，设置recall与1相同时，far略高于1的结果。</li>
</ul>
</li>
</ol>
<p>实验结果表明：</p>
<ol>
<li>4000小时数据，对于tdnn、音素或音节建模，分类数800-1000，1M参数量，足够建模，每个分类建模单元（pdf）平均分到4-5小时，完全足够建模（只算类别不够，还要具体算到模型的每个<strong>参数</strong>有多少时长&#x2F;帧数&#x2F;样本），4000小时包含了足够的样本丰富性，对正样本的增广（速度扰动、用更多加噪的正样本数据（原先是从加噪数据抽样）），没有带来提升。</li>
<li><strong>正负样本时长或数量比例影响到最终的识别率和误识别率，时长比例应不低于1：7，从而保证高识别率和低误识别率。</strong></li>
</ol>
<h2 id="建模单元"><a href="#建模单元" class="headerlink" title="建模单元"></a>建模单元</h2><p>两组建模单元：</p>
<ol>
<li>音素（67个音素，1000个状态），2音素建模（聚类到1000个pdf）</li>
<li>音节（405个音节，808状态），单音素建模（每个音素对应2个pdf）</li>
</ol>
<p>模型类似时（tdnn、5layer、256结点、LF-MMI、1M参数），1实验结果略优于2（差不多、略优于）</p>
<p>实验结果表明：</p>
<ol start="0">
<li><p>雷博说：对于多命令词来说：&#x3D;&#x3D;分类数与识别效果的关系&#x3D;&#x3D;：先增加后平稳后减少，一开始随着分类数的增加，是会改善效果的，随着分类数的继续增加，改善效果提升变得缓慢（雷博做实验，134类（67*2）与1000分类效果很接近，略差一点点），然后分类数越来越多，到几千后，可能由于分配到每个类别的特征少了，再加上分类数目太大，效果会降低。</p>
</li>
<li><p>对于该模型结构来说，说明该模型结果对于音节为建模单元就有点吃力了，因此对于越简单的模型，建模单元应该越小，减少模型的压力</p>
</li>
<li><p><strong>实验结果与分类数有关，分类数为800或1000时，无论建模单元是音素或音节，结果比较接近</strong></p>
</li>
</ol>
<p>[TODO]：</p>
<ol>
<li>增加建模单元状态数，训练模型</li>
</ol>
<h2 id="声学模型"><a href="#声学模型" class="headerlink" title="声学模型"></a>声学模型</h2><h3 id="Chain-model"><a href="#Chain-model" class="headerlink" title="Chain model"></a>Chain model</h3><p>两组模型：</p>
<ol>
<li>tdnn、5layer、256结点、左27右27拼帧、LF-MMI、1M参数、808分类数、前向real-time factor assuming 100 frames&#x2F;sec is  0.00387631</li>
<li>tdnnf、8layer，432_48结点、左27右27拼帧、LF-MMI、800K参数、808分类数、前向real-time factor assuming 100 frames&#x2F;sec is 0.00430389</li>
</ol>
<p>模型实验结果（挑选的最好模型）：</p>
<ol>
<li>模型1结果：<ul>
<li>小源recall：70.0%（split1，1.2w）；far：0.025%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）；</li>
<li>多命令词recall：73.91%（test1w，1w），far：0.6108%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）</li>
</ul>
</li>
<li>模型2结果：<ul>
<li>小源recall：70.5%（split1，1.2w）；far：0.012%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）；</li>
<li>多命令词recall：73.12%（test1w，1w），far：0.5783%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）</li>
</ul>
</li>
</ol>
<p>实验结果表明：</p>
<ol>
<li>前向时间完全相同的模型，tdnnf声学模型比tdnn差（未展示），因此在很小模型的要求下，用tdnn优于tdnnf</li>
<li>tdnnf前向时间略高于tdnn的声学模型下，tdnnf的建模能力高于tdnn，说明加深一定的网络层数会带来提升，使得声学模型建模能力提升。</li>
<li>tdnnf的小源小源单唤醒词基本达到要求，在唤醒词后接命令词的系统中，该模型可以使用。</li>
</ol>
<h3 id="Chain-model-和-CE-model"><a href="#Chain-model-和-CE-model" class="headerlink" title="Chain model 和 CE model"></a>Chain model 和 CE model</h3><p>两组模型：</p>
<ol>
<li>tdnn、5layer、256结点、左27右27拼帧、LF-MMI准则、1M参数、808分类</li>
<li>tdnn、5layer、256结点、左39右27拼帧、CE准则、1M参数、67分类</li>
</ol>
<p>模型实验结果（挑选的最好模型）：</p>
<ol>
<li>模型1结果：<ul>
<li>小源recall：70.0%（split1，1.2w）；far：0.025%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）；</li>
<li>多命令词recall：73.91%（test1w，1w），far：0.6108%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）</li>
</ul>
</li>
<li>模型2结果：<ul>
<li>小源recall：77.1%（split1，1.2w）；far：0.0172%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）；</li>
<li>多命令词recall：76.8%（test1w，1w），far：0.227%（测试集 train_rp_320_2pairs_n_kVeryHigh，48w）</li>
</ul>
</li>
</ol>
<p>实验结果表明：</p>
<ol>
<li>CE模型在测试集上优于Chain模型，但是实测下没有达到，因为把语言模型权重调的很大，解码路径需要改动等等？</li>
<li>CE模型的G.fst的权重需要精细调节</li>
</ol>
<h3 id="Alignemnt-Free-LF-MMI和-LF-MMI"><a href="#Alignemnt-Free-LF-MMI和-LF-MMI" class="headerlink" title="Alignemnt-Free LF-MMI和 LF-MMI"></a>Alignemnt-Free LF-MMI和 LF-MMI</h3><p>Alignment-Free当模型为tdnnf，13layer，80_20，参数量100K，状态数30时，很容易过拟合，说明模型太小时，不具备大建模单元（一个词用4状态表示）的建模能力；</p>
<p>​           </p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><ol>
<li>epoch&#x3D;4时，loss收敛了，变化小于0.01，但是当多训练一轮（epoch&#x3D;5）时，效果有提升，再多训epoch，效果会下降，因此可以多设置epoch，选取不同的中间模型进行测试，从测试结果选出最好的模型</li>
<li>训好的模型，解码训练集，赋予该false alarm和false rejection样本更大的权重，对所有样本，用小学习率多训一轮，对于tdnn的其他命令词提升，由于false alarm和false rejection里唤醒词数据不多，反而造成唤醒词的效果有略微的下降，对于tdnnf未提升，因此赋予不同权重只有很小的提升，并且要保证数据比例（1.正负样本比例；2.正样本中唤醒词和命令词的比例）</li>
<li>训好的模型，解码训练集，对false alarm和false rejection样本在保证正负样本比例前提下多训练一轮，效果比单纯多训练一轮来得差，很容易训练偏</li>
<li><strong>训练分母的phone lm从4gram到2gram，效果会提升，并且训练速度更快</strong>，训练中复杂的语言模型反而没有带来收益，推测原因：<ul>
<li>1.简单的语言模型能让声学模型得到的信息更少，加重了声学模型的训练难度，使得声学模型训练得更不容易过拟合；</li>
<li>2.复杂的语言模型（适配训练集的语言模型）使得声学模型更容易过拟合；</li>
<li>3.训练中简单的语言模型与测试的1gram语言模型更接近；</li>
</ul>
</li>
</ol>
<h2 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h2><ol>
<li>下图G.fst能降低误唤醒，实测也会降低当周围嘈杂时（触发VAD)时的唤醒率，实际不可用</li>
</ol>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E5%AE%9E%E9%AA%8C%E5%B0%8F%E7%BB%93/image-20211221170840524.png" alt="image-20211221170840524"></p>
<p>·</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（七）loss改进用命令词的论文</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89/</url>
    <content><![CDATA[<h1 id="loss改进用命令词的论文"><a href="#loss改进用命令词的论文" class="headerlink" title="loss改进用命令词的论文"></a>loss改进用命令词的论文</h1><blockquote>
<p>&#x3D;&#x3D;Yandong Wen, Kaipeng Zhang, Zhifeng Li and Yu Qiao. “A Discriminative Feature Learning Approach for Deep Face Recognition” European Conference on Computer Vision (2016)..&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>提出 <strong>center loss</strong>，目的是让相同类的特征表示尽可能相近（附带的效果：相似音是不同的类，该方法可以拉开二者距离，相当于&#x3D;&#x3D;区分了相似音&#x3D;&#x3D;）</li>
<li>学习每个类的deep feature的center，将输入特征的deep feature到该类中心的距离引入loss中，让类内intra-class距离小（类内方差小），目的是最小化类内距离</li>
<li>怎么让类间距离大？</li>
<li>Discriminative power characterizes features in both the compact intra-class variations and separable inter-class differences,</li>
<li>center loss：$\large{L_c&#x3D;\frac{1}{2}\sum^m_{i&#x3D;1}\Vert x_i-c_{yi}\Vert_2^2}$，           （L2范数，平方距离：$\Vert x \Vert_2&#x3D;(\vert x_1\vert^2+\vert x_2\vert^2+…+\vert x_n\vert^2)^{1&#x2F;2}$ ，所以$\Vert x \Vert_{2}^2&#x3D;(\vert x_1\vert^2+\vert x_2\vert^2+…+\vert x_n\vert^2)$ ））<ul>
<li>这里的x一般是最后一层线性层之前的输入特征，比如32维，而输出一共有10个类，所以c的维度是10*32</li>
</ul>
</li>
<li>center $c_{yi}$ 值：在每个minibatch里，$L_c$ 对样本特征求导，累计和，乘以&#x3D;&#x3D;学习率$\alpha$&#x3D;&#x3D;，来更新center值（不是用平均每类的样本特征而来）（其实不用真的是特征中心点，因为目的是不同x到某点的距离最短，这个点并不重要）【改进：不同类中心的距离越大越好，也加入loss，否则不同类之间的c都很接近的话，特征还是分不开？】</li>
<li>$\lambda$​：系数，用来平衡两个loss，主导了类内方差；</li>
<li>$\alpha$：center loss更新center值的学习率；（决定center的参数变化量）（center loss里的参数就是指的类中心特征值）</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89/image-20211206160520204.png" alt="image-20211206160520204" style="zoom: 67%;">

<p>（$\theta_C$的C是卷积，不是类中心c）</p>
<ul>
<li>调参：</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89/image-20220330165802859.png" alt="image-20220330165802859" style="zoom:67%;">

<hr>
<blockquote>
<p>&#x3D;&#x3D;Hadsell, R., Chopra, S., LeCun, Y.: Dimensionality reduction by learning an invariant mapping. In: 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, vol. 2, pp. 1735–1742. IEEE (2006)&#x3D;&#x3D;</p>
<p>&#x3D;&#x3D;Sun, Y., Chen, Y., Wang, X., Tang, X.: Deep learning face representation by joint identification-verification. In: Advances in Neural Information Processing Systems, pp. 1988–1996 (2014)&#x3D;&#x3D;</p>
<p>&#x3D;&#x3D;Wen, Y., Li, Z., Qiao, Y.: Latent factor guided convolutional neural networks for age-invariant face recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4893–4901 (2016)&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>提出 <strong>contrastive loss</strong>  </li>
<li>把图像对（image pair）引入loss</li>
<li>缺点：样本一多，收敛慢 ，不稳定，可通过精细选择image pairs来缓解</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Schroff, F., Kalenichenko, D., Philbin, J.: Facenet: a unified embedding for face recognition and clustering. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 815–823 (2015)&#x3D;&#x3D;  </p>
<p><a href="https://omoindrot.github.io/triplet-loss#batch-hard-strategy">https://omoindrot.github.io/triplet-loss#batch-hard-strategy</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/35560666">https://zhuanlan.zhihu.com/p/35560666</a></p>
<p>pytorch实现了：<a href="https://pytorch.org/docs/1.9.1/generated/torch.nn.TripletMarginLoss.html?highlight=tripletmarginloss%EF%BC%8C%E4%BD%86%E8%A6%81%E5%9C%A8dataloader%E9%87%8C%E7%BB%99%E5%AE%9A%E4%B8%89%E5%85%83%E7%BB%84">https://pytorch.org/docs/1.9.1/generated/torch.nn.TripletMarginLoss.html?highlight=tripletmarginloss，但要在dataloader里给定三元组</a></p>
<p>github：<a href="https://github.com/Cysu/open-reid/tree/master/reid/loss">https://github.com/Cysu/open-reid/tree/master/reid/loss</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/171627918">triplet loss 损失函数</a></p>
<p><a href="https://bindog.github.io/blog/2019/10/23/why-triplet-loss-works/">https://bindog.github.io/blog/2019/10/23/why-triplet-loss-works/</a></p>
<p>github人脸检测：<a href="https://github.com/kuaikuaikim/DFace">https://github.com/kuaikuaikim/DFace</a></p>
<p>facenet：<a href="https://github.com/davidsandberg/facenet">https://github.com/davidsandberg/facenet</a></p>
<p><a href="https://github.com/timesler/facenet-pytorch">https://github.com/timesler/facenet-pytorch</a></p>
</blockquote>
<ul>
<li>提出 <strong>triplet loss</strong>，最小化batch内同类特征embedding $f(x)$ 距离，最大化batch内不同类特征embedding距离</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89/image-20220413140757363.png" alt="image-20220413140757363" style="zoom: 80%;">

<ul>
<li><p>约束条件：$\large \Vert f(x_i^a)-f(x_i^p)\Vert_2^2 + \alpha &lt; \Vert f(x_i^a)-f(x_i^n)\Vert_2^2$  ，当$\large \forall(f(x_i^a),f(x_i^p),f(x_i^n))\in T $， 其中，$T$是三元组triplet</p>
</li>
<li><p>Loss fucntion为：$\large min L&#x3D;\sum\limits_i ^N \left[\Vert f(x_i^a)-f(x_i^p)\Vert_2^2 - \Vert f(x_i^a)-f(x_i^n)\Vert_2^2 + \alpha \right]$</p>
<p>更常用的loss是结合$max(0,d(a,p) - d(a,n) + margin)$</p>
<p>其中，$f(x)$ 为d维embedding特征</p>
<p>这个loss对于当前anchor特征，一个minibatch中p特征数量和n特征数量可能分布很不均，因此用求与p特征的argmax，与n特征的argmin，就只统计和一个同类距离和一个不同类距离作为loss，</p>
<p>维度d，所有维度都计算距离然后求和了（欧式距离）</p>
<p>但是这样会训练loss越训练，最后变成都在margin附近。。。no good</p>
</li>
<li><p>因此，不是用hardest positive，而是用所有的anchor-positive pair来算loss，anchor-negative还是用的hard negative</p>
</li>
<li><p>把图像三个一组（image triplet）引入loss，但这样收敛慢，对三元组triplet要求高</p>
</li>
<li><p>缺点：样本一多，收敛慢 ，不稳定，可通过精细选择image triplets来缓解</p>
</li>
<li><p>triplet loss里的anchor和目标检测的anchor不一样，是基于人脸识别提出的，是每个输入样本（叫做anchor）提一个embedding，和其他同类样本的embedding距离近，和不同类样本的embedding距离远作为loss（ps. 目标检测的anchor，一个图片N个anchor，理解为扫描图片，用很多框框去扫描 遍历）</p>
</li>
<li><p>Triplet Selection 来加速训练收敛：加快收敛的秘诀：找到不满足约束（难训）的triplet来训练；和同类的最远距离 与 和不同类的最近距离 如果很接近的话，说明是难训样本；两种方法来构造难训样本：</p>
<ol>
<li>在每个step中offline离线产生triplet三元组，用同一个模型计算argmax同类和argmin不同类距离</li>
<li>在每个minibatch中online在线产生triplet</li>
</ol>
</li>
<li><p>easy triplets、hard triplets、semi-hard triplets：</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89/image-20220414095451899.png" alt="image-20220414095451899" style="zoom:80%;">

<ul>
<li><p>在triplet loss基础上，又衍生出了其他许多改进和变体，例如一个比较有效的方法叫hard mining，在三元组选择过程中加入一些特定的策略，尽量选择一些距离Anchor较远的Positive和距离Anchor较近的Negative（也就是最不像的同类样本、最像的不同类样本）……此类方法还有许多，就不一一列举了。</p>
</li>
<li><p>triplet loss虽然有效，但是其常为人诟病的缺点也很明显：训练过程不稳定，收敛慢，需要极大的耐心去调参……所以在很多情况下，我们不会单独使用triplet loss，而是将其与softmax loss等方法相结合使用，以稳定训练过程。</p>
</li>
<li><p>在特征embedding后接L2正则得到新的embedding特征：</p>
<p>特征v，有$\large v&#x3D;\frac{v}{max(\Vert v\Vert_2,\epsilon)}$</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89/image-20220415114057425.png" alt="image-20220415114057425" style="zoom:80%;">

<h2 id="hinge-loss"><a href="#hinge-loss" class="headerlink" title="hinge loss"></a>hinge loss</h2><p>$\large d_i \in \mathbb R^{T\times f}$</p>
<p>$\large d_o \in \mathbb R^{N1+N2}$</p>
<p>$\large I \in \mathbb R^{n\times n}$</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（一）基于隐马尔可夫模型的补白模型</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="基于隐马尔可夫模型的补白模型"><a href="#基于隐马尔可夫模型的补白模型" class="headerlink" title="基于隐马尔可夫模型的补白模型"></a>基于隐马尔可夫模型的补白模型</h1><blockquote>
<p>Wilpon JG, Lee C, Rabiner L R, et al. <a href="https://web.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/application%20of%20hmm%20for%20limited%20word%20recognition.pdf">Application of hidden Markov models for recognition of a limited set of words in unconstrained speech</a>[C]. internationalconference on acoustics, speech, and signal processing, 1989: 254-257.</p>
</blockquote>
<p>《用HMM在无约束的语音中识别有限集合里的词》</p>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><p>无约束 指的是适用于一段说话语音（words embedded in speech）中 识别出关键词（之前的孤立词识别更适用于单独说出关键词，而说话语音中效果不好）</p>
<p>训练关键词的HMM model，输入一段语音找最优路径，看出来什么样的状态序列，根据序列里的状态确定有没有关键词。</p>
<p>还有个后处理过程 Postprocessor，因为最优路径还不能确定是不是关键词，还要经过后处理进一步判断。</p>
<p>在起止时间(i,j)内 ，算两个特征：</p>
<ul>
<li><p>特征1：average model likelihood:  $p(i,j)&#x3D;\frac{1}{j-i+1}\sum\limits_{k&#x3D;i}^j{m_p(k)}$</p>
<p>把最优路径的i，j起止时间内的似然分求平均</p>
</li>
<li><p>特征2：average state likelihood:  $s(i,j)&#x3D;\frac{1}{N}\sum\limits_{n&#x3D;1}^N{s_p(n)}$</p>
<p>某个model有N个状态，把其中每个状态在i，j起止时间内的的平均似然求和再求平均，得到这个model的s</p>
</li>
</ul>
<p>后处理判断准则：</p>
<ul>
<li>候选词的状态持续时间要大于一个阈值</li>
<li>能量大于一个阈值</li>
<li>average model likelihood 大于一个阈值</li>
<li>p&#x2F;s在一个范围内</li>
</ul>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>训练关键词hmm model过程：用word建模，用孤立词数据训练，但是这样不够，没有考虑到协同发音，因此把连续语音的关键词位置，切出来，再训练关键词的hmm model。</p>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>75000句子中，有关键词的有7981句</p>
<hr>
<blockquote>
<p>Sun M, Snyder D, Gao Y, et al. <a href="http://g-ecx.images-amazon.com/images/G/01/amazon.jobs/Interspeech_2017_4._CB503635227_.pdf">Compressed Time Delay Neural Network for Small-Footprint Keyword Spotting</a>.[C]. conference of the international speech communication association, 2017: 3607-3611.</p>
</blockquote>
<p>《用于低功耗命令词识别的压缩的时延神经网络》</p>
<h4 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h4><p>用DNN-HMM，当最优路径是唤醒词时，判断唤醒词路径的似然概率，比上filler路径的似然概率，是否大于一个阈值；</p>
<p>要满足低功耗，对模型做了改进：</p>
<ul>
<li>下采样，输入不是取一个集合比如[-2,2]（共五帧），而是下采样，取离散值，比如{-2,2}，只取左二帧和右二帧（共两帧）</li>
<li>SVD分解（体现在bottleneck层）</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/image-20210527144626557-1622098046854.png" alt="image-20210527144626557"></p>
<p>这是一个HMM model<br>建模单元是一个word（alexa）<br>这个word用多个phone组成<br>里面每个phone由三状态HMM的构成</p>
<p>不是对word去建一个模，而是通过G.fst&#x2F;L.fst来限制最后的hclg路径。</p>
<p>O—AX:ALEXA—O—L:ϵ—O—EH:ϵ—O—</p>
<p>走一遍，当最优路径是唤醒词时，拿出最优路径和次优路径<br>最优路径，这里就是指的时维特比解码，走到某个关键词节点最优；次优路径，指的是走到非关键词的最优</p>
<p>下采样：</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/image-20210527144643186.png" alt="image-20210527144643186"></p>
<h4 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h4><p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/image-20210527153439205.png" alt="image-20210527153439205"></p>
<p>训练模型用了很多技巧</p>
<ul>
<li>transfer learning 迁移学习：用训练好的语音识别声学模型，作为命令词声学模型的初始模型；</li>
<li>multi-task learning 多任务学习：训练命令词任务，辅助训练识别任务，最后把识别那部分移除；<ul>
<li>loss function：$L_t&#x3D;\lambda{L_t^1}+(1-\lambda){L_t^2}$，权重因子主任务命令词&#x3D;0.9，辅助任务语音识别&#x3D;0.1</li>
</ul>
</li>
<li>SVD Approximation ：为了用SVD近似训练TDNN，我们首先训练一个更大尺寸的全秩TDNN。然后，我们将全秩仿射矩阵的SVD初始化的线性瓶颈层添加到TDNN中，从输入层开始，每次一层。每加一个bottleneck层，就要训练一轮epoch</li>
</ul>
<h5 id="训练流程："><a href="#训练流程：" class="headerlink" title="训练流程："></a>训练流程：</h5><ol>
<li>训练一个全秩LVCSR TDNN、结构和全秩命令词TDNN一样，识别模型用于TDNN初始化；</li>
<li>在步骤1的网络结构上添加一层分开的隐藏层，一部分给命令词任务，一部分给识别任务，再一层输出层；$output_1&#x3D;y<em>w_1$，$output_2&#x3D;y</em>w_2$；</li>
<li>训练步骤2的网络结果，多任务学习，loss是二者加权结合；</li>
<li>训练一些轮epoch后，添加线性bottleneck层。这些bottleneck层神经元参数的初始化来源于满秩矩阵的SVD分解；</li>
<li>每次加一个bottleneck层，就要训练一轮，然后固定了模型结构后，还要接着训练一些轮epoch；</li>
<li>移除识别任务的隐藏层，只留下命令词任务的模型结构；</li>
</ol>
<h4 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h4><p>激活函数用sigmoid，每轮epoch学习率衰减；</p>
<p>训练20个epoch，SVD还要训练20个epoch；</p>
<p>这篇论文核心是提出一个效果好的模型，由于没有统一公开的测试集，要怎么证明模型效果好呢？通过和其他模型进行对比就可以。相对的。</p>
<p>TDNN SVD 对比 DNN SVD；对比 TDNN no SVD；保证三个模型参数量差不多。</p>
<hr>
<h1 id="Non-HMM-based-KWS"><a href="#Non-HMM-based-KWS" class="headerlink" title="Non-HMM based KWS"></a>Non-HMM based KWS</h1><p>DNN based filler models</p>
<p>另一种基于神经网络分类的方法就更加直接了，如下图所示，连续语音流<strong>逐段</strong>地送入神经网络进行分类。类别为所有的关键词，和一个额外的填充类别（Filler），比如有10个关键词，就有11类。</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/image-20210518105156830-1622101953221.png" alt="image-20210518105156830"></p>
<p>分类完成后，由于输出的概率可能出现“毛刺”，所以进行平滑后处理，之后如果某一个类别概率超过一个阈值，就认为某一个关键词被检测到了。这种方法内存占用小，不需要解码搜索，准确率高。但是由于需要准备大量包含关键词的语料，如果更换了关键词，则需要再另行搜集一批语料，所以也较难实际使用。相比之下，基于隐马尔可夫模型的Keyword Spotting由于是针对子词单元建模，语料用通用的就可以，所以更常用。</p>
<p>（一段语音一段语音地送入DNN，得到这一段语音，比如100帧的100个输出，每个输出有11分类的概率，平滑一下，看看关键词分类的概率是否高过阈值，判断关键词是否被检测到–yl）</p>
<ul>
<li>DNN is used as a framewisely classifier.</li>
<li>Then the posteriors are smoothed with a window.</li>
<li>The system is used in mobile devices.</li>
</ul>
<blockquote>
<p>Chen G, Parada C, Heigold G, et al. Small-footprint keyword spotting using deep neural networks[C]. international conference on acoustics, speech, and signal processing, 2014: 4087-4091.</p>
</blockquote>
<h4 id="思想-2"><a href="#思想-2" class="headerlink" title="思想"></a>思想</h4><ul>
<li>Deep KWS：没有走HMM（生成出state序列，state映射为keyword phone&#x2F;sutrbword，再viterbi解码找最优路径）的方法，而根据一段时间窗口内的DNN输出，根据DNN输出后验概率得到置信度分数confidence score，与阈值比较，判断是否有keyword；</li>
<li>dnn输入时会拼帧，类似TDNN，输入是一个拼帧的向量（左10帧右30帧），一帧对应一个label，输出label只有 n个keyword + non-keyword；每帧都会有一个标签，（一个输入对应一个输出，所以并不是一个多帧输入对应一个输出的问题）</li>
<li>loss function：$\large F(\theta)&#x3D;\sum_j{logp_{i_jj}}$，j是第j帧，i是第i个label</li>
<li>Posterior smoothing：平滑后的概率 $\large p(i,j)&#x3D;\frac{1}{j-h_{smooth}+1}\sum\limits_{k&#x3D;h_{smooth}}^j{p_{ik}}$<ul>
<li>$\large h_{smooth}&#x3D;max{1,j-w_{smooth}+1}$</li>
</ul>
</li>
<li>Confidence 置信度 $\large confidence&#x3D;\sqrt[n-1]{\prod\limits_{i&#x3D;1}^{n-1}\max\limits_{h_{max}\le{k}\le{j}}{p’_{ik}}}$</li>
<li>把类别乘起来，看看命令词的概率有多大，但这样比如说OKOK，或者GOOGLE GOOGLE，没办法区分的</li>
</ul>
<h4 id="训练-2"><a href="#训练-2" class="headerlink" title="训练"></a>训练</h4><p>本文的Deep KWS方法如果用asr数据训出的asr模型，和KWS迁移学习训练，效果会比只用命令词数据训练KWS更好。</p>
<p>baseline（对比模型）采用的是HMM KWS model：</p>
<ul>
<li>基于HMM的不需要keyword的训练数据，用asr训好的，就能作为keyword用，通过解码限制L吧。</li>
<li>基于HMM的命令词模型的训练数据里，如果有命令词数据，效果会更好。</li>
</ul>
<h4 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h4><ul>
<li><p>测试时用了带噪语音测试</p>
</li>
<li><p>2.3K training examples for each keyword, and 133K negative examples, comprised of anonymized voice search queries or other short phrases.  </p>
</li>
<li><p>asr模型用3000 hours；</p>
</li>
</ul>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><blockquote>
<p>参考 书籍《Kaldi语音识别实战》P206</p>
</blockquote>
<ul>
<li>基于单音素建模对于一些唤醒词来说是比较重要的一个优化。</li>
<li>在原始论文中，神经网络的输出节点是以词为单位进行建模的，一个输出节点对应一个完整的词。对于“OK Google”这种每个词都包含几个音节的唤醒词来说是比较合适的，但是对于一些语言，如中文，就不是特别合适了。举例来说，一个汉字，如果不考虑音调的话，有可能对应非常多的其他汉字，因此在中文中以词或字为建模单元，比较容易造成误唤醒。对于&#x3D;&#x3D;中文&#x3D;&#x3D;这样的语言，可以采用&#x3D;&#x3D;单音子为建模单元，效果往往会比以字或词为建模单元更优&#x3D;&#x3D;。建模单元的选择往往取决于具体的唤醒词，对于特定的唤醒词，读者也应该尽可能多地尝试不同的建模单元。<ul>
<li>雷博解释：因为“OK”、”Google”音素不重合，概率值是把平滑后”OK”的概率乘以平滑后”Google”的概率，但是中文音素容易重合，相乘的时候拿音素概率会拿到同一个。。？</li>
</ul>
</li>
<li>解码处理部分也是优化空间比较大的点。在原始论文中，笔者采用对神经网络输出节点对应后验概率取最大值并做几何平均的方式来计算特定窗口中出现唤醒词的置信分数。对于“OKGoogle”这种只有两个词，并且以整词为建模单元的唤醒词来说，这样的处理方式是合理的，但是对于中文唤醒词，如果以单音素作为建模单元，则&#x3D;&#x3D;一个唤醒词中的不同地方可能出现相同的音素&#x3D;&#x3D;，原始论文中的解码处理方法就不太适用了。这种情况下，&#x3D;&#x3D;我们依然可以采用滑动窗口的处理方式，但是需要利用维特比算法(ViterbiAlgorithm)求解窗口中的最佳路径，并计算最佳路径对应的置信分数&#x3D;&#x3D;。读者也可以尝试完全抛弃滑动窗口的处理方式，采用其他更复杂的解码处理方法。</li>
<li>对于语音唤醒应用来说，误唤醒是非常重要的一个指标，过高的误唤醒会直接影响用户体验，甚至可能导致用户停止使用整个语音功能。为了压制误唤醒，可以采用二阶段唤醒的框架。二阶段唤醒又分为云端二阶段唤醒和设备端二阶段唤醒。云端二阶段唤醒的实现比较简单,一般的做法是，设备端的第一阶段唤醒引擎被唤醒了之后，设备会把保存下来的唤醒词传输到云端，云端可以利用更加复杂的模型(比如语音识别模型)对上传过来的音频做二次确认，如果云端模型也判断为唤醒词，则认为真的出现唤醒词了。不足之处是，由于需要经过网络传输，唤醒词的确认过程会有一定的延时。设备端二阶段唤醒受制于设备端上有限的计算资源。往往不能采用像谱音识别这样的复杂模型来进行二次验证。</li>
<li>通用的做法是训练一个简单的基于逻辑回归或神经网络的分类器。从第一阶段唤醒引擎中，我们可以提取诸如置信分数、延时、时长等一系列的信息，这些信息可以作为第二阶段分类器的输入特征，训练分类器做出是否唤醒词的判断。二阶段唤醒可以极大地降低出现误唤醒的概率。值得一提的是，在二阶段框架中，训练数据的选择会变得非常重要。我们建议读者尽可能多地采集生活中可能出现的音频数据，用第一阶段引擎筛选出容易造成误唤醒的片段，然后针对性地训练第二阶段分类器来对误唤醒进行压制。</li>
<li>还有其他一些技巧也有助于唤醒引擎的优化，比如数据增强、尝试不同的神经网络模型结构、神经网络模型压缩等，本节不再一一展开介绍。</li>
</ul>
<hr>
<blockquote>
<p> Wu M, Panchapagesan S, Sun M, et al. Monophone-based background modeling for two-stage on-device wake word detection[C]&#x2F;&#x2F;2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 5494-5498.</p>
</blockquote>
<h4 id="思想-3"><a href="#思想-3" class="headerlink" title="思想"></a>思想</h4><ol>
<li>two stage，用命令词模型的DNN输出，提取67维特征，作为二级DNN的输入</li>
<li>把filler model不是简单的用non speech和非命令词speech训练，而是把每个音素也作为分类label，使得filler model数量变多，命令词模型的DNN输出提取的不止67维，更高维，作为二级DNN输入，也就是说filler model分类变多，命令词的label类别变多，效果反而会提升。</li>
</ol>
<hr>
<blockquote>
<p>He Y, Prabhavalkar R, Rao K, et al. Streaming small-footprint keyword spotting using sequence-to-sequence models[C]&#x2F;&#x2F;Automatic Speech Recognition and Understanding Workshop (ASRU), 2017IEEE.</p>
</blockquote>
<ul>
<li><input disabled type="checkbox"> </li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Bai Y, Yi J, Ni H, et al. End-to-end keywords spotting based on connectionist temporal classification for mandarin[C]&#x2F;&#x2F;2016 10th International Symposium on Chinese Spoken Language Processing (ISCSLP). IEEE, 2016: 1-5.&#x3D;&#x3D;</p>
</blockquote>
<h4 id="思想-4"><a href="#思想-4" class="headerlink" title="思想"></a>思想</h4><ul>
<li>用 LVCSR 做kws</li>
<li>用CTC代替DNN-HMM</li>
<li>用 timed factor transducer 进行decode</li>
</ul>
<h4 id="实验-3"><a href="#实验-3" class="headerlink" title="实验"></a>实验</h4><ul>
<li><p>用 EESEN 框架训练 ctc model</p>
</li>
<li><p>CTC建模单元mandarin syllable</p>
</li>
<li><p>CTC输入特征 MFCC 优于 FBank</p>
</li>
</ul>
<hr>
<p>ps.雷博：走fst不用限制时长（比如固定1s、2s），可以一直走很长fst，直到有命令词。</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（三）命令词中文论文</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="命令词中文论文"><a href="#命令词中文论文" class="headerlink" title="命令词中文论文"></a>命令词中文论文</h1><blockquote>
<p>&#x3D;&#x3D;车载噪声环境下的语音命令词识别的仿真研究 涂志强 华南理工大学 2018&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>和上一篇“基于深度学习的唤醒词识别方法研究 郭瑜 2019 大连理工大学”，思想基本一致，数据集也都相同，都用的 tensorflow 1s speech_commands 数据集</li>
<li>探索了降噪模型和识别模型结合的效果，加入降噪模型在训练识别模型可以提升1%的识别效果</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;基于深度学习的语音唤醒研究及其应用 刘凯 2018 厦门大学 硕士论文&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>deep kws 置信度计算方法：</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210618171112653.png" alt="image-20210618171112653"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210618171128265.png" alt="image-20210618171128265"></p>
<hr>
<blockquote>
<p> &#x3D;&#x3D;基于深度学习的唤醒词识别方法研究 郭瑜 2019 大连理工大学&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>基于tensorflow开发，使用python库中的提供自动语音识别功能的 Python-Speech-Features 包，用于实时录音的Py Audio 包；</li>
<li>输入一段语音，输出标签概率（many to one），概率高于阈值，则唤醒；</li>
<li>基于注意力机制的唤醒：（很奇怪c长度和帧长一致？要怎么做softmax？加权平均）</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210812164104515.png" alt="image-20210812164104515"></p>
<ul>
<li>比较了多种神经网络：</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210619105841352.png" alt="image-20210619105841352"></p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;噪声环境下的语音关键词检测_谷悦.caj 2019 内蒙古大学&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>语音增强和kws联合</li>
<li>CRN由于bLSTM，下一步计划引入resnet</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;深度学习的低延迟终端命令词识别系统设计与实现_轩晓光.caj 哈尔滨工业大学 2019&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>得到神经网络后验概率，不是像deep kws一样做smooth，而是用将每一帧语音最大概率对应的拼音提出，构成一个拼音序列，然后去掉重复部分，再与每一个命令词的真实拼音序列求编辑距离。（这样容易不准确吧），最小距离如果小于阈值则取最小距离对应的目标词。（感觉不是很靠谱，阈值是4？）</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;基于端到端的语音唤醒技术研究_张宁.2019 厦门大学 硕士论文&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>2017年，蚂蚁金服AI部门的Zhiming Wang等人充分利用连续语音识别的语料库中庞大的语料，将DNN和CTC结合进行端到端语音唤醒，解决了关键字特定数据较少的问题[53]。Small-footprint Keyword Spotting Using Deep Neural Network and Connectionist Temporal Classifier</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;基于LFMMI的两级唤醒词检测研究 陈凯斌 2020 华南理工大学 硕士论文&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>CNN-TDNNF结构</li>
<li>二级置信度评估</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;面向物端芯片的语音关键词识别技术_穆维林.caj 2020 中科院计算所&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>CNN-LSTM-Attention（value似乎是一维的，c是一维向量，做sigmoid，得到输出概率）</li>
<li>量化</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;语音唤醒技术在语音助手系统中的应用与实现_穆培婷.caj 2020 西安电子科技大学&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>Average  attention：在这种注意力方法中，没有需要训练的参数，αt就是时间 T的平均值，$\alpha_t&#x3D;\frac{1}{T}$</li>
<li>CNN-GRU-Attention，固定时间长度输入（1.9s）</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;基于深度学习的命令词识别方法研究_何琪琪.caj 大连理工大学 2020&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>这篇论文还不错！可以好好看看！试试方法！</li>
<li>基于 DSE-CNN 的命令词识别方法。Depthwise-Squeeze-Excitation(DSE)模块由深度可分离卷积与 Squeeze-and-Excitation (SE)  模块结合而成。</li>
<li>使用GhostNet 中的 <strong>Ghost</strong> 模块改进 MS 模块，以去除冗余操作、减少运算量，提出Ghost-Squeeze(GS)结构。</li>
<li>帧长、帧移对结果有一点影响</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210812173138904.png" alt="image-20210812173138904"></p>
<ul>
<li>实验结果：</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210812173250917.png" alt="image-20210812173250917"></p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;低内存低延迟的语音关键词检测算法研究_邹台 西安电子科技大学 2020&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li><p>提出时间关注（Time Attention Convolutional Recurrent Neural Net-works,TACRNN）的语音关键词检测模型 TACRNN，也就是CRNN加入attention</p>
</li>
<li><p>CRNN结构</p>
</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210812195432414.png" alt="image-20210812195432414"></p>
<ul>
<li><p>注意力机制中的 a 为对齐函数。对齐函数 a 主要有三种方式，分别为 dot、general、concat（参考了：Luong M T , Pham H , Manning C D . Effective Approaches to Attention-based Neural Machine Translation[J]. Computer ence, 2015）</p>
<ul>
<li>dot：$\large{a&#x3D;score(h_t,\overline{h}_s)&#x3D;h_t^T\overline{h}_s}$</li>
<li>general: $\large{a&#x3D;score(h_t,\overline{h}_s)&#x3D;h_t^TW_a\overline{h}_s}$</li>
<li>concat:$\large{a&#x3D;score(h_t,\overline{h}_s)&#x3D;v_a^Ttanh(W_a[h_t;\overline{h}_s])}$</li>
<li>soft attention：就是做softmax： $\large{\alpha^t&#x3D;\frac{exp(e_t)}{\sum_{j&#x3D;1}^{T_x}exp(e_j)}}$</li>
</ul>
</li>
<li><p>通过奇异值分解，压缩模型大小。奇异值分解可以将参数权重进行分解，之后截取重要成分，从而恢复原始的重要数据，降低数据参数。对于一个网络权重参数 W&#x3D;m* n，通过奇异值分解可得，对应的三个矩阵维度分别为 m* k，k* k，k* n；奇异值处理前后的参数量即为矩阵的大小，处理前的参数 P1&#x3D;m* n，处理后的参数 P2&#x3D;(m* k+k* k+k*n)，得到前后参数的比值为 $\large{\frac{P_1}{P_2}&#x3D;\frac{mn}{(m+n+k)k}}$</p>
</li>
<li><p>取秩大小 k&#x3D;2，分别对应语音关键词的时间维度和频率维度，对语音关键词检测网络进行压缩;（因为这里输入时间定长，比如100帧，频率维度固定，比如10，100* 10的输入，然后做SVD分解），（我们TDNN输入是250维，一帧一个输出）</p>
</li>
<li><p>只对时间域做卷积（其实就是TDNN）</p>
</li>
<li><p>总体结构：</p>
</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210813115523239.png" alt="image-20210813115523239"></p>
<ul>
<li>softmax出来是一个单词的后验，但是关键词一般是不止一个单词，因此做平滑处理，常规Deep KWS平滑后验 置信度得分，分数大于阈值才换唤醒；</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;冯大航–1023基于时间如何提升语音唤醒性能_v3.pptx&#x3D;&#x3D;</p>
</blockquote>
<ul>
<li>cnn-trad-fpool结构</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20210812175144817.png" alt="image-20210812175144817"></p>
<ul>
<li>唤醒是一个细活，唤醒数据录音永远是有限的，而且为了在低信噪比下可以唤醒，还需要扩充一些数据。最简单的数据扩充方法，麦克风时间延迟，房间冲击响应。在单麦和多麦的仿真方法还要考虑更多的空间信息。</li>
<li>上端解码大多的方法为后验概率平滑的方法和识别两条路径的分差</li>
<li>未来趋势<ul>
<li>模型压缩，小型化</li>
<li>云端的二次确认</li>
<li>前端阵列信号处理与唤醒的深度融合</li>
<li>尽可能少的唤醒词录音数据达到比较好的效果</li>
</ul>
</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;百度语音唤醒技术解析及实践.pdf 唐立亮&#x3D;&#x3D;</p>
</blockquote>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>基于置信度</td>
<td>构建唤醒识别网络，并通过某种信息等得到置信度，根据置信度是否大于指定门限来确定是否是唤醒；</td>
</tr>
<tr>
<td>基于识别的唤醒系统</td>
<td>利用一套语音识别系统进行识别，往往采用语言模型作为解码的网络,根据识别结果进行后处理匹配判断是否唤醒；</td>
</tr>
<tr>
<td>基于垃圾词网络</td>
<td>使用垃圾词网络进行唤醒，即选出一些垃圾词和唤醒词组成识别网络，得出最终的识别结果；</td>
</tr>
</tbody></table>
<ul>
<li>Wakeup Word Analysis、Garbage Phones Modification、Wakeup Dict Control、Wakeup Net Builder、Noise Suppression、Viterbi Decoder 、 DNN-HMM、FilterBank Feature Get、Voice Activity Detection、Automatic Gain Control、Confidence Decision、BigData Acoustic Model、Double Layer Decoder、Pyramid Acoustic Model、Short Word Acoustic Model  </li>
<li>唤醒正确率高 ：<ul>
<li>唤醒词解析+动态解码  </li>
<li>神经网络+大数据+CTC+短词优化  </li>
<li>噪声抑制+增益控制+声学模型匹配训练</li>
</ul>
</li>
<li>误报低  <ul>
<li>基于统计和规则的垃圾音素网络  </li>
<li>置信系统</li>
</ul>
</li>
<li>功耗低 省电  <ul>
<li>双层解码器+裁剪策略+解码器优化  </li>
<li>神经网络neon运算优化  </li>
<li>金字塔声学模型</li>
</ul>
</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Rybakov O, Kononenko N, Subrahmanya N, et al. Streaming keyword spotting on mobile devices[J]. arXiv preprint arXiv:2005.06720, 2020.&#x3D;&#x3D;谷歌 icassp2020</p>
</blockquote>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（九）Spoken Term Detection</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B9%9D%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Spoken-Term-Detection"><a href="#Spoken-Term-Detection" class="headerlink" title="Spoken Term Detection"></a>Spoken Term Detection</h1><blockquote>
<p><a href="https://kaldi-asr.org/doc/kws.html">Keyword Search in Kaldi</a></p>
<p>语音检索.md</p>
</blockquote>
<p>基于大词汇量连续语音识别系统的关键词检测主要是用于音频文档检索任务。首先使用语音识别系统将语音转化为某种形式的文本，然后建立索引，供用户索引。</p>
<p>与一般文本索引不同的是，语音关键词检索中的索引需要包含每一个<strong>词的时间</strong>位置信息（词的开始时间和结束时间），方便用户定位检索到词的位置。另外一点就是，语音识别结果可能包含一些错误，导致关键词不能找到，所以希望索引将语音识别出的次优候选结果也包含进来，提高检索的召回率。针对这两点的主要方法是，将语音识别出的词格（Lattice）建立为索引。词格是一种保存语音识别候选结果的紧凑形式，还可以包含时间位置信息。</p>
<h2 id="FT"><a href="#FT" class="headerlink" title="FT"></a>FT</h2><blockquote>
<p>&#x3D;&#x3D;Dogan Can and Murat Saraclar. “Lattice Indexing for Spoken Term Detection” IEEE Transactions on Audio, Speech, and Language Processing 19 (2011): 2338-2347.&#x3D;&#x3D;</p>
<p>jarvan wang 博客园 <a href="https://www.cnblogs.com/JarvanWang/p/9152660.html">Kaldi的关键词搜索（Keyword Search，KWS）</a></p>
</blockquote>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><ul>
<li>提出改进的因子转换器factor transducer，</li>
<li>这个因子转换器实际上是lattice中看到的所有单词序列的倒排索引</li>
<li>索引的对象分别有句子ID，开始时间，结束时间，分数</li>
<li>把时间信息放在output labels上</li>
</ul>
<p>本文为spoken term detection技术构建反向索引，具体的，在确定的WFST中存储软命中（soft-hit）信息（utterance-id, start time, end time, posterior score四元组，用于与目标词匹配）。展示了如何在多个Lattice中（多个语句中）生成所有子字符串的索引。  ASR候选解码结果通常储存在带权有向无环图——即lattices中。由于有限状态转换器框架提供了通用的搜索、优化、合并算法，通常使用有限状态转换器来表示ASR Lattice。对以WFST形式的lattice进行索引和搜索的问题，可以被看作是在文本文档中对模式进行搜索的扩展。搜索问题的有限解决办法使用了一种称为因子转换器的结构[12]。一个因子转换器是一个组成一篇文档的字符串集合中子字符串集合的倒排索引。因子转换器是一个非常有效的顺序索引，并且十分适用于需要确切序列匹配的话语检出应用。话语段和口语词检测是两种话语应用，分别用于找到语句以及包含查询词确切序列的语句中的时间间隔。</p>
<p>[TODO]：一些凸优化里面半群的相关公式，看不懂</p>
<h2 id="OOV"><a href="#OOV" class="headerlink" title="OOV"></a>OOV</h2><p>代理关键字是模糊搜索方法之一，用来处理OOV。</p>
<p>由于语音识别的结果都是在词表内的词，这样如果待查的关键词是集外词，就不可能被查找到了。然而，用户喜欢查找的，往往是人名、地名、组织机构名这样的命名实体，这些词往往都是集外词。解决这一问题的一个方法是代理词：即用一个发音相近的集内词作为待查集外词的“代理”，检索的时候查找“代理”，如果找到了代理，就认为待查的集外词找到了。</p>
<blockquote>
<p>&#x3D;&#x3D;Chen G, Yilmaz O, Trmal J, et al. Using proxies for OOV keywords in the keyword search task[C]. ieee automatic speechrecognition and understanding workshop, 2013: 416-421.&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><ul>
<li>之前处理oov的方法使用的是sub-word units的方法，找比如解码phone&#x2F;syllable序列，根据phone序列从而找到oov；</li>
<li>提出代理词proxy keywords，代理词是包含oov的集内词串，把oov事先标出其lexicon，然后根据其与其他已知lexicon的phone组成的编辑距离（作为边的cost？），构建WFST网路，然后在WFST里进行解码；比如，oov是balloon，集内词有samba、loon，当发音some balloon时，代理词是samba loon或者loon。</li>
<li>构建代理词WFST方法：$K’ &#x3D; Project(ShortestPath(K\circ{L_{2}}\circ{E}\circ({L^{*}_1})^{-1}))$<ul>
<li>K是oov keyword的FSA（G）</li>
<li>L2是oov keyword 的lexicon的FSA（L）</li>
<li>E是phone序列之间的编辑距离（wieght&#x2F;cost）</li>
<li>L1是LVCSR的lexicon（L）</li>
<li>K’是代理词的FSA</li>
</ul>
</li>
<li>oov 发音lexicon用G2P得到</li>
<li>边上权重来源：ASR解码序列与参考对齐序列比较，记下替换错误的后验概率，统计，得到每个音素与其他混淆音素的相似度，得到混淆矩阵E的FSA：</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B9%9D%EF%BC%89/image-20211224105441016.png" alt="image-20211224105441016" style="zoom:80%;">

<ul>
<li>优点：多OOV词下，可以并行查找这些OOV？</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Guoguo Chen et al. “Quantifying the value of pronunciation lexicons for keyword search in lowresource languages” International Conference on Acoustics, Speech, and Signal Processing (2013).&#x3D;&#x3D;</p>
<p>jarvan wang 博客园 <a href="https://www.cnblogs.com/JarvanWang/p/9152660.html">Kaldi的关键词搜索（Keyword Search，KWS）</a></p>
</blockquote>
<ul>
<li>KWS系统：根据[2]，为Lattice进行索引分为以下几步：</li>
</ul>
<ol>
<li>为测试集（eval, evalution，评估）中每一语句的有限状态转换器（FST）转换为（如何转换？）泛化因子转换器结构。该结构中，每个词的实例都拥有一个三元组（词的开始时间，词的结束时间，后验概率）。因子转换器，隐含了测试集中所有词序列的逆序（以后验概率排序）列表。可以使用Google OpenFST对其进行进一步的处理。</li>
<li>要在上述因子转换器中对某个词或短语进行检索，首先构建该词的有限状态机，然后与因子转换器进行组合（如何组合？），即得到了上述词的逆序列表。</li>
<li>使用[20]提出的方法，通过最大化所有关键词的期望词权重值（expected term weighted value，ETWV）（是啥？），估计一个决策阈值（如何估计），用于对各个结果作出Yes&#x2F;No的决策。</li>
<li>最后，所有关键词命中集合将通过NIST 2006 Spoken Term Detection评估协议计算实际词权重值（actual term weighted value）（如何计算）。</li>
</ol>
<p>某个关键词在测试集中的出现次数&#x3D;所有预测命中的后验概率。</p>
<ul>
<li><p>词典扩充对LVCSR和KWS的影响：提高发音词典词汇量，能提升1-4％的识别率，能提升KWS中实际的词加权值约60％的效果。在LVCSR阶段的词典扩充大大优于KWS阶段。</p>
<p>词典扩充只能适度降低WER，但是能很大程度地提高随后的ATWV。</p>
</li>
</ul>
<h3 id="TODO"><a href="#TODO" class="headerlink" title="[TODO]"></a>[TODO]</h3><p>这篇看得不是很明白</p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;语音关键词检测中的置信度研究_王朋.caj 解放军信息工程大学 2015 硕士论文&#x3D;&#x3D;</p>
</blockquote>
<h3 id="模糊匹配（早期处理OOV方法）"><a href="#模糊匹配（早期处理OOV方法）" class="headerlink" title="模糊匹配（早期处理OOV方法）"></a>模糊匹配（早期处理OOV方法）</h3><p>模糊匹配是一种常见的解决集外词问题方法，其主要应用声学信息，通过在连续语音识别结果中进行动态匹配，检测可能的集外词候选结果，并在匹配期间允许存在一定程度的音素替换、插入和删除错误。虽然该方法能够有效解决集外词召回率低的问题，但由于模糊匹配计算中的不精准性，也易导致部分集内词被误匹配为集外词，并产生集外词虚警 。</p>
<p>理解为：在允许的插入删除错误程度内，看匹配了吗</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（二）使用Google Speech Commands dataset的论文</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="使用Google-Speech-Commands-dataset的论文"><a href="#使用Google-Speech-Commands-dataset的论文" class="headerlink" title="使用Google Speech Commands dataset的论文"></a>使用Google Speech Commands dataset的论文</h1><ul>
<li>Google speech commands dataset：谷歌开源唤醒词数据集，有6万条，30个唤醒词，每条音频长度1s</li>
<li>Speech commands dataset v1  下载地址：<a href="http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz">http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz</a>  </li>
<li>Speech commands dataset v2  下载地址：<a href="http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz">http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz</a> 或 <a href="https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz">https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz</a></li>
<li>官方例子：<a href="https://www.tensorflow.org/tutorials/audio/simple_audio">https://www.tensorflow.org/tutorials/audio/simple_audio</a></li>
<li>输入t帧（其实就是1s），输出1个类别向量（每个类是一个关键词（yes、no、on、off……））</li>
</ul>
<h2 id="paper、code目录"><a href="#paper、code目录" class="headerlink" title="paper、code目录"></a>paper、code目录</h2><blockquote>
<p>Sainath, Tara N., and Carolina Parada. “Convolutional neural networks for small-footprint keyword spotting.” <em>Sixteenth Annual Conference of the International Speech Communication Association</em>. 2015</p>
<p>github开源代码：<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands</a></p>
</blockquote>
<blockquote>
<p>Choi S ,  Seo S ,  Shin B , et al. Temporal Convolution for Real-time Keyword Spotting on Mobile Devices[J].  2019</p>
<p>github开源代码：<a href="https://github.com/hyperconnect/TC-ResNet">https://github.com/hyperconnect/TC-ResNet</a></p>
</blockquote>
<blockquote>
<p>de Andrade, Douglas Coimbra, et al. “A neural attention model for speech command recognition.” <em>arXiv preprint arXiv:1808.08929</em> (2018).</p>
<p>github开源代码：<a href="https://github.com/douglas125/SpeechCmdRecognition">https://github.com/douglas125/SpeechCmdRecognition</a></p>
</blockquote>
<blockquote>
<p>Vygon, Roman, and Nikolay Mikhaylovskiy. “Learning efficient representations for keyword spotting with triplet loss.” <em>International Conference on Speech and Computer</em>. Springer, Cham, 2021</p>
<p>github：<a href="https://github.com/roman-vygon/triplet_loss_kws">Github: Learning Efficient Representations for Keyword Spotting with Triplet Loss</a> pytorch、nemo</p>
</blockquote>
<blockquote>
<p>Shan C, Zhang J, Wang Y, et al. Attention-based end-to-end models for small-footprint keyword spotting[J]. arXiv preprint arXiv:1803.10916, 2018.</p>
<p>github：<a href="https://github.com/isadrtdinov/kws-attention">https://github.com/isadrtdinov/kws-attention</a> 网友的复现代码</p>
<p>github：<a href="https://github.com/Kirili4ik/kws-attention-pytorch">https://github.com/Kirili4ik/kws-attention-pytorch</a> 网友的复现代码</p>
</blockquote>
<blockquote>
<p>D. Seo, H. -S. Oh and Y. Jung, “Wav2KWS: Transfer Learning From Speech Representations for Keyword Spotting,” in IEEE Access, vol. 9, pp. 80682-80691, 2021, doi: 10.1109&#x2F;ACCESS.2021.3078715.</p>
<p>github：<a href="https://github.com/qute012/Wav2Keyword">https://github.com/qute012/Wav2Keyword</a></p>
</blockquote>
<blockquote>
<p>Howl: A Deployed, Open-Source Wake Word Detection System</p>
<p>github：<a href="https://github.com/castorini/howl">https://github.com/castorini/howl</a> pytorch</p>
</blockquote>
<blockquote>
<p>BYOL for Audio: Self-Supervised Learning for General-Purpose Audio Representation</p>
<p>github：<a href="https://github.com/nttcslab/byol-a">https://github.com/nttcslab/byol-a</a> pytorch</p>
</blockquote>
<blockquote>
<p>Stochastic Adaptive Neural Architecture Search for Keyword Spotting</p>
<p>github：<a href="https://github.com/TomVeniat/SANAS">https://github.com/TomVeniat/SANAS</a> pytorch</p>
</blockquote>
<blockquote>
<p>Keyword Transformer: A Self-Attention Model for Keyword Spotting</p>
<p>github：<a href="https://github.com/ARM-software/keyword-transformer">https://github.com/ARM-software/keyword-transformer</a> tensorflow</p>
</blockquote>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Sainath, Tara N., and Carolina Parada. “Convolutional neural networks for small-footprint keyword spotting.” <em>Sixteenth Annual Conference of the International Speech Communication Association</em>. 2015. citation：383&#x3D;&#x3D; 谷歌的论文</p>
<p><a href="https://blog.csdn.net/jialilian5181/article/details/83787886">论文翻译：Convolutional Neural Networks for Small-footprint Keyword Spotting</a></p>
<p><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands">开源代码</a>，在TensorFlow官网可以下载</p>
</blockquote>
<ul>
<li>和Deep Kws做法一致，将DNN换成CNN</li>
<li>CNN输入：time*frequency，strides filters in frequency ，pools in time </li>
<li>尝试了不同下采样、pooling</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Shan C, Zhang J, Wang Y, et al. Attention-based end-to-end models for small-footprint keyword spotting[J]. arXiv preprint arXiv:1803.10916, 2018.&#x3D;&#x3D;</p>
<p>github：<a href="https://github.com/isadrtdinov/kws-attention">https://github.com/isadrtdinov/kws-attention</a> 网友的复现代码</p>
<p>github：<a href="https://github.com/Kirili4ik/kws-attention-pytorch">https://github.com/Kirili4ik/kws-attention-pytorch</a> 网友的复现代码</p>
</blockquote>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210820000810717.png" alt="image-20210820000810717"></p>
<ul>
<li>用attention机制的模型做命令词模型，没有事先训asr模型，输入T帧fbank语音特征，输出一个命令词概率，高于阈值就是命令词，是end2end，</li>
<li>用CRNN&#x2F;GRU做encoder，输入fbank feature，输出high level feature（效果CRNN&gt;GRU&gt;LSTM）</li>
<li>CRNN性能好，但是有1.5s延时，还是GRU更合适。</li>
<li>attention用soft attention和average attention（效果soft attention&gt;average attention）</li>
<li>减少计算量：滑动窗口时，每次滑动会得到一个T帧对应label概率，此时只要计算新添加的帧的计算，重叠部分不计算</li>
<li>运行时窗长都是100帧地执行，计算量小。[可改进之处]：当检测到keyword时（即当前帧超过给定的阈值，触发），那么就把窗长变为189帧，检测是否为keyword。</li>
<li>用20个滑动输出分类结果做smooth</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210820000826516.png" alt="image-20210820000826516"></p>
<ul>
<li><ul>
<li><input checked disabled type="checkbox"> 滑窗这个要好好想想怎么实现？答：雷博说：把倒一层构成c的每个α和h时间步的值都保留下来，然后下一帧来了，就可以只算下一帧的，然后再softmax计算。</li>
</ul>
</li>
</ul>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><ul>
<li>baseline用Deep KWS</li>
<li>网络结构：CRNN网络，一层CNN层，两层RNN层(64个节点)</li>
<li>训练集：正样本188.9k, 负样本 1007.4k</li>
<li>验证集：正样本9.9k, 负样本 53k</li>
<li>测试集：正样本 28.8k , 负样本32.8k</li>
<li>输入特征：PCEN特征。每条音频持续时间1.9 seconds.</li>
<li>four-syllable Mandarin Chinese term (“xiao-ai-tong-xue”)  ，∼188.9K positive examples (∼99.8h) and ∼1007.4K  negative examples (∼1581.8h) as the training set.   正样本：负样本&#x3D;10：1</li>
</ul>
<h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><ul>
<li>∼84K parameters </li>
<li>1.02% FRR at 1.0 FA&#x2F;hour.</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Bai Y, Yi J, Tao J, et al. A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting[C]&#x2F;&#x2F;INTERSPEECH. 2019: 2190-2194&#x3D;&#x3D;.</p>
</blockquote>
<h4 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h4><ul>
<li>用TDNN-attention结构做kws，输入音频特征，输出分类结果</li>
<li>特征量很小（12K）</li>
<li>没用RNN，用TDNN（前馈网络），减少计算量，支持并行</li>
<li>attention用的shared weight self-attention，就是Q、K、V本来由三个$w_ix+b_i$而来（不同project投影），现在是乘以同一个wx+b，最后是multi-head</li>
<li>输入特征做下采样（tdnn povey原始论文也做的）</li>
<li>attention层后接两层tdnn，后接 global average</li>
<li>多帧输出-&gt;1个输出</li>
</ul>
<p><strong>模型结构为</strong>：</p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210608174746396.png" alt="image-20210608174746396" style="zoom: 80%;">

<p>global average 做了polling，变成一个向量</p>
<p>最后softmax输出是只有一个向量</p>
<p><strong>下采样为</strong>：</p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210608174813294.png" alt="image-20210608174813294" style="zoom: 67%;">



<h4 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h4><ul>
<li>数据集用Google Speech Commands  ，都是1s，一个word的音频</li>
<li>10个命令词，20个filler（归为一个label）</li>
<li>用分类错误率作为评价指标</li>
</ul>
<blockquote>
<p>参考：<a href="https://blog.csdn.net/chenxi910911/article/details/102615068?spm=1001.2014.3001.5501">A Time Delay Neural Network with Shared Weight Self-Attention for Small-Footprint Keyword Spotting浅析</a></p>
</blockquote>
<p>中心思想：通过共享自注意力机制的权重，在维持性能不变的情况下，减少模型参数<br>本文的创新点：一是，用前馈神经网络代替在注意力机制中常用的回归神经网络，加速模型计算[用tdnn代替rnn]；二是，自注意力机制中的三个矩阵进行参数共享，减少模型参数<br>文章中提到的技术：TDNN、self-attention、SWSA(Shared-Weight Self-Attention)<br>TDNN技术：获取序列的局部特征<br>self-attention技术：用三个不同的权重矩阵将特征映射到不同空间中、获取序列的全局特征<br>shared-weight self-attention技术：用同一个权重矩阵将特征映射到同一空间中、减少模型参数。</p>
<p>模型结构：第一层TDNN-SUB（TDNN降采样层），实现方法：采用滑动窗的方式，在输入层矩阵T<em>in</em>上设置一个宽度W为3（通常根据第一层拼帧结构决定）的滑动窗，当步长K超过1时（步长不易超过窗长），达到了降采样的效果，维度D<em>out</em>减少为(T<em>in</em> − w + 1)&#x2F;k向上取整</p>
<p>第二层是SWSA（权重共享的自注意力机制），也是本文的重点，详细结构见F1（a）右手边虚框<br>第一步：输入为U，共享矩阵为W，Vi&#x3D;WU，Vi为自注意力机制的输入，Vi是通过自注意力机制将输入特征U映射到某一空间得到的特征<br>第二步：由于权重共享，原来的Vq×Vk也就是现在的V×（V转置）即矩阵与矩阵本身点乘；<br>第三步：第二步得到的矩阵进行scale操作&#x3D;&#x3D;（scale操作的目的：是为了防止矩阵上的值累加到很大的值，梯度更新过程中出现梯度消失的现象）通常是将矩阵上的值除以矩阵维度的开方&#x3D;&#x3D;；<br>第四步：计算注意力得分，经过softmax层，对矩阵的每一行进行一个softmax规整，即矩阵的每一行的值加和为1；<br>第五步：将注意力得分与V点乘得到新的矩阵输出后紧跟RELU和LayerNorm层，最终得到SWSA层的输出<br>第三层和第四层是TDNN层<br>第五层：&#x3D;&#x3D;globalAverage层：CNN中有类似的全局平均池化层&#x3D;&#x3D;<br>在这边文章中未提及，但通过后面的实验章节推测，是权重矩阵每一列求平均值最终输出一个与当前层输入矩阵相同维度的向量</p>
<p>下面是权重共享后的self-attention公式：</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/20191017213712901.png" alt="在这里插入图片描述"></p>
<p>multi-head self-attention版本</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/20191017214108129.png" alt="在这里插入图片描述"></p>
<p>其中i的值等于共享权重矩阵的个数，当i为1是就是上述描述的权重共享self-attention机制；当i大于1是此时的共享权重是i个（类似于CNN有i个卷积核的概念），当i大于1时，权重矩阵的维度就会缩减为原来的1&#x2F;i,通常为整数，其他步骤与上述的self-attention步骤一致，在self-attention输出层后增加一层将muli-head self-attention的输出拼接到一起，乘一个矩阵得到与i为1时相同大小的矩阵</p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/20191017215828482.jpg" alt="在这里插入图片描述" style="zoom:50%;">



<hr>
<blockquote>
<p>&#x3D;&#x3D;Choi S ,  Seo S ,  Shin B , et al. Temporal Convolution for Real-time Keyword Spotting on Mobile Devices[J].  2019. citation：41&#x3D;&#x3D;</p>
<p>论文开源代码：<a href="https://github.com/hyperconnect/TC-ResNet">https://github.com/hyperconnect/TC-ResNet</a>  </p>
<p><a href="https://blog.csdn.net/weixin_37598106/article/details/105518851">Lebhoryi的csdn笔记TC-ResNet</a></p>
<p><a href="https://www.jianshu.com/p/83e159170dbb">实时语音唤醒–Temporal Convolution for Real-time Keyword Spotting on Mobile Devices</a></p>
</blockquote>
<h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><ul>
<li><p>评测目标之一是测量在移动设备上的实际延迟 latency；</p>
</li>
<li><p>采用一维卷积，一维卷积优点：不对频率维度卷积，能具有更大的感受野（对于特征是语谱图输入的一些模型来说），同时获取高频和低频信息，计算量减少；</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210824101219809.png" alt="image-20210824101219809"></p>
</li>
</ul>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><ul>
<li><p>输入MFCC，mfcc维度作为通道数c</p>
</li>
<li><p>使用一个宽度系数width multiplier，用来增加或减少每一层的通道数c，比如原来是{16,24,32,48}，乘1.5&#x3D;{24,36,48.72}，命名为TC-ResNet8-1.5</p>
</li>
<li><p>使用ResNet结构，cnn卷积核m *1（而不是3 *3），第一层m&#x3D;3，其他层m&#x3D;9</p>
</li>
<li><p>没有bias，bn层的作用是scale&amp;shift</p>
</li>
<li><p>网络结构：（其中k是width multiplier倍乘系数）</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210824101255801.png" alt="image-20210824101255801"></p>
</li>
</ul>
<h4 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h4><ul>
<li><p>实验结果考核了accuracy、ROC、耗时&#x3D;&#x3D;FLOPs&#x3D;&#x3D;、Params</p>
</li>
<li><p>TensorFlow Lite Android benchmark tool 判断推理时间的好坏</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210824101358185.png" alt="image-20210824101358185"></p>
</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210824101413415.png" alt="image-20210824101413415"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/12976336-3796810af0e64f2b.png" alt="12976336-3796810af0e64f2b"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/12976336-003886915241671f.png" alt="12976336-003886915241671f"></p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/20200414190510809.png" alt="img">

<hr>
<blockquote>
<p>&#x3D;&#x3D;Mittermaier S, Kürzinger L, Waschneck B, et al. Small-footprint keyword spotting on raw audio data with sinc-convolutions[C]&#x2F;&#x2F;ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020: 7454-7458.  citation:14&#x3D;&#x3D;</p>
<p><a href="https://blog.csdn.net/weixin_37598106/article/details/105540840">Lebhoryi的csdn笔记</a></p>
</blockquote>
<h4 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h4><ul>
<li>用SincNet直接读取原始音频进行训练</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210824110540981.png" alt="image-20210824110540981"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20210824110631141.png" alt="image-20210824110631141"></p>
<h4 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h4><ul>
<li>sincConv+GDSConv模型的accuracy（97.3%）比TC-ResNet（96.6%）更高；参数量（62k）比TC-ResNet（305k）更少；</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Chen X, Yin S, Song D, et al. Small-footprint keyword spotting with graph convolutional network[C]&#x2F;&#x2F;2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU). IEEE, 2019: 539-546. citation：6&#x3D;&#x3D;</p>
<p><a href="https://blog.csdn.net/weixin_37598106/article/details/105560949">Lebhoryi的csdn笔记CENet-GCN (2019年)</a></p>
</blockquote>
<h4 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h4><ul>
<li>使用了图神经网络GCN</li>
<li>结构紧凑</li>
</ul>
<h4 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h4><p>- </p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/JkoL7t.png" alt="img"></p>
<hr>
<p>【重要】</p>
<blockquote>
<p>&#x3D;&#x3D;Rybakov O, Kononenko N, Subrahmanya N, et al. Streaming keyword spotting on mobile devices[J]. arXiv preprint arXiv:2005.06720, 2020. citations：15&#x3D;&#x3D; 谷歌的论文</p>
<p>github开源代码：<a href="https://github.com/google-research/google-research/tree/master/kws_streaming">https://github.com/google-research/google-research/tree/master/kws_streaming</a></p>
<p><a href="https://blog.csdn.net/weixin_37598106/article/details/106801481">Lebhoryi的csdn笔记stream_kws_cnn</a></p>
</blockquote>
<h4 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h4><ul>
<li>stream流式 卷积也可以流式，意味着不用输入定长才有输出，输入任意一段（甚至只要给1帧）就会有输出，要研究代码，看是否可以一个vad长度输入，得到一个输出</li>
<li></li>
</ul>
<hr>
<p>A survey on structured discriminative spoken keywordspotting  </p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;de Andrade, Douglas Coimbra, et al. “A neural attention model for speech command recognition.” <em>arXiv preprint arXiv:1808.08929</em> (2018).&#x3D;&#x3D;</p>
<p>github开源代码：<a href="https://github.com/douglas125/SpeechCmdRecognition">https://github.com/douglas125/SpeechCmdRecognition</a></p>
</blockquote>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Yang, Chen, Xue Wen, and Liming Song. “Multi-Scale Convolution for Robust Keyword Spotting.” <em>INTERSPEECH</em>. 2020.&#x3D;&#x3D;三星研究院</p>
<p>线上会议video：<a href="http://www.interspeech2020.org/index.php?m=content&amp;c=index&amp;a=show&amp;catid=321&amp;id=835">http://www.interspeech2020.org/index.php?m=content&amp;c=index&amp;a=show&amp;catid=321&amp;id=835</a></p>
</blockquote>
<h3 id="PPT"><a href="#PPT" class="headerlink" title="PPT"></a>PPT</h3><ul>
<li>HMM在噪声环境下表现较差</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104100737871.png" alt="image-20220104100737871"></p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104100921735.png" alt="image-20220104100921735" style="zoom:80%;">



<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104100945713.png" alt="image-20220104100945713"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104101011948.png" alt="image-20220104101011948"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104101029737.png" alt="image-20220104101029737"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104101052521.png" alt="image-20220104101052521"></p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104101107772.png" alt="image-20220104101107772">



<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104101142998.png" alt="image-20220104101142998"></p>
<h3 id="思路-4"><a href="#思路-4" class="headerlink" title="思路"></a>思路</h3><ul>
<li>实现低功耗small footprint：通过使用depthwise-separable convolutions in a ResNet framework；</li>
<li>实现噪声鲁棒性：通过multi-scale ensemble of classifiers；每个分类器处理不同的输入特征，同时通过大量的参数共享让size紧凑；</li>
<li>多个depthwise-separable residual unit (DRU)   堆叠起来的，用现在最流行的depthwise-separable cnn（减少参数量），然后加上resnet；</li>
<li>model compression in <strong>DRU</strong> 具体实现过程：Incoming 𝑛 -channel feature map is down-projected to 𝑛&#x2F;2 channels by 1 × 1 convolution, processed per-channel by 3 × 3, up-projected to 𝑛 channels by another 1 × 1, then summed with original input to complete the residual unit；<ol>
<li>一开始正常1* 1卷积滤波器个数n&#x2F;2，参数量 1* 1* n* n&#x2F;2</li>
<li>然后depthwise conv（channel个数n&#x2F;2），参数量 3* 3* n&#x2F;2</li>
<li>最后1* 1 pointwise卷积（其实也是普通卷积）滤波器个数n，参数量 1* 1* n&#x2F;2* n</li>
</ol>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104111436716.png" alt="image-20220104111436716" style="zoom:80%;">



<ul>
<li><p>Multi-scale ensemble  具体实现过程：</p>
<p>在不同的层，不同的t，不同的持续时间窗口w（d,t,w），抽取output，经过变换矩阵softmax，输出某个head的结果，每个head的帧取的时间间隔不同，比如第一个head是取0.8s，帧移0.4s取，第二个head是取1s，帧移0.5s取；</p>
<p>不同head所经过的变换矩阵里面的权重参数是一样的（经过同一个变换矩阵）（weight sharing），这是为了结构紧凑；</p>
<p>分类是数帧进行average pooling，再分类</p>
</li>
<li><p>loss function：$naiveCE:&#x3D;\sum_{d,t,w}logp_{d,t,w}(y)$</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220104145324460.png" alt="image-20220104145324460" style="zoom:80%;">

<ul>
<li>分类判断 $ \large{result&#x3D;\left{<br>\begin{aligned}<br>arg\max_{v\in{v}}(\max\limits_{d,t,w}p_{d,t,w}(v)),if{\exists}p_{d,t,w}(v)&gt;th \<br>nonkeyword, otherwise<br>\end{aligned}<br>\right.}$</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul>
<li>10 conv layers in total, including one initial convolution and 9 stacked DRUs  </li>
<li>Initial convolution reduces input size and projects features into multiple channels  </li>
<li>The 9 DRUs are arranged in three groups. DRUs in the same group have the same number of channels. Deeper groups are allocated more channels to learn more complex features</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Li, Ximin, Xiaodong Wei, and Xiaowei Qin. “Small-Footprint Keyword Spotting with Multi-Scale Temporal Convolution.” <em>arXiv preprint arXiv:2010.09960</em> (2020).&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思路-5"><a href="#思路-5" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>一维卷积，time是长，没有宽，宽是1，特征维度（频率）是channel，这种卷积叫temporal convolution；</p>
</li>
<li><p>提出temporal efficient neural network (TENet)  ，主要结构是inverted bottleneck block (IBB)  ，该结构两头小中间大（和普通的bottleneck相反，因此叫inverted bottleneck），两头是1* 1卷积（沿着channel卷）（pointwise），中间是不沿着channel卷积的9*1卷积（depthwise），和普通的depthwise separable conv顺序相反。</p>
<p>IBB里的第一个1×1卷积的目的是通过扩展channel的数量，将input嵌入（embed）到高维子空间中；</p>
<p>IBB里的depthwise卷积是temporal卷积，通过对每个输入channel应用一个卷积滤波器，和非线性变换，来实现轻量级滤波；（注意这里只是depthwise conv不是depthwise seperate conv）</p>
<p>IBB里的最后一个1×1卷积将tensor转换回低维compact子空间，用于channels间的信息传输；</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220105142223167.png" alt="image-20220105142223167" style="zoom: 50%;">



<ul>
<li>末尾层 average pooling -&gt; fully connected -&gt; softmax</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220105142911152.png" alt="image-20220105142911152" style="zoom:50%;">

<ul>
<li><p>提出Multi-branch Temporal Convolution Module，目的是为了捕捉短期和长期时间信息特征；</p>
<p>具体实现过程：让每个branch的kernel size都不同，从而帮助branch从它的时间粒度中学习不一样的模式；</p>
<p>多尺度融合（不同kernel size后的特征融合）：element-wise add（各个位置的元素等于两&#x2F;N个输入矩阵相同位置元素的乘积的矩阵，再加和） (Hadamard product)</p>
<p>在训练时，将TENet中的所有depthwise卷积层都替换为MTConvs（IBB里独一个depthwise conv，替换成kernel size不同的多个depthwise conv（最后element-wise），叫做multi-scale））</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220105142956043.png" alt="image-20220105142956043" style="zoom:50%;">

<p>​	把下图原本只有一个的卷积，替换成多个不同kernel size卷积加和（上图）</p>
<ul>
<li><p>kernel fusion of MTConv </p>
<p>$\large{O_{t,1,j}&#x3D;(\sum\limits^k_{i&#x3D;-k}M_{t+i,1,j}F_{i+k+1,1,j}-u_j)\frac{\gamma_j}{\sigma_j}+\beta_j}$</p>
<p>其中，M是输入，F是卷积核，$k&#x3D;\frac{D-1}{2}$，D是卷积核尺寸（D×1×C），$u_j$和$\sigma_j$是BN层的channel-wise均值和标准差，$\gamma_j$和$\beta_j$是scaling和shifting系数（可训练 更新）；</p>
</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Vygon, Roman, and Nikolay Mikhaylovskiy. “Learning efficient representations for keyword spotting with triplet loss.” <em>International Conference on Speech and Computer</em>. Springer, Cham, 2021.&#x3D;&#x3D;ciations：12</p>
<p>github：<a href="https://github.com/roman-vygon/triplet_loss_kws">Github: Learning Efficient Representations for Keyword Spotting with Triplet Loss</a></p>
</blockquote>
<h3 id="思路-6"><a href="#思路-6" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>triplet loss：$\large l(p_i,p_i ^+,p_i ^- &#x3D; {0, g + D(f(p_i), f(p_i ^+)) - D(f(p_i), f(p_i ^-))})$</p>
<p>其中，$p_i$ 是anchor image，$p_i ^+$ 是positive image， $p_i ^-$ 是negative image，$g$ 是gap parameter regularizes the gap between the distance of the two image pairs: $(p_i,p_i ^+)$ and $(p_i,p_i ^-)$，D可以是欧氏距离；</p>
<p>这里是用来提embedding用的，输入A样本特征，输出embedding（高级特征），让A的embedding和同一个batch里的同类embedding距离近，让A的embedding和同一个batch里的不同类embedding距离远；</p>
<p>这里的triplet loss用来训练一个 <strong>triplet encoder</strong></p>
</li>
<li><p>提出triplet-loss based metric embeddings   + KNN分类器；实验优于ce，达到Google Speech Commands dataset  的SOTA（98.55% (V1 12分类(10keyword+sil+unknown)) 、98.37% (V2 12分类) ）；</p>
</li>
<li><p>提出基于音素相似度的batch sampling方法，改善了当数据不平衡时的F1</p>
</li>
<li><p>&#x3D;&#x3D;论文中做实验表明RNN-based的模型用上triplet loss会变差&#x3D;&#x3D;</p>
</li>
<li><p>先用模型提特征，把特征用KNN进行分类</p>
</li>
<li><p>batch sampling：Phonetic: Calculate a matrix of phonetic similarity for all the words in the dataset, sample batch_size&#x2F;2 classes, then, for each sampled class add three random phonetically similar words (equally distributed) to the batch. Similarity score is calculated using SoundEx, Caverphone, Metaphone and NYSIIS algorithms；在一个batch里，相似的音多采样一点，triplet loss才比较有效，不然已经很不相似了，本身就很不像，不怎么需要区分开；</p>
</li>
</ul>
<h3 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h3><ul>
<li>基于Honk框架，直接用了（honk框架和wekws一样是框架），提高级特征（embedding）</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220331115729019.png" alt="image-20220331115729019" style="zoom:67%;">

<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220331115825729.png" alt="image-20220331115825729" style="zoom: 67%;">

<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220331123332076.png" alt="image-20220331123332076" style="zoom:67%;">

<h3 id="实验-3"><a href="#实验-3" class="headerlink" title="实验"></a>实验</h3><ul>
<li>做了两组实验：</li>
</ul>
<ol>
<li>Google Speech Commands dataset；</li>
<li>LibriWords Datasets  这是用librispeech经过,the Montreal Forced Aligner(“Montreal forced aligner:Trainable text-speech alignment using kaldi” ) 对齐，得到word边界，进行实验，目的是查看用triplet loss在数据更大，分类数更多的情况效果能有多好  ；尝试了LibriWords10, LibriWords100, LibriWords1000, LibriWords10000</li>
</ol>
<h3 id="结果-3"><a href="#结果-3" class="headerlink" title="结果"></a>结果</h3><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220331123319620.png" alt="image-20220331123319620" style="zoom:67%;">

<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><blockquote>
<p>github：<a href="https://github.com/roman-vygon/triplet_loss_kws">https://github.com/roman-vygon/triplet_loss_kws</a></p>
</blockquote>
<p>requirement：安装nemo、nemo-asr、apex、protobuf&#x3D;&#x3D;3.9.2，安装如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装nemo</span></span><br><span class="line">pip install nemo-toolkit[all]</span><br><span class="line">pip install nemo_toolkit==0.10.1？</span><br><span class="line">pip install nemo_toolkit[asr]？</span><br><span class="line"><span class="comment"># 安装protobuf：</span></span><br><span class="line">pip install protobuf==3.9.2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装apex 直接用pip install apex安装后会报错</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/NVIDIA/apex</span><br><span class="line"><span class="built_in">cd</span> apex</span><br><span class="line">pip install -v --disable-pip-version-check --no-cache-dir ./</span><br><span class="line"><span class="comment">#pip install -v --disable-pip-version-check --no-cache-dir --global-option=&quot;--cpp_ext&quot; --global-option=&quot;--cuda_ext&quot; ./</span></span><br></pre></td></tr></table></figure>





<hr>
<blockquote>
<p>&#x3D;&#x3D;Kim, Byeonggeun, et al. “Broadcasted residual learning for efficient keyword spotting.” <em>arXiv preprint arXiv:2106.04140</em> (2021).&#x3D;&#x3D;</p>
<p>github：&#x2F;home&#x2F;data&#x2F;yelong&#x2F;google-research&#x2F;kws_streaming&#x2F;models&#x2F;bc_resnet.py</p>
<p>github网友复现代码：<a href="https://github.com/roman-vygon/BCResNet">https://github.com/roman-vygon/BCResNet</a></p>
</blockquote>
<h3 id="思路-7"><a href="#思路-7" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出broadcasted residual learning方法、broadcasted-residual connection  、Broadcasting-residual network  (BC-ResNet)</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220426151746370.png" alt="image-20220426151746370"></p>
<ul>
<li><p>Broadcasted Residual Learning  :在残差结构$y&#x3D;x+f(x)$上改进为：$\large y&#x3D;x+BC(f_1(avgpool(f_2(x))))$</p>
<p>其中，$f_1$是时间维度的函数，$f_2$是时间、频率二维图；</p>
<p>$f_2$ 输出也是二维的，然后对频率轴进行平均池化，得到时间、channel轴，再进入$f_1$函数，相当于$f_2$是一个提取不同帧时间&#x2F;不同高低频率之间相关性的一个特征抽取器（我们之前拿frequency作为channel，这里是单独一个维度、（channel有它自己一个维度）），经过$f_1$后又扩展成2D；在每个residual block里重复这种平均、扩展操作；称之为Broadcasted Residual Learning  </p>
</li>
<li><p>BC-ResNet Block ：$\large y&#x3D;x+f_2(x)+ BC(f_1(avgpool(f_2(x))))$</p>
<p>流程：（描述时忽略channel通道）$x\in R^{h\times w}$  ,h是frequency，w是time，做3* 1的frequency-depthwise卷积（$f_2$），就是沿着频率h轴做depthwise卷积（滤波器数量和frequency一致，不求和，kerenl size&#x3D;3），做SSN归一化，沿着频率轴做平均池化，再沿着时间轴w做1* 3time-depthwise卷积（$f_1$）（滤波器数量和time一致，不求和，kerenl size&#x3D;3），接BN层，swish激活函数，再接1* 1 pointwise卷积，提取时间帧前后关系信息，再沿着channel轴做dropout，输出 $y\in R^{h\times w}$</p>
</li>
<li><p>SubSpectral Normalization (SSN)  ：将输入频率分成多组，分别做归一化；用SSN代替BN层，来获取frequency-aware temporal features</p>
</li>
</ul>
<p>12分类，训练时unknown和silence label的比例为10、10；40维mfcc 30ms帧长10ms帧移；time shift [-100,100]，概率0.8、0.8比例加噪、spec augment 只用two time 和two frequency masks，没用time wraping</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（五）区分性训练用在命令词的论文</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/</url>
    <content><![CDATA[<h1 id="区分性训练用在命令词的论文"><a href="#区分性训练用在命令词的论文" class="headerlink" title="区分性训练用在命令词的论文"></a>区分性训练用在命令词的论文</h1><blockquote>
<p>&#x3D;&#x3D;Chen, Zhehuai, Yanmin Qian, and Kai Yu. “Sequence discriminative training for deep learning based acoustic keyword spotting.” <em>Speech Communication</em> 102 (2018): 100-111.&#x3D;&#x3D;</p>
</blockquote>
<h3 id="post-processing-后处理："><a href="#post-processing-后处理：" class="headerlink" title="post-processing 后处理："></a>post-processing 后处理：</h3><p>acoustic KWS usually does not require a language model but needs post-processing after the frame-level acoustic model inference  </p>
<h4 id="HMM"><a href="#HMM" class="headerlink" title="HMM"></a>HMM</h4><ul>
<li>The post-processing method can be categorized into three groups:</li>
</ul>
<ol>
<li><p><strong>Posterior smoothing</strong> </p>
<p>aim to filter out the noise posterior output by heuristic  methods  启发式方法滤除噪声后验输出</p>
<p>（Chen, G., Parada, C., Heigold, G., 2014a. Small-footprint keyword spotting using deep neural networks. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, pp. 4087–4091.）</p>
</li>
<li><p><strong>Model based inference</strong></p>
<p>aim to filter out the noise posterior output by data-driven  methods  数据驱动方法滤除噪声后验输出</p>
<p>（Ge, F., Yan, Y., 2017. Deep neural network based wake-up-word speech recognition with two-stage detection. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). pp. 2761–2765. New Orleans, USA）</p>
</li>
<li><p><strong>filler based decoding</strong>（In some recent works (Chen et al., 2014b; 2017a), a small language model can be applied in the filler modeling and shows moderate improvement  ）</p>
<p>model out-of-domain search space </p>
<p>（Chen, I.-F., Ni, C., Lim, B.P., Chen, N.F., Lee, C.-H., 2014b. A novel keyword+ lvcsr-filler based grammar network representation for spoken keyword search. Proceedings of the 2014 9th International Symposium on Chinese Spoken Lansguage Processing (ISCSLP). IEEE, pp. 192–196.）</p>
<p>（Chen, Z., Qian, Y., Yu, K., 2017a. A unified confidence measure framework using auxiliary normalization graph ）</p>
</li>
</ol>
<p>the possible competing words are usually not enumerable and the competing hypotheses generation is computationally expensive if using the same procedure as in LVCSR  ：</p>
<p>Chen, S.F., Kingsbury, B., Mangu, L., Povey, D., Saon, G., Soltau, H., Zweig, G., 2006. Advances in speech transcription at ibm under the darpa ears program. IEEE Trans. Audio Speech. Lang. Process. 14 (5), 1596–1608  </p>
<h4 id="CTC"><a href="#CTC" class="headerlink" title="CTC"></a>CTC</h4><ol>
<li><strong>MED</strong> 最小编辑距离</li>
</ol>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20211028095727692.png" alt="image-20211028095727692"></p>
<h4 id="CTC中的MED方法难以引入HMM的原因"><a href="#CTC中的MED方法难以引入HMM的原因" class="headerlink" title="CTC中的MED方法难以引入HMM的原因"></a>CTC中的MED方法难以引入HMM的原因</h4><ul>
<li>MED在lattice上进行，CTC有尖峰，可降低复杂度，HMM无尖峰</li>
<li>HMM的神经网络输出$p(o_{ut}|q_t)$，区分性训练过程已经有了该信息</li>
</ul>
<h3 id="区分性训练的non-keyword部分："><a href="#区分性训练的non-keyword部分：" class="headerlink" title="区分性训练的non-keyword部分："></a>区分性训练的non-keyword部分：</h3><ul>
<li><p>MMI准则公式为：$\large{\mathcal{F}_{MMI}&#x3D;\sum_ulog\frac{P(\textbf{O}_u|\textbf{W}_u)^kP(\textbf{W}<em>u)}{\sum</em>{\textbf{W}}P(\textbf{O}<em>u|\textbf{W})^kP(\textbf{W})}&#x3D;\sum_ulog\frac{\sum</em>{L\in{\mathcal{L}(W)}}p(\textbf{O}|\textbf{L})^kP(\textbf{L}|\textbf{W})^kP(\textbf{W}_u)}{\sum_Wp(\textbf{O}_u|\textbf{W})^kP(\textbf{W})}}$</p>
</li>
<li><p>由于不知道non-keyword序列，通过补偿composite alternate hypotheses 的概率来模拟这个过程，</p>
<ul>
<li><p>提出两个建模单元：</p>
<ul>
<li>filler model for non-keyword speech 建模非keyword</li>
<li>anti-keyword model for mis-recognitions 建模易与keyword混淆的音</li>
</ul>
</li>
<li><p>实际上该方法不可行</p>
</li>
</ul>
</li>
</ul>
<p>（Sukkar, R.A., Lee, C.-H., 1996. Vocabulary independent discriminative utterance verification for nonkeyword rejection in subword based speech recognition. IEEE Trans. Speech Audio Process. 4 (6), 420–429.）<br>（Sukkar, R.A., Setlur, A.R., Rahim, M.G., Lee, C.-H., 1996. Utterance verification of keyword strings using word-based minimum verification error (wb-mve) training. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing. 1. IEEE, pp. 518–521. ）</p>
<ul>
<li><p>在单词级CTC（Fernández et al.，2007）中，虽然它自然是一个序列级标准，但它不直接模拟非关键字元素。也就是说，在关键字之间插入空格以模拟它们之间的上下文。因此，序列级准则提高了关键字之间而不是关键字与非关键字之间的序列预测能力</p>
</li>
<li><p>我们现在的训练数据，都是单独的关键词句子、非关键词句子，在关键词训练数据中有非关键词，可以提高预测能力？会不会增加far？</p>
</li>
<li><p>A per-frame non-uniform weight can be added into the loss functions; operates inMCE.   The key point is to emphasize the loss during the span of possible keyword false rejection and false alarm in the training data.</p>
</li>
</ul>
<p>(Meng, Z., Juang, B.-H., 2016. Non-uniform boosted mce training of deep neural networks for keyword spotting. Proceedings of the Interspeech 2016. pp. 770–774.  )</p>
<ul>
<li>LF-MMI与原始MMI的区别：：<ul>
<li>分子：原始分子文本对齐序列用的硬对齐的alignment，chain model用软对齐，左右帧移窗口，全部算进分子。</li>
<li>分母：chain model语言模型用的3gram phone，sub-word level语言模型（chain model即使用音节建模，音节相当于“phone”，也是子词了，训练的3gram phone也是3gram syllable）</li>
<li>改变topo结构，chain model用的标签状态pdf后接可选的（属于该状态的）blank状态 pdf，（还是用的三音素）</li>
<li>输出帧下采样3倍</li>
</ul>
</li>
<li>本论文与LF-MMI的区别：<ul>
<li>用单音素建模（改善很小？但是可以节约计算量）</li>
<li>这里blank可以在标签前，也可以前后都有。这叫做”label delay“，能改善性能（不确定就可以先输出blank的意思？）（eer从3.1下降到3.0，改善很小？）</li>
<li>LF-MMI公式改进为LF-bMMI</li>
<li>训练时加重出现false alarm和false rejection的训练数据的loss</li>
</ul>
</li>
</ul>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>LSTM与TDNN比较：对于hmm的lf-mmi来说，blstm效果和tdnn一致，参数量还更大，所以用tdnn就可以了<ul>
<li>对KWS任务，依赖的上下文并不长</li>
<li>小模型参数下会更限制lstm效果</li>
<li>tdnn速度更快</li>
</ul>
</li>
<li>CI与CD建模单元比较：效果一致，CI的数量更小，用CI就可以了</li>
<li>不同交叉熵正则权重，该训练集中权重0.7合适，会有一定影响，这是因为测试时语言模型和训练不同，因此要权衡</li>
<li>topo结构比较，BP最佳（BPB由于训练数据更少，提升很小（文章用了“显著性检验”指标来衡量提升幅度））</li>
</ul>
<p>实验结果来看，最有效的还是训练时引入不同权重策略（给false alarm和false rejection样本更高的训练权重）</p>
<h4 id="训练时引入不同权重策略如何实现"><a href="#训练时引入不同权重策略如何实现" class="headerlink" title="训练时引入不同权重策略如何实现"></a>训练时引入不同权重策略如何实现</h4><p>雷博想法：先训练一个不错的模型，然后解码，根据解码结构，确定哪些是false alarm和false rejection，在egs的post中（本来都是1），提高他们的概率，再训练。</p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Wang Y, Lv H, Povey D, et al. Wake Word Detection with Alignment-Free Lattice-Free MMI[J]. arXiv preprint arXiv:2005.08347, 2020.&#x3D;&#x3D;</p>
<p>&#x3D;&#x3D;Wang, Yiming. <em>WAKE WORD DETECTION AND ITS APPLICATIONS</em>. Diss. Johns Hopkins University, 2021.&#x3D;&#x3D;王一鸣博士论文</p>
<p>&#x3D;&#x3D;github开源代码&#x3D;&#x3D;：The code and recipes are available in Kaldi [24]: <a href="https://github.com/kaldi-asr/kaldi/tree/master/egs/%7Bsnips,mobvoi,mobvoihotwords%7D">https://github.com/kaldi-asr/kaldi/tree/master/egs/{snips,mobvoi,mobvoihotwords}</a>. </p>
<p>&#x3D;&#x3D;github代码&#x3D;&#x3D;：<a href="https://github.com/YiwenShaoStephen/pychain">https://github.com/YiwenShaoStephen/pychain</a></p>
<p>&#x3D;&#x3D;csdn 博客&#x3D;&#x3D;：<a href="https://blog.csdn.net/chenxi910911/article/details/107674366">Wake Word Detection with Alignment-Free Lattice-Free MMI</a></p>
</blockquote>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><ul>
<li>提出alignment free LF-MMI，不需要对齐分子lattice</li>
<li>不把唤醒词里面每个音素建模，而是把整个唤醒词建模 model the whole wake phrase  ，用一个固定状态数的HMM去建模唤醒词（该数量少于唤醒词音素组成数量）</li>
<li>keyword、non-keyword、sil 都各用一个HMM建模</li>
<li>针对唤醒任务，提出alignment free LFMMI，分子不用对齐文本得到分子lattice，由于文本就是keyword&#x2F;non-keyword，文本只有一个HMM，直接遍历HMM所有可能路径，求路径和概率。（直接用文本图上添加自环，让解码更自由，前后向可选的路径更多）</li>
<li>负样本文本一般比较长，一个HMM可能建模不了，因此把负样本切成和正常本长度差不多，每个负样本的训练文本为freetext（一个HMM），就可以去生成egs了</li>
<li>负样本如果不segment，会严重过拟合</li>
<li>该方法能有效改善FAR高</li>
<li>分母图上路径权重：按正负样本比例来分配</li>
</ul>
<p>分子图fst：用一个文本构成（一个文本就是一个单词，一个单词用一个HMM建模）</p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/51e33547d077a96de000bf42d8c40e61.jpg" alt="img" style="zoom: 25%;">



<p>分母图fst：可以理解成word 并联序列，只不过添加了sil（不是loop，不能重复走）</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20211029145733035.png" alt="image-20211029145733035"></p>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><ul>
<li>负样本进行了分块chunk，&#x3D;&#x3D;chunk长度和正样本差不多&#x3D;&#x3D;，	</li>
<li>负样本后继chunk重叠0.3s，使得前一个chunk被截掉的单词有机会在后继chunk全词出现</li>
<li>声学模型：TDNN-F，分解到两个低秩矩阵，前一个矩阵是半正定的，确保高维到低维信息不会丢失</li>
<li>前一层的输入乘上缩放比例0.66与本层输入加和（是add，而不是concatenate）</li>
<li>拼帧结构：把本来要拼在一层的结构 分解到两层会更好，比如第一层拼(-3,0,3)，第二层拼(0)，更好的做法是第一层拼(-3,0)，第二层拼(0,3)</li>
<li>训练了一个alignment-free LF-MMI后，对齐lattice，重新训练一个普通的LF-MMI，效果会更好</li>
<li>alignment-free体现在：<ul>
<li>（雷博）不需要GMM-HMM训练过程，不需要对齐ali文件</li>
<li>不需要对齐训练样本然后统计得到phone-lm</li>
<li>一个没有一点对齐能力的模型（0.mdl）也可以拿来使用的</li>
<li>nnet3-chain-e2e-get-egs分子cegs生成，直接用text构建的fst，找到所有可能的fst中的状态序列求和就是分子，普通的还要由fst构建lattice？（感觉二者差不多）</li>
</ul>
</li>
<li>博士论文中比较了不同topo结构：<ul>
<li>把sil和freetext表示在一个HMM中，该HMM有多种可走的路径，这样就能够表示当训练样本前后是非命令词，中间是静音的情况。结果是增加了训练难度，误拒率很高，只有对齐准确的初始模型可能会得到好一点的误拒率，但是还是不好，因此最好不要把sil和freetext放在一起建模</li>
<li>用5状态建模HMM，效果比3状态好</li>
</ul>
</li>
</ul>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><h4 id><a href="#" class="headerlink" title></a></h4><ul>
<li>雷博说：<ul>
<li>负样本切chunk后，要注意正负样本比例，不要让负样本远远多于正样本。</li>
<li>切割负样本（长文本切到短文本）时，文本不知道对应的是sil还是freetext，不好得知文本，把静音段也视作freeetext会有问题</li>
<li>实验效果好，可能由于数据集较小</li>
</ul>
</li>
</ul>
<h4 id="在线解码"><a href="#在线解码" class="headerlink" title="在线解码"></a>在线解码</h4><ul>
<li>解码FST：其实长得有点像分母图，不同之处在于是起始状态和终止状态在同一个结点，使得可以生成词串，比如生成word后还可以生成freetext，再生成word等等，文本串；而分母图要不然就走freetext，要不然就走word，不能都串行出现。</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20211029150244872.png" alt="image-20211029150244872"></p>
<ul>
<li><p>在线解码：一个chunk一个chunk解码，每次解码了一个chunk后，就去更新immortal token和prev_immortal token（在所有active tok里找公共祖先（emitting[0]，或者说tokenOne），作为immortal tok，把前一次的immortal tok作为prevImmortal tok），每次在两个immortal tokens之间的路径寻找（backtrace）是否有唤醒词，实现了逐chunk搜索。</p>
</li>
<li><p>每处理过一段固定长度的录音后，我们用更新不朽token算法来回溯最近两个“不朽token”中间的这些帧，检查这部分回溯是否包含唤醒词。如果发现唤醒词则停止解码，如果没有唤醒词继续解码。（不朽token是现存激活token的共同祖先）</p>
<p>这个是基于这样一个假设：如果现有的存活的部分假设都是来自于前一个时刻的相同的token（不朽token），同时在这之前的所有的假设都已经压缩到了这一个token上，我们就可以从这个“不朽token”检查是否具有唤醒词 [csdn]</p>
</li>
<li><p>伪代码 online decoding：</p>
</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20211029144006785.png" alt="image-20211029144006785"></p>
<ul>
<li>更新immortal token，用于回溯</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20211029144433677.png" alt="image-20211029144433677"></p>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>The code and recipes are available in Kaldi [24]: <a href="https://github.com/kaldi-asr/kaldi/tree/master/egs/%7Bsnips,mobvoi,mobvoihotwords%7D">https://github.com/kaldi-asr/kaldi/tree/master/egs/{snips,mobvoi,mobvoihotwords}</a>.  </p>
<p>本文中引入了一种不需要对齐（Alignment-free）、不需要词图的（Lattice-Free MMI）鉴别性准则训练的模型<br>相比Lattice-free MMI准则需要额外修改一下发音字典、HMM拓扑结构</p>
<p>1.HMM拓扑结构（KW和freetext）用的是5个状态；silence用的是2个状态，但是保持（Lattice-free MMI）的结构self-loop-pdf和forward-pdf对应两个不同的PDF-id，因此神经网络共82+21&#x3D;18个pdf</p>
<p>2.分子图与分母图<br>分子图和chain的不同点在于：不需要依赖对齐结果生成label对应的图，生成一个非扩展的fst，在训练过程中通过前后向算法更加灵活的学习对齐结果<br>分母图和chain的不同点在于：phone级别的语言模型不再需要通过训练数据训练得到，直接手动生成一个语言模型fst，一共3条路径，关键词路径、freetext、silence，其中关键词和freetext前后都可加silence。每一条路径上的权重受训练数据中正负样本的占比因素影响<br>3.声学模型<br>使用TDNN-F模型（因式分解的TDNN），将一层的参数矩阵分解成两个低秩矩阵、第一个矩阵强制限制为半正定矩阵<br>模型（20层每层80节点）存在跨层连接，前一层的输入乘上缩放比例0.66与本层输入加和。<br>4.数据预处理和增强<br>对于负样本（存在很多样本时长较长）会按照正样本的时长分布，对负样本进行切段，每一段分配一个负样本标签。<br>增强：尽管训练数据很多是在实际场景中录制的，增强后效果仍然后提升<br>5.解码<br>手动构造词级别的解码网络FST，每条路径上的权重生成和分母图的LM-fst图方式是一样的。在开始token和结束token上增加从结束token到开始token的空边，原因是音频中可能存在唤醒词和其他可能的音频交叉现象。<br>在线解码的过程中：每处理过一段固定长度的录音后，我们用更新不朽token算法来回溯最近两个“不朽token”中间的这些帧，检查这部分回溯是否包含唤醒词。如果发现唤醒词则停止解码，如果没有唤醒词继续解码。（不朽token是现存激活token的共同祖先）</p>
<p>这个是基于这样一个假设：如果现有的存活的部分假设都是来自于前一个时刻的相同的token（不朽token），同时在这之前的所有的假设都已经压缩到了这一个token上，我们就可以从这个“不朽token”检查是否具有唤醒词</p>
<ul>
<li>与其他模型的对比结果</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20211124173256429.png" alt="image-20211124173256429"></p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Shrivastava A ,  Kundu A ,  Dhir C , et al. Optimize What Matters: Training DNN-Hmm Keyword Spotting Model Using End Metric[C]&#x2F;&#x2F; ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021.&#x3D;&#x3D; Apple</p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出状态分类精度和命令词识别的目标不一致，分类精度高不代表检测分数高</li>
<li>从目标检测领域迁移而来提出IOU loss function：关键词groundtruth起止时间与预测的起止时间交集&#x2F;并集，但是这篇论文不是真的用这个IOU loss，而是借鉴了IOU loss，原始IOU的groundtruth的起止时间区域，到了这边就是groundtruth keyword；而预测的起止时间，变成是viterbi对齐keyword后的区域，没有groundtruth的起止时间，而是一心要最大化positive sample预测的起止时间内的平均概率（和最小化negative sample预测的起止时间内的平均概率）</li>
<li>特地挑选子词+垃圾词作为负样本，从训练样本入手减少误唤醒</li>
<li>增加数据已经不能提升模型效果，可能是由于唤醒任务太简单，因此把目标函数弄复杂一点，增加训练难度，如果还能训练好的话，原本的唤醒任务也会训练得很好</li>
<li>把ground-truth（关键词）分成两部分并交换次序比如“静音”，变成“音静”，构建新的负样本，这样打乱顺序，可以强迫模型学会前后顺序（一定要减小音量才能唤醒，音量减小不能唤醒）</li>
</ul>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><ul>
<li>训练时，根据viterbi对齐（训练时文本已知）（不是前后向，前后向是路径求和，这里是找最佳路径）找到最佳路径，得到路径分数，找到关键词的起始位置，得到关键词平均路径分数，记为检测分数$d$，$d&#x3D;v_C(T)$，其中，C是关键词末尾状态</li>
<li>使用 hinge loss，loss function：</li>
<li>使用 hinge loss，loss function：$\large{L_{e2e}&#x3D;\min_\limits{\theta}\sum_\limits{j\in{X_p}}max(0,1-d_j)+\sum_\limits{j\in{X_n}}max(0,1+d_j)}$，其中，p是正样本，n是负样本</li>
<li>一个唤醒词，正负样本比例1：30，50w样本</li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20211110143717599.png" alt="image-20211110143717599"></p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;X. Wang, S. Sun, C. Shan, J. Hou, L. Xie, S. Li, and X. Lei, “Adversarial examples for improving end-to-end attention-based small-footprint keyword spotting,”in Proc. ICASSP, 2019, pp. 6366–6370.&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>kws里的false alarmed和false rejected样本作为对抗样本adversarial examples，用fast gradient sign method（FGSM）构建对抗样本，作为数据增广；</p>
</li>
<li><p>用模型输出正确的样本（输出为ground-truth），对样本输入进行扰动，使得模型输出不正确，这种新的输入，来作为对抗样本：</p>
<p>a pair of correctly-classified example $(x_i;y_i) $ ，其中$y_i$是ground-truth，对抗样本$x_i^{adj}&#x3D;x_i+\delta_i$，并且满足$y_i\neq{f(x_i^{adv};\theta)}$，其中，${\Vert \delta_i \Vert}\ll{\Vert x_i \Vert}$</p>
<p>FGSM试图在输入空间中找到一个方向，使loss函数有效地增大，这个方向通过对输入求导来获得</p>
<p>$\delta_i^{FGSM}&#x3D;\epsilon{sign}(\frac{L(y_i,\partial f(x_i;\theta))}{\partial x_i})$	（sign是符号函数 -1,1）</p>
<p>$x_i^{adv}&#x3D;x_i+\delta_i^{FGSM}$</p>
<p>其中，$\epsilon$是调节扰动幅度的一个小常数</p>
</li>
<li><p>添加一点点扰动，模型预测错误说明：神经网络模型的输出相对于输入是不平滑的，在输入空间存在“盲点”。该模型很不smooth；</p>
</li>
<li><p>对抗样本生成：先训练一个好的模型后，对样本中的正样本添加扰动（只对keyword segment区域）；对样本中的负样本添加扰动（全部区域），然后再retrain</p>
</li>
<li><p>用对抗样本能最大提高模型性能，模型最少见对抗样本的这种情况，而用随机扰动，模型只能改善一点；</p>
</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20220321175134525.png" alt="image-20220321175134525" style="zoom:67%;">

<p>总体是一个attention结构，encoder是一个1层GRU，</p>
<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><ul>
<li>正样本差不多2s，因此把负样本也segment成最大2s；</li>
<li>在一个训练好的模型基础上，再retrain；retrain的过程为：在每个minibatch中，动态生成对抗样本；</li>
<li>只对正样本做对抗样本生成，效果最好；</li>
</ul>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><ul>
<li>200帧窗长，1帧帧移</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. “Explaining and harnessing adversarial examples.” <em>arXiv preprint arXiv:1412.6572</em> (2014).&#x3D;&#x3D;ciations：10772</p>
<p><a href="https://blog.csdn.net/u014380165/article/details/90723948">图像对抗算法-攻击篇（FGSM）</a></p>
</blockquote>
<h3 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>提出the fast gradient sign method (FGSM)  </p>
</li>
<li><p>常规的分类模型训练在更新参数时都是将参数减去计算得到的梯度，这样就能使得损失值越来越小，从而模型预测对的概率越来越大。既然无目标攻击是希望模型将输入图像错分类成正确类别以外的其他任何一个类别都算攻击成功，那么只需要损失值越来越大就可以达到这个目标，也就是模型预测的概率中对应于真实标签的概率越小越好，这和原来的参数更新目的正好相反。因此我只需要在输入图像中加上计算得到的梯度方向，这样修改后的图像经过分类网络时的损失值就比修改前的图像经过分类网络时的损失值要大，换句话说，模型预测对的概率变小了。这就是FGSM算法的内容，一方面是基于输入图像计算梯度，另一方面更新输入图像时是加上梯度，而不是减去梯度，这和常见的分类模型更新参数正好背道而驰。</p>
</li>
<li><p>按比例和原始数据融合  $\hat J(\theta,x,y)&#x3D;\alpha J(\theta,x,y) + (1-\alpha) J(\theta,x + \epsilon sign(\nabla_x J(\theta,x,y)))$</p>
<p>$\alpha$ 一般取0.5</p>
</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;A. Coucke, M. Chlieh, T. Gisselbrecht, D. Leroy, M. Poumeyrol, and T. Lavril, “Efficient keyword spotting using dilated convolutions and gating,” in Proc. ICASSP, 2019, pp. 6351–6355&#x3D;&#x3D;  </p>
</blockquote>
<h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><ul>
<li>用了 dilated convolution 空洞卷积和 gated activations 门激活函数；</li>
<li>只检测keyword结束位置的输出概率，做loss function计算和推理，不用max pooling loss；（我命名为）【end loss】 很好用</li>
<li>没用alignment得到边界信息，而是用VAD（这个应该都无所谓），然后对keyword end位置的输出概率做计算，这个结束位置不是固定一帧，而是一个范围$\Delta t$，也就是在这个范围内的帧的输出概率去计算loss，$\Delta t$的最优值用dev set调参；这样的好处是，模型不会倾向于在命令词音频开头就触发，不然如果说的是命令词的子词就是误触发了；？这个是怎么用的，是这个范围内都是这个标签，more label ce吗？【这个思路还挺好的】【改进，随机选这个范围内的一帧去计算？增加扰动，随机性】</li>
<li>加了mask【？】，防止模型去学习精确的边界，这个是我们所不希望学习的？</li>
<li>可以流式推理【TODO】看不懂：</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20220323115129116.png" alt="image-20220323115129116" style="zoom:67%;">

<h3 id="训练-2"><a href="#训练-2" class="headerlink" title="训练"></a>训练</h3><ul>
<li>数据集：“Hey Snips” datase  （<a href="https://research.snips.ai/datasets/keyword-spotting">https://research.snips.ai/datasets/keyword-spotting</a> ），a crowdsourced closetalk dataset  </li>
<li>正负样本的背景音（录制场所）最好一样，防止模型训练变成分辨两种环境了</li>
<li>$\Delta t$最佳值是160ms (15 frames before and 15 frames after the end of the keyword)  </li>
<li>平滑窗口是30帧</li>
<li>感受野receptive field 182帧（1.83s）</li>
<li>24层，学习率1e-3，gradient norm clipping 10 ，A scaled uniform distribution for initialization</li>
</ul>
<h3 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h3><ul>
<li><p>参考TTS里的wavenet结构，用了Dilated causal convolutions  空洞因果卷积，门激活函数，residual连接；</p>
</li>
<li><p>Gated activations  ：结合了tanh和sigmoid；a combination of tanh and sigmoid activations controlling the propagation  of information to the next layer  ，就是cnn出来，接两个激活函数，然后相乘；</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20220323113837633.png" alt="image-20220323113837633" style="zoom: 80%;">

<ul>
<li>residual connection用的矩阵是projection layer，就是正交矩阵，32维投影到16维，再恢复32维</li>
</ul>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><ul>
<li>对比模型是LSTM，max-pooling（基于ce初始模型）的模型，max-pooling loss的思想是通过反向传播损失来教会网络在其最高置信时刻触发，这种损失来自于信息量最大的关键字帧，该关键字帧具有相应关键字的最大后向。lstm输入是左拼帧10帧右拼帧10帧的stack起来作为输入（11帧的向量，比如是440维），学习率5e-5‘</li>
<li>Ablation analysis  还做了消融分析</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20220323193422151.png" alt="image-20220323193422151" style="zoom:67%;">

<p>分析不同特征对识别结果的影响程度，发现end-of-keyword labeling影响最大，对FRR的改善最大，特别是在噪声环境下；</p>
<ul>
<li>learning rate 1e-3</li>
</ul>
<h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h3><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89/image-20220323192121077.png" alt="image-20220323192121077" style="zoom:67%;">



<hr>
<blockquote>
<p>&#x3D;&#x3D;Majumdar, Somshubra, and Boris Ginsburg. “Matchboxnet: 1d time-channel separable convolutional neural network architecture for speech commands recognition.” <em>arXiv preprint arXiv:2004.08531</em> (2020).&#x3D;&#x3D;ciations：28</p>
</blockquote>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Mordido, Gonçalo, Matthijs Van Keirsbilck, and Alexander Keller. “Compressing 1D Time-Channel Separable Convolutions using Sparse Random Ternary Matrices.” <em>arXiv preprint arXiv:2103.17142</em> (2021).&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h3><p>在Matchboxnet基础上，replacing 1x1-convolutions in 1D time-channel separable convolutions by constant, sparse random ternary matrices with weights in {-1; 0; +1}  </p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Tang, Raphael, and Jimmy Lin. “Honk: A pytorch reimplementation of convolutional neural networks for keyword spotting.” <em>arXiv preprint arXiv:1710.06554</em> (2017).&#x3D;&#x3D;</p>
<p>github：<a href="https://github.com/castorini/honk">https://github.com/castorini/honk</a></p>
</blockquote>
<h3 id="思路-4"><a href="#思路-4" class="headerlink" title="思路"></a>思路</h3><ul>
<li>类似wekws，也是一个框架，可以直接用！！！</li>
</ul>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（八）Query by Example</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Query-by-Example"><a href="#Query-by-Example" class="headerlink" title="Query by Example"></a>Query by Example</h1><blockquote>
<p>&#x3D;&#x3D;Timothy J. Hazen et al. “Query-by-example spoken term detection using phonetic posteriorgram templates” IEEE Automatic Speech Recognition and Understanding Workshop (2009).&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><ul>
<li>用声学模型输出后验直方图（t帧*分类数）作为匹配的对象</li>
<li>模板匹配，用DTW</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89/image-20211223115725885.png" alt="image-20211223115725885" style="zoom:80%;">

<p>分数归一化（$\frac{1}{m}$），使得路径分数从query frame获得的贡献相同（不管路径吸收了多少test frame）</p>
<ul>
<li>多个query的情况（多个命令词），不用知道识别了哪个命令词，只要知道有没有识别命令词即可。两种方法：<ul>
<li>1.把多个query模板combine成一个；</li>
<li>2.把所有的query模板都拿去于test匹配，把匹配分数求和取平均：</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89/image-20211223120603171.png" alt="image-20211223120603171" style="zoom:80%;">



<hr>
<blockquote>
<p>&#x3D;&#x3D;Chen Guoguo,Parada C, Sainath T N, et al. Query-by-example keyword spotting using longshort-term memory networks[C]. international conference on acoustics, speech,and signal processing, 2015: 5236-5240.&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><ul>
<li>嵌入学习embedding的样例检索</li>
<li>自定义唤醒词</li>
</ul>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（六）蒸馏学习用在命令词的论文</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/</url>
    <content><![CDATA[<h1 id="蒸馏学习用在命令词的论文"><a href="#蒸馏学习用在命令词的论文" class="headerlink" title="蒸馏学习用在命令词的论文"></a>蒸馏学习用在命令词的论文</h1><blockquote>
<p>&#x3D;&#x3D;Geoffrey E. Hinton, Oriol Vinyals, &amp; Jeffrey Dean (2015). Distilling the Knowledge in a Neural Network arXiv: Machine Learning.&#x3D;&#x3D;</p>
<p><a href="https://www.zhihu.com/question/50519680">如何理解soft target这一做法？</a> 知乎</p>
<p><a href="https://zhuanlan.zhihu.com/p/343988823">知识蒸馏里面的公式推导</a> 知乎</p>
</blockquote>
<ul>
<li>知识蒸馏 Knowledge Distill 的开创论文</li>
<li>知识蒸馏：一个小模型（student）如何训练得更好？通过学习大模型（teacher）给的知识，大模型用交叉熵训练，要让正确标签的概率越高，对于不正确标签的概率，交叉熵并不考虑其概率，但是一个训练得好的大模型，其他标签概率也包含着一些信息，比如和正确标签更相近的其他标签概率，会比和正确标签很不相近的其他标签概率更大，这就涵盖了信息。如果只有label这样的一个目标的话，那么这个模型的目标就是把训练样本中每一类的样本强制映射到同一个点上，这样其实对于训练很有帮助的类内variance和类间distance就损失掉了<ul>
<li>要如何突出这些信息，就是通过“soft target”，小模型的训练目标标签不是groundtruth了，而是大模型输出的soft target作为小模型的训练目标标签了。可以看成是利用训练好的大模型对原始的标定空间进行了一次data augmentation</li>
</ul>
</li>
<li>因此，知识蒸馏是一种弥补分类问题监督信号不足的办法</li>
<li>soft logit里的temperature，分为高温和低温，高温的时候，蒸馏操作相当于最小化大模型的logits和蒸馏模型的logits的MSE，低温的时候那些数值小的logits不太被关注，这些数值很小的logits可能是噪声，所以一定程度上对蒸馏模型的效果是有好处的。 但同时这些很小的也有可能代表了一些非常重要的信息，因为很小的温度效果不一定最好，选取适中的T得到最好的结果</li>
</ul>
<h3 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h3><p>（这里参考的知乎的变量，和论文的q、p相反）</p>
<p>小模型的输出为：<br>$$<br>p_i&#x3D;softmax(z_i)&#x3D;\frac{exp(z_i)}{\sum_{j&#x3D;1}^Nexp(z_j)}<br>$$<br>交叉熵损失的公式，其中$q_i$是真实概率，$p_i$是预测概率：<br>$$<br>Loss&#x3D;-\sum_{j&#x3D;1}^Nq_ilog(p_i)<br>$$</p>
<h4 id="softmax的求导"><a href="#softmax的求导" class="headerlink" title="softmax的求导"></a>softmax的求导</h4><p>$softmax(p_i)$是和所有的logit相关的，所有分为两种情况：</p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/image-20211216112502927.png" alt="image-20211216112502927" style="zoom: 80%;">

<h4 id="交叉熵的求导："><a href="#交叉熵的求导：" class="headerlink" title="交叉熵的求导："></a>交叉熵的求导：</h4><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/image-20211216112622941.png" alt="image-20211216112622941" style="zoom:80%;">

<h4 id="知识蒸馏："><a href="#知识蒸馏：" class="headerlink" title="知识蒸馏："></a>知识蒸馏：</h4><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/image-20211216113433442.png" alt="image-20211216113433442" style="zoom:80%;">

<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89/image-20211216112715710.png" alt="image-20211216112715710" style="zoom:80%;">

<hr>
<blockquote>
<p>&#x3D;&#x3D;Gao, Yan, Titouan Parcollet, and Nicholas Lane. “Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition.” <em>arXiv preprint arXiv:2005.09310</em> (2020).&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出知识蒸馏（Knowledge Distillation, KD）</li>
</ul>
<blockquote>
<p>MINIMUM WORD ERROR RATE TRAINING FOR ATTENTION-BASED SEQUENCE-TO-SEQUENCE MODELS  </p>
</blockquote>
<blockquote>
<p>Dictionary-guided Scene Text Recognition  </p>
</blockquote>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（十一）</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>END-TO-END STREAMING KEYWORD SPOTTING  </p>
<p>EFFICIENT KEYWORD SPOTTING USING DILATED CONVOLUTIONS AND GATING  </p>
<p>SEQUENCE-TO-SEQUENCE MODELS FOR SMALL-FOOTPRINT KEYWORD SPOTTING  </p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Lin, James, et al. “Training keyword spotters with limited and synthesized speech data.” <em>ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 2020.&#x3D;&#x3D;</p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/181298315">论文精读：Training Keyword Spotters</a></p>
</blockquote>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Wu, Haiwei, et al. “Domain aware training for far-field small-footprint keyword spotting.” <em>arXiv preprint arXiv:2005.03633</em> (2020).&#x3D;&#x3D;</p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/333477908">论文精读：Domain Aware Training</a></p>
</blockquote>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Chen, Wuyang, et al. “Collaborative global-local networks for memory-efficient segmentation of ultra-high resolution images.” <em>Proceedings of the IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition</em>. 2019.&#x3D;&#x3D; citations：85</p>
<p>github：<a href="https://github.com/chenwydj/ultra_high_resolution_segmentation">https://github.com/chenwydj/ultra_high_resolution_segmentation</a>  、<a href="https://github.com/VITA-Group/GLNet">https://github.com/VITA-Group/GLNet</a></p>
<p>简书：<a href="https://www.jianshu.com/p/8c76f0ddb447">Collaborative Global-Local Networks (GLNet)</a></p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出Global-Local Networks (GLNet)</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;He, Tong, et al. “Bag of tricks for image classification with convolutional neural networks.” <em>Proceedings of the IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition</em>. 2019.&#x3D;&#x3D;ciations：702</p>
<p>github：<a href="https://github.com/dmlc/gluon-cv">https://github.com/dmlc/gluon-cv</a>  </p>
</blockquote>
<h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><h4 id="Efficient-Training"><a href="#Efficient-Training" class="headerlink" title="Efficient Training"></a>Efficient Training</h4><ul>
<li>Large-batch training  认为大的batch会造成精度下降，而且训练更慢，对于凸问题，batch越大，收敛速度更慢。解决方法：<ul>
<li>**Linear scaling learning rate **：因为每个batch里的样本随机，因此梯度下降是随机的，更大的batch虽然也是随机的，但是它的方差更小，因此梯度下降的学习率可以设置更大；<ul>
<li>举例，batch size 256，学习率0.1，换成batch size &#x3D; b，学习率则改为 0.1 * b&#x2F;256；</li>
</ul>
</li>
<li><strong>Learning rate warmup</strong>：  在训练的开始，所有的参数通常是随机值，因此远离最终的解决方案。使用过大的学习率可能会导致数值不稳定。</li>
<li>**Zero $\gamma$  **：给BN层结尾的residual block（x+block(x)）的BN层的超参 $\gamma$ 初始化为0（$\gamma\hat{x}+\beta$）；这样返回的就是input x，一开始模型结构变得简单更易于训练；</li>
<li>**No bias decay  **：设置bias不需要进行weight decay（L2正则），BN层不进行weight decay；</li>
</ul>
</li>
<li><strong>Low-precision training</strong>  以往的训练都是32-bit floating point（FP32），FLOPS没有低精度FP16高，速度慢，因此部分参数用FP16比较好：<ul>
<li>store all parameters and activations in FP16  and use FP16 to compute gradients  </li>
<li>all parameters have an copy in FP32 for parameter updating  </li>
<li>multiplying a scalar to the loss to better align the range of the gradient into FP16</li>
</ul>
</li>
</ul>
<p>结果有小幅度的提升：</p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/image-20220314171704088.png" alt="image-20220314171704088" style="zoom:67%;">

<h4 id="Model-Tweaks改变模型结构"><a href="#Model-Tweaks改变模型结构" class="headerlink" title="Model Tweaks改变模型结构"></a>Model Tweaks改变模型结构</h4><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/image-20220314170820209.png" alt="image-20220314170820209" style="zoom:67%;">

<p>结果都有一定提升：</p>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/image-20220314170952706.png" alt="image-20220314170952706" style="zoom:67%;">

<h4 id="Training-Refinements"><a href="#Training-Refinements" class="headerlink" title="Training Refinements"></a>Training Refinements</h4><ul>
<li>**Cosine Learning Rate Decay **：学习率衰减策略用cos函数</li>
<li>&#x3D;&#x3D;**Label Smoothing **&#x3D;&#x3D;：</li>
</ul>
<p>$q_i&#x3D;<br>\begin{cases}<br>1-\epsilon&amp; \text{if i&#x3D;y}\<br>\epsilon&#x2F;(K-1)&amp; \text{otherwise}<br>\end{cases}$，                              $z_i^*&#x3D;<br>\begin{cases}<br>log((K-1)(1-\epsilon)&#x2F;\epsilon)+\alpha&amp; \text{if i&#x3D;y}\<br>\alpha&amp; \text{otherwise}<br>\end{cases}$</p>
<p>K是类别，如果K&#x3D;2，则分别是1-e，e</p>
<ul>
<li><strong>Knowledge Distillation</strong></li>
</ul>
<p>学生模型倒一层输出$z$，教师模型倒一层输出$r$，真实概率分布$p$，目标函数为   $l(p,softmax(z))+T^2l(softmax(r&#x2F;T),softmax(z&#x2F;T))$</p>
<p>T：温度超参，让softmax输出更smooth，从而从教师的预测中提炼出标签分布的知识；</p>
<ul>
<li><strong>Mixup Training</strong>  <ul>
<li>每个时刻，随机采样两个样本，加权线性插值构造新样本，然后用新样本进行训练；each time we randomly sample two examples (xi; yi) and (xj; yj). Then we form a new example by a weighted linear interpolation of these two examples:  </li>
<li>$\hat{x}&#x3D;\lambda{x}_i+(1-\lambda)x_j$，$\hat{y}&#x3D;\lambda{y}_i+(1-\lambda)y_j$</li>
<li>where λ 2 [0; 1] is a random number drawn from the Beta(α; α) distribution.  </li>
<li>In mixup training, we only use the new example $(\hat{x},\hat{y})$.</li>
</ul>
</li>
</ul>
<h4 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h4><hr>
<p><a href="https://readpaper.com/search/Region%20proposal%20network%20based%20small-footprint%20keyword%20spotting">https://readpaper.com/search/Region%20proposal%20network%20based%20small-footprint%20keyword%20spotting</a></p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Berg, Axel, Mark O’Connor, and Miguel Tairum Cruz. “Keyword transformer: A self-attention model for keyword spotting.” <em>arXiv preprint arXiv:2104.00769</em> (2021).&#x3D;&#x3D;</p>
<p>github：<a href="https://github.com/ARM-software/keyword-transformer">https://github.com/ARM-software/keyword-transformer</a></p>
<p>github：<a href="https://github.com/jingyonghou/Audiomer-PyTorch">https://github.com/jingyonghou/Audiomer-PyTorch</a></p>
</blockquote>
<hr>
<blockquote>
<p>&#x3D;&#x3D;He, Kaiming, et al. “Masked autoencoders are scalable vision learners.” <em>arXiv preprint arXiv:2111.06377</em> (2021).&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出一种masked autoencoder（MAE），scalable self-supervised learner 可扩展的自监督学习器，应用于计算机视觉中</li>
<li>MAE的结构是一个不对称的encoder-decoder结构：<ul>
<li>encoder只在可见的输入子集（subset of patches）上训练（输入mask，但token没有mask）</li>
<li>decoder是一个lightweight的decoder，输入隐藏层特征（latent representation）和mask token，输出重建的image</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/image-20220412150102662.png" alt="image-20220412150102662" style="zoom: 80%;">

<ul>
<li>mask随机块pathches，并且mask比例很大，大部分都要遮住（比如75%），大大改善自监督任务性能</li>
<li>为什么自编码器方法在计算机视觉里一开始用得少，在nlp用得多：<ul>
<li>因为卷积都是规规矩矩沿着常规grids计算的，mask token和positional embedding不好弄？Convolutions typically operate on regular grids and it is not straightforward to integrate ‘indicators’ such as mask tokens  or positional embeddings  【不知道mask token是什么，看bert论文【TODO】】，这个不同之处，通过Vision Transformers (ViT)  解决了；</li>
<li>nlp的文本信息是稠密的，每个字都是有用的，而图片信息分布稀疏，图片中缺失一些信息不影响图片识别；为了解决这个不同之处，提出了masking a very high portion of random patches，mask随机块pathches，并且mask比例很大，大部分都要遮住；这种策略在很大程度上减少了冗余，并创建了一个挑战性的自监督任务；</li>
<li>自编码器的decoder（decoder作用是将隐层特征映射回input），文本和图像的decoder也有所不同，视觉decoder输出的是像素pixels，像素的语义级别很低，低级特征，（那我们恢复的是音频特征，也是比较低级的），要输出信息量比较少、不具有代表性的输出，对decoder的要求就很高（nlp的自编码器decoder可以很简单，比如MLP），因此cv的自编码器的decoder建模能力要强；</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/image-20220412151956350.png" alt="image-20220412151956350">



<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/image-20220412152043014.png" alt="image-20220412152043014">



<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/image-20220412152111124.png" alt="image-20220412152111124" style="zoom:80%;">

<ul>
<li>Related Word<ul>
<li><strong>Masked language modeling</strong>：比如BERT和GPT，是输入特征序列只输入全序列中的部分序列，训练模型以预测缺失部分；</li>
<li><strong>Autoencoding</strong>  ：学习representation的经典方法，encoder映射 input 到 latent representation，decoder映射 latent representation到input，比如 PCA、k-means；Denoising autoencoders (DAE)   是破坏输入，输出未破坏的干净信号，来学会抗干扰能力；破坏的方法比如masking pixels 、removing color channels ；</li>
<li><strong>Masked image encoding</strong> ：应该是把encoding的输出也做mask，再给decoder？？</li>
<li><strong>Self-supervised learning</strong> ：  pre-training  、contrastive learning</li>
</ul>
</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Park, Daniel S., et al. “Specaugment: A simple data augmentation method for automatic speech recognition.” <em>arXiv preprint arXiv:1904.08779</em> (2019).&#x3D;&#x3D;citations：1603</p>
<p>[论文翻译]SpecAugment:一种用于自动语音识别的简单数据扩增方法 <a href="https://blog.ailemon.net/2020/03/09/paper-translation-specaugment-a-simple-data-augmentation-method-for-automatic-speech-recognition/">https://blog.ailemon.net/2020/03/09/paper-translation-specaugment-a-simple-data-augmentation-method-for-automatic-speech-recognition/</a></p>
</blockquote>
<h3 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h3><ul>
<li>之前论文里的数据扩展方法：VTLN、叠加噪声、速度扰动、模拟房间音频</li>
<li>提出一种数据增广方法，叫做 SpecAugment，对语音特征的log mel spectrogram 进行处理来进行数据增广（而不是直接对原始信号），这是因为特征做这些变形，有助于模型的robust，三种处理方法：<ul>
<li>time warping ：在时间轴进行变形，对应tensorflow的函数sparse_image_warp ，给定时间步t的特征，看作图像（时间轴是水平的，频率轴是垂直的）[?????]</li>
<li>time  masking  ：在连续时间步进行一些mask，$[t_0,t_0+t]$被masked，t是0-T之间的均匀分布中选的一个数（T是超参，叫time mask parameter），$t_0 \in [0,\tau-t]$</li>
<li>frequency  masking：在mel 频率channel进行一些mask，$f$个频谱被masked，masked区间$[f_0,f_0+f]$，<ul>
<li>$f$是从0到$F$之间的均匀分布中选出的一个数，$F$是超参（叫frequency mask parameter），</li>
<li>$f_0 \in [0,v-f]$中选出的一个值，$v$是mel frequency channel的总数</li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/image-20220414144527861.png" alt="image-20220414144527861" style="zoom: 80%;">















]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（十三）基于Transformer、conformer的识别</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="基于Transformer、conformer的识别"><a href="#基于Transformer、conformer的识别" class="headerlink" title="基于Transformer、conformer的识别"></a>基于Transformer、conformer的识别</h1><blockquote>
<p>&#x3D;&#x3D;Gulati, Anmol, et al. “Conformer: Convolution-augmented transformer for speech recognition.” <em>arXiv preprint arXiv:2005.08100</em> (2020).&#x3D;&#x3D;</p>
<p>github：<a href="https://github.com/lucidrains/conformer">https://github.com/lucidrains/conformer</a></p>
<p>github：<a href="https://github.com/openspeech-team/openspeech">https://github.com/openspeech-team/openspeech</a></p>
<p>github：<a href="https://github.com/open-mmlab/mmclassification">https://github.com/open-mmlab/mmclassification</a></p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li>transformer模型善于捕捉基于content的global interaction全部的影响，而CNN善于捕捉local features，结合二者，提出convolution-augmented transformer，称为conformer</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul>
<li>conformer encoder：</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220411160754591.png" alt="image-20220411160754591" style="zoom:80%;">

<p>conformer block的输入输出：</p>
<p>$\large \widetilde x_i&#x3D;x_i+\frac{1}{2}FFN(x_i) $		（Feed Forward Module）</p>
<p>$\large x_i’&#x3D;\widetilde x_i + MHSA(\widetilde x_i)$		（Multi-Head Self Attention Module）</p>
<p>$\large x_i’’&#x3D;x_i’+Conv(x_i’)$				（Convolution Module）</p>
<p>$\large y_i&#x3D;Layernorm(x_i’’+\frac{1}{2}FFN(x_i’’))$		（Feed Forward Module）</p>
<ul>
<li>Convolution Module：<ul>
<li>pointwise 卷积（每个channel只被一个卷积核卷），接门激活函数，接linear（gated linear unit（GLU）），接1维 depthwise 卷积</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220411161347727.png" alt="image-20220411161347727" style="zoom:80%;">

<ul>
<li>Multi-Head Self Attention Module：<ul>
<li>multi-headed self-attention (MHSA)   ，输入是relative positional embedding，位置编码适用于边长序列，后接prenorm residual units</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220411161425674.png" alt="image-20220411161425674" style="zoom:80%;">

<ul>
<li>Feed Forward Module</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220411161500457.png" alt="image-20220411161500457" style="zoom:80%;">

<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据：数据用SpecAugment进行增广，mask参数 F&#x3D;27；进行了10次mask，最大time-mask比ps&#x3D;0.05[???]</li>
<li>训练了参数量为10M，30M，118M的三个模型，decoder用的单层LSTM</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220412090008847.png" alt="image-20220412090008847" style="zoom:80%;">

<ul>
<li><p>每个residual unit都加dropout，P_dropout&#x3D;0.1，L2 正则（weight decay）&#x3D; 1e-6   ，</p>
</li>
<li><p>Adam optimizer ，$\beta_1&#x3D;0.9$，$\beta_2&#x3D;0.98$，$\epsilon&#x3D;10e^{-9}$， transformer learning rate schedule  </p>
</li>
<li><p>10k步 warmup，peak learning rate $0.05&#x2F;\sqrt d$ where d is the model dimension in conformer encoder</p>
</li>
<li><p>语言模型，用3层LSTM，width 4096，10千WPM，和声学模型用权重$\lambda$进行shallow fusion</p>
</li>
<li><p>实现框架用的 Lingvo toolkik</p>
</li>
<li><p>总体的模型对比，和ContextNet 、Transformer transducer  、QuartzNet  进行比较：</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220412104706101.png" alt="image-20220412104706101" style="zoom:80%;">

<ul>
<li>做了消融实验Ablation ，对比Conformer Block vs. Transformer Block：<ul>
<li>不同之处：conformer结果用了a convolution block and having a pair of FFNs surrounding the block in the Macaron-style.  </li>
<li>消融实验发现，convolution sub-block是最重要的特征</li>
<li>同等参数量下，马卡龙结构的FFN pair比单个FFN有改善（两个FFN中间夹着attention和conv）</li>
<li>用swish activations 能更快收敛（可能没改善？但是能加速收敛）</li>
</ul>
</li>
<li>Disentangling  conformer，把几个有用的分别用其他代替，看看哪个最影响识别率</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220412104649411.png" alt="image-20220412104649411" style="zoom:80%;">

<ul>
<li>Combinations of Convolution and Transformer Modules ：<ul>
<li>把depthwise 卷积换成 lightweight 卷积，效果马上变差，不ok</li>
<li>把convolution module放在MHSA module之前，效果变差一丢丢，不ok，卷积层放在注意力层之后会更好</li>
<li>convolution module和MHSA module并联，在concatenate，效果变差较多，不ok</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220412111130621.png" alt="image-20220412111130621" style="zoom:80%;">

<ul>
<li>Macaron Feed Forward Modules  <ul>
<li>transformer用的single FFN，conformer用的前后两个FNN（称之为FFN pair），包裹中间的 MHSA module和convolution module（像sandwiching  三明治&#x2F;Macaron  马卡龙结构）</li>
<li>Conformer feed forward modules are used with half-step residuals</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220412113607307.png" alt="image-20220412113607307" style="zoom:80%;">

<ul>
<li>Number of Attention Heads ：不同head数量 、dim的影响，觉得head&#x3D;16好一点</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220412124137582.png" alt="image-20220412124137582" style="zoom: 67%;">

<ul>
<li>Convolution Kernel Sizes ：在{3, 7, 17, 32, 65}   ，kerenl size对性能的改善是先增后降，32最好</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89/image-20220412124554861.png" alt="image-20220412124554861" style="zoom: 67%;">

<p>最后两个实验感觉是凑数的</p>
<h3 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h3><ul>
<li><input checked disabled type="checkbox"> swish activations？</li>
<li><input disabled type="checkbox"> lightweight？</li>
</ul>
<h3 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h3><ul>
<li><p>设计模块的方式：马卡龙方式</p>
</li>
<li><p>卷积和自注意力模块的组合方式：卷积在后</p>
</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（十二）Awesome Keyword Spotting</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Awesome-Keyword-Spotting"><a href="#Awesome-Keyword-Spotting" class="headerlink" title="Awesome Keyword Spotting"></a>Awesome Keyword Spotting</h1><blockquote>
<p>github：<a href="https://github.com/zycv/awesome-keyword-spotting">awesome-keyword-spotting</a></p>
</blockquote>
<h2 id="Table-of-contents"><a href="#Table-of-contents" class="headerlink" title="Table of contents"></a>Table of contents</h2><ul>
<li><a href="#awesome-keyword-spotting">Awesome Keyword Spotting</a><ul>
<li><a href="#table-of-contents">Table of contents</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#publications">Publications</a><ul>
<li><a href="#2022">2022</a></li>
<li><a href="#2021">2021</a></li>
<li><a href="#2020">2020</a></li>
<li><a href="#2019">2019</a></li>
<li><a href="#2018">2018</a></li>
<li><a href="#others">Others</a></li>
</ul>
</li>
<li><a href="#opensource-code">OpenSource Code</a></li>
<li><a href="#software">Software</a></li>
<li><a href="#datesets">Datesets</a></li>
<li><a href="#challenge">Challenge</a></li>
<li><a href="#leaderboard">Leaderboard</a></li>
</ul>
</li>
</ul>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>In speech processing, keyword spotting deals with the identification of keywords in utterances. This repo is a curated list of awesome Speech Keyword Spotting (Wake-Up Word Detection) papers.</p>
<h2 id="Survey"><a href="#Survey" class="headerlink" title="Survey"></a>Survey</h2><ul>
<li><a href="https://arxiv.org/abs/2111.10592">Deep Spoken Keyword Spotting: An Overview</a>, JOHN H.L. HANSEN (Fellow, IEEE), 2021.11</li>
</ul>
<h2 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h2><h3 id="2022"><a href="#2022" class="headerlink" title="2022"></a>2022</h3><ul>
<li><a href="https://arxiv.org/abs/2202.06483v1">BiFSMN: Binary Neural Network for Keyword Spotting</a>,Beihang University &amp; Bytedance AI Lab,2022.02</li>
<li><a href="https://arxiv.org/abs/2202.02361">A Fast Network Exploration Strategy to Profile Low Energy Consumption for Keyword Spotting</a>, University of Maryland, Baltimore County, 2022.02</li>
<li><a href="https://arxiv.org/abs/2201.12546">Progressive Continual Learning for Spoken Keyword Spotting</a>, A*STAR, Singapore &amp; Nanyang Technological University, 2022.01</li>
<li><a href="https://arxiv.org/abs/2201.05863">ConvMixer: Feature Interactive Convolution with Curriculum Learning for Small Footprint and Noisy Far-field Keyword Spotting</a>, Alibaba &amp; Nanyang Technological University, 2022.01</li>
</ul>
<h3 id="2021"><a href="#2021" class="headerlink" title="2021"></a>2021</h3><ul>
<li><a href="https://arxiv.org/abs/2112.01757">BBS-KWS:The Mandarin Keyword Spotting System Won the Video Keyword Wakeup Challenge</a>, Netease, 2021.12</li>
<li><a href="https://arxiv.org/abs/2111.10639">Implicit Acoustic Echo Cancellation for Keyword Spotting and Device-Directed Speech Detection</a>, Universita Politecnica delle Marche &amp; Amazon, 2021.11</li>
<li><a href="https://arxiv.org/abs/2111.01456">WaveSense: Efficient Temporal Convolutions with Spiking Neural Networks for Keyword Spotting</a>, SynSense AG, 2021.11</li>
<li><a href="https://arxiv.org/abs/2110.07498">End-to-end Keyword Spotting using Xception-1d</a>, University of Valencia, 2021.10</li>
<li><a href="https://arxiv.org/abs/2110.01077">Multi-task Voice Activated Framework using Self-supervised Learning</a>, University of California &amp; Qualcomm, 2021.10</li>
<li><a href="https://arxiv.org/abs/2109.11165">Lightweight dynamic filter for keyword spotting</a>, Korea University &amp; Drexel University, 2021.09</li>
<li><a href="https://arxiv.org/abs/2109.10252">Audiomer: A Convolutional Transformer for Keyword Spotting</a>, George Mason University, 2021.09</li>
<li><a href="https://arxiv.org/abs/2109.07930">Behavior of Keyword Spotting Networks Under Noisy Conditions</a>, Indian Institute Technology &amp; University of T¨ubingen, 2021.09</li>
<li><a href="https://arxiv.org/abs/2109.00260">A Separable Temporal Convolution Neural Network with Attention for Small-Footprint Keyword Spotting</a>, Beijing Institute of Technology &amp; Xiaomi Inc., 2021.09</li>
<li><a href="https://arxiv.org/abs/2108.05516">Text Anchor Based Metric Learning for Small-footprint Keyword Spotting</a>, ADSPLAB Peking University, 2021.08</li>
<li><a href="https://arxiv.org/abs/2107.07634">Multi-task Learning with Cross Attention for Keyword Spotting</a>, Apple &amp; The University of Hong Kong, 2021.07</li>
<li><a href="https://arxiv.org/abs/2107.05859">AUC Optimization for Robust Small-footprint Keyword Spotting with Limited Training Data</a>, Northwestern Polytechnical University, 2021.07</li>
<li><a href="https://arxiv.org/abs/2106.15950">An Integrated Framework for Two-pass Personalized Voice Trigger</a>, Xiamen University, 2021.06</li>
<li><a href="https://arxiv.org/abs/2106.10019">Zero-Shot Federated Learning with New Classes for Audio Classification</a>, Global AI Accelerator, Ericsson, 2021.06</li>
<li><a href="https://arxiv.org/abs/2106.04140">Broadcasted Residual Learning for Efficient Keyword Spotting</a>, Qualcomm AI Research, 2021.06</li>
<li><a href="https://arxiv.org/abs/2106.02738">Encoder-Decoder Neural Architecture Optimization for Keyword Spotting</a>, University of Alberta &amp; University of Montreal, 2021.06</li>
<li><a href="https://arxiv.org/abs/2106.02443">Teaching keyword spotters to spot new keywords with limited examples</a>, Google Research, 2021.06</li>
<li><a href="https://arxiv.org/abs/2106.01604">Noisy student-teacher training for robust keyword spotting</a>, Google Inc., 2021.06</li>
<li><a href="https://arxiv.org/abs/2105.10042">A Streaming End-to-End Framework For Spoken Language Understanding</a>, University of Waterloo &amp; HuaWei &amp; Tsinghua University, 2021.05</li>
<li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9427206">Wav2KWS: Transfer Learning from Speech Representations for Keyword Spotting</a>, Kumoh National Institute of Technology (KIT), 2021.05</li>
<li><a href="https://arxiv.org/abs/2105.06598">Streaming Transformer for Hardware Efficient Voice Trigger Detection and False Trigger Mitigation</a>, Apple, 2021.05</li>
<li><a href="https://arxiv.org/abs/2104.08086">Efficient Keyword Spotting through long-range interactions with Temporal Lambda Networks</a>, Universitat Polit ́ecnica de Catalunya, 2021.04</li>
<li><a href="https://arxiv.org/abs/2104.06666">End-to-end Keyword Spotting using Neural Architecture Search and Quantization</a>, Graz University of Technology, 2021.04</li>
<li><a href="https://arxiv.org/abs/2104.04993">The DKU System Description for The Interspeech 2021 Auto-KWS Challenge</a>, Duke Kunshan University, 2021.04</li>
<li><a href="https://arxiv.org/abs/2104.01454">Few-Shot Keyword Spotting in Any Language</a>, Harvard University &amp; Coqui &amp; Google, 2021.04</li>
<li><a href="https://arxiv.org/pdf/2104.00769">Keyword Transformer A Self-Attention Model for Keyword Spotting</a>, Arm ML Research Lab, 2021.04</li>
<li><a href="https://arxiv.org/pdf/2101.04792">Learning Efficient Representations for Keyword Spotting with Triplet Loss</a>, Tomsk State University &amp; NTR Labs, 2021.01</li>
<li><a href="https://arxiv.org/pdf/2101.01935">The 2020 Personalized Voice Trigger Challenge: Open Database, Evaluation Metrics and the Baseline Systems</a>, Duke Kunshan University, 2021.01</li>
</ul>
<h3 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h3><ul>
<li><a href="https://arxiv.org/pdf/2011.01151">Optimize what matters: Training DNN-HMM Keyword Spotting Model Using End Metric</a>, Apple, 2020.11</li>
<li><a href="https://arxiv.org/pdf/2011.01460">Training Wake Word Detection with Synthesized Speech Data on Confusion Words</a>, Duke Kunshan University, 2020.11</li>
<li><a href="https://arxiv.org/pdf/2011.02198">Ieee slt 2021 alpha-mini speech challenge: Open datasets, tracks, rules and baselines</a>, Northwestern Polytechnical University, 2020.11</li>
<li><a href="https://asmp-eurasipjournals.springeropen.com/track/pdf/10.1186/s13636-020-00176-2.pdf">A depthwise separable convolutional neural network for keyword spotting on an embedded system</a>, Technical University of Denmark, 2020.10</li>
<li><a href="https://arxiv.org/pdf/2010.09960">Small-Footprint Keyword Spotting with Multi-Scale Temporal Convolution</a>, University of Science and Technology of China, 2020.10</li>
<li><a href="https://proceedings.mlsys.org/paper/2021/file/a3c65c2974270fd093ee8a9bf8ae7d0b-Paper.pdf">Micronets: Neural network architectures for deploying tinyml applications on commodity microcontrollers</a>, Arm ML Research &amp; Harvard University, 2020.10</li>
<li><a href="https://arxiv.org/pdf/2009.00165">Neural Architecture Search For Keyword Spotting</a>, University of Alberta &amp; Huawei Technologies, 2020.09</li>
<li><a href="https://arxiv.org/pdf/2009.01225">Seeing wake words: Audio-visual keyword spotting</a>, University of Oxford, 2020.09</li>
<li><a href="https://arxiv.org/pdf/2009.03658">AutoKWS: Keyword Spotting with Differentiable Architecture Search</a>, Xiaomi AI Lab, 2020.09</li>
<li><a href="https://arxiv.org/pdf/2009.04465">Hardware Aware Training for Efficient Keyword Spotting on General Purpose and Specialized Hardware</a>, Applied Brain Research Inc., 2020.09</li>
<li><a href="https://arxiv.org/pdf/2008.00209">Neural ODE with Temporal Convolution and Time Delay Neural Networks for Small-Footprint Keyword Spotting</a>, AIST, 2020.08</li>
<li><a href="https://arxiv.org/pdf/2008.07109">WSRNet: Joint Spotting and Recognition of Handwritten Words</a>, National Technical University of Athens, 2020.08</li>
<li><a href="https://indico2.conference4me.psnc.pl/event/35/contributions/3468/attachments/1026/1067/Wed-2-2-4.pdf">Domain Aware Training for Far-field Small-footprint Keyword Spotting</a>, Duke Kunshan University, 2020.08</li>
<li><a href="https://arxiv.org/pdf/2007.10706">Very Fast Keyword Spotting System with Real Time Factor Below 0.01</a>, Technical University of Liberec, 2020.07</li>
<li><a href="https://arxiv.org/pdf/2007.14463">Few-Shot Keyword Spotting With Prototypical Networks</a>, The University of North Carolina at Charlotte, 2020.07</li>
<li><a href="https://arxiv.org/pdf/2006.00217">Exploring Filterbank Learning for Keyword Spotting</a>, Aalborg University, 2020.06</li>
<li><a href="http://lxie.nwpu-aslp.org/papers/2020ICASSP_HJY.pdf">Mining Effective Negative Training Samples for Keyword Spotting</a>, Northwestern Polytechnical University &amp; Mobvoi Inc., 2020.05</li>
<li><a href="https://arxiv.org/pdf/2005.10406">Training Keyword Spotting Models on Non-IID Data with Federated Learning</a>, Google LLC, 2020.05</li>
<li><a href="https://arxiv.org/pdf/2005.03867">Multi-Task Network for Noise-Robust Keyword Spotting and Speaker Verification using CTC-based Soft VAD and Global Query Attention</a>, KAIST, 2020.05</li>
<li><a href="https://arxiv.org/pdf/2005.06720">Streaming keyword spotting on mobile devices</a>, Google Research, 2020.05</li>
<li><a href="https://arxiv.org/pdf/2005.08776">Metric Learning for Keyword Spotting</a>, Naver Corporation, 2020.05</li>
<li><a href="https://arxiv.org/pdf/2005.10386">End-to-End Multi-Look Keyword Spotting</a>, Tencent AI Lab, 2020.05</li>
<li><a href="https://arxiv.org/pdf/2004.12200">Depthwise Separable Convolutional ResNet with Squeeze-and-Excitation Blocks for Small-footprint Keyword Spotting</a>, Northwestern Polytechnical University, 2020.04</li>
<li><a href="https://arxiv.org/pdf/2002.04992">Phoneme boundary detection using learnable segmental features</a>, Bar-Ilan University &amp; Facebook Inc., 2020.02</li>
<li><a href="https://arxiv.org/pdf/2002.10851">Small-Footprint Open-Vocabulary Keyword Spotting with Quantized LSTM Networks</a>, Sonos Inc., 2020.02</li>
<li><a href="https://arxiv.org/pdf/2002.01322">Training Keyword Spotters with Limited and Synthesized Speech Data</a>, Google Research, 2020.02</li>
<li><a href="https://arxiv.org/pdf/2001.09246">Learning to detect keyword parts and whole by smoothed max pooling</a>, Google Inc. 2020.01</li>
<li><a href="https://arxiv.org/pdf/2001.10816">Multi-Task Learning for Speaker Verification and Voice Trigger Detection</a>, Apple, 2020.01</li>
<li><a href="https://arxiv.org/pdf/2001.02976">Performance-Oriented Neural Architecture Search</a>, Trinity College Dublin, 2020.01</li>
</ul>
<h3 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h3><ul>
<li><a href="https://arxiv.org/pdf/1912.05124">Small-footprint keyword spotting with graph convolutional network</a>, Tsinghua University, 2019.12</li>
<li><a href="https://arxiv.org/pdf/1912.07575">Predicting detection filters for small footprint open-vocabulary keyword spotting</a>, 2019.12</li>
<li><a href="https://arxiv.org/pdf/1911.01803">Temporal feedback convolutional recurrent neural networks for keyword spotting</a>, KAIST, 2019.11</li>
<li><a href="https://arxiv.org/pdf/1911.02086">Small-footprint keyword spotting on raw audio data with sinc-convolutions</a>, Technische Universität München, 2019.11</li>
<li><a href="https://arxiv.org/pdf/1910.04500">Orthogonality constrained multi-head attention for keyword spotting</a>, Qualcomm AI Research, 2019.10</li>
<li><a href="https://arxiv.org/pdf/1910.05171">Query-by-example on-device keyword spotting</a>, Qualcomm AI Research, 2019.10</li>
<li><a href="https://arxiv.org/pdf/1910.10013">Adversarial example detection by classification for deep speech recognition</a>, Aalborg University, 2019.10</li>
<li><a href="https://arxiv.org/pdf/1909.05623">A Channel-Pruned and Weight-Binarized Convolutional Neural Network for Keyword Spotting</a>, UC Irvine, 2019.09</li>
<li><a href="https://arxiv.org/pdf/1907.01448">Sub-band Convolutional Neural Networks for Small-footprint Spoken Term Classification</a>, Amazon, 2019.07</li>
<li><a href="https://arxiv.org/pdf/1907.03988">Improving reverberant speech training using diffuse acoustic simulation</a>, University of Maryland &amp; Tencent, 2019.07</li>
<li><a href="https://arxiv.org/pdf/1907.04536">Multi-layer Attention Mechanism for Speech Keyword Recognition</a>, Sichuan University, 2019.07</li>
<li><a href="https://arxiv.org/pdf/1906.08415">A Monaural Speech Enhancement Method for Robust Small-Footprint Keyword Spotting</a>, Inner Mongolia University, 2019.06</li>
<li><a href="https://arxiv.org/pdf/1906.09417">Keyword Spotting for Hearing Assistive Devices Robust to External Speakers</a>, Aalborg University, 2019.06</li>
<li><a href="https://arxiv.org/pdf/1904.03814">Temporal Convolution for Real-time Keyword Spotting on Mobile Devices</a>, Hyperconnect, 2019.04</li>
<li><a href="https://arxiv.org/pdf/1904.07704">SpeechYOLO: Detection and Localization of Speech Objects</a>, Bar-Ilan University, 2019.04</li>
<li><a href="https://arxiv.org/pdf/1903.01531">Ternary hybrid neural-tree networks for highly constrained iot applications</a>, Arm ML Research Lab. 2019.03</li>
<li><a href="https://research.fb.com/wp-content/uploads/2019/03/Stochastic-Adaptive-Neural-Architecture-Search-for-Keyword-Spotting-.pdf">Stochastic Adaptive Neural Architecture Search for Keyword Spotting</a>, Paris &amp; Facebook AI Research, 2019.03</li>
<li><a href="https://ieeexplore.ieee.org/document/8807313">Region Proposal Network Based Small-Footprint Keyword Spotting</a>, Northwestern Polytechnical University &amp; Mobvoi, 2019.08</li>
<li><a href="https://researchonline.jcu.edu.au/61847/">An In-Vehicle Keyword Spotting System with Multi-Source Fusion for Vehicle Applications</a>, Beijing University of Posts and Telecommunications, 2019.02</li>
<li><a href="https://arxiv.org/pdf/1811.07684">Efficient keyword spotting using dilated convolutions and gating</a>,Snips, 2019.01</li>
<li><a href="https://arxiv.org/pdf/1812.02802">End-to-end streaming keyword spotting</a>, Google Inc. 2019.01</li>
<li><a href="https://arxiv.org/pdf/1901.03860">Prototypical metric transfer learning for continuous speech keyword spotting with limited training data</a>, ParallelDots, Inc. 2019.01</li>
</ul>
<h3 id="2018"><a href="#2018" class="headerlink" title="2018"></a>2018</h3><ul>
<li><a href="https://arxiv.org/pdf/1812.01739">Benchmarking Keyword Spotting Efficiency on Neuromorphic Hardware</a>, Applied Brain Research, Inc., 2018.12</li>
<li><a href="https://arxiv.org/pdf/1812.07754">Streaming Voice Query Recognition using Causal Convolutional Recurrent Neural Networks</a>, University of Waterloo, 2018.12</li>
<li><a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/2204.pdf">Efficient Voice Trigger Detection for Low Resource Hardware</a>, Siri Speech, 2018.11 Apple,</li>
<li><a href="https://arxiv.org/pdf/1811.00348">Sequence-to-sequence models for small-footprint keyword spotting</a>, Xiaomi Inc., 2018.11</li>
<li><a href="https://arxiv.org/pdf/1811.00350">End-to-end Models with auditory attention in Multi-channel Keyword Spotting</a>, Xiaomi Inc., 2018.11</li>
<li><a href="https://arxiv.org/pdf/1811.02320">Hierarchical Neural Network Architecture In Keyword Spotting</a>, NIO Co., Ltd, 2018.11</li>
<li><a href="https://arxiv.org/pdf/1811.08284">Feature exploration for almost zero-resource ASR-free keyword spotting using a multilingual bottleneck extractor and correspondence autoencoders</a>, Stellenbosch University, 2018.11</li>
<li><a href="https://arxiv.org/pdf/1811.10736">DONUT: CTC-based Query-by-Example Keyword Spotting</a>, Fluent.ai, 2018.11</li>
<li><a href="https://arxiv.org/pdf/1810.05512">Federated learning for keyword spotting</a>, Snips, 2018.10</li>
<li><a href="https://arxiv.org/pdf/1810.12859">JavaScript Convolutional Neural Networks for Keyword Spotting in the Browser: An Experimental Analysis</a>, University of Waterloo, 2018.10</li>
<li><a href="https://arxiv.org/pdf/1808.00563">Data augmentation for robust keyword spotting under playback interference</a>, Amazon Alexa &amp; Google Inc &amp; Purdue University, 2018.08</li>
<li><a href="https://arxiv.org/pdf/1808.00639">Sequence discriminative training for deep learning based acoustic keyword spotting</a>, Zhehuai Chen, 2018.08</li>
<li><a href="https://arxiv.org/pdf/1807.00560">Weight-importance sparse training in keyword spotting</a>, NIO Co., Ltd, 2018.07</li>
<li><a href="https://arxiv.org/pdf/1807.04353">Efficient keyword spotting using time delay neural networks</a>, Fluent.ai Inc., 2018.07</li>
<li><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Themos_Stafylakis_Zero-shot_keyword_search_ECCV_2018_paper.pdf">Zero-shot keyword spotting for visual speech recognition in-the-wild</a>, University of Nottingham, 2018.07</li>
<li><a href="https://arxiv.org/pdf/1807.08666">ASR-free CNN-DTW keyword spotting using multilingual bottleneck features for almost zero-resource languages</a>, Stellenbosch University, 2018.07</li>
<li><a href="https://arxiv.org/pdf/1806.07912">Resource-Efficient Neural Architect</a>, Baidu, 2018.06</li>
<li><a href="https://arxiv.org/pdf/1806.05030">Visually grounded cross-lingual keyword spotting in speech</a>, Stellenbosch University, 2018.06</li>
<li><a href="https://arxiv.org/pdf/1804.03209">Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition</a>, Google Brain, 2018.04</li>
<li><a href="https://arxiv.org/pdf/1804.05166">Developing far-field speaker system via teacher-student learning</a>, Microsoft AI &amp; Research, 2018.04</li>
<li><a href="https://arxiv.org/abs/1803.01271">An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</a>, Carnegie Mellon University, 2018.03</li>
<li><a href="https://arxiv.org/pdf/1803.03759">Speech recognition: keyword spotting through image recognition</a>, UCSU, 2018.03</li>
<li><a href="https://arxiv.org/pdf/1803.10916">Attention-based End-to-End Models for Small-Footprint Keyword Spotting</a>, Xiaomi Inc., 2018.03</li>
</ul>
<h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><ul>
<li><a href="https://arxiv.org/pdf/1712.03603">A Cascade Architecture for Keyword Spotting on Mobile Devices</a>, Google Inc. 2017.12</li>
<li><a href="https://arxiv.org/pdf/1711.08058">Multiple-Instance, Cascaded Classification for Keyword Spotting in Narrow-Band Audio</a>, Voicera, 2017.11</li>
<li><a href="https://arxiv.org/pdf/1711.00333">An experimental analysis of the power consumption of convolutional neural networks for keyword spotting</a>, University of Waterloo, 2017.11</li>
<li><a href="https://arxiv.org/abs/1711.07128">Hello Edge: Keyword Spotting on Microcontrollers</a>, Arm &amp; Stanford University, 2017.11</li>
<li><a href="https://arxiv.org/pdf/1710.10361">Deep residual learning for small-footprint keyword spotting</a>, University of Waterloo, 2017.10</li>
<li><a href="https://arxiv.org/pdf/1710.09617">Streaming small-footprint keyword spotting using sequence-to-sequence models</a>, 2017.10</li>
<li><a href="https://arxiv.org/pdf/1709.03665">Small-footprint keyword spotting using deep neural network and connectionist temporal classifier</a>, Ant Financial Group, 2017.09</li>
<li><a href="https://pdfs.semanticscholar.org/8eda/5fa7103406403a14342336c684b666dfdfc8.pdf">Compressed Time Delay Neural Network for Small-Footprint Keyword Spotting</a>, Amazon, 2017.08</li>
<li><a href="https://arxiv.org/pdf/1705.02411">Max-pooling loss training of long short-term memory networks for small-footprint keyword spotting</a>, Amazon &amp; Google Brain, 2017.05</li>
<li><a href="https://arxiv.org/pdf/1703.05390">Convolutional Recurrent Neural Networks for Small-Footprint Keyword Spotting</a>, Baidu, 2017.03</li>
<li><a href="https://arxiv.org/pdf/1611.09405">An End-to-End Architecture for Keyword Spotting and Voice Activity Detection</a>, Mindori, 2016.11</li>
<li><a href="https://arxiv.org/pdf/1607.05666">Trainable Frontend For Robust and Far-Field Keyword Spotting</a>, Google, 2016.07</li>
<li><a href="https://pdfs.semanticscholar.org/22f3/6191692485746b1a67d722d5364a5365c132.pdf">Low Resource High Accuracy Keyword Spotting</a>, Guoguo Chen, 2016</li>
<li><a href="https://arxiv.org/pdf/1512.08903">Online keyword spotting with a character-level recurrent neural network</a>, 2015.12</li>
<li><a href="https://arxiv.org/pdf/1510.01722">Structured Transforms for Small-Footprint Deep Learning</a>, Google, 2015.10</li>
<li><a href="https://research.google/pubs/pub42537.pdf">Small-footprint keyword spotting using deep neural networks</a>, Guoguo Chen, 2014</li>
</ul>
<h2 id="OpenSource-Code"><a href="#OpenSource-Code" class="headerlink" title="OpenSource Code"></a>OpenSource Code</h2><ul>
<li><a href="https://github.com/qute012/Wav2Keyword">Github: Wav2KWS: Transfer Learning from Speech Representations for Keyword Spotting</a> ( <strong>State-of-the-Art</strong> )</li>
<li><a href="https://github.com/jingyonghou/KWS_Max-pooling_RHE">Github: Mining Effective Negative Training Samples for Keyword Spotting</a></li>
<li><a href="https://github.com/PeterMS123/KWS-DS-CNN-for-embedded">Github: A depthwise separable convolutional neural network for keyword spotting on an embedded system</a></li>
<li><a href="https://github.com/ARM-software/ML-KWS-for-MCU">Github: Hello Edge: Keyword spotting on Microcontrollers</a></li>
<li><a href="https://github.com/harvard-edge/multilingual_kws">Github: Few-Shot Keyword Spotting in Any Language</a></li>
<li><a href="https://github.com/roman-vygon/triplet_loss_kws">Github: Learning Efficient Representations for Keyword Spotting with Triplet Loss</a></li>
<li><a href="https://github.com/lenovo-voice/THE-2020-PERSONALIZED-VOICE-TRIGGER-CHALLENGE-BASELINE-SYSTEM">Github: The 2020 Personalized Voice Trigger Challenge: Open Database, Evaluation Metrics and the Baseline Systems</a></li>
<li><a href="https://github.com/ARM-software/ML-zoo">Github: Micronets: Neural network architectures for deploying tinyml applications on commodity microcontrollers</a></li>
<li><a href="https://github.com/fkhiro/kws-ode">Github: Neural ODE with Temporal Convolution and Time Delay Neural Networks for Small-Footprint Keyword Spotting</a></li>
<li><a href="https://github.com/ArchitParnami/Few-Shot-KWS">Github: Few-Shot Keyword Spotting With Prototypical Networks</a></li>
<li><a href="https://github.com/jingyonghou/RPN_KWS">Region Proposal Network Based Small-Footprint Keyword Spotting</a></li>
<li><a href="https://gamma.umd.edu/pro/speech/asr">Official code: Improving reverberant speech training using diffuse acoustic simulation</a></li>
<li><a href="https://github.com/hyperconnect/TC-ResNet">Github: Temporal Convolution for Real-time Keyword Spotting on Mobile Devices</a></li>
<li><a href="https://github.com/abr/power_benchmarks/">Github: Benchmarking Keyword Spotting Efficiency on Neuromorphic Hardware</a></li>
</ul>
<h2 id="Software"><a href="#Software" class="headerlink" title="Software"></a>Software</h2><ol>
<li><p><a href="https://github.com/wenet-e2e/wekws">WeKws (Production First and Production Ready End-to-End Keyword Spotting Toolkit)</a></p>
<p> Small footprint keyword spotting (KWS), or specifically wake-up word (WuW) detection is a typical and important module in internet of things (IoT) devices. It provides a way for users to control IoT devices with a hands-free experience. A WuW detection system usually runs locally and persistently on IoT devices, which requires low consumptional power, less model parameters, low computational comlexity and to detect predefined keyword in a streaming way, i.e., requires low latency.</p>
</li>
<li><p><a href="https://github.com/Picovoice/porcupine">Porcupine</a></p>
<p>Porcupine is a highly-accurate and lightweight wake word engine. It enables building always-listening voice-enabled applications.</p>
</li>
<li><p><a href="https://github.com/evancohen/sonus">Sonus</a></p>
<p> Sonus lets you quickly and easily add a VUI (Voice User Interface) to any hardware or software project. Just like Alexa, Google Assistant, and Siri, Sonus is always listening offline for a customizable hotword. Once that hotword is detected your speech is streamed to the cloud recognition service of your choice - then you get the results in realtime.</p>
</li>
<li><p><a href="https://github.com/Picovoice/picovoice">Picovoice</a></p>
<p> Picovoice is the end-to-end platform for building voice products on your terms. Unlike Alexa and Google services, Picovoice runs entirely on-device while being more accurate.</p>
</li>
<li><p><a href="https://github.com/MycroftAI/mycroft-precise">Mycroft Precise</a></p>
<p> A lightweight, simple-to-use, RNN wake word listener.</p>
<p> Precise is a wake word listener. The software monitors an audio stream ( usually a microphone ) and when it recognizes a specific phrase it triggers an event. For example, at Mycroft AI the team has trained Precise to recognize the phrase “Hey, Mycroft”. When the software recognizes this phrase it puts the rest of Mycroft’s software into command mode and waits for a command from the person using the device. Mycroft Precise is fully open source and can be trined to recognize anything from a name to a cough.</p>
</li>
</ol>
<h2 id="Datesets"><a href="#Datesets" class="headerlink" title="Datesets"></a>Datesets</h2><ol>
<li><p>Speech Commands</p>
<ul>
<li><p>Homepage: <a href="https://arxiv.org/abs/1804.03209">Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition</a></p>
</li>
<li><p>Description: An audio dataset of spoken words designed to help train and evaluate keyword spotting systems. Its primary goal is to provide a way to build and test small models that detect when a single word is spoken, from a set of ten target words, with as few false positives as possible from background noise or unrelated speech. Note that in the train and validation set, the label “unknown” is much more prevalent than the labels of the target words or background noise. One difference from the release version is the handling of silent segments. While in the test set the silence segments are regular 1 second files, in the training they are provided as long segments under “background_noise” folder. Here we split these background noise into 1 second clips, and also keep one of the files for the validation set.</p>
</li>
<li><p>Download:</p>
<ul>
<li><p>training data: <a href="http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz">http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz</a></p>
</li>
<li><p>test data: <a href="http://download.tensorflow.org/data/speech_commands_test_set_v0.02.tar.gz">http://download.tensorflow.org/data/speech_commands_test_set_v0.02.tar.gz</a></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Mobvoi Hotwords</p>
<ul>
<li><p>Homepage: <a href="http://openslr.org/87/">Region Proposal Network Based Small-Footprint Keyword Spotting</a></p>
</li>
<li><p>Description:</p>
<ul>
<li>The MobvoiHotwords is a corpus of wake-up words collected from a commercial smart speaker of Mobvoi. It consists of keyword and non-keyword utterances.</li>
<li>For keyword data, keyword utterances contain either ‘Hi xiaowen’ or ‘Nihao Wenwen’ are collected. For each keyword, there are about 36k utterances. All keyword data is collected from 788 subjects, ages 3-65, with different distances from the smart speaker (1, 3 and 5 meters). Different noises (typical home environment noises like music and TV) with varying sound pressure levels are played in the background during the collection. The keyword data is identical to the keyword data used in the paper below:</li>
</ul>
</li>
<li><p>Download: <a href="http://openslr.org/87/">MobvoiHotwords</a></p>
</li>
</ul>
</li>
<li><p>HI-MIA</p>
<ul>
<li><p>Homepage: <a href="http://www.aishelltech.com/wakeup_data">A far-field text-dependent speaker verification database for AISHELL Speaker Verification Challenge 2019</a></p>
</li>
<li><p>Description:</p>
<ul>
<li>The data is used in AISHELL Speaker Verification Challenge 2019. It is extracted from a larger database called AISHELL-WakeUp-1.</li>
<li>The contents are wake-up words “Hi, Mia” in both Chinese and English. The data is collected in real home environment using microphone arrays and Hi-Fi microphone. The collection process and development of a baseline system was described in the paper below. The data used in the challenge is extracted from 1 Hi-Fi microphone and 16-channel circular microphone arrays for 1&#x2F;3&#x2F;5 meters. And the contents are the Chinese wake-up words. The whole set is divided into train (254 people), dev (42 people) and test (44 people) subsets. Test subset is provided with paired target&#x2F;non-target answer to evaluate verification results.</li>
</ul>
</li>
<li><p>Download: <a href="http://openslr.org/85/">HI-MIA</a></p>
</li>
</ul>
</li>
</ol>
<h2 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h2><ol>
<li><p><a href="https://www.4paradigm.com/content/details_85_1870.html">AutoSpeech 2020 Challenge</a></p>
<p>In this challenge, we further propose the Automated Speech (AutoSpeech) competition which aims at proposing automated solutions for speech-related tasks. This challenge is restricted to multi-label classification problems, which come from different speech classification domains. The provided solutions are expected to discover various kinds of paralinguistic speech attribute information, such as speaker, language, emotion, etc, when only raw data (speech features) and meta information are provided. There are two kinds of datasets, which correspond to public and private leaderboard respectively. Five public datasets (without labels in the testing part) are provided to the participants for developing AutoSpeech solutions. Afterward, solutions will be evaluated on private datasets without human intervention. The results of these private datasets determine the final ranking.</p>
<p>Officical Code: <a href="https://github.com/VITA-Group/AutoSpeech">AutoSpeech</a></p>
</li>
<li><p><a href="https://www.pvtc2020.org/">The 2020 Personalized Voice Trigger Challenge (PVTC2020)</a></p>
<p>Recently, personalized voice trigger or wake-up word detection is gaining popularity among speech researchers and developers. Conventionally, the wake-up word detection and speaker verification are carried out separately in pipeline, where a wake-up word detection system is used to generate successful trigger followed by a speaker verification system used to perform identity authentication. In such case, the wake-up word detection system and the speaker verification system are optimized separately, not through an overall joint optimization with a unified goal. As a consequence, their respective network parameters and extracted information are not effectively shared and jointly utilized. Generally the wake-up word detection system needs to run all the time，but the network of speaker verification is relatively large and may not meet the requirements of computing resources on embedding devices. The joint learning or multi-task learning network might be either very light at a small scale as a single always on system, or with a much larger scale at the second stage after a successful wake-up by the first stage voice trigger.</p>
<p>Paper: <a href="https://arxiv.org/abs/2104.04993">The DKU System Description for The Interspeech 2021 Auto-KWS Challenge</a></p>
<p>Officical Code: <a href="https://github.com/lenovo-voice/THE-2020-PERSONALIZED-VOICE-TRIGGER-CHALLENGE-BASELINE-SYSTEM">PVTC2020</a></p>
</li>
</ol>
<h2 id="Leaderboard"><a href="#Leaderboard" class="headerlink" title="Leaderboard"></a>Leaderboard</h2><ol>
<li><a href="https://paperswithcode.com/sota/keyword-spotting-on-google-speech-commands">Keyword Spotting on Google Speech Commands
</a></li>
</ol>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（四）</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://machinelearning.apple.com/research/hey-siri">Hey Siri: An On-device DNN-powered Voice Trigger for Apple’s Personal Assistant</a> 2017.10</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzU4MTA0NDE5NQ==&mid=2247485151&idx=1&sn=289bc2112aa55bf7bb449b987b424e53&chksm=fd4cd453ca3b5d452c25e5e61b856bd9034d5609a3432673a884850770cd00942b6b81b3d21a&token=9133224&lang=zh_CN#rd">Hey Siri唤醒原理</a></p>
</blockquote>
<ul>
<li><p>DNN分数：路径分数（贪心） </p>
</li>
<li><p>三个阈值，一个阈值在small DNN中，两个阈值在large DNN中；</p>
</li>
<li><p>large DNN，一个正常阈值（normal），一个较低阈值（lower）；当超过较低阈值时，但没有超过较高阈值，系统会进入一个更敏感的状态几秒钟，如果此时用户重复了命令词，就可以轻易唤醒。</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/TwoPassDetector-1-5636f19f2c0346344c4e2efc78baf85c.png" alt="TwoPassDetector-1-5636f19f2c0346344c4e2efc78baf85c" style="zoom:67%;">

<ul>
<li>Always On Processor (AOP) (a small, low-power auxiliary processor, that is, the embedded Motion Coprocessor) </li>
<li>经过小的DNN的分数超过阈值（primary），则原信号再进入大DNN进行处理（没超过阈值，不会进入大DNN）When the score exceeds a threshold the motion coprocessor wakes up the main processor, which analyzes the signal using a larger DNN. </li>
<li>小DNN：5层，32节点；大DNN：5层，192节点；In the first versions with AOP support, the first detector used a DNN with 5 layers of 32 hidden units and the second detector had 5 layers of 192 hidden units.           </li>
<li>DNN分数：对关键词phrase做强制对齐，得到关键词边界，计算边界内的路径分数；</li>
</ul>
<h4 id="声学模型训练"><a href="#声学模型训练" class="headerlink" title="声学模型训练"></a>声学模型训练</h4><ul>
<li>每个phone三个状态建模 phonetic symbol results in three speech sound classes (beginning, middle and end)</li>
<li>训练的时候用了先验，这个先验会很不平均，要补偿（设置成一样？）</li>
<li>调整阈值，把lower阈值设置为允许far大一点的位置，normal阈值设置为far小一点的位置</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/GraphFRR-FAR-1-f52f46690c0472b709d9ef31a5073ee9-1629643646860.png" alt="GraphFRR-FAR-1-f52f46690c0472b709d9ef31a5073ee9" style="zoom:67%;">



<hr>
<blockquote>
<p>语音识别基本法（清华） <a href="https://mp.weixin.qq.com/s?__biz=MzI2MzU4NDI4NA==&mid=2247484308&idx=1&sn=99a9d08fda9ca2ca321751e9334a5cc2&chksm=eab8ece7ddcf65f16601ca3ab3ab45ce73d1e50f9dd0480c13e37a68bd03adc81f639311731d&scene=178&cur_album_id=1472128841614753794#rd">语音识别实际问题：（九）关键词识别与嵌入式应用</a> 2020.8</p>
</blockquote>
<h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20210822225055980.png" alt="image-20210822225055980" style="zoom:67%;">

<ul>
<li>滑窗机制包含了一个无法覆盖的关键词语音（？），相邻的数个窗口之间可以并行计算，且窗口之间重叠部分的中间输出结果可以重复利用。</li>
<li>假设窗长为<em>window</em>，窗口滑动步长为<em>step</em>，某个命令词语音时长为<em>cmd</em>，为了保证该命令词不会漏检，则需要保证<em>step+cmd &lt; window</em>；而为了该词不被重检，则需要在检出一个关键词时，直接丢弃该窗口内的语音，不再参与下一次识别。</li>
</ul>
<h3 id="Small-footprint"><a href="#Small-footprint" class="headerlink" title="Small-footprint"></a>Small-footprint</h3><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20210822225109640.png" alt="image-20210822225109640" style="zoom:67%;">



<h4 id="模型压缩（Model-Compression）"><a href="#模型压缩（Model-Compression）" class="headerlink" title="模型压缩（Model Compression）"></a>模型压缩（Model Compression）</h4><p>训练大模型、网络修剪、网络微调（Fine-tuning）  </p>
<ul>
<li>点、边<ul>
<li>损失函数对参数的海森矩阵（Hessian Matrix）[105,106]。我们常用的一阶范数（L1-norm）、二阶范数（L2-norm，Weight Decay）正则化方法本质上都是限制权重的值，使其尽可能趋近于0，从而自动学习到稀疏结构，然后可以将权重为0或极小的边直接剪掉，或者用于下一步的网络修剪。  </li>
<li>彩票假设（The Lottery Ticket Hypothesis）[107]</li>
</ul>
</li>
<li>权重<ul>
<li>权重的等价存储或高效存储是模型压缩的重要手段。对权重的量化（Quantization）、二值化（Binarization）可以将原始网络中一个浮点数参数由更少的位数来表示，而不明显影响模型性能，也可以直接从头训练一个事先固定好参数位数的网络。  </li>
<li>编码是数字存储中必须要考虑的问题，神经网络的所有权重就是一堆位置相关的数字，也直接决定着模型大小，对这些数字可以采用更加高效的组织形式或编码算法，如哈希桶（Hash Bucket）[108]、哈夫曼编码（Huffman Coding）[109] 等</li>
</ul>
</li>
<li>子结构<ul>
<li>卷积神经网络的卷积操作就使用了共享过滤器（及其参数）的机制；奇异值分解（Singular Value Decomposition，SVD）和低秩矩阵分解（Low-rank Matrix Factorization）等手段都是使得一个较大的权重矩阵可以由更小计算规模的矩阵表示；模型训练前便限制权重矩阵的格式，比如限制其为一个对称矩阵，缩减一半参数量；特定子结构的修剪，比如卷积神经网络以滤波器为单位进行修剪[110]。</li>
</ul>
</li>
</ul>
<h4 id="迁移学习（Transfer-Learning）"><a href="#迁移学习（Transfer-Learning）" class="headerlink" title="迁移学习（Transfer Learning）"></a>迁移学习（Transfer Learning）</h4><ul>
<li>师傅带着徒弟学习（将一个网络的结构和参数用于另一个网络的初始化也属于迁移学习，但这样的迁移学习是同等规模的网络迁移）。</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20210822225127050.png" alt="image-20210822225127050" style="zoom:67%;">

<ul>
<li>迁移学习中一个重要的问题是如何显性表征教师模型的知识，或者是学生模型要学习的目标，其中一个常用的手段则是知识萃取（Knowledge Distillation）[111]。考虑一个典型的深度神经网络分类器，网络经过Softmax后的最终输出本身已是一种知识表征，但为了增加Softmax输出的“柔韧”度，可以引入一个可调系数，记为温度（沿用了能量模型中的相关概念），并将知识拓展为暗知识（Dark Knowledge），该表征可以作为学生模型的学习目标。</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20210822225143003.png" alt="image-20210822225143003" style="zoom:67%;">

<h4 id="网络结构搜索与设计"><a href="#网络结构搜索与设计" class="headerlink" title="网络结构搜索与设计"></a>网络结构搜索与设计</h4><ul>
<li>修剪一个模型，结构的重要性大于权重  。让机器自行进行神经网络结构搜索（Neural Architecture Search，NAS）[112]。  </li>
<li>常见的精小人工设计网络结构都基于卷积神经网络，包括 MobileNet[113, 114]、ShuffleNet[115, 116]、 EfficientNet[117]等。</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Arik S O, Kliegl M, Child R, et al. Convolutional recurrent neural networks for small-footprint keyword spotting[J]. arXiv preprint arXiv:1703.05390, 2017.&#x3D;&#x3D;</p>
</blockquote>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><ul>
<li>用CRNN做分类，命令词</li>
<li>适用于<strong>低信噪比</strong>环境</li>
<li>输入特征perchannel energy normalized (PCEN) mel spectrograms，经过二维卷积提高维特征，送入双向GRU，因为用了双向，因此推理时需要等输入输完后（1.5s输入）才能进行计算，有1.5s延迟；</li>
</ul>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><ul>
<li>PCEN -&gt; CNN -&gt; BRNN -&gt; DNN -&gt; SoftMax</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20210623104150399.png" alt="image-20210623104150399"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20210623104157469.png" alt="image-20210623104157469"></p>
<ul>
<li>伪代码看不是很懂？？</li>
<li>使用CE loss，平滑分数</li>
</ul>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><ul>
<li>输入40*151（1.5s）PCEN特征</li>
<li>网络结构：一层CNN层，两层RNN层(64个节点)</li>
<li>在Deep Speech2上训练</li>
<li>没有和其他文献中模型对比，模型对比，采用的是不同神经元节点&#x2F;gru&#x2F;lstm对比</li>
<li>对比的是不同信噪比下、不同远场距离下的frr&#x2F;far曲线</li>
<li>gru优于lstm</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Lengerich, Chris, and Awni Hannun. “An end-to-end architecture for keyword spotting and voice activity detection.” <em>arXiv preprint arXiv:1611.09405</em> (2016).&#x3D;&#x3D;</p>
<p>开源代码：<a href="https://github.com/mindorii/kws">https://github.com/mindorii/kws</a></p>
</blockquote>
<h4 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h4><ul>
<li>用一个模型，解决KWS和VAD任务，但是这样，就等于一个网络要一直检测VAD，能耗就高了</li>
<li>PS. 我们现在的做法：VAD没有用网络，降噪后的信号进入VAD检测，若触发，则把降噪前的信号送进KWS网络。</li>
</ul>
<h4 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h4><ul>
<li>CRNN结构、ctc loss、输出字母、blank、空格</li>
<li>VAD推理置信度分数：$\large{logp(speech|x_{t:t+\omega})&#x3D;1-\sum\limits_{i&#x3D;t}^{t+\omega}p_i(\epsilon|x_{t:t+\omega})}$</li>
<li>KWS推理置信度分数：每100ms走命令词（包含建模单元间blank）文本路径，得到路径分数，累计800ms，得到一个置信度分数</li>
</ul>
<h4 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h4><ul>
<li>kws baseline：<a href="https://github.com/Kitt-AI/snowboy">https://github.com/Kitt-AI/snowboy</a>  </li>
<li>vad baseline：<a href="https://github.com/wiseman/py-webrtcvad">https://github.com/wiseman/py-webrtcvad</a>  </li>
<li>结构：1 层 CNN（filter尺寸11*32，stride&#x3D;3，filter数量32）、3 层 RNN（256 hidden），1.5M参数量</li>
<li>不带噪声数据集：正样本1544条，负样本526k；带噪声数据集：正样本1544*10条，负样本526k +57k.</li>
<li>训练集组成 KW + KW-noise   &gt; KW + KW-noise + noise  &gt; KW，即“只对正样本里加噪声，负样本不加噪声”优于“额外加负样本噪声”</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Sigtia, Siddharth, et al. “Efficient Voice Trigger Detection for Low Resource Hardware.” <em>INTERSPEECH</em>. 2018. citation：20&#x3D;&#x3D; Apple</p>
</blockquote>
<h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><ul>
<li>two stage 一个简易的网络，普通的阈值，超过阈值，才把原信号输入kws网络，类似vad、kws思路</li>
<li>minimum duration constraint ：每个phone用一个状态建模，每个状态至少持续n帧，n为3、4时，效果好（我现在是每个状态至少持续1帧，可以尝试该方法），是改帧长 or 解码时添加约束？</li>
<li>frame rate：帧移，因为hmm假设，所以帧与帧之间不要重叠？帧移为n，帧移60ms不错（我现在是帧移10ms，可以尝试该方法）</li>
<li>实现每个phone至少持续n帧的方法：比如 小源小源对应的words是 x x x iao iao iao vv vv vv van van van这样？？【这种效果没有送进解码器进行下采样效果好，差一点点】</li>
</ul>
<h4 id="实测效果"><a href="#实测效果" class="headerlink" title="实测效果"></a>实测效果</h4><ul>
<li>&#x3D;&#x3D;下采样确实会让far降低很多&#x3D;&#x3D;</li>
</ul>
<hr>
<p>吴本谷：今天带来一篇模拟远场数据的论文用在唤醒上。论文题目：A study on more realistic room simulation for far-field keyword spotting，地址：<a href="https://arxiv.org/pdf/2006.02774.pdf">https://arxiv.org/pdf/2006.02774.pdf</a> 。这篇文章的主要思想就是生成RIR来提高远场唤醒的性能，使用image source method (ISM) 来生成，也提供了对应的工具箱。<a href="https://github.com/LCAV/pyroomacoustics%EF%BC%9Bhttps://github.com/ebezzam/room-simulation%E3%80%82%E7%94%A8%E8%BF%99%E7%A7%8D%E7%94%9F%E6%88%90%E7%9A%84RIR%E5%9C%A8%E6%9C%AA%E7%9F%A5%E7%9A%84%E5%9C%BA%E6%99%AF%E4%B8%8B%E5%8F%AF%E4%BB%A5%E6%9C%89%E6%95%88%E7%9A%84%E6%8F%90%E9%AB%98%E5%94%A4%E9%86%92%E7%8E%87%E3%80%82%E5%9F%BA%E6%9C%AC%E8%BF%99%E7%A7%8D%E6%96%B9%E6%B3%95%E4%B9%9F%E6%98%AF%E9%80%9A%E7%94%A8%E5%8A%9E%E6%B3%95%E3%80%82%E5%A6%82%E6%9E%9C%E7%94%9F%E6%88%90%E5%A4%9A%E7%A7%8D%E5%A4%9A%E6%A0%B7%E7%9A%84RIR%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E7%9A%84%E8%B7%91%E8%B5%B7%E6%9D%A5%E3%80%82kaldi%E9%87%8C%E7%9A%84wav-reverberate%E7%B1%BB%E4%BC%BC%EF%BC%8C%E4%BD%86kaldi%E9%87%8C%E7%9A%84rir%E6%98%AF%E5%AE%9E%E9%99%85%E5%9C%BA%E6%99%AF%E6%90%9E%E5%87%BA%E6%9D%A5%E7%9A%84%EF%BC%8C%E6%A8%A1%E6%8B%9F%E7%9A%84%E8%AF%9D%E5%8F%AF%E4%BB%A5%E7%94%9F%E6%88%90%E5%BE%88%E5%A4%9A%E7%A7%8D%E7%B1%BB%E3%80%82%E6%9C%89%E5%85%B4%E8%B6%A3%E7%9A%84%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E8%AF%95%E8%AF%95%E3%80%82">https://github.com/LCAV/pyroomacoustics；https://github.com/ebezzam/room-simulation。用这种生成的RIR在未知的场景下可以有效的提高唤醒率。基本这种方法也是通用办法。如果生成多种多样的RIR，以及如何高效的跑起来。kaldi里的wav-reverberate类似，但kaldi里的rir是实际场景搞出来的，模拟的话可以生成很多种类。有兴趣的可以使用试试。</a></p>
<p>之前还有一个版本的用GPU生成RIR的，地址：<a href="https://github.com/DavidDiazGuerra/gpuRIR">https://github.com/DavidDiazGuerra/gpuRIR</a> .</p>
<p>因为interspeech很多人收到接受的邮件，所以最近感觉arxiv上论文有点多。今天继续带来唤醒的论文，这些apple跟amazon的团队的两篇唤醒论文。</p>
<p>1.<a href="https://arxiv.org/pdf/2008.03405.pdf">Stacked 1D convolutional networks for end-to-end small footprint voice trigger detection</a></p>
<p>2.<a href="https://arxiv.org/pdf/2008.03790.pdf">Accurate Detection of Wake Word Start and End Using a CNN</a></p>
<p>第一篇论文来自apple团队，跟<a href="https://articles.zsxq.com/id_sowwcmj0407f.html">20200807那个每日分享的论文</a>基本两个思路，这个是在网络结构上动的功夫，把SVDF引入到唤醒，可以保证性能不怎么变的情况下，模型大小变小。SVDF又可以用CNN来弄，所以变成2个CNN层来弄就可以了。这个想法是借鉴谷歌论文的思想，地址：<a href="http://150.162.46.34:8080/icassp2019/ICASSP2019/pdfs/0006336.pdf">http://150.162.46.34:8080/icassp2019/ICASSP2019/pdfs/0006336.pdf</a> 。</p>
<p>同时，论文在DNN-HMM的框架下跟E2E下来验证性能：</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/Ft88mbHJ7-Nm30q-DPyWMzy1o_2m" alt="img"></p>
<p>做唤醒的标配做法吧，如果计算资源不够，可以尝试下。</p>
<p>第二篇论文是亚马逊的唤醒做法</p>
<p>我们之前在介绍亚马逊一直是基于二级模型做的，然后也是keyword-filler的方案。但这篇论文一改之前的方案，直接基于DNN-KWS的方法来。而且更直接，直接提取特征，训练了一个2分类的模型。</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/FiP7Vw6K1JvyVITOeTlpWaZzhypH" alt="img"></p>
<p>直接拿一段时间的频谱特征，输出就是是否是唤醒词。但这个方案没法有起点跟尾点的检测，那么就来个方案是：</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/FgKK9cQFbJ9_24eQHYosjkSee-ky" alt="img"><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/Fkz5h--75RzuzGkz633x_hHv950c" alt="img"></p>
<p>直接把之前唤醒词建模的网络freeze掉，然后来搞起点跟尾点的检测。此外，也尝试放在一起搞的方案，最终论文发出来了，效果当然也不错。这个思想其实挺好的，会抛弃原来建模的一些思想，但我理解就是比较难训练。</p>
<p>做唤醒的同学可以认真看看这些论文，值得好好研究。基本唤醒就这么多做法。相信后面也不会突破这些基本的框架体系。</p>
<p>好的，祝大家学习愉快。</p>
<hr>
<p>&#x3D;&#x3D;Sigtia, Siddharth, et al. “Multi-task learning for speaker verification and voice trigger detection.” <em>ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 2020.&#x3D;&#x3D;</p>
<hr>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>命令词论文笔记（十）端到端命令词识别</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/</url>
    <content><![CDATA[<h1 id="端到端命令词识别"><a href="#端到端命令词识别" class="headerlink" title="端到端命令词识别"></a>端到端命令词识别</h1><blockquote>
<p>&#x3D;&#x3D;Yiming Wang et al. “Wake Word Detection with Streaming Transformers” International Conference on Acoustics, Speech, and Signal Processing (2021).&#x3D;&#x3D;</p>
<p>github代码：<a href="https://github.com/freewym/espresso">https://github.com/freewym/espresso</a></p>
</blockquote>
<h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><ul>
<li>之前的transformer是非流式，需要输入一整个序列，知道transformer-XL提出流式后，才能流式，但是transformer适用于长序列，没有文章表明对于短序列（比如唤醒任务）效果也好，本文做了实验；</li>
<li>唤醒任务不关心唤醒词出现在序列的哪个位置，只关心有没有出现，因此不用transformer提出的基于整个句子的position embedding，而是采用相对位置编码relative positional encoding，将位置编码为层的隐藏值；</li>
<li>$Q&#x3D;W_QX$，$&#x3D;K&#x3D;W_KX$，$V&#x3D;W_VX$  $\in{\mathbb{R}^{d_h\times{T}}}$</li>
<li>$h_i&#x3D;(V+E)a_i\in{\mathbb{R}^{d_h}}$，  $\large{a_i&#x3D;softmax(\frac{[Q^T(K+E)]_i}{\sqrt{d_h}})}\in{\mathbb{R}^{T}}$</li>
</ul>
<p>（之前是：$h_i&#x3D;Va_i\in{\mathbb{R}^{d_h}}$，  $\large{a_i&#x3D;softmax(\frac{[Q^TK]_i}{\sqrt{d_h}})}\in{\mathbb{R}^{T}}$）</p>
<ul>
<li>state-caching是选择哪些参数来更新，之前的参数要不要更新（gradient stopping）</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20211230161921604.png" alt="image-20211230161921604" style="zoom:80%;">

<ul>
<li>本文探索了look-ahead of the future chunk, and different gradient stopping,layer dependency, and positional embedding strategies 对性能的影响</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20211230161946436.png" alt="image-20211230161946436" style="zoom:80%;">

<h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><ul>
<li><p>baseline：5层1维空洞卷积 dilated convolution，48个filter，kernel size&#x3D;5， leading to 30 frames for both left and right context   ，58k参数量</p>
</li>
<li><p>streaming transfomer：前两层1维卷积，然后3层attention层，32维embedding，4head，48k参数量</p>
</li>
<li><p>chunk size 27，27是实验得到的最优值，太短了效果下降，太长了效果没有明显改善但是带来了延迟</p>
</li>
</ul>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul>
<li><p>mobvoi数据集</p>
</li>
<li><p>初始学习率1e-3，Adam，学习率减半，epoch不超过15，或者学习率小于1e-5停止训练</p>
</li>
<li><p>学习率warm-up在该实验中无效，可能由于任务简单</p>
</li>
<li><p>建模单元是？</p>
</li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul>
<li>效果劣于Alignment-free LF-MMI；</li>
<li>without state-caching效果优于with state-caching；</li>
<li>stream transformer一定要加 look-ahead chunk，看见未来信息，不然效果不好</li>
<li>用相对位置编码relative positional embedding  更适合唤醒任务，这个embedding放在value上效果更好</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20211230162010582.png" alt="image-20211230162010582">

<ul>
<li>最好的一组：without state-caching，transformer + look-ahead + relative embedding to value，每小时虚警0.5次的条件下，“hi xiaowen”误拒率0.6%，“nihao wenwen” 误拒率0.6%</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Sun, Ming et al. “Max-pooling loss training of long short-term memory networks for small-footprint keyword spotting.” <em>2016 IEEE Spoken Language Technology Workshop (SLT)</em> (2016): 474-480.&#x3D;&#x3D;  citations：93</p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>输入t帧语音特征，输出t帧*类别，二分类，word level labels，关键词alexa和非关键词background</p>
</li>
<li><p>提出max-pooling loss，是在keyword区域内模型输出的最大后验概率，加入loss function（目标之一是最大化keyword输出的某帧后验概率）</p>
</li>
<li><p>后处理：每30帧计算一次是否触发，30帧的滑动窗口，平滑窗口内的后验概率，若大于阈值，视为触发，触发后的40帧不再计算（lock out period），以免重复触发；有触发的音频发送完后，会多送入20帧（latency windows），以防没送完。</p>
</li>
<li><p>loss function：$\large{L_T^{maxpool}&#x3D;-\sum\limits_{t\in{\hat{L}}}lny_t^{k_t^+}-\sum\limits_{p&#x3D;1}^Plny_{l_p^+}^{k_p^+}}$</p>
<p>其中：$\hat{L}$是非keyword区域的其他区域，$l_p$：keyword帧区域；$k_p^+$：target keyword label；$l_p^+$：keyword帧区域内的最大后验概率对应的帧，$k_t^+$：target nonkeyword label</p>
<p>也就是说，只有keyword区域时，用第二项计算，非keyword区域时（positive sample里的非keyword区域也算），用第一项计算；</p>
<p>因此非keyword计算&#x2F;更新的帧远多于keyword参与计算&#x2F;更新的帧数，会有正负样本不平衡的问题；</p>
</li>
<li><p>为了减少匹配keyword初始段的类似帧的误触发，将当前帧与左右相邻帧进行堆叠，再送入DNN，作为baseline。</p>
</li>
</ul>
<h3 id="网络-1"><a href="#网络-1" class="headerlink" title="网络"></a>网络</h3><ul>
<li>LSTM</li>
<li>参数量：$n &#x3D; n_c×n_r×4+n_i×n_c×4+n_r×n_o+n_c×n_r+n_c×3$</li>
</ul>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><ul>
<li>LSTM参数量118k，随机初始化时，ce loss的初始学习率0.00001，max-pooling的初始学习率0.00005；ce模型作为初始预训练模型时，max-pooling的初始学习率0.00005 ；</li>
<li>数据集非开源，用了大量房间内的远场数据</li>
</ul>
<h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h3><ul>
<li>比CE训练得好；其中，ce预训练模型再用max-pooling loss训练的模型效果最好</li>
</ul>
<h3 id="启发"><a href="#启发" class="headerlink" title="启发"></a>启发</h3><ul>
<li>逐帧出分类结果的适用模型是看得范围比较远的模型，比如lstm，甚至我感觉lstm后面区域的帧分类结果才比较准确，因为只看前面几帧，比如读一个“小源小源”的“小”，就要求lstm二分类，分类正确，这着实有点为难了（对于单向lstm来说），因此小区域的cnn（tdnn）还不是很适用，大感受野的cnn、lstm会比较使用于逐帧都有分类结果的任务。</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Hou, Jingyong, et al. “Mining effective negative training samples for keyword spotting.” <em>ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 2020.&#x3D;&#x3D;西北工业大学</p>
<p>&#x3D;&#x3D;github开源代码&#x3D;&#x3D;：<a href="https://github.com/jingyonghou/KWS_Max-pooling_RHE">https://github.com/jingyonghou/KWS_Max-pooling_RHE</a> KWS_Max-pooling_RHE</p>
</blockquote>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><ul>
<li>把最近的KWS架构分为两种：<ol>
<li>keyword&#x2F;filler posterior modeling followed by a search algorithm；最近都是alexa那种hmm</li>
<li>end-to-end (E2E) based architectures ；把keyword作为建模单元，逐帧判断是否是keyword，二分类任务（如果只有一个keyword）</li>
</ol>
</li>
</ul>
<h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><ul>
<li>针对论文“Max-pooling loss training of long short-term memory networks for small-footprint keyword spotting”使用的max-pooling loss存在的正负样本不平衡的问题，做出了改进：<ul>
<li>为了缓解对齐标签不准确的影响，训练初期epoch做的max-pooling来自对齐keyword区域内的最大后验概率帧，训练后期的max-pooling来自正样本全句的keyword类别的最大后验概率帧，这是由于后期模型训练得比较好了；[一点点用]</li>
<li>在keyword区域的结尾再做max-pooling，而不是中间？？？</li>
<li>训练的正样本里的其他非keyword区域的帧，不用来计算loss了，丢弃之；</li>
<li>二分类，只用一个输出结点（sigmoid），而不是原论文的两个结点（softmax）</li>
<li>对负样本进行下采样，没有用到负样本的所有帧</li>
</ul>
</li>
<li>借鉴目标检测论文“Training region-based object detectors with online hard example mining”提出Mining <strong>regional hard examples (RHE)</strong>   来缓解类不平衡问题，具体做法：</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20211231111939439.png" alt="image-20211231111939439" style="zoom:80%;">

<p>简单说来，就是负样本的输出概率中，keyword分类的概率高的（二分类keyword分类高于非keyword的）取出来，这些是难训练的负样本；</p>
<p>至于怎么取出来，是把分类高的进行从高到低排序，取出高的，周围一小区域帧就不考虑了（不列入难训负样本），然后遍历所有帧，取出来难训负样本，然后只保留rP帧，P是正样本帧数，r是正负样本比例；</p>
<h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据集mobvoi：<ul>
<li>keyword时长0.3s-2s；</li>
</ul>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20211231114324350.png" alt="image-20211231114324350" style="zoom:80%;">

<ul>
<li>谱增广SpecAugment：对每个minibatch里1&#x2F;3样本time masking，1&#x2F;3样本frequency masking，1&#x2F;3样本time masking和frequency masking；<ul>
<li>time masking：随机选50帧特征设为0（mel-filter bank&#x3D;0）；</li>
<li>frequency masking：在所有帧中，随机选30维（40维特征）特征设为0；</li>
</ul>
</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul>
<li>GRU：2层单向，128结点，一层projection层 ReLU激活函数，128结点；学习率0.0005；</li>
<li>dilated TCN；第一层1×1的1维causal 卷积，8层dilated causal  卷积，卷积核8，8 dilated rates are {1,2,4,8,1,2,4,8}，感受野210帧，relu激活函数，filter数量64；学习率0.01；</li>
<li>minibatch size&#x3D;400；Adam optimization；不少于15epoch</li>
<li>学习率warm-up（前200minibatch小学习率，逐渐增加至0.0005&#x2F;0.01）；</li>
</ul>
<h3 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h3><ul>
<li>GRU优于TCN</li>
<li>用“Efficient keyword spotting using dilated convolutions and gating“效果不差</li>
<li>负样本下采样的max-pooling相比于负样本全用的max-pooling，有改进一点</li>
<li>RHE很有用</li>
<li>对该数据集 specaugment很有用</li>
<li>最佳超参数：正负帧数比例1：10；RHE处理时前后的$\triangle$&#x3D;200帧（不用再处理的时长）</li>
</ul>
<h3 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h3><ul>
<li>不是很懂这个到底是比如平滑后验概率和阈值判断，还是逐帧分类？</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Hou, Jingyong, et al. “Region proposal network based small-footprint keyword spotting.” <em>IEEE Signal Processing Letters</em> 26.10 (2019): 1471-1475.&#x3D;&#x3D;ciations：14 西北工业大学 侯</p>
<p>github：<a href="https://github.com/jingyonghou/RPN_KWS">https://github.com/jingyonghou/RPN_KWS</a></p>
</blockquote>
<h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><ul>
<li>借鉴目标检测领域的anchor-based region proposal network（RPN）jointly optimize keyword detection and location  loss function：分类准确度+区域估计准确度</li>
</ul>
<h3 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h3><ul>
<li>GRU作为特征抽取器M0，输入声学特征x，输出高级特征h，$\mathbf{h}&#x3D;M_0(\mathbf{x};\theta)$</li>
<li>Region classifiction：子网络M1选出一些anchors（keyword起止时间）（分类），输入高级特征h，输出K个anchor分类概率，$\vec{y_t}&#x3D;M_1(h_t;\theta_1)$，只有一个关键词（唤醒词）的任务，则y是标量，输出一个概率；？一个linear层</li>
<li>Region Transformation ：子网络M2 predicts the transformation needed to extract the full keyword associated with that region  （回归）有点像二级，在一级唤醒后才触发，anchor是positive anchor才会计算，输入高级特征h，输出anchor的转换向量，$\vec{p_t}&#x3D;M_2(h_t;\theta_2)$，每个anchor都有一个$p_t^i$向量，向量元素为平移shifting因子和scaling因子；MSE loss 进行更新，一个linear层</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20220316143124725.png" alt="image-20220316143124725" style="zoom:67%;">

<ul>
<li><p>Anchors  锚（框框区域）：对每帧t，t作为终止时间，往前一些步作为起始时间，有K个不同的起始时间，K个anchors ，K是超参，用cv集调参；</p>
</li>
<li><p>举例：anchor $P(t_1,t_2)$（一个很小的区域），标签$Q(t_3,t_4)$，（t1、t3表示区域开始帧，t2、t4表示区域结束帧），希望P变换到Q，因此对P做平移u，使得P中点与Q中点重合，在scale v，使得区域长度和Q一样长：</p>
<p>$u&#x3D;(t3+t4)&#x2F;2-(t1+t2)&#x2F;2$</p>
<p>$v&#x3D;(t4-t3)&#x2F;(t2-t1)$</p>
<p>用的时候，M2预测的是$\hat{u}&#x3D;u&#x2F;l$，scale因子$\hat{v}&#x3D;log(v)$，其中，$l&#x3D;t_2-t_1$</p>
</li>
<li><p>确定哪些是positive anchor：用IoU区域判断，大于阈值0.7就认为是positive anchor</p>
<p>$IoU(P,Q)&#x3D;\frac{P \cap Q}{P \cup Q}$</p>
<p>$P \cap Q &#x3D; max(min(t_2,t_4)-max(t_1,t_3),0)$</p>
<p>$P \cup Q &#x3D; (t_4-t_3) + (t_2-t_1) - (P\cap Q)$</p>
</li>
</ul>
<p>ps.论文“Shrivastava A ,  Kundu A ,  Dhir C , et al. Optimize What Matters: Training DNN-Hmm Keyword Spotting Model Using End Metric[C]&#x2F;&#x2F; ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021”也是用了iou，不过是作为loss funciton进行训练的，keyword spotting最近经常使用目标检测提出的方法，可以关注一波目标检测最新的方法；</p>
<ul>
<li>目标函数MTL objective function   $\large{Loss&#x3D;\frac{1}{N}\sum\limits_{i&#x3D;1}^NL_c(y(i),y^*(i))+\frac{\lambda}{N_+}\sum\limits_{i:a(i)\in{A^+}}L_r(p(i),p^*(i))}$</li>
</ul>
<p>其中，$A^+$是positive anchor，$p(i)&#x3D;(\hat{u}(i),\hat{v}(i))$，        $L_c$是预测概率 $y(i)$ 和标签 $y_i^*$ 之间的交叉熵，$L_r$是预测转换向量 $p(i)$ 和训练目标 $p^*(i)$ 之间的 MSE loss，所有样本训练M1，只对正样本训练M2</p>
<ul>
<li>推理：找到每帧最大后验概率y对应的，大于阈值，则唤醒？</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Zhang Y, Suda N, Lai L, et al. Hello edge: Keyword spotting on microcontrollers[J]. arXiv preprint arXiv:1711.07128, 2017.&#x3D;&#x3D; citations：225 </p>
<p>github开源代码：<a href="https://github.com/ARM-software/ML-KWS-for-MCU">https://github.com/ARM-software/ML-KWS-for-MCU</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/222741730">Hello Edge: Keyword Spotting on Microcontrollers</a></p>
</blockquote>
<h3 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h3><ul>
<li>模型采用 depthwise separable convolutional neural network (DS-CNN)</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Sørensen, Peter Mølgaard, Bastian Epp, and Tobias May. “A depthwise separable convolutional neural network for keyword spotting on an embedded system.” <em>EURASIP Journal on Audio, Speech, and Music Processing</em> 2020.1 (2020): 1-14.&#x3D;&#x3D;</p>
<p>github开源代码：<a href="https://github.com/PeterMS123/KWS-DS-CNN-for-embedded">https://github.com/PeterMS123/KWS-DS-CNN-for-embedded</a></p>
</blockquote>
<h3 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>这篇和”Hello edge: Keyword spotting on microcontrollers”其实很像；</p>
</li>
<li><p>探索降低(scale?)网络复杂度时哪个参数对性能改变最大；</p>
</li>
<li><p>10个词的任务，在ARM Cortex M4</p>
</li>
<li><p>每次处理1s（49帧），20维，每次送入网络的输入是20*49</p>
</li>
<li><p>后处理：1s一个分类，然后帧移动0.25s又计算一次（也就是说1s计算4次），一共延长检测时间为$T_{integrate}$，然后看关键词的<strong>平均后验概率</strong>有没有超过阈值，然后如果触发了关键词，则后面一段时间$T_{refractory}$不再计算，以免多次触发；</p>
<p>本文$T_{integrate}&#x3D;0.75s$，$T_{refractory}&#x3D;1s$；</p>
</li>
<li><p>数据增广的噪声源之一是开源噪声源：TUT database、DEMAND database；通过filtering and noise adding tool (FaNT) 工具添加背景噪声到干净音频中；</p>
</li>
<li><p>噪声添加进音频中分类两类，分为match和mismatch噪声；给训练集添加A噪声，测试带有A噪声的测试集，叫做match噪声集；给训练集添加A噪声，测试带有B噪声的测试集，叫做mismatch噪声集；match噪声集和mismatch噪声集都测试，就知道网络的泛化性如何了。</p>
</li>
<li><p>资源估计：</p>
<ul>
<li>Operations  计算量，网络的乘法数和加法数；</li>
<li>Memory  内存，网络需要储存的参数量</li>
<li>Execution time  执行时间，用处理器上的timer测量</li>
</ul>
</li>
</ul>
<h3 id="网络-2"><a href="#网络-2" class="headerlink" title="网络"></a>网络</h3><ul>
<li>DS-CNN网络</li>
</ul>
<h3 id="实验-3"><a href="#实验-3" class="headerlink" title="实验"></a>实验</h3><ul>
<li>为了查看(量化)系统复杂度与性能的关系：对比了2层10个滤波器，一直到9层300个滤波器的很多个模型；</li>
<li>可以使用更大的学习率，因为每一层的梯度的大小更相似，这导致更快的模型收敛。</li>
<li>数据集google speech commands，正负比例8：2</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Bai, Shaojie, J. Zico Kolter, and Vladlen Koltun. “An empirical evaluation of generic convolutional and recurrent networks for sequence modeling.” <em>arXiv preprint arXiv:1803.01271</em> (2018).&#x3D;&#x3D;citations：1782</p>
<p>github开源代码： <a href="http://github.com/locuslab/TCN">http://github.com/locuslab/TCN</a>  </p>
</blockquote>
<h3 id="思路-4"><a href="#思路-4" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>sequence modeling一般使用RNN，本文探讨了CNN能有比RNN更好的序列建模能力，更适合序列任务</p>
</li>
<li><p>提出TCN网络，TCN&#x3D;1D FCN + dilated casual convolutions</p>
<p>其中，FCN是fully-convolutional network，隐层神经元数量和输入层数量相同，并且0padding，pad长度为(kernel size−1)，以保持后一层与前一层的长度相同；</p>
<p>casual convolutions因果卷积：当前t之和之前t有关</p>
</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20220103135158616.png" alt="image-20220103135158616"></p>
<ul>
<li>$\large{F(s)&#x3D;(x*<em>df)(s)&#x3D;\sum\limits</em>{i&#x3D;0}^{k-1}f(i)\cdot{x_{s-d\cdot{i}}}}$</li>
</ul>
<p>其中，d&#x3D;1，和普通卷积一样；d&gt;1，对每帧意味着更大的输入范围；</p>
<ul>
<li><p>增加TCN感受野的方法：更大的filter size、更大的dilation factor；每层的历史信息&#x3D;(filter_size - 1)*dilation_factor</p>
</li>
<li><p>残差结构</p>
</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Leem, Seong-Gyun, In-Chul Yoo, and Dongsuk Yook. “Multitask learning of deep neural network-based keyword spotting for IoT devices.” <em>IEEE Transactions on Consumer Electronics</em> 65.2 (2019): 188-194.&#x3D;&#x3D;citations:19 高丽大学</p>
</blockquote>
<h3 id="思路-5"><a href="#思路-5" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>GMM-HMM-Based Keyword Spotting：</p>
<p>输入特征同时进入triphone训练的keyword model和monophone训练的filler model，log keyword路径分数 - log filler路径分数是否大于阈值（log-likelihood ratio），判断是否唤醒；</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20220104164339520.png" alt="image-20220104164339520" style="zoom:80%;">

<ul>
<li><p>DNN-HMM-Based Keyword Spotting</p>
<p>$P_{filler}(x)&#x3D;\alpha\max\limits_{k,i}P_{k,i}(x)+(1-\alpha)\min\limits_{k,i}P_{k,i}(x)$</p>
<p>其中，$k$是可能的keyword系数，$i$是状态系数；</p>
<p>[？]filler概率为keyword最大路径分数和最小路径分数加权求和？？</p>
</li>
<li><p>Multitask DNN architecture that predicts both triphone state probabilities for keyword models and monophone state probabilities for filler models </p>
<p>前面层参数都相同，最后一层参数区分，输出keyword或者filler；</p>
<p>这个思路好奇怪，本来是可以简单认为是分类任务，现在把一个分类任务变成两个分类任务</p>
<p>$Loss&#x3D;\beta{Loss_{triphone}}+(1-\beta)Loss_{monophone}$</p>
</li>
</ul>
<img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89/image-20220104173023074.png" alt="image-20220104173023074" style="zoom:80%;">



<hr>
<blockquote>
<p>Temporal Feedback Convolutional Recurrent Neural Networks for Keyword Spotting</p>
<p><a href="https://github.com/tae-jun/temporal-feedback-crnn">https://github.com/tae-jun/temporal-feedback-crnn</a> （无内容）</p>
</blockquote>
<hr>
<blockquote>
<p>An End-to-End Architecture for Keyword Spotting and Voice Activity Detection</p>
<p><a href="https://github.com/taylorlu/AudioKWS">https://github.com/taylorlu/AudioKWS</a></p>
</blockquote>
<p><a href="https://github.com/jingyonghou/wakeword-benchmark">https://github.com/jingyonghou/wakeword-benchmark</a></p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>基于分类的命令词识别</title>
    <url>/2022/01/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<h1 id="基于分类的命令词识别"><a href="#基于分类的命令词识别" class="headerlink" title="基于分类的命令词识别"></a>基于分类的命令词识别</h1><h3 id="三种情况："><a href="#三种情况：" class="headerlink" title="三种情况："></a>三种情况：</h3><ol>
<li>输入T帧，输出1个类别向量（每个类是一个关键词）</li>
<li>输入T帧，输出T帧类别向量（每个类是一个关键词）；测试时，每输入N帧，计算关键词类别的平滑后验概率，超过阈值则唤醒</li>
<li>输入T帧，输出T帧类别向量（每个类是一个关键词），只要有其中一帧keyword类别超过阈值，则唤醒；</li>
</ol>
<p>另外一种情况：输入T帧，输出N个字符类别向量（比如transformer模型），输出字符串有beam search过程</p>
<p>查阅的文献里只针对一两个关键词的情况（google speech commands没考虑）</p>
<h4 id="情况1："><a href="#情况1：" class="headerlink" title="情况1："></a>情况1：</h4><blockquote>
<p>开源代码：<a href="https://github.com/wenet-e2e/wekws">https://github.com/wenet-e2e/wekws</a></p>
</blockquote>
<ul>
<li>数据集mobvoi，包含两个关键词：</li>
</ul>
<img src="/2022/01/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AF%86%E5%88%AB/image-20211230171745163.png" alt="image-20211230171745163" style="zoom:80%;">

<ul>
<li><p>最佳情况（对应模型MDTC_Small）：每小时虚警1次情况下，关键词“hi_xiaowen”的误拒率为0.53%，关键词“nihao_wenwen”的误拒率为0.59%；</p>
</li>
<li><p>数据集snips，包含一个关键词：</p>
</li>
</ul>
<img src="/2022/01/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AF%86%E5%88%AB/image-20211230172057409.png" alt="image-20211230172057409" style="zoom:80%;">

<ul>
<li>最佳情况（对应模型MDTC_Small）：每小时虚警1次情况下，关键词“hey_snips”的误拒率为0.87%；</li>
</ul>
<h4 id="情况2："><a href="#情况2：" class="headerlink" title="情况2："></a>情况2：</h4><blockquote>
<p>Sun, Ming et al. “Max-pooling loss training of long short-term memory networks for small-footprint keyword spotting.” <em>2016 IEEE Spoken Language Technology Workshop (SLT)</em> (2016): 474-480.</p>
</blockquote>
<ul>
<li><p>数据集（非开源）alexa，包含一个关键词</p>
</li>
<li><p>提出max-pooling loss，是在keyword区域内模型输出的最大后验概率，加入loss function（目标之一是最大化keyword输出的某帧后验概率）</p>
</li>
<li><p>后处理：每30帧计算一次是否触发，30帧的滑动窗口，平滑窗口内的后验概率，若大于阈值，视为触发，触发后的40帧不再计算（lock out period），以免重复触发；有触发的音频发送完后，会多送入20帧（latency windows），以防没送完。</p>
</li>
</ul>
<p>[TODO] 情况2 开源数据集的结果</p>
<h4 id="参考情况："><a href="#参考情况：" class="headerlink" title="参考情况："></a>参考情况：</h4><blockquote>
<p>Alignment-Free LF-MMI</p>
</blockquote>
<ul>
<li>数据集mobvoi，包含两个关键词；数据集snips，包含一个关键词：：</li>
</ul>
<img src="/2022/01/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AF%86%E5%88%AB/image-20211230174135668.png" alt="image-20211230174135668" style="zoom:80%;">

<img src="/2022/01/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AF%86%E5%88%AB/image-20211230174313004.png" alt="image-20211230174313004" style="zoom:80%;">

<ul>
<li>每小时虚警1次情况下，关键词“hey_snips”的误拒率为0%；关键词“hi_xiaowen”的误拒率为0.25%，关键词“nihao_wenwen”的误拒率为0.4%；</li>
<li>效果优于<strong>情况1</strong></li>
</ul>
<blockquote>
<p>Yiming Wang et al. “Wake Word Detection with Streaming Transformers” International Conference on Acoustics, Speech, and Signal Processing (2021)</p>
</blockquote>
<ul>
<li>数据集mobvoi，包含两个关键词；数据集snips，包含一个关键词：：</li>
</ul>
<img src="/2022/01/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AF%86%E5%88%AB/image-20211230174650152.png" alt="image-20211230174650152" style="zoom:80%;">

<img src="/2022/01/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%8D%E8%AF%86%E5%88%AB/image-20211230174700498.png" alt="image-20211230174700498" style="zoom:80%;">

<ul>
<li>每小时虚警1次情况下，关键词“hi_xiaowen”的误拒率为0.45%，关键词“nihao_wenwen”的误拒率&lt;0.5%；</li>
<li>效果优于<strong>情况1</strong></li>
</ul>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>基于chain多唤醒词识别模型</title>
    <url>/2021/12/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8Echain%E5%A4%9A%E5%94%A4%E9%86%92%E8%AF%8D%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="基于chain多唤醒词识别模型"><a href="#基于chain多唤醒词识别模型" class="headerlink" title="基于chain多唤醒词识别模型"></a>基于chain多唤醒词识别模型</h1><blockquote>
<p>参考袁有根NCMMSC会议分享</p>
</blockquote>
<p><img src="/2021/12/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8Echain%E5%A4%9A%E5%94%A4%E9%86%92%E8%AF%8D%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B/image-20211021162722733.png" alt="image-20211021162722733"></p>
<p>目标：训练更好的AM；如何将测试时的解码网络内的参数自动调整；</p>
<p>思路：一开始想要防止语言模型过拟合！！！其实根本没必要！！！，因为端到端模型中有语言模型部分，该部分参数会更新，因此越训练会越适配训练集，因此语言模型容易过拟合（而一般外部语言模型用的可不止训练数据，用的是很大文本统计得到的，可以做shallow fusion），而chain model里面参与计算loss的语言模型部分根本不会跟新，不用考虑过拟合问题！！！</p>
<p>如果是只考虑有无必要把语言模型融入，按照人家拼命把语言模型拿掉的思路，是没有必要再引入语言模型的。</p>
<p>但是希望测试时的解码网络的参数能调整，因此借鉴模型fusion的思路，1.shallow fusion cold fusion 外部语言模型参与，可使得模型倾向于</p>
<p>用无调音节建模</p>
<p>step1. 训练一个初始大一点的chain模型，分母网用训练数据得到的3gram phone ，记作chain model1，目的是后续的对齐；</p>
<p>用tri3对齐lattice，训练大chain model</p>
<p>用tri3对齐，训练tdnn，用tdnn进行后续对齐：local&#x2F;nnet3&#x2F;run_tdnn_bigmodel_for_align.sh</p>
<p>step2. 对齐生成lattice，重新训练，注意，此时构建egs时不再下采样（frame-subsampling-factor&#x3D;1），分母网用训练数据得到的3gram phone loop，记作chain model2，目的是做finetune的初始模型</p>
<p>step3. finetune：</p>
<ul>
<li>语言模型P(W)都是1，进行finetune，得到chain model2，这个想法是为了训练更好的声学模型，让声学模型受语言模型的帮助更小，更独立。花哥说，这有点类似em思路，固定语言模型，更新声学模型，再放开语言模型，更新声学模型，最后的结果可能和一开始就引入语言模型的结果差不多；</li>
<li>用测试解码网络作为P(W)进行finetune，得到唤醒任务的chain model3，雷博尝试了该方法，并且把学习率调小，结果far会很高，可能由于解码网络的竞争路径太少，竞争路径的分数也很高？</li>
<li>loss分母竞争路径分数-唤醒路径分数（如何挑选出唤醒路径？），参考专利《[重要]CN201710343427-基于鉴别性训练的定制语音唤醒优化方法及系统-审定授权.pdf》</li>
<li>训练LM网络，LM网络的输入是测试解码网络概率，输出是新G概率，再用该概率去做分母，这个如何实现？？</li>
</ul>
<p>step4. 用step1的模型，用上下文无关音节建模，减少分类数，重新对齐生成lattice，再训练一个chain model</p>
<p>先看一下language model fusion的论文《LANGUAGE MODEL FUSION FOR STREAMING END TO END SPEECH RECOGNITION  》，看一下如何容融合外部语言模型</p>
<h2 id="赋予loss不同权重"><a href="#赋予loss不同权重" class="headerlink" title="赋予loss不同权重"></a>赋予loss不同权重</h2><h3 id="思路："><a href="#思路：" class="headerlink" title="思路："></a>思路：</h3><p>参考多任务学习的赋予权重思路：kaldi&#x2F;egs&#x2F;babel_multilang&#x2F;s5&#x2F;local&#x2F;nnet3&#x2F;run_tdnn_multilingual.sh</p>
<p>修改多任务学习的脚本，使得loss不同权重，但是又只训练一个任务</p>
<p>kaldi判断多任务的脚本：steps&#x2F;nnet3&#x2F;train_raw_dnn.py</p>
<p>通过有没有valid_diagnostic.scp或valid_diagnostic.ark来判断use_multitask_egs&#x3D;True还是False，这个只在raw里有，因此要把mdl中的也增加多任务学习，然后作用到train_lib.common.train_one_iteration训练。</p>
<p>train_one_iteration里决定存储的是mdl还是raw的符号：get_raw_nnet_from_am。</p>
<h1 id="实验汇总"><a href="#实验汇总" class="headerlink" title="实验汇总"></a>实验汇总</h1><h3 id="topo区别实验"><a href="#topo区别实验" class="headerlink" title="topo区别实验"></a>topo区别实验</h3><p>比较四&#x2F;三&#x2F;二个字用四&#x2F;三&#x2F;二状态建模，与不管几个字都用四状态建模的区别。</p>
<p>比较单音素（现在里面是单音素）与三音素的区别？需要比较吗</p>
<h3 id="DNN对齐模型区别实验"><a href="#DNN对齐模型区别实验" class="headerlink" title="DNN对齐模型区别实验"></a>DNN对齐模型区别实验</h3><ul>
<li>用tdnn大模型（69M）作为后续对齐模型：<ul>
<li>路径：25.3：&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;hi_mia&#x2F;w1&#x2F;exp_syll&#x2F;nnet3&#x2F;tdnn</li>
<li>脚本：local&#x2F;nnet3&#x2F;run_tdnn_bigmodel_for_align.sh</li>
<li>学习率：initial_effective_lrate&#x3D;0.008，final_effective_lrate&#x3D;0.00008，num_epochs&#x3D;6（这样学习率太大了会报LOG Per-component max-change active）</li>
<li>训练集特征：train_set&#x3D;data&#x2F;plp&#x2F;train_12000</li>
<li>对齐：ali_dir&#x3D;exp_syll&#x2F;tri3_ali</li>
<li>模型：tdnn，6层，1024结点，左拼13右拼9</li>
<li>分类数：8000类</li>
<li>结果：loss&#x3D;-2，acc&#x3D;46%（可能因为分类数太多，调小学习率继续训练无改善）</li>
</ul>
</li>
<li>用conv tdnnf的chain大模型（67M）作为后续对齐模型<ul>
<li>路径24.4:&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;hi_mia&#x2F;w1&#x2F;exp_syll&#x2F;chain&#x2F;tdnn_cnn_tdnnf</li>
<li>脚本：run_2_chain_ddt1500h.sh</li>
<li>lattice：&#x2F;home&#x2F;storage&#x2F;yelong&#x2F;lattice&#x2F;exp_syll&#x2F;tri3_lats</li>
<li>tree：exp_syll&#x2F;chain&#x2F;tri4_cd_tree</li>
<li>feat：data&#x2F;plp&#x2F;train_12000</li>
<li>模型：cnn-tdnnf</li>
</ul>
</li>
</ul>
<h3 id="对齐大模型生成lattice"><a href="#对齐大模型生成lattice" class="headerlink" title="对齐大模型生成lattice"></a>对齐大模型生成lattice</h3><ul>
<li>tdnn大模型生成lattice：<ul>
<li>训练集：负样本12000小时（1111万条），正样本2000小时（380万条），data_multi&#x2F;merge_all_sub4_12000&#x2F;，正负样本1：6</li>
<li>tdnn大模型路径：25.3：&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;hi_mia&#x2F;w1&#x2F;exp_syll&#x2F;nnet3&#x2F;tdnn</li>
<li>对齐lattice路径：exp_syll&#x2F;nnet3&#x2F;tdnn_12000n_2000p_lats&#x2F;（集群跑的）</li>
</ul>
</li>
<li>chain大模型生成lattice<ul>
<li>训练集：负样本12000小时（1111万条），正样本2000小时（380万条），data_multi&#x2F;merge_all_sub4_12000&#x2F;，正负样本1：6</li>
<li>对齐lattice路径：exp_syll&#x2F;chain&#x2F;tdnn_cnn_tdnnf_12000n_2000p_lats&#x2F;（集群跑的）[没跑完]</li>
<li>这次把命令词都放在词典中，作为整词，不分词【没必要，因为chain用1状态建模（2个pdf），不是三音素是单音素，和前后文无关】</li>
<li>料想和tdnn对齐模型效果差不多，实验暂停。</li>
</ul>
</li>
</ul>
<h3 id="构建单音素（每个音素两个pdf）"><a href="#构建单音素（每个音素两个pdf）" class="headerlink" title="构建单音素（每个音素两个pdf）"></a>构建单音素（每个音素两个pdf）</h3><ul>
<li><p>脚本：25.3：&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;hi_mia&#x2F;w1&#x2F;run_2_chain_ddt1500h.sh</p>
</li>
<li><p>构建单音素build-tree时：–context-width&#x3D;1 –central-position&#x3D;0</p>
</li>
<li><p>得到pdf&#x3D;808（不是810，这是因为音节den和dia的forward-pdf和self-loop&#x3D;pdf相同，应该是因为训练样本里没有？）</p>
</li>
</ul>
<h3 id="训练chain-model"><a href="#训练chain-model" class="headerlink" title="训练chain model"></a>训练chain model</h3><h2 id="Finetune"><a href="#Finetune" class="headerlink" title="Finetune"></a>Finetune</h2><ul>
<li><p>根据chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm，解码训练集data_multi&#x2F;merge_all_sub4_12000，得到data_multi&#x2F;merge_all_sub4_12000_filter_false_rejection_alarm，其中，</p>
<ul>
<li>false alarm数量6k</li>
<li>false rejection数量50w，其中，7w条是识别成其他唤醒词（也就是其他唤醒词的误唤醒），7w条中有6w条是上&#x2F;下一曲&#x2F;集的误唤醒，小源小源4w</li>
<li>方法2重训后，再次解码false alarm和false rejection样本<ul>
<li>false alarm：6k -&gt; 5k（下降19%）</li>
<li>false rejection：50w -&gt; 48w（下降4.7%）</li>
</ul>
</li>
</ul>
</li>
<li><p>根据chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch，解码训练集data_multi&#x2F;merge_all_sub4_12000，得到data_multi&#x2F;merge_all_sub4_12000_filter_false_rejection_alarm_tdnnf8，其中，</p>
<ul>
<li>false alarm数量1.8w</li>
<li>false rejection数量66w，其中，小源小源4.8w</li>
<li>测试集far会更低的，但是解码训练集，居然比chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm的更多！！！</li>
<li>方法2重训后，再次解码false alarm和false rejection样本，和想象的不同的是，误唤醒和误拒绝并没有少很多，感觉还是没训练好<ul>
<li>false alarm：1.8w -&gt; 1.5w （下降17.2%）</li>
<li>false rejection：66w -&gt; 62w（下降5.6%）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="方法1："><a href="#方法1：" class="headerlink" title="方法1："></a>方法1：</h4><ul>
<li>只对这些样本重新训练一轮（也要保证正负样本比例，小源正样本还不能少，否则唤醒率会略有下降）<ul>
<li>随机shuf取出300w的负样本，与false alarm构成300w的负样本，正样本50w</li>
<li>在exp_syll&#x2F;nnet3&#x2F;tdnn_12000n_2000p_lats&#x2F;中用</li>
<li>脚本：25.3:&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;hi_mia&#x2F;w1&#x2F;run_2_chain_ddt1500h.filter_far_frejection.sh</li>
<li>模型：exp_syll&#x2F;chain&#x2F;chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_filter_false_reje_ala_small_learningrate</li>
<li>input_model：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm&#x2F;final.mdl</li>
<li>初始和结束的学习率都为&#x3D;&#x3D;0.000001&#x3D;&#x3D;</li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lattice-copy <span class="string">&quot;--include=cat data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/uttlist |&quot;</span> --ignore-missing <span class="string">&quot;ark:gunzip -c exp_syll/nnet3/tdnn_12000n_2000p_lats/lat.1.gz |&quot;</span> <span class="string">&quot;ark:| gzip -c &gt; exp_syll/nnet3/tdnn_12000n_2000p_filter_false_rejection_alarm_lats/lat.1.gz&quot;</span></span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">lattice-copy <span class="string">&quot;--include=cat data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/uttlist |&quot;</span> --ignore-missing <span class="string">&quot;ark:gunzip -c exp_syll/nnet3/tdnn_12000n_2000p_lats/lat.1.gz |&quot;</span> ark,t:exp_syll/nnet3/tdnn_12000n_2000p_filter_false_rejection_alarm_lats/lat.1.ark</span><br><span class="line"></span><br><span class="line"><span class="comment"># 脚本：</span></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> $(<span class="built_in">seq</span> 1 120);<span class="keyword">do</span></span><br><span class="line">     <span class="comment">#lattice-copy &quot;--include=cat data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/uttlist |&quot; --ignore-missing &quot;ark:gunzip -c exp_syll/nnet3/tdnn_12000n_2000p_lats/lat.$n.gz |&quot; &quot;ark:| gzip -c &gt; exp_syll/nnet3/tdnn_12000n_2000p_filter_false_rejection_alarm_lats/lat.$n.gz&quot;</span></span><br><span class="line">    lattice-copy <span class="string">&quot;ark:gunzip -c exp_syll/nnet3/tdnn_12000n_2000p_filter_false_rejection_alarm_lats/lat.<span class="variable">$n</span>.gz |&quot;</span> ark,t:1</span><br><span class="line">    awk <span class="string">&#x27;&#123;if(NF==1)print$1,$1&#125;&#x27;</span> 1 | grep -E <span class="string">&quot;^0|^K|^Xiaoyuan|^SY|^sp&quot;</span> &gt; data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/utt2spk</span><br><span class="line"><span class="built_in">cp</span> data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/utt2spk data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/spk2utt</span><br><span class="line">    utils/filter_scp.pl data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/utt2spk data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/feats.scp &gt; data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/feats.scp</span><br><span class="line">    utils/filter_scp.pl data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/utt2spk data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/cmvn.scp &gt; data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/cmvn.scp</span><br><span class="line">    utils/filter_scp.pl data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/utt2spk data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/text &gt; data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/text</span><br><span class="line">    utils/filter_scp.pl data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/utt2spk data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/utt2dur &gt; data_multi/merge_all_sub4_12000_filter_false_rejection_alarm/split120/<span class="variable">$n</span>/utt2dur</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>将筛选出的lattice放在exp_syll&#x2F;nnet3&#x2F;tdnn_12000n_2000p_filter_false_rejection_alarm_lats中<ul>
<li>结果：如果学习率是0.00015开始训练的，学习率一开始设置得较大，<strong>效果不好，没有改善</strong>，误唤醒还增加了，但是&#x3D;&#x3D;调小学习率后，效果变好了&#x3D;&#x3D;</li>
</ul>
</li>
<li>用同一批数据finetune tdnnf8试一试</li>
</ul>
<h4 id="方法2："><a href="#方法2：" class="headerlink" title="方法2："></a>方法2：</h4><ul>
<li>对这些样本赋予高一点的权重，其他样本赋予低一点的权重，对所有样本finetune训练一轮</li>
<li>脚本：25.3:&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;hi_mia&#x2F;w1&#x2F;run_tdnn_multilingual.sh</li>
<li>模型：exp_syll&#x2F;chain&#x2F;chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch_multitask_test_input_model&#x2F;<ul>
<li><code>awk -F&#39;-&#39; &#39;&#123;$NF=null;print$0&#125;&#39; 1| sed &#39;s/ *$//&#39; | tr &#39; &#39; &#39;-&#39; | paste -d &#39; &#39; - 1</code></li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> $(<span class="built_in">seq</span> 1 3430);<span class="keyword">do</span></span><br><span class="line">    nnet3-chain-copy-egs ark:exp_syll/chain/chain_tdnnf13_320_32_l27r27_id_merge_all_sub4_12000_basedTDNN/egs/cegs.<span class="variable">$&#123;n&#125;</span>.ark ark,scp:exp_syll/chain/chain_tdnnf13_320_32_l27r27_id_merge_all_sub4_12000_basedTDNN_multi_2/egs/cegs.<span class="variable">$&#123;n&#125;</span>.temp.ark,exp_syll/chain/chain_tdnnf13_320_32_l27r27_id_merge_all_sub4_12000_basedTDNN_multi_2/egs/cegs.<span class="variable">$&#123;n&#125;</span>.temp.scp</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>



<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">src=exp_syll/chain/chain_tdnnf13_320_32_l27r27_id_merge_all_sub4_12000_basedTDNN_multi_2/egs</span><br><span class="line"><span class="built_in">dir</span>=exp_syll/chain/chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch_multitask/egs</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> $(<span class="built_in">seq</span> 1 3430);<span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$n</span></span><br><span class="line">  <span class="built_in">cp</span> <span class="variable">$src</span>/cegs.<span class="variable">$n</span>.temp.scp <span class="variable">$dir</span>/cegs.<span class="variable">$n</span>.scp</span><br><span class="line">  awk -F<span class="string">&#x27;-&#x27;</span> <span class="string">&#x27;&#123;$NF=null;print$0&#125;&#x27;</span> <span class="variable">$dir</span>/cegs.<span class="variable">$n</span>.scp| sed <span class="string">&#x27;s/ *$//&#x27;</span> | <span class="built_in">tr</span> <span class="string">&#x27; &#x27;</span> <span class="string">&#x27;-&#x27;</span> | <span class="built_in">paste</span> -d <span class="string">&#x27; &#x27;</span> - <span class="variable">$dir</span>/cegs.<span class="variable">$n</span>.scp | utils/filter_scp.pl false_alarm_rejection - &gt; <span class="variable">$dir</span>/<span class="variable">$n</span>.temp.ark.1</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$2,&quot;2.5&quot;&#125;&#x27;</span>  <span class="variable">$dir</span>/<span class="variable">$n</span>.temp.ark.1 &gt;  <span class="variable">$dir</span>/cegs.weight.<span class="variable">$n</span>.ark.1</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$2,&quot;output-0&quot;&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$n</span>.temp.ark.1 &gt;  <span class="variable">$dir</span>/cegs.output.<span class="variable">$n</span>.ark.1</span><br><span class="line">  awk -F<span class="string">&#x27;-&#x27;</span> <span class="string">&#x27;&#123;$NF=null;print$0&#125;&#x27;</span> <span class="variable">$dir</span>/cegs.<span class="variable">$n</span>.scp| sed <span class="string">&#x27;s/ *$//&#x27;</span> | <span class="built_in">tr</span> <span class="string">&#x27; &#x27;</span> <span class="string">&#x27;-&#x27;</span> | <span class="built_in">paste</span> -d <span class="string">&#x27; &#x27;</span> - <span class="variable">$dir</span>/cegs.<span class="variable">$n</span>.scp | utils/filter_scp.pl --exclude false_alarm_rejection - &gt; <span class="variable">$dir</span>/<span class="variable">$n</span>.temp.ark.2</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$2,&quot;1&quot;&#125;&#x27;</span>  <span class="variable">$dir</span>/<span class="variable">$n</span>.temp.ark.2 &gt;  <span class="variable">$dir</span>/cegs.weight.<span class="variable">$n</span>.ark.2</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$2,&quot;output-1&quot;&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$n</span>.temp.ark.2 &gt;  <span class="variable">$dir</span>/cegs.output.<span class="variable">$n</span>.ark.2</span><br><span class="line">  <span class="built_in">cat</span> <span class="variable">$dir</span>/cegs.weight.<span class="variable">$n</span>.ark.1 <span class="variable">$dir</span>/cegs.weight.<span class="variable">$n</span>.ark.2 &gt; <span class="variable">$dir</span>/cegs.weight.<span class="variable">$n</span>.ark.3</span><br><span class="line">  <span class="built_in">cat</span> <span class="variable">$dir</span>/cegs.output.<span class="variable">$n</span>.ark.1 <span class="variable">$dir</span>/cegs.output.<span class="variable">$n</span>.ark.2 &gt; <span class="variable">$dir</span>/cegs.output.<span class="variable">$n</span>.ark.3</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$1,$1&#125;&#x27;</span> <span class="variable">$dir</span>/cegs.<span class="variable">$n</span>.scp |  utils/apply_map.pl -f 1 <span class="variable">$dir</span>/cegs.weight.<span class="variable">$n</span>.ark.3 | awk <span class="string">&#x27;&#123;print$2,$1&#125;&#x27;</span> &gt; <span class="variable">$dir</span>/cegs.weight.<span class="variable">$n</span>.ark</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$1,$1&#125;&#x27;</span> <span class="variable">$dir</span>/cegs.<span class="variable">$n</span>.scp |  utils/apply_map.pl -f 1 <span class="variable">$dir</span>/cegs.output.<span class="variable">$n</span>.ark.3 | awk <span class="string">&#x27;&#123;print$2,$1&#125;&#x27;</span> &gt; <span class="variable">$dir</span>/cegs.output.<span class="variable">$n</span>.ark</span><br><span class="line">  <span class="built_in">rm</span> <span class="variable">$dir</span>/cegs.weight.<span class="variable">$n</span>.ark.*</span><br><span class="line">  <span class="built_in">rm</span> <span class="variable">$dir</span>/cegs.output.<span class="variable">$n</span>.ark.*</span><br><span class="line">  <span class="built_in">rm</span>  <span class="variable">$dir</span>/<span class="variable">$n</span>.temp.ark.*</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> combine train_diagnostic valid_diagnostic;<span class="keyword">do</span></span><br><span class="line">  nnet3-chain-copy-egs ark:exp_syll/chain/chain_tdnnf13_320_32_l27r27_id_merge_all_sub4_12000_basedTDNN/egs/<span class="variable">$i</span>.cegs ark,scp:<span class="variable">$src</span>/<span class="variable">$i</span>.cegs,<span class="variable">$src</span>/<span class="variable">$i</span>.scp</span><br><span class="line">  <span class="built_in">cp</span> <span class="variable">$src</span>/<span class="variable">$i</span>.scp <span class="variable">$dir</span>/<span class="variable">$i</span>.scp</span><br><span class="line">  awk -F<span class="string">&#x27;-&#x27;</span> <span class="string">&#x27;&#123;$NF=null;print$0&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.scp | sed <span class="string">&#x27;s/ *$//&#x27;</span> | <span class="built_in">tr</span> <span class="string">&#x27; &#x27;</span> <span class="string">&#x27;-&#x27;</span> | <span class="built_in">paste</span> -d <span class="string">&#x27; &#x27;</span> - <span class="variable">$dir</span>/<span class="variable">$i</span>.scp | utils/filter_scp.pl false_alarm_rejection - &gt; <span class="variable">$dir</span>/<span class="variable">$i</span>.temp.ark.1</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$2,&quot;2.5&quot;&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.temp.ark.1 &gt;  <span class="variable">$dir</span>/<span class="variable">$i</span>.weight.ark.1</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$2,&quot;output-0&quot;&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.temp.ark.1 &gt;  <span class="variable">$dir</span>/<span class="variable">$i</span>.output.ark.1</span><br><span class="line"></span><br><span class="line">  awk -F<span class="string">&#x27;-&#x27;</span> <span class="string">&#x27;&#123;$NF=null;print$0&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.scp| sed <span class="string">&#x27;s/ *$//&#x27;</span> | <span class="built_in">tr</span> <span class="string">&#x27; &#x27;</span> <span class="string">&#x27;-&#x27;</span> | <span class="built_in">paste</span> -d <span class="string">&#x27; &#x27;</span> - <span class="variable">$dir</span>/<span class="variable">$i</span>.scp | utils/filter_scp.pl --exclude false_alarm_rejection - &gt; <span class="variable">$dir</span>/<span class="variable">$i</span>.temp.ark.2</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$2,&quot;1&quot;&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.temp.ark.2 &gt;  <span class="variable">$dir</span>/<span class="variable">$i</span>.weight.ark.2</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$2,&quot;output-1&quot;&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.temp.ark.2 &gt;  <span class="variable">$dir</span>/<span class="variable">$i</span>.output.ark.2</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cat</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.weight.ark.1 <span class="variable">$dir</span>/<span class="variable">$i</span>.weight.ark.2 &gt; <span class="variable">$dir</span>/<span class="variable">$i</span>.weight.ark.3</span><br><span class="line">  <span class="built_in">cat</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.output.ark.1 <span class="variable">$dir</span>/<span class="variable">$i</span>.output.ark.2 &gt; <span class="variable">$dir</span>/<span class="variable">$i</span>.output.ark.3</span><br><span class="line"></span><br><span class="line">  awk <span class="string">&#x27;&#123;print$1,$1&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.scp |  utils/apply_map.pl -f 1 <span class="variable">$dir</span>/<span class="variable">$i</span>.weight.ark.3 | awk <span class="string">&#x27;&#123;print$2,$1&#125;&#x27;</span> &gt; <span class="variable">$dir</span>/<span class="variable">$i</span>.weight.ark</span><br><span class="line">  awk <span class="string">&#x27;&#123;print$1,$1&#125;&#x27;</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.scp |  utils/apply_map.pl -f 1 <span class="variable">$dir</span>/<span class="variable">$i</span>.output.ark.3 | awk <span class="string">&#x27;&#123;print$2,$1&#125;&#x27;</span> &gt; <span class="variable">$dir</span>/<span class="variable">$i</span>.output.ark</span><br><span class="line">  <span class="built_in">rm</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.weight.ark.*</span><br><span class="line">  <span class="built_in">rm</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.output.ark.*</span><br><span class="line">  <span class="built_in">rm</span> <span class="variable">$dir</span>/<span class="variable">$i</span>.temp.ark.*</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<ul>
<li>初始学习率设置为1.2e-04（8卡，脚本里对应0.000015）或者1e6，结果差不多</li>
<li>input_model：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;final_add_output01.mdl</li>
<li>似乎是因为这是tdnn5的false alarm和false rejection样本，似乎对于tdnnf8无效，因此没有改善，应该用tdnnf8的解码训练集训一轮，会好一点</li>
</ul>
<h4 id="把以上对于tdnn5不同权重finetune一轮："><a href="#把以上对于tdnn5不同权重finetune一轮：" class="headerlink" title="把以上对于tdnn5不同权重finetune一轮："></a>把以上对于tdnn5不同权重finetune一轮：</h4><ul>
<li><p>脚本：25.3:&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;hi_mia&#x2F;w1&#x2F;run_tdnn_multilingual_tdnn5.sh</p>
</li>
<li><p>模型：exp_syll&#x2F;chain&#x2F;chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_multitask</p>
</li>
<li><p>input_model：exp_syll&#x2F;chain&#x2F;chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm&#x2F;final_add_output01.mdl</p>
</li>
<li><p>初始和结束的学习率都为&#x3D;&#x3D;0.000001&#x3D;&#x3D;（8卡，脚本里对应0.000000125）（是否有点小了？）</p>
</li>
<li><p>有改善，改善比方法1多，不知道这个改善是否来源于多训练一轮epoch？</p>
</li>
</ul>
<h4 id="重新解码tdnnf8训练集，用tdnnf8解码的false-alarm和false-rejection样本finetune一轮"><a href="#重新解码tdnnf8训练集，用tdnnf8解码的false-alarm和false-rejection样本finetune一轮" class="headerlink" title="重新解码tdnnf8训练集，用tdnnf8解码的false alarm和false rejection样本finetune一轮"></a>重新解码tdnnf8训练集，用tdnnf8解码的false alarm和false rejection样本finetune一轮</h4><ul>
<li>weight比例2.5：1，无论学习率是1e-6（8卡后）或者1.5e-5（8卡后），效果都没有改善</li>
<li>查看有没有&#x3D;&#x3D;过拟合&#x3D;&#x3D;：<code>grep output-0-xent compute_prob_valid.* | sed &#39;s/valid./ /g&#39; | sed &#39;s/.log/ /g&#39; | sort -k 2 -n</code></li>
<li><code>grep &quot;average objective function for &#39;output-0&#39;&quot; train.*.1.log |  sed &#39;s/train./ /g&#39; | sed &#39;s/.1.log/ /g&#39; |  sort -k 1 -n</code></li>
<li>少数测试集有改善</li>
</ul>
<h3 id="学习率设置"><a href="#学习率设置" class="headerlink" title="学习率设置"></a>学习率设置</h3><table>
<thead>
<tr>
<th></th>
<th>脚本里initial_lr（实际lr (乘以gpu数)</th>
<th>脚本里final_lr（实际lr (乘以gpu数)</th>
</tr>
</thead>
<tbody><tr>
<td>普通</td>
<td>0.00015</td>
<td>0.000015</td>
</tr>
<tr>
<td>more_epoch</td>
<td>0.000015</td>
<td>0.0000015</td>
</tr>
<tr>
<td>false_reje_ala：训练的是tdnn5（结果不好）</td>
<td>0.00015</td>
<td>0.000015</td>
</tr>
<tr>
<td>false_reje_ala调小学习率：训练的是tdnn5（有改善）</td>
<td>1.25e-7（1e-06）</td>
<td>1.25e-7（1e-06）</td>
</tr>
<tr>
<td>multitask_test_input_model：训练的是tdnnf8（没有改善）</td>
<td>0.000015（0.00012）</td>
<td>0.0000015（1.2e-05）</td>
</tr>
<tr>
<td>multitask_test_input_model_small_learningrate：训练的是tdnnf8（没有改善）</td>
<td>1.25e-7（1e-06）</td>
<td>1.25e-7（1e-06）</td>
</tr>
</tbody></table>
<h3 id="测试解码"><a href="#测试解码" class="headerlink" title="测试解码"></a>测试解码</h3><ul>
<li>chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm</li>
</ul>
<h3 id="实验测试结果"><a href="#实验测试结果" class="headerlink" title="实验测试结果"></a>实验测试结果</h3><ul>
<li><p>10000条命令词，测唤醒率</p>
</li>
<li><p>tdnn[1]：chain_tdnn5_256_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm&#x2F;graph_add_two</p>
</li>
<li><p>tdnn[2]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_filter_false_reje_ala_small_learningrate&#x2F;graph</p>
</li>
<li><p>tdnn[3]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_multitask&#x2F;graph</p>
</li>
<li><p>tdnn[4]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph</p>
</li>
<li><p>tdnnf[1]：chain_tdnnf13_320_32_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm</p>
</li>
<li><p>tdnnf[2]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph_add_two2&#x2F;</p>
</li>
<li><p>tdnnf[3]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch_multitask_tdnnf8decode&#x2F;graph_10_1</p>
</li>
<li><p>tdnnf[4]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph1&#x2F;  （2gram lm）[实际不可用]</p>
</li>
<li><p>47万条随机语音片段，测误唤醒（479984）</p>
</li>
<li><p>tdnn[1]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm&#x2F;graph_add_two</p>
</li>
<li><p>tdnn[2]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_filter_false_reje_ala_small_learningrate&#x2F;graph</p>
</li>
<li><p>tdnn[3]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_multitask&#x2F;graph</p>
</li>
<li><p>tdnn[4]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph</p>
</li>
<li><p>tdnnf[1]：chain_tdnnf13_320_32_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm</p>
</li>
<li><p>tdnnf[2]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph_add_two2&#x2F;</p>
</li>
<li><p>tdnnf[3]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch_multitask_tdnnf8decode&#x2F;graph_10_1</p>
</li>
<li><p>tdnnf[4]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph1&#x2F;  （2gram lm）[实际不可用]</p>
</li>
<li><p>小源小源一个唤醒词</p>
</li>
<li><p>lei：V1+SIL</p>
</li>
<li><p>tdnn[1]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm&#x2F;graph_add_two</p>
</li>
<li><p>tdnn[2]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_filter_false_reje_ala_small_learningrate&#x2F;graph</p>
</li>
<li><p>tdnn[3]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_multitask&#x2F;graph</p>
</li>
<li><p>tdnn[4]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph</p>
</li>
<li><p>tdnnf[1]：chain_tdnnf13_320_32_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm&#x2F;graph_add_two2 前向计算时间长，不考虑</p>
</li>
<li><p>tdnnf[2]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph_add_two2</p>
</li>
<li><p>tdnnf[3]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch_multitask_tdnnf8decode&#x2F;graph_10_1</p>
</li>
<li><p>tdnnf[4]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph1&#x2F;  （2gram lm）[实际不可用]</p>
</li>
<li><p>()内是所有命令词的误唤醒</p>
</li>
</ul>
<h3 id="实验小结"><a href="#实验小结" class="headerlink" title="实验小结"></a>实验小结</h3><ul>
<li>从声学模型输出观察：</li>
</ul>
<p><code>pdf2phone exp_syll/chain/chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm/final.mdl ark:feats.scp1.1.1 | utils/int2sym.pl -f 2- exp_syll/chain/chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm/phones.txt -</code></p>
<p>发现确实是声学模型不够好造成的误触发。相似音（比如jing和ji）容易误触发</p>
<ul>
<li><p>多训练epoch效果有改善（4epoch-&gt;5epoch）</p>
</li>
<li><p>学习率不能调高，否则易过拟合</p>
</li>
<li><p>训练分母的phone lm从4gram到2gram，效果会提升，训练中复杂的语言模型反而没有带来收益，推测原因：</p>
<ul>
<li>1.简单的语言模型能让声学模型得到的信息更少，加重了声学模型的训练难度，使得声学模型训练得更不容易过拟合；</li>
<li>2.复杂的语言模型（适配训练集的语言模型）使得声学模型更容易过拟合；</li>
<li>3.训练中简单的语言模型与测试的1gram语言模型更接近；</li>
</ul>
</li>
<li><p>解码训练集，用false alarm和false rejection的样本，增加高一点权重（调参10:1和2.5:1）,不同学习率，重训练一轮。结果没有改善</p>
</li>
</ul>
<h2 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h2><ul>
<li>小源小源唤醒词的唤醒率、误唤醒基本可以达到要求，但是其他唤醒词的误唤醒还是比较高。</li>
<li>尝试从样本出发：解码训练集，用false alarm和false rejection的样本，增加高一点权重（调参10:1和2.5:1），重训练一轮。结果：没有改善</li>
<li>尝试从后处理出发：增加简单二级阈值判断（解码命令词起止时间长度，解码命令词cost值）。结果：没有改善，简单阈值判断不出。</li>
<li>尝试从训练目标函数出发：用最大化状态&#x2F;音素正确率作为目标函数（sMBR、MPE），增加唤醒词的唤醒率；尝试center loss减少类内距离（从而增加类间距离）（未完成）</li>
<li>尝试从声学模型出发：tdnnf比tdnn好，在前向时间相同情况下尝试其他声学模型（未完成）</li>
</ul>
<h2 id="增加解码竞争路径"><a href="#增加解码竞争路径" class="headerlink" title="增加解码竞争路径"></a>增加解码竞争路径</h2><p>花哥说，用类似2gram语言模型思路，通过判断两个字前后的文本是怎样的，来抑制两个字的误触发。</p>
<p>具体做法思路：把1gram里的命令词去掉，放在2gram里</p>
<p>路径：25.3:&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;hi_mia&#x2F;w1&#x2F;data_syll&#x2F;lang_context</p>
<p>HCLG：exp_syll&#x2F;chain&#x2F;chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph1&#x2F; </p>
<p>把四字放到2gram里，删掉1gram它的路径，效果没有提升反而下降，原因分析 </p>
<p>该方法有效降低误触发，二、三字误触发能降低17%~30%</p>
<p><img src="/2021/12/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8Echain%E5%A4%9A%E5%94%A4%E9%86%92%E8%AF%8D%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B/image-20211220141423434.png" alt="image-20211220141423434"></p>
<p>1是开始状态，两个圈是结束状态。</p>
<p>表示只能以 2gram里只能以 比如 静音 开头，可以 有“静音 其他音” 的路径，但没有“其他音 静音” 的路径</p>
<p>与原先区别：命令词前有其他声音会降低唤醒率（要很大声）（现实总是有其他声音的，不可行）</p>
<p>实验不可行：测试0807（实际录音），小源小源也采用上述方法放进2gram，发现唤醒率很低。</p>
<p>虽然在test_1w里，四字的唤醒率没有降低，但是在0807实测测试集里，唤醒率大幅度降低</p>
<h4 id="2gram"><a href="#2gram" class="headerlink" title="2gram"></a>2gram</h4><p>用训练集ali训练的2gram LM，误识别率可以下降34%，但是时间多5倍</p>
<p>剪枝后：</p>
<p>ngram -lm srilm.o3g.kn.gz -order 2  -prune 0.00001 -write-lm newlm：误唤醒能下降28%，时间2倍之前（雷博说这个可能测不准，要用keyword_lib测才会准一点）</p>
<p>ngram -lm srilm.o3g.kn.gz -order 2  -prune 0.0001 -write-lm newlm：误唤醒只能下降4%，时间1.4倍之前</p>
<h4 id="降低一点点识别率，同时也降低误识别率的方法："><a href="#降低一点点识别率，同时也降低误识别率的方法：" class="headerlink" title="降低一点点识别率，同时也降低误识别率的方法："></a>降低一点点识别率，同时也降低误识别率的方法：</h4><p>把相似音（比如zan的相似音zai、zi、zhan…….）的权重提高一点</p>
<h4 id="误触发常发生在有个xiao-x2F-yuan开头的音，即使音后面不同，也会触发"><a href="#误触发常发生在有个xiao-x2F-yuan开头的音，即使音后面不同，也会触发" class="headerlink" title="误触发常发生在有个xiao&#x2F;yuan开头的音，即使音后面不同，也会触发"></a>误触发常发生在有个xiao&#x2F;yuan开头的音，即使音后面不同，也会触发</h4><p>我的意思是修改FST，让小源小源在发音发完整个词后，output label才是小源小源。</p>
<p>雷博说，现在输出文本，都是发完小源小源，达到结束state了，才会回溯判断是否有小源小源，不存在发音一半就出来小源小源的情况；</p>
<p>唯一可能减少一点误触发的方法就是，小&#x2F;源状态自己也有结束state，可能到达小&#x2F;源就结束；</p>
<p>但其实这个在垃圾路径里已经添加了，没有走到还是路径权重的原因；</p>
<img src="/2021/12/03/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%9F%BA%E4%BA%8Echain%E5%A4%9A%E5%94%A4%E9%86%92%E8%AF%8D%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B/image-20220104172646296.png" alt="image-20220104172646296" style="zoom: 25%;">



]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>多唤醒词识别模型</title>
    <url>/2022/04/01/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E5%A4%9A%E5%94%A4%E9%86%92%E8%AF%8D%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="多唤醒词识别模型"><a href="#多唤醒词识别模型" class="headerlink" title="多唤醒词识别模型"></a>多唤醒词识别模型</h1><p>和单一唤醒词识别的思路一致，只不过训练的是多个唤醒词模型</p>
<p>建模单元之间一直说“音素”，其实应该说汉字声韵母</p>
<p>语言模型words可以是声韵母，或音节（声母+韵母组合）</p>
<h2 id="减少误触发"><a href="#减少误触发" class="headerlink" title="减少误触发"></a>减少误触发</h2><ul>
<li><p>方法1.雷博教</p>
<p>词典中唤醒词的音素映射 前后加sil（原来的音素映射不要了）</p>
</li>
<li><p>方法2：我做的，但是一开始没做好，雷博教</p>
<p>小源小源的音素映射 x iao vv van x iao vv van 改成 x x iao iao vv vv van van x x iao iao vv vv van van，我这样直接改变效果不好</p>
<p>雷博教，这样改了之后，训练数据也要改，重新训，效果才会好</p>
</li>
<li><p>方法3：不要prefix_drop，让唤醒率上去，误唤醒就能调低一点了，这样雷博说前面1s也要进行解码，会造成cpu使用快速上升</p>
</li>
<li><p>方法4：加二级DNN</p>
</li>
<li><p>方法5：雷博其他唤醒词作为一级，我的模型作为二级，级联</p>
</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol>
<li>实测：1w条测试集估计和训练集有重合，当实测0927_lei下，我的模型唤醒率低（和0927_lei测试集在kaldi结果一致，因此排除自研解码器原因；和adb打的log差别几条，因此排除log抓不全的原因），因此不是语言模型的原因，就是模型的问题导致测试效果不好；</li>
<li>速度扰动的数据增广有一定提升；</li>
<li>基于ce的声学模型，手调语言模型对自定义唤醒词不友好（唤醒语言模型权重没有一定规律，而雷博的chain model模型规律 两字、三字、四字唤醒词之间权重相近）；</li>
<li>基于ce的声学模型对于少分类可行（≤36分类），多分类不稳定（67分类），67分类ce model效果不及641分类chain model；</li>
<li>语言模型对唤醒结果有一定影响和作用，调到最好情况下，大语言模型权重大比小语言模型权重效果好（recall更高、far更低），2gram比1gram稳定，但是2gram手调数量太多，需要自动调参的手段。</li>
<li>语言模型的words，垃圾音可选全音素或者全音节，音素可减少解码路径，但是音素效果比音节差；因此对于超低功耗的唤醒词识别，垃圾音选择音素；对于ftv项目，选择音节；</li>
<li>语言模型的垃圾音为音素时，是唤醒词里有的每个音素 + 唤醒词里没有的音素用一个音表示（比如gbg）；需要与建模单元相同，假如全部垃圾音都用gbg表示，由于训练时这些音用的是自有音素表示，因此gbg无法表示这些音，造成far上升；</li>
</ol>
<h2 id="模型汇总"><a href="#模型汇总" class="headerlink" title="模型汇总"></a>模型汇总</h2><p>…</p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>片段语音唤醒</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E7%89%87%E6%AE%B5%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92/</url>
    <content><![CDATA[<h1 id="片段语音唤醒"><a href="#片段语音唤醒" class="headerlink" title="片段语音唤醒"></a>片段语音唤醒</h1><h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><ol>
<li>输入长度为T帧的语音片段，输出1个类别向量（每个类是一个唤醒词），超过阈值则唤醒；✔<ol>
<li>如果只有一个命令词（唤醒任务），可以只输出一个概率值；</li>
<li>适用模型：感受野较大的模型（CNN）（因为唤醒词持续数帧）、RNN</li>
</ol>
</li>
<li>输入长度为T帧的语音片段，输出T帧类别向量（每个类是一个唤醒词）；计算唤醒词类别的平滑后验概率等后处理方式，超过阈值则唤醒；<ol>
<li>适用模型：与上下文有关的RNN</li>
</ol>
</li>
<li>输入长度为T帧的语音片段，输出T帧类别向量（每个类是是唤醒词的子词、音节、音素），后处理唤醒词组成单元的概率，超过阈值则唤醒；✔<ol>
<li>适用模型：无限制（一帧语音特征可表示一个组成单元）</li>
</ol>
</li>
<li>输入长度为T帧的语音片段，输出T帧类别向量（每个类是是唤醒词的子词、音节、音素、以及非唤醒词），WFST解码，搜索最优路径，最优路径是否出现唤醒词则唤醒；✔<ol>
<li>适用模型：HMM模型</li>
</ol>
</li>
<li>输入长度为T帧的语音片段，输出N个类别向量（每个类是是唤醒词或子词、字符），搜索最优路径，最优路径是否出现唤醒词则唤醒；<ol>
<li>适用模型：transformer模型、RNN-T模型、CTC模型</li>
</ol>
</li>
</ol>
<p>[✔表示已做过实验]</p>
<h2 id="基于CNN的片段语音唤醒"><a href="#基于CNN的片段语音唤醒" class="headerlink" title="基于CNN的片段语音唤醒"></a>基于CNN的片段语音唤醒</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul>
<li>CNN结构、depthwise卷积、pointwise卷积、dialted卷积；</li>
<li>感受野1.84s，无padding（输入N帧，输出N-184帧）；</li>
<li>残差结构，不同感受野的特征层element-wise add；</li>
</ul>
<h4 id="模型图"><a href="#模型图" class="headerlink" title="模型图"></a>模型图</h4><p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E7%89%87%E6%AE%B5%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92/02.png" alt="02"></p>
<h4 id="模型对比"><a href="#模型对比" class="headerlink" title="模型对比"></a>模型对比</h4><ul>
<li>对比论文“Small-Footprint Keyword Spotting with Multi-Scale Temporal Convolution”的模型结构，上述模型结果更好；</li>
</ul>
<h3 id="训练、推理特征输入方式"><a href="#训练、推理特征输入方式" class="headerlink" title="训练、推理特征输入方式"></a>训练、推理特征输入方式</h3><ol>
<li><p>offline cmvn</p>
<p>​	1.1 语音特征文件做好offline cmvn后</p>
<p>​				1.1.1 训练时封装batch时pad_sequence补零，batch内最大长度不足1.84s的也补零至1.84s，训练时不再做cmvn；</p>
<p>​				1.1.2 训练时封装batch时pad_sequence复制第一帧，batch内最大长度不足1.84s的也复制第一帧至1.84s，训练时不再做cmvn；✔</p>
<p>​	（前期做了cmvn，训练中不用做cmvn，训练速度快）</p>
<p>​	1.2 语音特征文件没做cmvn</p>
<p>​				1.2.1 训练时封装batch时pad_sequence补零，batch内最大长度不足1.84s的也补零至1.84s</p>
<p>​							1.2.1.1	训练时根据实际长度做offline cmvn；（与1.1.1特征相同）</p>
<p>​							1.2.1.2	训练时根据pad_sequence后长度做offline cmvn；</p>
<p>​				1.2.2 训练时封装batch时pad_sequence复制第一帧，batch内最大长度不足1.84s的也复制第一帧至1.84s，训练时再做offline cmvn；</p>
<p>​							1.2.2.1	训练时根据实际长度做offline cmvn；（与1.1.2特征相同）</p>
<p>​							1.2.2.2	训练时根据pad_sequence后长度做offline cmvn；</p>
</li>
<li><p>sliding cmvn，将上述offline cmvn换成sliding cmvn</p>
</li>
<li><p>global cmvn，将上述offline cmvn换成global cmvn</p>
<ol>
<li>语音特征文件没做cmvn，利用训练集统计出的全局均值方差，训练时封装batch时pad_sequence补零，再做cmvn后，pad_sequence部分值不为0，作用于网络中，但它们没有物理含义，espnet和wenet框架都是这样做的，会有问题吗？</li>
</ol>
</li>
</ol>
<h3 id="训练目标函数"><a href="#训练目标函数" class="headerlink" title="训练目标函数"></a>训练目标函数</h3><ol>
<li><p>max_pooling loss 只取最大概率帧 </p>
<ol>
<li><p>target &#x3D; filler时：$loss&#x3D;\min\limits_T(1-P_{keyword})$	（min pooling）</p>
<p>target &#x3D; keyword时：$loss&#x3D;\max\limits_TP_{keyword}$	（max pooling）</p>
</li>
<li><p>取正样本某帧的最大正类概率值，让这帧概率越大越好，取负样本某帧的最小负类概率值，让这帧的概率越大越好；</p>
</li>
</ol>
</li>
<li><p>more_label loss 逐输出分类（每个输出都有标签）（普通的逐帧分类）</p>
<ol>
<li>扩充正负样本标签数量，取正样本输出时间轴所有帧，让所有时间帧的正类概率越大越好，取负样本输出时间轴所有帧，让所有时间帧的负类概率越小越好；</li>
<li>由于输入输出不等长，标签序列未知，要求训练数据片段内尽可能是一个分类（比如输入2s，输出16帧，16帧都要是正样本，因此2s尽可能是唤醒词，并且前后静音短）</li>
</ol>
</li>
<li><p>mean_pooling loss 平均概率</p>
<ol>
<li>取输出实际片段内平均概率，求bceloss</li>
</ol>
</li>
</ol>
<h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>最好结果：more_label loss训练得到初始模型，再用max_pooling loss训练；</p>
<h3 id="输出概率层"><a href="#输出概率层" class="headerlink" title="输出概率层"></a>输出概率层</h3><ul>
<li>单唤醒词，一个分类，用sigmoid</li>
</ul>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><h4 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h4><ul>
<li>train_p522h_n4000h：筛选出满足唤醒词对齐区间在2.5s内正样本数据，负样本segment为2s语音。正样本101万条，负样本717万条。</li>
</ul>
<h4 id="训练数据数据增广"><a href="#训练数据数据增广" class="headerlink" title="训练数据数据增广"></a>训练数据数据增广</h4><ul>
<li>正样本：原始“小源小源”音频14万条，加噪、速度扰动、扩充为102万条（667小时），筛选出满足唤醒词对齐区间在2.5s内正样本数据，得到101万条，522小时；</li>
<li>负样本：原始4000小时负样本、300小时mobvoihotwords，加噪900小时（5类噪声、NoiseX_92_carcafenoise、两两混合制造重叠说话人的效果），切割为2s音频，舍弃小于2s的，的搭配717万条，4000小时；</li>
</ul>
<h4 id="验证集"><a href="#验证集" class="headerlink" title="验证集"></a>验证集</h4><ul>
<li>训练的几个初始模型经过测试集，从测试集中选取far高、recall低作为cv；</li>
<li>正样本：0.6-6.5s，4k条，3h；</li>
<li>负样本：1.1-3.1s，15k条，11h；</li>
</ul>
<h3 id="推理过程"><a href="#推理过程" class="headerlink" title="推理过程"></a>推理过程</h3><ul>
<li>窗长200帧，窗移30帧的滑动窗口语音特征送入网路进行前向计算，输出16帧内，若同时满足最大概率值高于阈值1和平均概率高于阈值2，则唤醒；<ul>
<li>送入整句语音，实际长度小于1.85s，复制第一帧直到总长度为1.85s，计算概率（输出一帧）；实际长度在1.85s-2s之间，按实际长度计算概率，不用滑动；实际长度大于2s，进行滑动</li>
</ul>
</li>
<li>FLOPS &#x3D; 2M（未复用）、模型参数33k</li>
</ul>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><ul>
<li>tdnnf[2]：chain_tdnnf8_432_48_l27r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_more_epoch&#x2F;graph_add_two2；</li>
<li>tdnn[3]：chain_tdnn5_256_l39r27_id_merge_all_sub4_12000_basedTDNN_smaller_phone_lm_multitask&#x2F;graph；</li>
<li>tdnn10：keyword_lib&#x2F;data&#x2F;asr_config_xiaoyuan&#x2F;tdnn_10&#x2F;xyxyxy_2gram；</li>
<li>n10：exp_1&#x2F;mdtc_offline_cmvn_p382h_n4000h_max_pooling&#x2F;6.pt；</li>
</ul>
<h2 id="C-api"><a href="#C-api" class="headerlink" title="C++ api"></a>C++ api</h2><ul>
<li><p>模型pt格式转为onnx格式，用onnxruntime的动态链接库进行调用；</p>
</li>
<li><p>每次读入包大小（0.32s&#x2F;0.3s）的语音片段，</p>
<ul>
<li>到达最后一个包并且累计语音片段长度小于1.85s，复制第一帧直到总长度为1.85s，计算概率（输出一帧）；</li>
<li>到达最后一个包并且累计语音片段长度在1.85s-2s之间，按实际长度计算概率，不用滑动；</li>
<li>未到达最后一个包并且累计语音片段长度大于2s，计算概率，若唤醒，则向后滑动1s，1s内不检测，若未唤醒，则向滑动0.3s，继续判断；</li>
</ul>
</li>
<li><p>RTF在原来1&#x2F;3~1&#x2F;2；</p>
</li>
</ul>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>语音关键词检测方法综述</title>
    <url>/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/</url>
    <content><![CDATA[<h1 id="语音关键词检测方法综述"><a href="#语音关键词检测方法综述" class="headerlink" title="语音关键词检测方法综述"></a>语音关键词检测方法综述</h1><blockquote>
<p>参考：<a href="https://cloud.tencent.com/developer/article/1626816">语音关键词检测方法综述【附PPT与视频资料】</a></p>
<p>参考：《语音关键词检测方法综述 白烨.pptx》</p>
</blockquote>
<p>[TOC]</p>
<h1 id="主流方法-Mainstream-Approaches"><a href="#主流方法-Mainstream-Approaches" class="headerlink" title="主流方法 Mainstream Approaches"></a>主流方法 Mainstream Approaches</h1><p>Keyword Spotting”、“Keyword Search”、“Spoken Term Detection”，</p>
<p><strong>语音检索：</strong>从大段语音文档中定位到关键词所在位置。语音关键词检测相关的英文术语有“Keyword Spotting”、“Keyword Search”、“Spoken Term Detection”，然而它们实际上有不同的侧重，是两类不同的问题。Keyword Spotting 指的是语音设备控制这一类应用，一般来说它的关键词是固定的，关注的是低内存占用，低计算复杂度，低功耗下的高准确率；Spoken Term Detection或Keyword Search的关键词一般是可变的，需要定位出关键词在音频文档中的位置，困难点在集外词问题。下面我们分别就这两类问题，介绍相关的三种主流方法，然后在介绍几个前沿进展，最后做一个总结。</p>
<ul>
<li><p><strong>语音唤醒</strong>：Keyword Spotting，用于Voice-controlled devices</p>
<ul>
<li>特点：Keywords are usually fixed、Small-footprint、Efficient computation、Low-power consumption</li>
</ul>
</li>
<li><p><strong>语音检索</strong>：Spoken Term Detection（Keywords Search），用于Searching keywords in audio，在一大段语音音频中找到多个关键词</p>
<ul>
<li>特点：Keywords are changeable、Need to locate the keywords in audio、Out-of-vocabulary</li>
</ul>
</li>
</ul>
<h2 id="1、补白模型（Filler-Models）"><a href="#1、补白模型（Filler-Models）" class="headerlink" title="1、补白模型（Filler Models）"></a>1、补白模型（Filler Models）</h2><p>补白模型有时也被称为垃圾模型，它将Keyword Spotting问题考虑为一个逐帧的序列标注问题。关键词定为不同的标注，而一个额外的“补白”标注用来匹配所有非关键词。（序列标注：关键词,关键词,关键词,非关键词,非关键词,非关键词,…..这样的序列，多少帧多少标注，找最优路径，词级别的建模 –yl）</p>
<p>基于隐马尔可夫模型的补白模型最早用于Keyword Spotting。它对每一个关键词建立一个隐马尔可夫模型，对非关键词额外建立一个隐马尔可夫模型，观测概率通过混合高斯或神经网络建模。直接针对关键词建模在数据稀疏的问题。目前流行的隐马尔可夫模型则采用子词单元，如音素，进行建模。这种情况下，它与基于HMM混合模型的语音识别中的声学模型就十分类似了，只是解码图是手工设计的文法，而不是基于统计语言模型生成的。亚马逊Alexa语音助手所用的Keyword Spotting系统就是基于这一类方法的。</p>
<ul>
<li>The filler models are sometimes known as garbage models or acoustic keyword spotting.</li>
<li>This model can be seen as a framewise &#x3D;&#x3D;sequence labelling&#x3D;&#x3D; problem. </li>
<li>Keywords and non-keywords are modeled respectively in this approach.</li>
<li>Filler models are a set of models which can match &#x3D;&#x3D;arbitrary non-keyword&#x3D;&#x3D; speech utterances.</li>
</ul>
<h3 id="HMM-based-filler-models"><a href="#HMM-based-filler-models" class="headerlink" title="HMM based filler models"></a>HMM based filler models</h3><p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518104914019.png" alt="image-20210518104914019"></p>
<ul>
<li>Each keyword and a filler are modeled using HMM respectively.</li>
<li>Generative probability of a frame of speech parameters given a state of HMMs is estimated with GMMs or DNNs.</li>
</ul>
<blockquote>
<p>Wilpon J G, Lee C, Rabiner L R, et al. Application of hidden Markov models for recognition of a limited set of words in unconstrained speech[C]. international conference on acoustics, speech, and signal processing, 1989: 254-257.</p>
</blockquote>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518105057472.png" alt="image-20210518105057472"></p>
<ul>
<li>Each phone is modeled by an HMM model.</li>
<li>Searching Graph is built with a handcraft phone-level grammar. 手工打造的</li>
</ul>
<blockquote>
<p>Sun M, Snyder D, Gao Y, et al. Compressed Time Delay Neural Network for Small-Footprint Keyword Spotting.[C]. conference of the international speech communication association, 2017: 3607-3611.</p>
</blockquote>
<h3 id="DNN-based-filler-models"><a href="#DNN-based-filler-models" class="headerlink" title="DNN based filler models"></a>DNN based filler models</h3><p>另一种基于神经网络分类的方法就更加直接了，如下图所示，连续语音流<strong>逐段</strong>地送入神经网络进行分类。类别为所有的关键词，和一个额外的填充类别（Filler），比如有10个关键词，就有11类。</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518105156830.png" alt="image-20210518105156830"></p>
<p>分类完成后，由于输出的概率可能出现“毛刺”，所以进行平滑后处理，之后如果某一个类别概率超过一个阈值，就认为某一个关键词被检测到了。这种方法内存占用小，不需要解码搜索，准确率高。但是由于需要准备大量包含关键词的语料，如果更换了关键词，则需要再另行搜集一批语料，所以也较难实际使用。相比之下，基于隐马尔可夫模型的Keyword Spotting由于是针对子词单元建模，语料用通用的就可以，所以更常用。</p>
<p>（一段语音一段语音地送入DNN，得到这一段语音，比如100帧的100个输出，每个输出有11分类的概率，平滑一下，看看关键词分类的概率是否高过阈值，判断关键词是否被检测到–yl）</p>
<ul>
<li>DNN is used as a framewisely classifier.</li>
<li>Then the posteriors are smoothed with a window.</li>
<li>The system is used in mobile devices.</li>
</ul>
<blockquote>
<p>Chen G, Parada C, Heigold G, et al. Small-footprint keyword spotting using deep neural networks[C]. international conference on acoustics, speech, and signal processing, 2014: 4087-4091.</p>
</blockquote>
<h2 id="2、基于样例的Keyword-Spotting-Query-by-Example"><a href="#2、基于样例的Keyword-Spotting-Query-by-Example" class="headerlink" title="2、基于样例的Keyword Spotting (Query-by-Example)"></a>2、基于样例的Keyword Spotting (Query-by-Example)</h2><p>基于样例的Keyword Spotting，则将问题考虑为匹配问题。考虑关键词的音频样例，和几个测试音频，分别计算它们的相似度，测试音频中和关键词相似度超过某个阈值的，就认为它是检测出来的关键词。这种方式在使用的过程中，用户可以录制自己的音频并定义为关键词，使用起来就更个性化。</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518111612519.png" alt="image-20210518111612519"></p>
<ul>
<li>Query-by-example is a task to detect some keywords in a speech signal, where the keywords are saved as &#x3D;&#x3D;patterns&#x3D;&#x3D;. </li>
<li>Query-by-example methods allow users define their own keywords. It is more &#x3D;&#x3D;personalized&#x3D;&#x3D; for them to control their own devices.</li>
</ul>
<p><strong>Query-by-example methods</strong></p>
<p>基于样例的关键词检测可以分为两类，一种基于动态时间弯折（Dynamic Time Warping，DTW）算法，它使用DTW算法计算两个音频特征序列之间的相似度；另一种是基于嵌入学习的，它将两个音频分别编码为向量，然后直接计算两个向量之间的距离。基于DTW的方法从上世纪70年代就开始开始应用，但是它在匹配两个序列的时候计算复杂度比较高，目前主要用于无监督的情形；基于嵌入学习的方法，匹配的时候更为简单，在深度学习火热以后就流行起来。</p>
<ul>
<li>DTW Based Methods<ul>
<li>Extended from isolated word speech recognition.和孤立词识别方法一样，计算dtw距离，判断一段语音是不是关键词</li>
<li>The main difference is that the query is a word and the reference may be a longer sentence.和孤立词识别不同的是，query是词，reference是长句子</li>
</ul>
</li>
<li>Embedding Learning Based Method<ul>
<li>Represent speech sequence of arbitrary length as a fixed-dimensional vector are used in KWS.把任意长语音序列embed到固定维度向量</li>
</ul>
</li>
</ul>
<h3 id="DTW-Based-Methods"><a href="#DTW-Based-Methods" class="headerlink" title="DTW Based Methods"></a>DTW Based Methods</h3><ul>
<li>Compute similarity between two sequences of vectors.   用动态规划 计算两个向量的相似度</li>
<li>Two stages:<ul>
<li>Convert the queries and target speech into same representations using acoustic models.通过声学模型得到query和target speech的输出</li>
<li>Compute confidence of appearance of the keywords to decide whether the keywords appear in speech stream. 计算keyword置信度</li>
</ul>
</li>
</ul>
<blockquote>
<p>Itakura F. Minimum prediction residual principle applied to speech recognition[J]. IEEE Transactions on Acoustics, Speech, and Signal Processing, 1975, 23(1): 154-158.</p>
<p>Sakoe H, Chiba S. Dynamic programming algorithm optimization for spoken word recognition[J]. IEEE Transactions on Acoustics, Speech, and Signal Processing, 1978, 26(1): 159-165.</p>
</blockquote>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518112341053.png" alt="image-20210518112341053"></p>
<p>Formally Given two sequences  $X&#x3D;x_1,…,x_N$、$Y&#x3D;y_1,…,y_M$</p>
<p>Consider 累计距离 $c(k)&#x3D;(i(k),j(k))$</p>
<p>The matching pattern is a sequence of points $F&#x3D;c(1),c(2),…,c(k),..,c(K)$</p>
<p>The time-normalized distance is defined as:<br>$$<br>D(X,Y)&#x3D;\min_F{\frac{\sum\limits^K_{k&#x3D;1}d(c(k))w(k)}{\sum\limits_{k&#x3D;1}^Kw(k)}}<br>$$<br> 与长度有关，因此要归一化。</p>
<p><strong>约束条件 Five constraints:</strong></p>
<ol>
<li><p>Monotonicity  $i(k-1)\leq{i(k)}$ and $j(k-1)\leq{j(k)}$</p>
</li>
<li><p>Continuity $i(k)-i(k-1)\leq1$ and $j(k)-j(k-1)\leq1$</p>
</li>
<li><p>Boundary $i(1)&#x3D;1$, $j(1)&#x3D;1$ and $i(K)&#x3D;N$, $j(K)&#x3D;M$</p>
</li>
<li><p>Adjustment window $|i(k)-j(k)|\leq{R}$</p>
</li>
<li><p>Slope constraint</p>
</li>
</ol>
<p><strong>Several variants of DTW for KWS</strong></p>
<p>原先用于孤立词的DTW，用于KWS时，要做一些变化，因为一段语音里有很多内容，不确定匹配的有没有命令词。可以做分段DTW，也就是每隔一段语音就做一次DTW，看看和命令词的相似度；也可以做不分段的DTW，通过距离找到和模板第一个特征距离最小的测试语音的位置，然后才做DTW。</p>
<ul>
<li><p>Segmental DTW</p>
</li>
<li><p>Segmented DTW</p>
</li>
<li><p>Non-segmental DTW</p>
</li>
<li><p>Subsequence DTW</p>
</li>
<li><p>Segmental local normalized DTW</p>
</li>
</ul>
<blockquote>
<p>Mantena G V, Achanta S, Prahallad K, et al. Query-by-example spoken term detection using frequency domain linear prediction and non-segmental dynamic time warping[J]. IEEE Transactions on Audio, Speech, and Language Processing, 2014, 22(5): 946-955.</p>
<p>Zhang Y, Glass J R. Unsupervised spoken keyword spotting via segmental DTW on Gaussian posteriorgrams[C]. ieee automatic speech recognition and understanding workshop, 2009: 398-403.</p>
</blockquote>
<p><strong>Segmental DTW：</strong></p>
<p>每隔一段语音就做一次DTW，看看和命令词的相似度；</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518143143649.png" alt="image-20210518143143649"></p>
<p><strong>Segmental local normalized DTW</strong></p>
<p>Time complexity of SLN-DTW is O(mnd)</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518143222050.png" alt="image-20210518143222050"></p>
<p><strong>Feature representations and distance computation 特征表示和距离计算</strong></p>
<ul>
<li>Main feature representations<ul>
<li>Acoustic parameters (MFCC, FBANK)</li>
<li>Posteriogram (GMM, DNN) </li>
<li>Bottleneck feature (DNN, Autoencoder)</li>
</ul>
</li>
<li>Distance computation<ul>
<li>Compute similarity at each DTW step</li>
<li>Euclid distance</li>
<li>$-log(x\cdot{y})$ （对数内积）</li>
<li>$1-\frac{x\cdot{y}}{|x||y|}$ （1 - cosθ）</li>
</ul>
</li>
</ul>
<p><strong>Some drawbacks of DTW</strong></p>
<ul>
<li>Comparing two sequences using DTW based methods costs polynomial time.计算相似度耗时高（多项式的时间）</li>
<li>DTW is often oversensitive to longer phonetic segments. （长的音素段会过敏感）</li>
</ul>
<h3 id="Embedding-Learning-Based-Method"><a href="#Embedding-Learning-Based-Method" class="headerlink" title="Embedding Learning Based Method"></a>Embedding Learning Based Method</h3><ul>
<li>General ideas of non-DTW methods are based on to construct a &#x3D;&#x3D;fixed-dimensional vector&#x3D;&#x3D; to represent a speech segment of arbitrary length. </li>
<li>In this case, common distances such as Euclid or cosine can be used to measure similarity between two sequences.</li>
</ul>
<p><strong>Embedding learning using LSTM</strong></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518143222050-1621327747439.png" alt="image-20210518143222050"></p>
<ul>
<li><p>Audio is preprocessed by a voice activity detection system.</p>
</li>
<li><p>For speech regions, 40-dimensional mel-filterbank features are generated.</p>
</li>
<li><p>15k output targets represent whole word units</p>
</li>
<li><p>A fixed-length representation $f$ is created by choosing the last $k$ state vectors.</p>
</li>
</ul>
<p>如图所示就是一个基于嵌入学习的关键词检测系统。它由一个LSTM网络构成。训练时，将LSTM视为一个词级别的分类器；测试时，将测试音频和关键词音频输入进LSTM，将最后k个状态拼接起来，计算余弦距离，如果超过某个阈值，就认为是检测到了关键词。</p>
<blockquote>
<p>Chen G, Parada C, Sainath T N, et al. Query-by-example keyword spotting using long short-term memory networks[C]. international conference on acoustics, speech, and signal processing, 2015: 5236-5240.</p>
</blockquote>
<p><strong>Siamese networks based on CNN 孪生网络</strong></p>
<p>雷博说，孪生网络是人脸识别中提出的，可以比较两张人脸的相似度</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518153306116.png" alt="image-20210518153306116"></p>
<ul>
<li>Weakly supervised: the transcripts of training data and testing data are unknown.</li>
</ul>
<blockquote>
<p>Kamper H, Wang W, Livescu K, et al. Deep convolutional acoustic word embeddings using word-pair side information[J]. international conference on acoustics, speech, and signal processing, 2016: 4950-4954.</p>
</blockquote>
<h2 id="3、基于大词汇量连续语音识别系统的关键词检测-LVCSR-Based-Methods"><a href="#3、基于大词汇量连续语音识别系统的关键词检测-LVCSR-Based-Methods" class="headerlink" title="3、基于大词汇量连续语音识别系统的关键词检测(LVCSR Based Methods)"></a>3、基于大词汇量连续语音识别系统的关键词检测(LVCSR Based Methods)</h2><p>基于大词汇量连续语音识别系统的关键词检测主要是用于音频文档检索任务。首先使用语音识别系统将语音转化为某种形式的文本，然后建立索引，供用户索引。</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518153638215.png" alt="image-20210518153638215"></p>
<p>与一般文本索引不同的是，语音关键词检索中的索引需要包含每一个词的时间位置信息，方便用户定位检索到词的位置。另外一点就是，语音识别结果可能包含一些错误，导致关键词不能找到，所以希望索引将语音识别出的次优候选结果也包含进来，提高检索的召回率。针对这两点的主要方法是，将语音识别出的词格（Lattice）建立为索引。词格是一种保存语音识别候选结果的紧凑形式，还可以包含时间位置信息。</p>
<ul>
<li>The recognition results of LVCSR may contain errors, which will hurt the keyword spotting effect. </li>
<li>How to index raw result of ASR?<ul>
<li>Location of each word</li>
<li>Lattice</li>
</ul>
</li>
</ul>
<p><strong>Lattice</strong></p>
<ul>
<li>A lattice is a compact representation of ASR results.</li>
</ul>
<h3 id="Timed-Factor-Transducer"><a href="#Timed-Factor-Transducer" class="headerlink" title="Timed Factor Transducer"></a>Timed Factor Transducer</h3><ul>
<li><p><input disabled type="checkbox"> 
因子自动机？</p>
</li>
<li><p>A TFT is a WFST mapping each factor x:</p>
<ul>
<li>the set of automata in which x appears;</li>
<li>start-end times of the intervals where appears in each automaton;</li>
<li>the posterior probabilities of actually occurring in each automaton.</li>
</ul>
</li>
<li><p>Indexing</p>
<ul>
<li>Convert lattices to TFTs</li>
<li>Union</li>
<li>Optimize</li>
</ul>
</li>
</ul>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518160913616.png" alt="image-20210518160913616"></p>
<p>当前比较流行关键词检索的索引是时间因子转换器（Timed Factor Transducer，TFT），在著名的语音识别工具包Kaldi中已经被实现。它可以在线性复杂度下检索到关键词。具体的TFT的构建需要大量背景知识，这里就不展开介绍，详细请见参考文献。</p>
<blockquote>
<p>Can D, Saraclar M. Lattice Indexing for Spoken Term Detection[J]. IEEE Transactions on Audio, Speech, and Language Processing, 2011, 19(8): 2338-2347.</p>
</blockquote>
<p><strong>TFT for Lattice Indexing</strong></p>
<ul>
<li>Searching<ul>
<li>Convert query to a linear acceptor X</li>
<li>Compose X and T: R</li>
<li>Each successful path in R is a single arc, the label is the automaton id, and a (LogP, start-time, end-time) triplet.</li>
</ul>
</li>
</ul>
<h3 id="OOV-problem"><a href="#OOV-problem" class="headerlink" title="OOV problem"></a>OOV problem</h3><p>由于语音识别的结果都是在词表内的词，这样如果待查的关键词是集外词，就不可能被查找到了。然而，用户喜欢查找的，往往是人名、地名、组织机构名这样的命名实体，这些词往往都是集外词。解决这一问题的一个方法是代理词：即用一个发音相近的集内词作为待查集外词的“代理”，检索的时候查找“代理”，如果找到了代理，就认为待查的集外词找到了。</p>
<p>（前面从音频特征或者embedding到向量，都是从音频出发，不会有asr识别过程，因此没有oov问题–yl）</p>
<ul>
<li>The out-of-vocabulary problem is more important in KWS than in ASR.</li>
<li>Users often would like to search names or new words which are out-of-vocabulary.</li>
<li>A basic approach to tackle OOV problem is using sub-word units such as phones or syllables as results of the LVCSR system.子词</li>
</ul>
<p><strong>Proxy word: a unified process method 代词</strong></p>
<ul>
<li>Proxy words are IV keywords which are acoustically similar as OOV keywords.</li>
<li>In spotting stage, proxy words are searched in the index instead of original out-of-vocabulary query.</li>
</ul>
<blockquote>
<p>Chen G, Yilmaz O, Trmal J, et al. Using proxies for OOV keywords in the keyword search task[C]. ieee automatic speech recognition and understanding workshop, 2013: 416-421.</p>
</blockquote>
<p><strong>Proxy words generation</strong></p>
<ul>
<li>Proxy words are generated based on WFST $K’ &#x3D; Project(ShortestPath(K\circ{L_{2}}\circ{E}\circ({L^{*}_1})^{-1}))$</li>
<li>where K is a FSA for an OOV keyword</li>
<li>L2 a FSA for the pronunciation of the OOV keyword</li>
<li>E is  an edit-distance transducer</li>
<li>L1 denote the pronunciation lexicon of the LVCSR</li>
<li>K’ is a FSA corresponding to proxy words</li>
</ul>
<p><strong>Phone confusion matrix estimation</strong></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518162440496.png" alt="image-20210518162440496"></p>
<p>边上权重：相似度</p>
<ul>
<li><p>The phone confusion matrix is generated using maximum likelihood estimation. </p>
</li>
<li><p>The pronunciations of the words are obtained using G2P software.</p>
</li>
</ul>
<h1 id="前沿进展-Some-Advances"><a href="#前沿进展-Some-Advances" class="headerlink" title="前沿进展 Some Advances"></a>前沿进展 Some Advances</h1><h2 id="Model-Compression"><a href="#Model-Compression" class="headerlink" title="Model Compression"></a>Model Compression</h2><p><strong>TDNN</strong></p>
<p>在HMM补白模型方面，亚马逊在2017年Interspeech发表了一篇声学模型压缩的文章。具体上，采用时延神经网络（Time Delay Neural Networks，TDNNs）以及降采样结构来减小模型参数，进一步地，还使用了SVD分解，将大的仿射变换矩阵分解为两个小的矩阵相乘的结构，大大减小了参数量。</p>
<p>TDNN优点：可以跳帧</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518164226957.png" alt="image-20210518164226957"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518164246210.png" alt="image-20210518164246210"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518184714948.png" alt="image-20210518184714948"></p>
<p>SVD分解</p>
<p>$m<em>n$的矩阵运算，变为$m</em>r+r*n$，当$r\ll\frac{mn}{m+n}$时，能节省很多运算量（虽然两个矩阵的秩变小了）</p>
<blockquote>
<p>Sun M, Snyder D, Gao Y, et al. Compressed Time Delay Neural Network for Small-Footprint Keyword Spotting.[C]. conference of the international speech communication association, 2017: 3607-3611.</p>
</blockquote>
<h3 id="Compute-similarities-between-heterogeneous-patterns"><a href="#Compute-similarities-between-heterogeneous-patterns" class="headerlink" title="Compute similarities between heterogeneous patterns"></a>Compute similarities between heterogeneous patterns</h3><p>基于神经网络来计算异质数据之间相似度的关键词检测。具体上，对于音频用一个循环神经网络来提取高层特征，而对于文本关键词，则采用卷积神经网络来提取高层特征，然后利用多层感知机来判断这两个高层特征是否匹配。由于语音和文本是两个模态的数据，以往的方法很难去计算它们的相似度，而深度神经网络的强大特征映射能力则给我们带来了直接计算两个模态数据相似度的可能。</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518192512252.png" alt="image-20210518192512252"></p>
<blockquote>
<p>Audhkhasi K, Rosenberg A, Sethy A, et al. End-to-end ASR-free keyword search from speech[J]. IEEE Journal of Selected Topics in Signal Processing, 2017, 11(8): 1351-1359.</p>
</blockquote>
<h3 id="Similarity-Image-Classification-For-Query-by-Example-KWS"><a href="#Similarity-Image-Classification-For-Query-by-Example-KWS" class="headerlink" title="Similarity Image Classification For Query-by-Example KWS"></a>Similarity Image Classification For Query-by-Example KWS</h3><p>如果相似度高，则会连成一个斜线，然后用图像的方法分类出来</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518192534449.png" alt="image-20210518192534449"></p>
<blockquote>
<p>Ram D, Miculicich L, Bourlard H. CNN based query by example spoken term detection[C]&#x2F;&#x2F;Proceedings of the Nineteenth Annual Conference of the International Speech Communication Association (INTERSPEECH). 2018.</p>
</blockquote>
<h3 id="Streaming-Seq2Seq-Models-for-KWS"><a href="#Streaming-Seq2Seq-Models-for-KWS" class="headerlink" title="Streaming Seq2Seq Models for KWS"></a>Streaming Seq2Seq Models for KWS</h3><p>针对关键词检测的流式序列到序列模型。RNN-Transducer是语音识别中的一种端到端方法。它可以分为3个部分：encoder是一个RNN，计算高层声学表示；Prediction Network是一个语言模型，计算预测的Label之间的转移概率；Joint Network则融合前两个模块计算出的表示，做出预测。</p>
<p>CTC存在一个问题，那就是 label之间的关系无法体现出来（比如辅音后面接元音概率大，辅音后面接辅音概率小）</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518192557360.png" alt="image-20210518192557360"></p>
<p>这篇论文在RNN-Transducer的基础上，加入关键词的编码模块与注意力机制，“引导（bias）”RNN-Transducer解码出关键词，提升了关键词检测的准确率。</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518192615094.png" alt="image-20210518192615094"></p>
<p>有M个关键词$k^{enc}&#x3D;[k_1^{enc},…,k_{M}^{enc},k_{M+1}^{enc}]$is one-hot encodings of M+1 phonemes of a keyword.<br>$$<br>\large\beta_{j,u}&#x3D;\langle\phi(k_j^{enc}),\psi(h_{u-1}^{att})\rangle<br>$$</p>
<p>$$<br>\large\alpha&#x3D;\frac{e^{\beta_{j,u}}}{\sum\limits_{j’&#x3D;1}^{M+1}e^{\beta_{j’,u}}}<br>$$</p>
<p>$$<br>\large{c_u&#x3D;\sum\limits_{j&#x3D;1}^{M+1}\alpha_{j,u}k_j^{enc}}<br>$$</p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518194050817.png" alt="image-20210518194050817"></p>
<p><img src="/2021/06/29/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%AF%AD%E9%9F%B3%E6%A3%80%E7%B4%A2/image-20210518194100411.png" alt="image-20210518194100411"></p>
<blockquote>
<p>He Y, Prabhavalkar R, Rao K, et al. Streaming small-footprint keyword spotting using sequence-to-sequence models[C]&#x2F;&#x2F;Automatic Speech Recognition and Understanding Workshop (ASRU), 2017 IEEE</p>
</blockquote>
<h1 id="总结-Take-Home-Messages"><a href="#总结-Take-Home-Messages" class="headerlink" title="总结 Take Home Messages"></a>总结 Take Home Messages</h1><ul>
<li>Keyword spotting focuses on detecting keywords in computation constrained conditions.</li>
<li>The out-of-vocabulary keywords are problems of spoken term detection.</li>
</ul>
<p>关键词检测分为两种：KeywordSpotting关注在计算资源有限的情况下，快速准确地从音频流中检测出关键词；Spoken Term Detection中的一大难题是如何检测出集外词。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>基于隐马尔可夫模型的补白模型</p>
<ol>
<li><p>Wilpon JG, Lee C, Rabiner L R, et al. Application of hidden Markov models for recognition of a limited set of words in unconstrained speech[C]. internationalconference on acoustics, speech, and signal processing, 1989: 254-257.</p>
</li>
<li><p>Sun M,Snyder D, Gao Y, et al. Compressed Time Delay Neural Network for Small-Footprint Keyword Spotting.[C]. conference of the international speechcommunication association, 2017: 3607-3611.</p>
</li>
</ol>
<p>直接用DNN进行分类的补白模型</p>
<ol start="3">
<li>Chen G,Parada C, Heigold G, et al. Small-footprint keyword spotting using deep neuralnetworks[C]. international conference on acoustics, speech, and signalprocessing, 2014: 4087-4091.</li>
</ol>
<p>动态时间弯折</p>
<ol start="4">
<li><p>ItakuraF. Minimum prediction residual principle applied to speech recognition[J]. IEEETransactions on Acoustics, Speech, and Signal Processing, 1975, 23(1): 154-158.</p>
</li>
<li><p>Sakoe H,Chiba S. Dynamic programming algorithm optimization for spoken wordrecognition[J]. IEEE Transactions on Acoustics, Speech, and Signal Processing,1978, 26(1): 159-165.</p>
</li>
<li><p>MantenaG V, Achanta S, Prahallad K, et al. Query-by-example spoken term detectionusing frequency domain linear prediction and non-segmental dynamic timewarping[J]. IEEE Transactions on Audio, Speech, and Language Processing, 2014,22(5): 946-955.</p>
</li>
<li><p>Zhang Y,Glass J R. Unsupervised spoken keyword spotting via segmental DTW on Gaussianposteriorgrams[C]. ieee automatic speech recognition and understandingworkshop, 2009: 398-403.</p>
</li>
</ol>
<p>基于嵌入学习的样例检索</p>
<ol start="8">
<li><p>Chen G,Parada C, Sainath T N, et al. Query-by-example keyword spotting using longshort-term memory networks[C]. international conference on acoustics, speech,and signal processing, 2015: 5236-5240.</p>
</li>
<li><p>KamperH, Wang W, Livescu K, et al. Deep convolutional acoustic word embeddings usingword-pair side information[J]. international conference on acoustics, speech,and signal processing, 2016: 4950-4954.</p>
</li>
</ol>
<p>大词汇量连续语音识别的关键词检索：时间因子转换器索引构建</p>
<ol start="10">
<li>Can D, Saraclar M. Lattice Indexing for Spoken Term Detection[J]. IEEE Transactions on Audio, Speech, and LanguageProcessing, 2011, 19(8): 2338-2347.</li>
</ol>
<p>大词汇量连续语音识别的关键词检索：代理词生成</p>
<ol start="11">
<li>Chen G, Yilmaz O, Trmal J, et al. Using proxies for OOV keywords in the keyword search task[C]. ieee automatic speechrecognition and understanding workshop, 2013: 416-421.</li>
</ol>
<p>异质数据相似度计算</p>
<ol start="12">
<li>Audhkhasi K, Rosenberg A, Sethy A, et al.End-to-end ASR-free keyword search from speech[J]. IEEE Journal of SelectedTopics in Signal Processing, 2017, 11(8): 1351-1359.</li>
</ol>
<p>流式端到端识别系统的关键词检测</p>
<ol start="13">
<li>He Y, Prabhavalkar R, Rao K, et al. Streaming small-footprint keyword spotting using sequence-to-sequence models[C]&#x2F;&#x2F;Automatic Speech Recognition and Understanding Workshop (ASRU), 2017IEEE.</li>
</ol>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>贝壳找房 语音唤醒分享</title>
    <url>/2022/04/07/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%B4%9D%E5%A3%B3%E6%89%BE%E6%88%BF%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<h1 id="贝壳找房-语音唤醒分享"><a href="#贝壳找房-语音唤醒分享" class="headerlink" title="贝壳找房 语音唤醒分享"></a>贝壳找房 语音唤醒分享</h1><blockquote>
<p>家居场景下语音唤醒技术的探索与实践</p>
<p>【语音之家】AI产业沙龙——语音技术在贝壳的应用</p>
<p>2022.4.7</p>
</blockquote>
<p><img src="/2022/04/07/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%B4%9D%E5%A3%B3%E6%89%BE%E6%88%BF%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%88%86%E4%BA%AB/image-20220408120145302.png" alt="image-20220408120145302"></p>
<ul>
<li>搜索后处理<ul>
<li>跳帧</li>
<li>多阈值</li>
<li>二遍决策</li>
</ul>
</li>
<li>比赛的数据处理<ul>
<li>音频规整</li>
<li>波束形成</li>
<li>数据模拟</li>
<li>谱增强</li>
</ul>
</li>
</ul>
<p><img src="/2022/04/07/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%B4%9D%E5%A3%B3%E6%89%BE%E6%88%BF%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%88%86%E4%BA%AB/image-20220408121213161.png" alt="image-20220408121213161"></p>
<p><img src="/2022/04/07/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E8%B4%9D%E5%A3%B3%E6%89%BE%E6%88%BF%E8%AF%AD%E9%9F%B3%E5%94%A4%E9%86%92%E5%88%86%E4%BA%AB/image-20220408185053043.png" alt="image-20220408185053043"></p>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>CLIP</title>
    <url>/2024/12/06/%E5%A4%9A%E6%A8%A1%E6%80%81/Clip/</url>
    <content><![CDATA[<h1 id="CLIP"><a href="#CLIP" class="headerlink" title="CLIP"></a>CLIP</h1><blockquote>
<p><a href="https://arxiv.org/abs/2103.00020">https://arxiv.org/abs/2103.00020</a></p>
<p>Radford, Alec, et al. “Learning transferable visual models from natural language supervision.” <em>International conference on machine learning</em>. PMLR, 2021.   citations：23716</p>
<p><a href="https://www.bilibili.com/video/BV1SL4y1s7LQ/?spm_id_from=333.999.0.0&vd_source=78ac87a714420a3f1e255985e582fe9c">CLIP 论文逐段精读【论文精读】</a></p>
<p><a href="https://github.com/openAI/CLIP">https://github.com/openAI/CLIP</a></p>
<p><a href="https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb">https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb</a></p>
</blockquote>
<ul>
<li><p>解决什么问题</p>
<p>学一个泛化性很好（不局限于要做的固定类别数的分类任务）的特征；</p>
</li>
<li><p>用了什么方法</p>
<p>图片的embedding和文本的embedding做对齐，在空间中配对的embedding很接近，不配对的embedding不接近，这样后续即使对于没见过的类别样本zero-shot，也可以通过去查看embedding相似度，找到相似度最大的一个类作为分类结果；</p>
<p>用了4亿张图片(image, text) pair做自监督训练（没有特别指定要做什么任务，<strong>固定类别数的任务</strong>）；多模态的对比学习；完成训练后，自然语言作为prompt引导模型做视觉分类；</p>
</li>
<li><p>效果如何</p>
<p>开启了cv新范式，之后很多cv论文都是基于CLIP的思路，结合自然语言处理，也就是文本内容去做的。</p>
<p>在30个cv任务上做zero shot看迁移效果，大部分任务效果都很好，能和有监督训练效果相当；</p>
</li>
<li><p>还有什么不足</p>
<p>对于完全没见过的领域数据，泛化性依然不好；在接收one-shot、few-shot样本下，效果没有zero-shot效果好，和人类的学习训练方法还是有区别。</p>
</li>
</ul>
<p>推理过程：图片经过训练好的图片编码器得到图片特征；有一些感兴趣的标签经过prompt engineering会变成一个句子（“a photo of plane&#x2F;car&#x2F;dog… ”）比如4个句子，然后经过text encoder得到4个文本特征，然后与图片特征计算cos similarity；后接softmax得到argmax的文本，大概率也就是描述这个图片的文本了。</p>
<img src="/2024/12/06/%E5%A4%9A%E6%A8%A1%E6%80%81/Clip/image-20241107010214230.png" alt="image-20241107010214230" style="zoom:80%;">






<p>nlp之前不是很好学，直到deep contextual representation learning兴起，也就是具有上下文语义环境的的学习方式，比如bert的完形填空，自监督的学习范式兴起，nlp终于可以用大量的文本监督信号了。</p>
<p>图片和文字绑定到一起，因此学到的特征是多模态的特征，很容易做zero-shot的迁移学习。（而如果只做单模态的自监督学习，单模态对比学习，比如MOCO，或单模态掩码学习，MAE，只能学到视觉特征。）</p>
<p>作者做了一个数据集，4亿个样本，图片文本对 叫WIT （WebImageText）</p>
<p>多模态预训练 训练起来非常耗时，因此要做很多<strong>提高训练效率的工作</strong>。</p>
<p>一开始的方法：图像用cnn结构，文本用transformer结构，jointly trained联合训练，目标是<strong>预测</strong>图片的caption，也就是图片的文本。用的方法不是gpt那样的预测任务（预测下一个单词），而是用<strong>对比学习</strong>的方法。只要文本和图片配对就行。把预测型的目标函数换成对比型的目标函数，训练效率一下子提高4倍。之所以用对比学习，就是因为能提高训练效率。</p>
<img src="/2024/12/06/%E5%A4%9A%E6%A8%A1%E6%80%81/Clip/image-20241122004525472.png" alt="image-20241122004525472" style="zoom:80%;">



<img src="/2024/12/06/%E5%A4%9A%E6%A8%A1%E6%80%81/Clip/image-20241122012133752.png" alt="image-20241122012133752" style="zoom:80%;">


<p>最后用的线性仿射层，但是其他纯训单模态的都是用非线性仿射层。作者说线性和非线性在多模态预训练里不会有太大区别。</p>
<p>对比学习里temperature是个非常重要的参数。作者不想手调，把temperature作为可学习参数放到训练里。</p>
<p>zero-shot transfer </p>
<p>之前的预训练模型的目的是学习泛化性好的特征，然后用到下游任务上，还需要下游数据finetune。<strong>如何能够训练一个模型，下游任务能够不用再训练和微调了呢？</strong>：</p>
<p>用文本作为引导（prompt），做zero-shot 迁移学习</p>
<h3 id="使用prompt的优势："><a href="#使用prompt的优势：" class="headerlink" title="使用prompt的优势："></a>使用prompt的优势：</h3><ol>
<li>假如只用一个单词、不用prompt的话，会引入多义性，歧义的问题，同一个单词有不同的意思，没有语境无法判断出是哪一个意思。</li>
<li>训练预训练模型使用的是句子，推理如果只有单词，会存在distribution gap的问题</li>
</ol>
<p>可以用prompt template提示模板 “A photo of a {label}” 比如下游任务是1000个类的imagenet，这里label就填入这1000个类。</p>
<p>ensemble：多用一些提示模板，做多次推理，综合结果，一般能取得更好的结果。</p>
<p>图片中有可以描述出来的物体，对应文本中应该也有这个物体的描述，匹配得就好；反之图片中没有可以描述出来的物体的话，CLIP表现就不好；</p>
<p>baseline用的是在imagenet训练好的resnet50，用 linear probe 在下游任务上（冻住参数，用作特征抽取器，额外加一个linear，只finetune这个linear层）（few shot）</p>
<p>之所以不用finetune，因为finetune可调的参数太多了，即使一个一般的预训练模型，可能最后也会有不错的效果；</p>
<p>clip在zero-shot、few shot、全量数据集效果都很好。</p>
]]></content>
      <categories>
        <category>多模态</category>
      </categories>
      <tags>
        <tag>多模态</tag>
      </tags>
  </entry>
  <entry>
    <title>集外词处理</title>
    <url>/2021/05/18/%E5%91%BD%E4%BB%A4%E8%AF%8D/%E9%9B%86%E5%A4%96%E8%AF%8D%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h1 id="集外词处理"><a href="#集外词处理" class="headerlink" title="集外词处理"></a>集外词处理</h1><blockquote>
<p>参考：《Kaldi 语音识别实战》P254</p>
</blockquote>
<h3 id="词表扩展："><a href="#词表扩展：" class="headerlink" title="词表扩展："></a>词表扩展：</h3><p>​		如果一个关键词不在语音识别系统的词汇表中，即一般所说的集外词，那么在这个基于语音识别系统的语音检索系统中，是没有办法找到这个关健词的，因此在上述示例中，我们把集外词从关键词列表中直接移除了。为了让语音检索系统可以更好地兼容集外词搜索，Kaldi采用了一系列的方法，包括词表扩展、关键词扩展、音素&#x2F;音节系统等。</p>
<p>​		词表扩展的基本思想是尽可能地扩大语音识别系统所使用的词汇表，从而增加关键词的覆盖率，减小集外词的比例。在理想状态下，我们希望加入词表中的都是日常生活中会使用的合规的词汇，这样可以更好地覆盖关键词，而事实上，我们很难收集一个语言中所有的词汇。</p>
<p>​		Kaldi的做法是，随机地生成大量从发音规则上来说合理的词汇并加入到词汇表中，尽管它们中的有些词从拼写上来说是不合理的。具体来说， Kaldi 把原始词汇表中的每个词的发音都当作一个基本组成单元为音节或音素的“句子”，并且针对这些“句子”训练一个语言模型。语言模型可以根据概率分布随机地生成可能的句子，所以我们可以利用在原始词汇表的发音序列上训练的语言模型，随机地生成音素或音节的序列，而这些序列也就是潜在词汇可能的发音序列。Kaldi会随机生成上百万这样的发音序列。同时，Kaldi 会利用原始词汇表，训练一个逆向的字母音素转换模型(Grapheme-to-Phoneme，G2P)，这个模型可以将词汇的音素或音节的序列转换成该词汇最有可能的拼写，利用这个模型，就可以使用前面产生的上百万个发音序列，转换成它们最有可能的拼写序列，从而生成扩展的词汇表。Kaldi 根据生成过程中的打分，对这些生成的词汇进行进一步的排序和删减，从而形成最终的词汇表。 </p>
<blockquote>
<p>G2P，不仅可以由词生成音素序列，还可以由音素序列生成词（yl）</p>
</blockquote>
<p>用来做词表扩展的脚本位于 babel 示例下面，具体文件是 egs&#x2F;babel&#x2F;s5d&#x2F;local&#x2F;extend_lexicon.sh</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv data/local/lexicon.txt data/local/lexicon_orig.txt</span><br><span class="line">local/extend_lexicon.sh --cmd &quot;$train_cmd&quot; --cleanup false --num-sent-gen $num_sent_gen --num-prons $num_prons data/local/lexicon_orig.txt data/local/extend data/dev2h/text</span><br><span class="line">cp data/loval/extend/lexiconp.txt data/local/</span><br></pre></td></tr></table></figure>

<p>其中，$num_sent_gen 是用语言模型生成的发音序列的数量，默认设置为12000 000；</p>
<p>$num_prons 是保留下来的有效发音序列的数量，默认设置为1000 000；</p>
<p>data&#x2F;loca&#x2F;lexicon_orig.txt 是原始的词汇表;data&#x2F;local&#x2F;extend 是工作目录，用于保存所有中间文件及最终生成的扩展后的带概率的词汇表 data&#x2F;local&#x2F;extend&#x2F;lexiconp.txt ；</p>
<p>而 data&#x2F;dev2h&#x2F;text 是一个可选的文本文件，如果提供了，则会计算在原始词汇表和扩展后词汇表中集外词的比例，从而判断词表扩展是否有效提高了集内词的覆盖率。</p>
<h3 id="关键词扩展："><a href="#关键词扩展：" class="headerlink" title="关键词扩展："></a>关键词扩展：</h3><p>​		假设待搜索音频中存在语音识别系统的词汇表中不包括的词汇，那么语音识别系统往往会把这个词汇转写成一个或若干个和该词汇发音比较接近且存在于词汇表中的词汇。基于这个事实，减缓集外词问题的另一个思路是将一个集外的关键词拓展为多个和这个集外关键词发音比较接近且存在于词汇表中的词或词组，并用它们作为代理关键词去搜索。这个方法也叫作代理关键词方法或模糊搜索方法。<br>​		Kaldi 中代理关键词的生成都是在 WFST 的框架下进行的。虽然本书会尽可能避开不必要的公式，但是代理关键词的生成用一个公式来描述最为形象，公式如下:<br>$$<br>K’ &#x3D; Project(ShortestPath(Prune(Prune(K\circ{L_{z}}\circ{E’})\circ{L^{-1}})))<br>$$<br>在上述公式中，K是集外关键词，L<del>2</del>是集外关键词对应的发音，往往可以通过字母音素转换模型(G2P)来产生，E’是编辑距离转换器，L<del>1</del>是语音识别系统原始的词汇表。除去剪枝(Prune)、最短路径(ShortestPath)等有限状态机中用来优化的操作，上面公式中主要的操作是复合(Composition)。简单来理解，当K复合了L<del>2</del>以后，生成的有限状态机可以将集外关键词的拼写转换为其对应的发音序列。再复合E’之后，生成的有限状态机可以将集外关键词的拼写转换为任意的发音序列，但是当生成的发。。。。。。。。。</p>
<ul>
<li><input disabled type="checkbox"> 未完待续</li>
</ul>
<blockquote>
<p>参考：<a href="https://kaldi-asr.org/doc/kws.html">kaldi官方文档 Keyword Search in Kaldi</a></p>
</blockquote>
]]></content>
      <categories>
        <category>命令词</category>
      </categories>
      <tags>
        <tag>命令词</tag>
      </tags>
  </entry>
  <entry>
    <title>pip笔记</title>
    <url>/2023/02/08/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/pip%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="pip笔记"><a href="#pip笔记" class="headerlink" title="pip笔记"></a>pip笔记</h1><h2 id="安装python包超时失败"><a href="#安装python包超时失败" class="headerlink" title="安装python包超时失败"></a>安装python包超时失败</h2><blockquote>
<p>stackoverflow ：<a href="https://stackoverflow.com/questions/43298872/how-to-solve-readtimeouterror-httpsconnectionpoolhost-pypi-python-org-port">How to solve ReadTimeoutError: HTTPSConnectionPool(host&#x3D;’pypi.python.org’, port&#x3D;443) with pip?</a></p>
<p><a href="https://blog.csdn.net/zhangvalue/article/details/104271094">解决安装Python包时超时失败ReadTimeoutError: HTTPSConnectionPool(host&#x3D;’files.pythonhosted.org’, port&#x3D;443)</a></p>
</blockquote>
<p>遇到超时 timeout error：</p>
<p><strong>方法1. 添加镜像源：</strong></p>
<p>使用国内的镜像源安装。在原来安装时在命令里加一个参数 -i，然后在i后面加国内镜像地址。</p>
<p>选择国内的镜像源列表如下：</p>
<p>清华源： <a href="https://pypi.tuna.tsinghua.edu.cn/simple/">https://pypi.tuna.tsinghua.edu.cn/simple/</a></p>
<p>阿里云： <a href="http://mirrors.aliyun.com/pypi/simple/">http://mirrors.aliyun.com/pypi/simple/</a></p>
<p>中国科技大学： <a href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.mirrors.ustc.edu.cn/simple/</a></p>
<p>豆瓣(douban)：<a href="http://pypi.douban.com/simple/">http://pypi.douban.com/simple/</a></p>
<p>清华大学： <a href="https://pypi.tuna.tsinghua.edu.cn/simple/">https://pypi.tuna.tsinghua.edu.cn/simple/</a></p>
<p>中国科学技术大学： <a href="http://pypi.mirrors.ustc.edu.cn/simple/">http://pypi.mirrors.ustc.edu.cn/simple/</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> pip install statsmodels -i https://pypi.tuna.tsinghua.edu.cn/simple/</span><br><span class="line">Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/</span><br></pre></td></tr></table></figure>



<p><strong>方法2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo pip install --default-timeout=100 xx包</span><br></pre></td></tr></table></figure>



<p><strong>方法3：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m pip install --upgrade pip</span><br></pre></td></tr></table></figure>



<blockquote>
<p>以下是chatgpt回答</p>
</blockquote>
<p>在安装Python包时如果超时失败，可以尝试以下几种方法：</p>
<ol>
<li>增加超时时间：可以在安装命令前添加参数，例如<code>pip install --default-timeout=1000 &lt;package-name&gt;</code>，以增加超时时间。</li>
<li>更换镜像源：可以尝试使用国内镜像源进行安装，以减少安装时间。</li>
<li>选择本地包：如果安装某个包时出现超时失败，可以尝试手动下载该包的.whl文件并使用<code>pip install &lt;whl-file&gt;</code>命令进行安装。</li>
<li>尝试其他安装方法：如果使用<code>pip install</code>命令安装失败，可以尝试使用<code>conda install</code>或其他安装方法进行安装。</li>
</ol>
<h2 id="pip安装的路径在哪里"><a href="#pip安装的路径在哪里" class="headerlink" title="pip安装的路径在哪里"></a>pip安装的路径在哪里</h2><blockquote>
<p>以下是chatgpt回答</p>
</blockquote>
<p>在 Windows 系统中，默认情况下 pip 安装的路径位于 Python 安装目录下的 Scripts 目录中，例如 <code>C:\PythonXX\Scripts</code>，其中 <code>XX</code> 代表 Python 的版本号。</p>
<p>在 Linux 和 macOS 系统中，pip 安装的路径通常位于 <code>/usr/local/bin</code> 或 <code>/usr/bin</code> 目录中。</p>
<p>可以使用以下命令查找 pip 安装的具体路径：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">which pip</span><br></pre></td></tr></table></figure>

<p>或者在命令行中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip show pip</span><br></pre></td></tr></table></figure>

<p>它将显示 pip 包的详细信息，其中包括安装路径。</p>
<h2 id="选择让pip安装在anaconda的虚拟环境中或默认环境中"><a href="#选择让pip安装在anaconda的虚拟环境中或默认环境中" class="headerlink" title="选择让pip安装在anaconda的虚拟环境中或默认环境中"></a>选择让pip安装在anaconda的虚拟环境中或默认环境中</h2><p>就是切换（activate激活）到虚拟环境中。</p>
<p>有三类pip：</p>
<ul>
<li>第一类没有在anaconda环境中，也有装pip工具的，pip install时，安装的包的路径一般在 <code>/usr/bin</code>下；</li>
<li>第二类在anaconda的base环境中，pip install时，安装的包的路径一般在 <code>XX/anaconda3/bin</code>下；</li>
<li>第二类在anaconda的自建的环境中，pip install时，安装的包的路径一般在 <code>XX/anaconda3/envs/XX/bin</code>下；</li>
</ul>
<blockquote>
<p>以下回答来自chatgpt</p>
</blockquote>
<p>如果想在 Anaconda 虚拟环境中使用 pip，请按以下步骤操作：</p>
<ol>
<li><p>创建虚拟环境：首先需要创建 Anaconda 虚拟环境，使用以下命令创建：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create --name &lt;env_name&gt;</span><br></pre></td></tr></table></figure>

<p>其中 <code>&lt;env_name&gt;</code> 是虚拟环境的名称。</p>
</li>
<li><p>激活虚拟环境：使用以下命令激活虚拟环境：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda activate &lt;env_name&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在虚拟环境中安装 pip：在虚拟环境中使用以下命令安装 pip：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install pip</span><br></pre></td></tr></table></figure></li>
</ol>
<p>现在，您已在 Anaconda 虚拟环境中安装了 pip，并且可以使用它来安装 Python 包。在使用 pip 安装包时，请确保该虚拟环境处于激活状态。</p>
<h2 id="用pip安装自己写的包"><a href="#用pip安装自己写的包" class="headerlink" title="用pip安装自己写的包"></a>用pip安装自己写的包</h2><p>要用pip安装自己写的包，可以使用pip install命令，并传入该包的路径作为参数：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install /path/to/your_package.tar.gz</span><br></pre></td></tr></table></figure>

<p>如果该包未打包成.tar.gz或.whl文件，需要先打包，然后再使用pip install命令安装。</p>
<p>打包方法：</p>
<ol>
<li><p>打包为.tar.gz文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python setup.py sdist</span><br></pre></td></tr></table></figure>
</li>
<li><p>打包为.whl文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python setup.py bdist_wheel</span><br></pre></td></tr></table></figure></li>
</ol>
<p>完成打包后，就可以使用pip install命令安装自己写的包了。</p>
<h2 id="安装完-发现有问题：XXXapi-so-undefined-symbol报错怎么办？"><a href="#安装完-发现有问题：XXXapi-so-undefined-symbol报错怎么办？" class="headerlink" title="安装完 发现有问题：XXXapi.so: undefined symbol报错怎么办？"></a>安装完 发现有问题：XXXapi.so: undefined symbol报错怎么办？</h2><blockquote>
<p><a href="https://github.com/pytorch/pytorch/issues/10234">https://github.com/pytorch/pytorch/issues/10234</a><br>chatgpt</p>
</blockquote>
<p>这个错误通常是由于共享库中缺少必要的符号引起的。原因可能是：</p>
<ol>
<li><p>缺少依赖库：检查它是否已安装，并确保它在系统库搜索路径中，或者使用环境变量LD_LIBRARY_PATH来指定其位置。具体地：<code>export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64</code> 把这个库链接到lib的path里，再试一试。</p>
</li>
<li><p>版本不兼容：检查该库的版本与使用它的程序的版本是否兼容。</p>
</li>
<li><p>损坏的共享库：重新安装该库并确保其完整性。</p>
</li>
</ol>
<p>如果仍然不能解决问题，可以在问题的具体环境下向社区寻求帮助，例如编程论坛或 Stack Overflow。</p>
<p>具体报错为：<code>ImportError: /mnt/k/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: _ZNK3c104Type14isSubtypeOfExtERKSt10shared_ptrIS0_EPSo</code></p>
<h2 id="torch下载慢"><a href="#torch下载慢" class="headerlink" title="torch下载慢"></a>torch下载慢</h2><p>解决方法：直接在浏览器里下载网页的链接wsl文件，然后pip install手动安装。</p>
<p>另一种方法，换channel：</p>
<blockquote>
<p><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</a><br>今天以pytorch1.7.1举栗子。<br>pytorch官网查看pytorch安装命令</p>
</blockquote>
<p><code>conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0</code> -c pytorch<br>1<br>首先，使用命令将下述网址添加conda源</p>
<p>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</a><br>1<br>其次，最后使用新的安装命令，将-c pytorch去掉，表示从我们配置的新路径中下载</p>
<p>conda install pytorch&#x3D;&#x3D;1.7.1 torchvision&#x3D;&#x3D;0.8.2 torchaudio&#x3D;&#x3D;0.7.2 cudatoolkit&#x3D;11.0</p>
<h2 id="pip-install-r"><a href="#pip-install-r" class="headerlink" title="pip install -r"></a>pip install -r</h2><p>在 pip install 时可以通过使用 -r 参数来安装一个包的依赖。比如，如果你想要安装包A，并且包A需要包B才能工作，你可以使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<p>其中 requirements.txt 文件是一个文本文件，包含了需要安装的所有包的名称，比如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">packageB</span><br><span class="line">packageA</span><br></pre></td></tr></table></figure>

<p>运行以上命令后，pip 会先安装包B，再安装包A。</p>
<h2 id="pip-install-链接已有的包"><a href="#pip-install-链接已有的包" class="headerlink" title="pip install 链接已有的包"></a>pip install 链接已有的包</h2><p>使用 pip install 命令可以从网络上下载并安装包，你也可以通过链接已有的包安装。使用“-f”参数即可：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -f &lt;path-to-dependency&gt; &lt;your-package&gt;</span><br></pre></td></tr></table></figure>

<p>其中，<code>&lt;path-to-dependency&gt;</code>是已有包的路径，<code>&lt;your-package&gt;</code>是你的包名称。在执行此命令时，pip 将使用路径指向的包作为依赖安装。</p>
<h2 id="pip-install参数解释"><a href="#pip-install参数解释" class="headerlink" title="pip install参数解释"></a>pip install参数解释</h2><blockquote>
<p><a href="https://www.twle.cn/t/85">Python Pip 参考手册 - pip install 命令 ( 一 )</a></p>
</blockquote>
<h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><p><code>pip install</code> 命令的语法格式如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install [options] &lt;requirement specifier&gt; [package-index-options] ...</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install [options] -r &lt;requirements file&gt; [package-index-options] ...</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install [options] [-e] &lt;vcs project url&gt; ...</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install [options] [-e] &lt;local project path&gt; ...</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install [options] &lt;archive url/path&gt; ...</span><br></pre></td></tr></table></figure>

<p><code>pip install</code> 命令可以从以下地址安装包</p>
<ul>
<li>使用需求说明符从 PiPY 或其它索引上安装</li>
<li>VCS 项目网址</li>
<li>本地项目目录</li>
<li>本地或远程源代码归档</li>
</ul>
<p>pip 还支持从 「 需求文件 」 ( requirements file ) 安装，这为安装指定的整个环境提供了一种简便方法</p>
<ul>
<li><p><code>-c, --constraint &lt;file&gt;</code></p>
<p>使用给定的约束文件约束版本，该选项可以重复添加</p>
</li>
<li><p><code>-r, --requirement &lt;file&gt;</code></p>
<p>从给定的需求文件中安装，该选项可以重复添加</p>
<p>按照惯例，需求文件名为 <code>requirements.txt</code></p>
</li>
<li><p><code>--no-deps</code></p>
<p>不安装包的任何依赖项</p>
</li>
<li><p><code>--pre</code></p>
<p>包含预发布版本和开发版本，默认只会包行稳定的版本</p>
</li>
<li><p><code>-e, --editable &lt;path/url&gt;</code></p>
<p>在可编辑模式下从一个本地的项目路径或 VCS URL 中安装一个项目 ( 例如，setuptools 的 「 开发者模式 」 )</p>
</li>
<li><p><code>-t, --target &lt;dir&gt;</code></p>
<p>将包安装到指定目录 <code>&lt;dir&gt;</code></p>
<p>默认情况下，该选项并不会覆盖 <code>&lt;dir&gt;</code> 目录中已经存在的文件或目录，但可以使用 <code>--upgrade</code> 选项将已经存在的包更新到最新的版本</p>
</li>
<li><p><code>--user</code></p>
<p>将所有的包安装到我们的平台的Python 用户安装目录，通常为 <code>~/.local/</code> 或 Windows 上为 <code>%APPDATA%Python</code> ( 更多详细信息，可以查看 Python 文档中的 <code>site.USER_BASE</code> 部分 )</p>
</li>
<li><p><code>--root &lt;dir&gt;</code></p>
<p>安装与此备用根目录 <code>&lt;dir&gt;</code> 包含的所有内容</p>
</li>
<li><p><code>--prefix &lt;dir&gt;</code></p>
<p>安装时，<code>lib</code> 、<code>bin</code> 和其它顶级目录的存放目录，也就是这些目录的路径前缀</p>
</li>
<li><p><code>-b, --build &lt;dir&gt;</code></p>
<p>用于存放解压缩的包和构建的包</p>
<p>请注意，初始构建仍发生在临时目录中</p>
<p>可以通过适当地设置 <code>TMPDIR</code> 环境变量 （ Windows上的 <code>TEMP</code> ) 来控制临时目录的位置</p>
<p>注意，如果使用了该参数，当构建发生故障时，并不会清空构建目录</p>
</li>
<li><p><code>--src &lt;dir&gt;</code></p>
<p>用于存放迁出的可编辑项目</p>
<p>在虚拟环境中，默认的目录为 <code>&lt;venv path&gt;/src</code>， 在全局安装中，默认的目录为 <code>&lt;current dir&gt;/src</code></p>
</li>
<li><p><code>-U, --upgrade</code></p>
<p>更新所有指定的包到最新的可用版本。 依赖项的处理取决于所使用的升级策略</p>
</li>
<li><p><code>--upgrade-strategy &lt;upgrade_strategy&gt;</code></p>
<p>确定应如何处理依赖项升级 ( 默认值：「 仅在需要时 」)</p>
<ul>
<li><code>eager</code> - 无论当前安装的版本是否满足升级包的要求，都会升级依赖项</li>
<li><code>only-if-needed</code> - 仅在不满足升级包的要求时才升级</li>
</ul>
</li>
<li><p><code>--force-reinstall</code></p>
<p>重新安装所有的包，即使它们已经是最新的版本</p>
</li>
<li><p><code>-I, --ignore-installed</code></p>
<p>忽略已经安装的包 ( 用重新安装取代 )</p>
</li>
<li><p><code>--ignore-requires-python</code></p>
<p>忽略 Requires-Python 信息</p>
</li>
<li><p><code>--no-build-isolation</code></p>
<p>在构建现代的源代码分发包是禁用隔离</p>
<p>如果使用了此选项，则必须已安装 PEP518 规定的构建依赖项</p>
</li>
<li><p><code>--install-option &lt;options&gt;</code></p>
<p>安装时提供给 <code>setup.py</code> 安装命令的额外参数( 使用方法类似于 <code>--install-option=&quot;--install-scripts=/usr/local/bin&quot;</code> )</p>
<p>可以使用多个 <code>--install-option</code> 选项将多个选项传递给 <code>setup.py install</code></p>
<p>如果你使用带有目录路径的选项，请确保使用绝对路径</p>
</li>
<li><p><code>--global-option &lt;options&gt;</code></p>
<p>在 <code>bdist_wheel</code> 命令之前提供给 <code>setup.py</code> 调用的额外全局选项</p>
</li>
<li><p><code>--compile</code></p>
<p>将 Python 源代码编译为 bytecode</p>
</li>
<li><p><code>--no-compile</code></p>
<p>不要将 <a href="https://www.twle.cn/l/yufei/python30/python-30-index.html">Python</a> 源代码编译为 <code>bytecode</code></p>
</li>
<li><p><code>--no-warn-script-location</code></p>
<p>当安装脚本不在 <code>PATH</code> 路径中时不要发出警告</p>
</li>
<li><p><code>--no-warn-conflicts</code></p>
<p>出现已损坏的依赖关系时不要发出警告</p>
</li>
<li><p><code>--no-binary &lt;format_control&gt;</code></p>
<p>不使用二进制包</p>
<p>该选项可以重复添加，每增加一个就会自增当前的值</p>
<p>可选的值有</p>
<ul>
<li><code>:all:</code> ：禁用所有二进制包</li>
<li><code>:none:</code> ：清空集合，或者使用逗号之间的一个或多个包名称</li>
</ul>
<p>注意，某些软件包编译起来很棘手，并且，即使在添加了此选项后仍然可能无法安装</p>
</li>
<li><p><code>--only-binary &lt;format_control&gt;</code></p>
<p>不使用源代码包</p>
<p>该选项可以重复添加，每增加一个就会自增当前的值</p>
<p>可选的值有</p>
<ul>
<li><code>:all:</code> ：禁用所有源代码包</li>
<li><code>:none:</code> ：清空集合，或者使用逗号之间的一个或多个包名称</li>
</ul>
<p>注意，没有二进制发行版的软件包在使用此选项时将无法安装</p>
</li>
<li><p><code>--no-clean</code></p>
<p>不要清空构建目录</p>
</li>
<li><p><code>--require-hashes</code></p>
<p>对于可重复安装，需要根据哈希值来检查每个需求</p>
<p>如果需求文件中的任何一项包含了 <code>--hash</code> 选项，则隐式包含此选项</p>
</li>
<li><p><code>--progress-bar &lt;progress_bar&gt;</code></p>
<p>用于指定要显示的进度条类型，可选项有 <code>on</code>、<code>ascii</code>、<code>off</code>、<code>pretty</code>、<code>emoji</code>，默认为 <code>on</code></p>
</li>
<li><p><code>-i, --index-url &lt;url&gt;</code></p>
<p>Python 包索引的基础 URL 地址，默认为 <a href="https://pypi.org/simple">https://pypi.org/simple</a></p>
<p>该选项的值应该指向符合 PEP503 ( 简单存储库 API ) 的存储库或以相同格式布局的本地目录</p>
</li>
<li><p><code>--extra-index-url &lt;url&gt;</code></p>
<p>除了 <code>--index-url</code> 之外的附加的 Python 包索引 URL，规则和 <code>--index-url</code> 一样</p>
</li>
<li><p><code>--no-index</code></p>
<p>忽略包索引，使用 <code>--find-links</code> 指定的 URL</p>
</li>
<li><p><code>-f, --find-links &lt;url&gt;</code></p>
<p>如果提供的 URL 或路径链接到一个 html 文件，则会解析该 html 文件以获取归档</p>
<p>如果是本地目录，或 <code>file://url</code> 指向的是一个目录，那么就在该目录中查找归档</p>
</li>
<li><p><code>--process-dependency-links</code></p>
<p>启用依赖关系链接的处理</p>
</li>
</ul>
]]></content>
      <categories>
        <category>工程实践</category>
      </categories>
      <tags>
        <tag>工程实践</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第15章 工程应用实践————嵌入式移植</title>
    <url>/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%A7%BB%E6%A4%8D/</url>
    <content><![CDATA[<h1 id="嵌入式移植"><a href="#嵌入式移植" class="headerlink" title="嵌入式移植"></a>嵌入式移植</h1><blockquote>
<p>《语音识别原理与技术》洪青阳 工业应用实践 书、PPT 15.4</p>
</blockquote>
<p>随着物联网的发展和用户对录音隐私的担忧，现在越来越多的需求，如对智声能家居的语音控制，需要采用嵌入式平台，在本地端运行语音识别。下面我们针对ARMLinux 环境介绍嵌人式移植过程。</p>
<p>大部分的ARM平台都带有Linux系统，但用的是裁剪过的版本，里面的很多库跟CentOS或Ubuntu不兼容或缺少，因此移植起来较为繁琐。</p>
<p>以Kaldi的移植为例，其依赖的Atlas加速库包含libatlas.so和liblapack.so两个动态库，需要在ARM Linux环境重新编译。但单独编译这两个库有很多繁琐的配置，一种简便办法是通过Kaldi集成编译后得到，因为其工具包tools自带的安装脚本extras&#x2F;install_atlas.sh会生成这两个so动态库。基于这两个so，重新编译引擎动态库。（下面基于这两个so动态库，按《动态库封装》这一节介绍的过程，重新编译引擎动态库）。</p>
<p>由于内存空间受限，很多裁剪过的ARM Linux系统，不带编译环境，即只能运行不能编译程序。为编译引擎动态库，我们需要通过交叉编译方式，在服务器另外搭一套编译的环境，所采用的gcc&#x2F;g++编译器要跟ARM Linux一致，编译成功后再移植到ARM Linux环境。</p>
<p>有的 Linux 环境的 Atlas 加速库无法编译，只能采用 OpenBLAS 加速库，其编译出来的libopenblas.so 库还依赖其他静态库，要另外编译。这些库都准备到位后，再把它们集成到引擎动态库 Makefile 编译文件中，如以下例子：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">CC = arm-buildroot-linux-gnueabihf-gcc</span><br><span class="line">CXX = arm-buildroot-linux-gnueabihf-g++</span><br><span class="line">AR = arm-buildroot-linux-gnueabihf-ar</span><br><span class="line">LD = arm-buildroot-linux-gnueabihf-g++</span><br><span class="line"></span><br><span class="line">WINDRES = windres</span><br><span class="line"></span><br><span class="line">INC = -Isrc -Iopenfst/<span class="keyword">include</span> -IOpenBLAS/<span class="keyword">include</span></span><br><span class="line">CFLAGS = -std=c++11 -DHAVE_OPENBLAS -DHAVE_POSIX_MEMALIGN</span><br><span class="line">RESINC = </span><br><span class="line">LIBDIR = </span><br><span class="line">LIB = lib/libopenblas.so</span><br><span class="line">LDFLAGS = -ldl lib/libclapack.a lib/libblas.a lib/libf2c.a</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中，CC 和 CXX 指明编译器的名称，对应 gcc 和 g++的嵌入式版本，AR 和 LD配套更新。LDFLAGS用来链接以.a为扩展名的静态库。</p>
<p>嵌入式语音识别一般只支持命令词识别或小范围的“随便说”，如机器人的动作命令和简单的对话。对话内容可能只有几百句，语言模型就可以做得很小，而声学模型本身不会太大，因此编译出来的HCLG也就很小，文件只有几百KByte甚至更小。这样更容易部署到嵌入式平台，识别速度也更快。</p>
<p>针对更低端的DSP平台，嵌入式移植可能还涉及定点化问题，需要把解码器特别是特征提取和DNN的前向传播重新改写，即把浮点运算改为定点运算，而且不再包含加速库，这部分工作量比较大。</p>
]]></content>
      <categories>
        <category>工程实践</category>
      </categories>
      <tags>
        <tag>《语音识别原理与应用》</tag>
        <tag>工程实践</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第15章 工程应用实践————动态库封装</title>
    <url>/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E5%8A%A8%E6%80%81%E5%BA%93%E5%B0%81%E8%A3%85/</url>
    <content><![CDATA[<h1 id="动态库封装"><a href="#动态库封装" class="headerlink" title="动态库封装"></a>动态库封装</h1><blockquote>
<p>《语音识别原理与技术》洪青阳 工业应用实践 书、PPT 15.1</p>
</blockquote>
<ul>
<li>函数接口</li>
<li>动态库编译</li>
<li>动态库调用</li>
</ul>
<h2 id="函数接口"><a href="#函数接口" class="headerlink" title="函数接口"></a>函数接口</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">			基于语音缓冲区的语音识别（非特定人）</span></span><br><span class="line"><span class="comment">		@ handle	      : 线路资源标识（必须是已打开） 用来区分不同线程，防止共享资源同时修改某个地址的内容造成混乱 每个线程对应一个句柄号</span></span><br><span class="line"><span class="comment">		@ buffer           : 待识别语音缓冲区	short型 因为采样点一般用两个字节的short来保存</span></span><br><span class="line"><span class="comment">		@ length          : 待识别语音缓冲区长度	无符号的长整型 unsigned int 是buffer的长度 比如16000个采样点数 表示长度</span></span><br><span class="line"><span class="comment">		@ text              : 识别的文本内容 	字符串	是一个指针，因此结果即使已经有一部分输出了，也是可以随时修改前面的，输出变换后的内容</span></span><br><span class="line"><span class="comment">		@ scoreASR      : 语音识别得分		一般用置信度</span></span><br><span class="line"><span class="comment">		@ return	      : 成功识别返回SUCCESS</span></span><br><span class="line"><span class="comment">                                                                                                                                                                                   */</span></span><br><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="function">return_ASR_Code <span class="title">ASR_recSpeechBuf</span><span class="params">(Handle handle, <span class="type">short</span>* buffer, <span class="type">unsigned</span> <span class="type">long</span> length, <span class="type">char</span>* text, <span class="type">float</span> &amp;scoreASR)</span></span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>根据ASR_recSpeechBuf函数的输入和输出参数，我们&#x3D;&#x3D;改写&#x3D;&#x3D;了Kaldi的在线解码程序，包括以下函数：</p>
<ul>
<li><strong>ASR_recSpeechBuf</strong>函数：与外面调用程序交互，首先判断分配到的句柄handle是否空闲，如果忙则返回ASR_STATE_ERROR，表示已被占用；如果检查通过，则调用KaldiDecode函数进行解码，并把词序列索引转化为文本内容，保存到输出参数text，即为识别后的句子。</li>
<li><strong>KaldiDecode</strong>函数：实现从语音缓冲buffer到识别结果的具体解码过程，首先完成输入buffer到SubVector<BaseFloat> wave_part的转化过程，然后调用feature_pipeline.AcceptWaveform(samp_freq, wave_part)进行声学特征提取，注意声学特征一般有做倒谱均值减（CMN），因此在函数内部还要加上这步操作，接着调用decoder.AdvanceDecoding()进行分片段识别，得到中间解码结果，保存在Lattice里，随后采用decoder.FinalizeDecoding()进行Lattice解码，修正中间部分结果。最后调用GetDiagnosticsAndPrintOutput函数得到解码后的词序列索引。</BaseFloat></li>
<li><strong>GetDiagnosticsAndPrintOutput</strong>函数：根据输入的CompactLattice进行Lattice最优路径搜索并返回得到词序列和基于最小贝叶斯风险算出来的置信度，分别存放在输出参数words和words_conf（confidence置信度）。</li>
</ul>
<p>改写后：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据输入的CompactLattice进行Lattice最优路径搜索</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">GetDiagnosticsAndPrintOutput</span><span class="params">(<span class="type">const</span> fst::SymbolTable *word_syms,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  <span class="type">const</span> CompactLattice &amp;clat,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  int64 *tot_num_frames,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  <span class="type">double</span> *tot_like,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 std::vector&lt;int32&gt; &amp;words,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 BaseFloat &amp;words_conf)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (clat.<span class="built_in">NumStates</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">    KALDI_WARN &lt;&lt; <span class="string">&quot;Empty lattice.&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  CompactLattice best_path_clat;</span><br><span class="line">  <span class="built_in">CompactLatticeShortestPath</span>(clat, &amp;best_path_clat);</span><br><span class="line"></span><br><span class="line">  Lattice best_path_lat;</span><br><span class="line">  <span class="built_in">ConvertLattice</span>(best_path_clat, &amp;best_path_lat);</span><br><span class="line"></span><br><span class="line">  <span class="type">double</span> likelihood;</span><br><span class="line">  LatticeWeight weight;</span><br><span class="line">  int32 num_frames;</span><br><span class="line">  std::vector&lt;int32&gt; alignment;</span><br><span class="line">  <span class="built_in">GetLinearSymbolSequence</span>(best_path_lat, &amp;alignment, &amp;words, &amp;weight);</span><br><span class="line">  num_frames = alignment.<span class="built_in">size</span>();</span><br><span class="line">  likelihood = -(weight.<span class="built_in">Value1</span>() + weight.<span class="built_in">Value2</span>());</span><br><span class="line">  *tot_num_frames += num_frames;</span><br><span class="line">  *tot_like += likelihood;</span><br><span class="line">  <span class="built_in">KALDI_VLOG</span>(<span class="number">2</span>) &lt;&lt; <span class="string">&quot;Likelihood per frame for utterance &quot;</span> &lt;&lt; utt &lt;&lt; <span class="string">&quot; is &quot;</span></span><br><span class="line">                &lt;&lt; (likelihood / num_frames) &lt;&lt; <span class="string">&quot; over &quot;</span> &lt;&lt; num_frames</span><br><span class="line">                &lt;&lt; <span class="string">&quot; frames.&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="type">bool</span> decode_mbr = <span class="literal">true</span>;</span><br><span class="line">  MinimumBayesRisk *mbr = <span class="literal">NULL</span>;</span><br><span class="line">  mbr = <span class="keyword">new</span> <span class="built_in">MinimumBayesRisk</span>(clat, words);</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> std::vector&lt;BaseFloat&gt; &amp;conf = mbr-&gt;<span class="built_in">GetOneBestConfidences</span>();    </span><br><span class="line">  </span><br><span class="line">  words_conf = <span class="number">0.0</span>;</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">if</span> (word_syms != <span class="literal">NULL</span>) </span><br><span class="line">    std::cerr &lt;&lt; utt &lt;&lt; <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; words.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">      std::string s = word_syms-&gt;<span class="built_in">Find</span>(words[i]);</span><br><span class="line">      <span class="keyword">if</span> (s == <span class="string">&quot;&quot;</span>)&#123;</span><br><span class="line">        KALDI_ERR &lt;&lt; <span class="string">&quot;Word-id &quot;</span> &lt;&lt; words[i] &lt;&lt; <span class="string">&quot; not in symbol table.&quot;</span>;</span><br><span class="line">        words_conf += conf[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (words.size &gt; <span class="number">0</span>) words_conf /= words.<span class="built_in">size</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (mbr != <span class="literal">NULL</span>) <span class="keyword">delete</span> mbr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现从语音缓冲 buffer 到识别结果的具体解码过程</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">KaldiDecode</span><span class="params">(<span class="type">short</span>* buffer, <span class="type">unsigned</span> <span class="type">long</span> length, std::vector&lt;int32&gt; &amp;words, <span class="type">float</span> &amp;scoreASR)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        <span class="type">double</span> tot_like = <span class="number">0.0</span>;</span><br><span class="line">        int64 num_frames = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="function">OnlineNnet2FeaturePipelineInfo <span class="title">feature_info</span><span class="params">(feature_opots)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">stricmp</span> (asr_feature_type.<span class="built_in">c_str</span>(), <span class="string">&quot;mfcc&quot;</span>) == <span class="number">0</span>) </span><br><span class="line">            samp_freq = feature_info.mfcc_opts.frame_opts.samp_freq; </span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">stricmp</span> (asx_feature_type.<span class="built_in">c_str</span>(), <span class="string">&quot;plp&quot;</span>) == <span class="number">0</span> ) </span><br><span class="line">            samp_freq = feature_info.plp_opts.frame_opts.samp_freq; </span><br><span class="line">        <span class="keyword">else</span> <span class="comment">//default: fbank</span></span><br><span class="line">            </span><br><span class="line">        samp_freq = feature_info.fbank_opts.frame_opts.samp_freq;</span><br><span class="line">            </span><br><span class="line">            <span class="function">OnlineNnet2FeaturePipeline <span class="title">feature_pipeline</span> <span class="params">(feature_info)</span></span>;</span><br><span class="line">            </span><br><span class="line">            <span class="function">Online IvectorExtractorAdaptationstate <span class="title">adaptation_state</span> <span class="params">(feature_info.ivector_extractor_info)</span></span>;</span><br><span class="line">            feature_pipeline. <span class="built_in">SetAdaptationstate</span> (adaptation_state) ;</span><br><span class="line"></span><br><span class="line">            <span class="function">OnlineSilenceWeighting <span class="title">silence_weighting</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">                trans_model, feature_info.silence weighting_config,</span></span></span><br><span class="line"><span class="params"><span class="function">                decodable_opts .frame_subsampling_factor)</span></span>;</span><br><span class="line">            </span><br><span class="line">            <span class="function">SingleUtteranceNnet3Decoder <span class="title">decoder</span><span class="params">(decoder_opts, trans_model, *decode_fst, &amp;feature_pipeline)</span></span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// read data from buffer</span></span><br><span class="line">            <span class="function">Matrix&lt;BaseFloat&gt; <span class="title">data_</span><span class="params">(<span class="number">1</span>, length)</span></span>;</span><br><span class="line">            BaseFloat *data_ptr = data_.<span class="built_in">Data</span>();</span><br><span class="line">            <span class="keyword">for</span> (int32 i=<span class="number">0</span> ; i &lt; length; i++ )&#123;</span><br><span class="line">                data_ptr[i] = buffer[i];</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="function">Subvector&lt;Baserloat&gt; <span class="title">data</span><span class="params">(data_, <span class="number">0</span>)</span></span>;</span><br><span class="line">            </span><br><span class="line">            int32 chunk_length;</span><br><span class="line">            <span class="keyword">if</span> (chunk_length_secs &gt;<span class="number">0</span> )</span><br><span class="line">            &#123;</span><br><span class="line">                chunk_length = <span class="built_in">int32</span> (samp_freq * chunk_length_secs);</span><br><span class="line">                <span class="keyword">if</span> (chunk_length ==<span class="number">0</span> ) chunk_length = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                chunk_length = std::numeric_limits&lt;int32&gt;::<span class="built_in">max</span>();    </span><br><span class="line">            &#125;</span><br><span class="line">            int32 samp_offset = <span class="number">0</span>;</span><br><span class="line">            std::vector&lt;std::pair&lt;int32, BaseFloat&gt; &gt; delta_weights;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">while</span> (samp_offset &lt; data.<span class="built_in">Dim</span>())</span><br><span class="line">            &#123;</span><br><span class="line">                int32 samp_remaining = data.<span class="built_in">Dim</span>() - samp_offset;</span><br><span class="line">                int32 num_samp = chunk_length &lt; samp_remaining ? chunk_length : samp_remaining;</span><br><span class="line"></span><br><span class="line">                <span class="function">Subvector&lt;BaseFloat&gt; <span class="title">wave_part</span> <span class="params">(data, samp_offset, num_samp)</span></span>;</span><br><span class="line">                feature_pipeline.<span class="built_in">AcceptWaveform</span>(samp_freq, wave_part);</span><br><span class="line">                </span><br><span class="line">                samp_offset += num_samp;</span><br><span class="line">                <span class="keyword">if</span> (samp_offset == data.<span class="built_in">Dim</span>())&#123; </span><br><span class="line">                    <span class="comment">// no more input. flush out last frames</span></span><br><span class="line">                    feature_pipeline.<span class="built_in">InputFinished</span>();</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> (silence_weighting.<span class="built_in">Active</span>() &amp;&amp; feature_pipeline.<span class="built_in">IvectorFeature</span> () != <span class="literal">NULL</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    silence_weighting.<span class="built_in">ComputeCurrentTraceback</span> (decoder.<span class="built_in">Decoder</span>());</span><br><span class="line">        silence_weighting.<span class="built_in">GetDeltaWeights</span> (feature_pipeline.<span class="built_in">NumFramesReady</span> (), &amp;delta_weights);</span><br><span class="line">        feature_pipeline.<span class="built_in">IvectorFeature</span> () -&gt; <span class="built_in">UpdateFrameWeights</span> (delta_weights);</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                decoder.<span class="built_in">AdvanceDecoding</span> ();</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> (do_endpointing &amp;&amp; decoder.<span class="built_in">EndpointDetected</span>(endpoint_opts))</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            decoder.<span class="built_in">FinalizeDecoding</span> ();</span><br><span class="line">            </span><br><span class="line">            Compactlattice clat;</span><br><span class="line">            <span class="type">bool</span> end_of_utterance = <span class="literal">true</span>;</span><br><span class="line">            decoder. <span class="built_in">GetLattice</span>(end_of_utterance, &amp;clat);</span><br><span class="line">            </span><br><span class="line">            BaseFloat words_conf = <span class="number">0.0</span>;</span><br><span class="line">            <span class="built_in">GetDiagnosticsAndPrintoutput</span>(word_syms, clat, &amp;num_frames, &amp;tot_like, words, words_conf);</span><br><span class="line"></span><br><span class="line">            scoreASR = words_conf;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            <span class="built_in">catch</span>(<span class="type">const</span> std::exception&amp; e)</span><br><span class="line">            &#123;</span><br><span class="line">                std: : cerr &lt; e. <span class="built_in">what</span> ();</span><br><span class="line">                <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用来和外面调用程序交互</span></span><br><span class="line"><span class="function">return_ASR_Code <span class="title">ASR_recSpeechBuf</span> <span class="params">(Handle handle, <span class="type">short</span>* buffer, <span class="type">unsigned</span> <span class="type">long</span> length, <span class="type">char</span>* text, <span class="type">float</span> &amp;scoreASR)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!asr_bInited) <span class="keyword">return</span> ASR_STATE_ERROR; </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (handle &lt;=<span class="number">0</span> || handle&gt;asr_engine_thread_nb) <span class="keyword">return</span> ASR_HANDLE_ERROR;</span><br><span class="line">    <span class="built_in">ASR_P</span>() ;</span><br><span class="line">    <span class="keyword">if</span> (asr_state [handle] != TSASR_IDLE)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">ASR_V</span>();</span><br><span class="line">        <span class="keyword">return</span> ASR_STATE_ERROR;</span><br><span class="line">    &#125;</span><br><span class="line">    asr_state[handle] = TSASR_BUSY;</span><br><span class="line">    <span class="built_in">ASR_V</span>();</span><br><span class="line">    </span><br><span class="line">    std::vector&lt;int32&gt; words;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">Kaldidecode</span> (buffer, length, words, scoreASR);</span><br><span class="line">    </span><br><span class="line">    string recText = <span class="string">&quot;&quot;</span> ;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(int32 i=<span class="number">0</span> ; i&lt; words.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">        recText += word_syms-&gt;<span class="built_in">Find</span> (words[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    recText +=<span class="string">&quot;\0&quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">ASR_P</span>();</span><br><span class="line">    <span class="keyword">if</span>(asr_state[handle] == TSASR_BUSY) asr_state [handle] = TSASR_IDLE;</span><br><span class="line">    <span class="built_in">ASR_V</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ASR_SUCCEEDED_OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="函数接口——返回值"><a href="#函数接口——返回值" class="headerlink" title="函数接口——返回值"></a>函数接口——返回值</h3><p>函数返回结果是return_ASR_code类型，它包含运行中可能出现的各种情况，用枚举类型定义。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">return_ASR_Code</span></span><br><span class="line">&#123;</span><br><span class="line">	ASR_SUCCEEDED_OK=<span class="number">0</span>,	 <span class="comment">//	0:操作成功</span></span><br><span class="line">	ASR_WORKINGDIR_NOT_FIND,	 <span class="comment">//	1:工作目录不存在</span></span><br><span class="line">	ASR_CONFIG_FILE_NOT_FOUND,     <span class="comment">//	2:配置文件未找到</span></span><br><span class="line">	ASR_MODEL_FILE_NOT_FOUND,      <span class="comment">//               3:模型文件未找到</span></span><br><span class="line">	ASR_LICENSE_ERROR,     	 <span class="comment">//	4:授权有误</span></span><br><span class="line">	ASR_HANDLE_ERROR,   	 <span class="comment">//	5:句柄标识有误</span></span><br><span class="line">	ASR_STATE_ERROR,		 <span class="comment">//	6:句柄状态有误</span></span><br><span class="line">	ASR_TOO_SHORT_BUFFER,	 <span class="comment">//	7:语音太短</span></span><br><span class="line">	ASR_EXTRACT_FEAT_ERROR,	 <span class="comment">//	8:特征提取出错</span></span><br><span class="line">	ASR_MODEL_LOAD_ERROR,	 <span class="comment">//	9:模型加载出错</span></span><br><span class="line">	ASR_MODEL_SAVE_ERROR,	 <span class="comment">//	10:模型保存出错</span></span><br><span class="line">	TSASR_BUSY,		<span class="comment">//	11:线路正忙</span></span><br><span class="line">	TSASR_IDLE,		 <span class="comment">//	12:线路空闲</span></span><br><span class="line">	TSASR_CLOSE,		 <span class="comment">//	13:线路关闭</span></span><br><span class="line">	ASR_OTHER_ERROR		 <span class="comment">//	14:其他错误</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>用返回值来诊断引擎出现的问题。</p>
<p>为了提高可读性, 还需对识别后的句子进行加标点等后处理。加标点的操作可采用语言模型，该模型通过对规范的文本语料训练得到。</p>
<p>由于声学模型和 WFST 解码用的 HCLG 文件很大, 通用版本大小一般有 5GB 以上, 故只能在系统初始化阶段加载, 并且只需要加载一次。其相关代码如下:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 加载声学模型</span></span><br><span class="line"><span class="type">bool</span> binary;</span><br><span class="line"><span class="function">Input <span class="title">ki</span> <span class="params">(nnet3_rxfilename, &amp;binary)</span></span>;</span><br><span class="line">trans_model.<span class="built_in">Read</span> (ki.<span class="built_in">stream</span> (), binary);</span><br><span class="line">am_nnet.<span class="built_in">Read</span> (ki.<span class="built_in">Stream</span> (), binary);</span><br><span class="line"><span class="built_in">SetBatchnormTestMode</span> (<span class="literal">true</span>, &amp;(am_nnet.<span class="built_in">GetNnet</span> () ));</span><br><span class="line"><span class="built_in">SetDropoutTestMode</span> (<span class="literal">true</span>, &amp;(am_nnet.<span class="built_in">GetNnet</span> ()));</span><br><span class="line">nnet3::<span class="built_in">CollapseModel</span> (nnet3::<span class="built_in">CollapseModelConfig</span>(), &amp;(am_nnet.<span class="built_in">GetNnet</span>()));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 加载 HCLG</span></span><br><span class="line">decode_fst = <span class="built_in">ReadFstKaldiGeneric</span>(fst_rxfilename);</span><br><span class="line"></span><br><span class="line"><span class="comment">//加载词典</span></span><br><span class="line"><span class="keyword">if</span> (word_syms_rxfilename != <span class="string">&quot;&#x27;&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (! (word_syms = fst::SymbolTable::<span class="built_in">ReadText</span> (word_syms_rxfilename))</span><br><span class="line">        KALDI_ERR &lt;&lt; <span class="string">&quot;Could not read symbol table from file &quot;</span></span><br><span class="line">                    &lt;&lt; word_syms_rxfilename;</span><br><span class="line"></span><br><span class="line"><span class="comment">//解码参数初始化</span></span><br><span class="line">decodable_info = <span class="keyword">new</span> nnet3::<span class="built_in">DecodableNnetSimpleLoopedinfo</span>(decodable_opts, &amp;am_nnet);</span><br></pre></td></tr></table></figure>





<h3 id="函数接口—引擎初始化和关闭"><a href="#函数接口—引擎初始化和关闭" class="headerlink" title="函数接口—引擎初始化和关闭"></a>函数接口—引擎初始化和关闭</h3><p>对于引擎初始化，我们专门定义一个函数ASR_Init。</p>
<p>ASR_Init 函数除了进行引擎文件的加载外, 同时也检查线路授权, 分配能同时并发的路数, 以支持多路调用。调用 ASR_Init 函数后, 如果返回函数值为 ASR_SUCCEEDED_OK, 则表示初始化成功。如果要关闭语音识别服务, 则需要调用 ASR_Release 函数释放相关资源。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">	      		初始化引擎</span></span><br><span class="line"><span class="comment">		@ working_dir	: 工作目录下有引擎工作所必需的文件</span></span><br><span class="line"><span class="comment">		@ max_lines	: 引擎支持最大线数</span></span><br><span class="line"><span class="comment">		@ return		: 成功初始化返回SUCCESS</span></span><br><span class="line"><span class="comment">                                                                                                                                                                                   */</span></span><br><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="function">return_ASR_Code <span class="title">ASR_Init</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* config_file,<span class="type">int</span> max_lines)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">			关闭引擎：改变各线路状态为CLOSE</span></span><br><span class="line"><span class="comment">                                                                                                                                                                                   */</span></span><br><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="function">return_ASR_Code <span class="title">ASR_Release</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>



<h3 id="函数接口—句柄打开和关闭"><a href="#函数接口—句柄打开和关闭" class="headerlink" title="函数接口—句柄打开和关闭"></a>函数接口—句柄打开和关闭</h3><p>由于涉及多线程调用, 所以需要为每个线程分配专门的句柄, 因此还需要 ASR_Open 和 ASR_Close 两个函数。调用 ASR_Open 函数分配到句柄后，执行完相关操作也要及时调用 ASR_Close 函数释放句柄。这两个函数属于标准化的操作, 这里不再细述。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">				打开线路：h是线路资源标识</span></span><br><span class="line"><span class="comment">                                                                                                                                                                                   */</span></span><br><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="function">return_ASR_Code <span class="title">ASR_Open</span><span class="params">(Handle &amp;outh)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">*************************************************************************************************************************/</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">				关闭线路：h是线路资源标识</span></span><br><span class="line"><span class="comment">                                                                                                                                                                                   */</span></span><br><span class="line"><span class="comment">/*************************************************************************************************************************/</span></span><br><span class="line"><span class="function">return_ASR_Code <span class="title">ASR_Close</span><span class="params">(Handle &amp;h)</span></span>;</span><br></pre></td></tr></table></figure>





<h2 id="动态库编译"><a href="#动态库编译" class="headerlink" title="动态库编译"></a>动态库编译</h2><p>完成函数接口定义后，需要把引擎代码编译成动态库。接下来介绍Linux环境下so的编译过程。</p>
<h3 id="动态库编译—Linux环境"><a href="#动态库编译—Linux环境" class="headerlink" title="动态库编译—Linux环境"></a>动态库编译—Linux环境</h3><p>Linux环境不方便修改及调试代码，为便于操作，我们建议采用跨平台工具，开发环境可采用 &#x3D;&#x3D;CodeBlocks&#x3D;&#x3D;，读者可下载最新版本并安装到Windows系统。以CodeBlocks16.01版本为例，一旦安装完成后，在文件菜单里选择新建-&gt;工程-&gt;动态库（New -&gt; Project -&gt; DLL），打开codeblock动态库创建窗口，如图所示。</p>
<p><img src="/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E5%8A%A8%E6%80%81%E5%BA%93%E5%B0%81%E8%A3%85/%E5%9B%BE%E7%89%872-16750654093591.png" alt="图片2"></p>
<p>然后根据提示一步步创建，选择存放的目录，输入工程名，直到工程环境创建成功，如图所示。这时在工程目录会生成一个.cbp的工程文件，如asr.cbp。根据Kaldi函数调用关系，我们需要把在线解码需要的源程序全部加载到工程，并加入必要的外部支撑文件，用来读取配置文件，输出日志信息等。</p>
<p><img src="/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E5%8A%A8%E6%80%81%E5%BA%93%E5%B0%81%E8%A3%85/%E5%9B%BE%E7%89%871.png" alt="图片1"></p>
<p>工程配置保存完，把整个工程目录传到Linux环境，Linux的编译需要Makefile配置文件。为提高效率，可采用cbp2make工具（可网上下载）把asr.cbp工程文件转化为Makefile文件。有了Makefile文件，即可&#x3D;&#x3D;在Linux环境进行make编译&#x3D;&#x3D;。</p>
<p>我理解的流程是：先在windows新建工程（codeblock），把所以依赖文件放进来，然后把windows上的这个工程，转成makefile，再放到linux平台上编译，再根据报错情况，再在win平台上的codeblock工程进行修改，然后再转成makefile放到linux里进行编译，直到编译通过，生成.so文件（动态库）。</p>
<p>用了哪些库，比如数学的库，就要把这些库的头文件的路径在makefile里包含、引用进来。</p>
<p>由于kaldi需要调用第三方提供的数学加速库，如Atlas或MKL，因此需要在Makefile中进行如下配置：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">[采用Atlas库]</span><br><span class="line">INC = -Isrc -Iopenfst/<span class="keyword">include</span> -I/home/kaldi/tools/ATLAS/<span class="keyword">include</span> -I/usr/local/cuda/<span class="keyword">include</span>/ -I/home/kaldi/tools/portaudio/<span class="keyword">include</span> -I/home/kaldi/tools/portaudio/install/<span class="keyword">include</span> -I/usr/<span class="keyword">include</span>/glib-2.0 -I/usr/lib/x86_64-linux-gnu/glib-2.0/<span class="keyword">include</span> -I/usr/<span class="keyword">include</span>/libxml2/</span><br><span class="line">CFLAGS = -std=c++11 -DHAVE_ATLAS -DHAVE_POSIX_MEMALIGN</span><br><span class="line">RESINC = </span><br><span class="line">LIBDIR = </span><br><span class="line">LIB = lib/libatlas.so lib/liblapack.so</span><br><span class="line">LDFLAGS = -ldl</span><br><span class="line"></span><br><span class="line">[采用 MKL 库]</span><br><span class="line">INC = -Isrc -Iopenfst/<span class="keyword">include</span></span><br><span class="line">-I/opt/intel/compilers_and_libraries_2019.2.187/linux/mkl/<span class="keyword">include</span>/</span><br><span class="line">-I/usr/local/cuda/<span class="keyword">include</span>/-I/usr/lib/x86_64-1inux-gnu/glib-2.0/<span class="keyword">include</span></span><br><span class="line">-I/usr/<span class="keyword">include</span>/libxml2/</span><br><span class="line">CFLAGS = -std=c++11 -DHAVE_MKL_-DHAVE_POSIX_MEMALIGN</span><br><span class="line">RESINC =</span><br><span class="line">LIBDIR =</span><br><span class="line">LIB = lib_mkl/libiomp5.so lib_mkl/libmkl_core.so 11b_mkl/libmkl_intel_lp64.so</span><br><span class="line">LDFLAGS = -ldl -lpthread</span><br></pre></td></tr></table></figure>

<p>Linux环境差异大，包括centos，ubuntu等不同版本，安装库的位置也可能不同，需要根据实际环境，修改makefile里面关于这些库的访问路径配置。服务器一般采用centos。</p>
<p>由于Kaldi代码众多，包含很多子模块，函数互相之间关联度较强，加载的文件可能存在冗余或冲突，导致各种编译错误，读者需要根据报错信息一一修正，直至编译成功，最后生成so动态库文件。</p>
<p>这个so动态库需配套相应的头文件，包含可调用的函数接口及参数说明，供外部调用参照。</p>
<p>.so有release版本和debug版本，我们要用release版本，速度快。</p>
<h3 id="动态库编译—Windows环境"><a href="#动态库编译—Windows环境" class="headerlink" title="动态库编译—Windows环境"></a>动态库编译—Windows环境</h3><p>Windows环境编译的是dll动态库，主要采用Visual Studio开发工具。由于Kaldi代码采用C++ 11标准，需要安装Visual Studio 2015或更新的版本。另外，Windows环境的加速库只能采用Intel MKL或OpenBLAS。MKL集成相对容易，但需要安装Intel的配套工具，安装完MKL与Visual Studio 2015集成环境如图所示。</p>
<p><img src="/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E5%8A%A8%E6%80%81%E5%BA%93%E5%B0%81%E8%A3%85/%E5%9B%BE%E7%89%873.png" alt="图片3"></p>
<p>由于 Kaldi 默认在 Linux 环境下编译, 对 Windows 的支持不是很到位, 因此 部分变量和代码在编译时会出现问题, 需要修改, 例如在 kaldi-math.h 文件中需要补充针对_MSC_VER (Visual Studio 开发环境) 的定义。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> MSC_VER</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">isnan</span><span class="params">(<span class="type">double</span> x)</span> </span>&#123; <span class="keyword">return</span> x != x;&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">isinf</span><span class="params">(<span class="type">double</span> x )</span> </span>&#123; <span class="keyword">return</span> !<span class="built_in">isnan</span>(x) &amp;&amp; <span class="built_in">isnan</span>(x-x); &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> isfinite finite</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_ISNAN isnan</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_ISINF isinf</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_ISFINITE(x) isfinite(x)</span></span><br><span class="line"><span class="meta">#<span class="keyword">elif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_ISNAN std:: isnan</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_ISINF std:: isinf</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_ISFINITE(x) std::isfinite(x)</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>







<h2 id="动态库调用"><a href="#动态库调用" class="headerlink" title="动态库调用"></a>动态库调用</h2><p>外部程序调用编译好的动态库，要先集成到工程里，如Linux在Makefile里配置如下：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">CC = gcc</span><br><span class="line">CXX = g++</span><br><span class="line">AR = ar</span><br><span class="line">LD = g++</span><br><span class="line">WINDRES = windres</span><br><span class="line"></span><br><span class="line">INC = </span><br><span class="line">CFLAGS = -Wall -fexceptions</span><br><span class="line">RESINC = </span><br><span class="line">LIBDIR = </span><br><span class="line">LIB = lib/libatlas.so lib/libtsASR.so lib/liblapack.so</span><br><span class="line">LDFLAGS = </span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>程序要调用时，先初始化引擎，然后分配句柄，再调用相关的识别函数，识别完关闭句柄。程序到最后还要关闭引擎，释放资源。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//初始化引擎</span></span><br><span class="line"><span class="keyword">if</span>(ASR_SUCCEEDED_OK == <span class="built_in">ASR_Init</span>(config_asr_file.<span class="built_in">c_str</span>(),<span class="number">3</span>))</span><br><span class="line">&#123;</span><br><span class="line">      cout&lt;&lt;<span class="string">&quot;ASR init success!&quot;</span>&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">      cout&lt;&lt;<span class="string">&quot;ASR init fails!&quot;</span>&lt;&lt;endl;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//打开句柄</span></span><br><span class="line">Handle tsASR;</span><br><span class="line"><span class="built_in">ASR_Open</span>(tsASR);</span><br><span class="line"></span><br><span class="line"><span class="type">float</span> scoreASR;</span><br><span class="line"><span class="type">char</span> rec_text[<span class="number">10240</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">//语音识别</span></span><br><span class="line"><span class="keyword">if</span>(ASR_SUCCEEDED_OK == <span class="built_in">ASR_recSpeechBuf</span>(tsASR,pWavBuffer,length,rec_text,scoreASR))</span><br><span class="line">&#123;</span><br><span class="line">       cout&lt;&lt;<span class="string">&quot;Recognized text: &quot;</span>&lt;&lt;rec_text&lt;&lt;endl;</span><br><span class="line">       cout&lt;&lt;<span class="string">&quot;scoreASR: &quot;</span>&lt;&lt;scoreASR&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">       cout&lt;&lt;<span class="string">&quot;Recognize &quot;</span>&lt;&lt;wave_full_file.<span class="built_in">c_str</span>()&lt;&lt;<span class="string">&quot;error!&quot;</span>&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//关闭句柄</span></span><br><span class="line"><span class="built_in">ASR_Close</span>(tsASR);</span><br><span class="line"></span><br><span class="line"><span class="comment">//关闭引擎</span></span><br><span class="line"><span class="built_in">ASR_Release</span>();</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>工程实践</category>
      </categories>
      <tags>
        <tag>《语音识别原理与应用》</tag>
        <tag>工程实践</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第15章 工程应用实践————识别引擎优化</title>
    <url>/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E8%AF%86%E5%88%AB%E5%BC%95%E6%93%8E%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="识别引擎优化"><a href="#识别引擎优化" class="headerlink" title="识别引擎优化"></a>识别引擎优化</h1><blockquote>
<p>《语音识别原理与技术》洪青阳 工业应用实践 书、PPT 15.3</p>
</blockquote>
<ul>
<li>加快响应速度</li>
<li>定制语言模型</li>
<li>定制声学模型</li>
</ul>
<h2 id="加快响应速度"><a href="#加快响应速度" class="headerlink" title="加快响应速度"></a>加快响应速度</h2><ul>
<li><p>语音识别的响应速度可用<strong>实时率（RTF）</strong>来衡量，即识别时间与语音时长的比值，越低越好。响应速度也可采用倍实时指标，倍实时跟RTF正好相反，是语音时长与识别时间的比值，越高越好。</p>
</li>
<li><p>为加快响应速度，可从算法优化和工程优化两方面入手。算法优化主要针对WFST解码器优化。WFST的令牌传播机制和Lattice解码都有剪枝过程，默认的最大活跃节点数和剪枝阈值为：</p>
<p>max-active&#x3D;7000</p>
<p>beam&#x3D;15.0</p>
<p>lattice-beam&#x3D;8.0</p>
</li>
<li><p>对响应速度影响较大的是前两个参数，实验表明，识别率略微变差情况下，max-active和beam值可以减小如下：</p>
<p>max-active&#x3D;3000</p>
<p>beam&#x3D;10.0</p>
<p>lattice-beam&#x3D;8.0</p>
</li>
<li><p>修改后响应速度可大幅提升，比如3秒语音只要0.5秒即可识别出结果，即RTF&lt;0.2。</p>
</li>
<li><p>&#x3D;&#x3D;矩阵运算用到了线性代数运算加速库，可用库版本包括 ATLAS、OpenBLAS 和 MKL。离线测试结果显示 MKL 的加速性能最优。&#x3D;&#x3D;</p>
</li>
<li><p>另外，采用 GPU 解码加速声学模型计算过程，也可大幅提升响应速度。</p>
</li>
</ul>
<h2 id="定制语言模型"><a href="#定制语言模型" class="headerlink" title="定制语言模型"></a>定制语言模型</h2><ul>
<li>通用语言模型一般使用日常生活、工作、新闻等范畴的文本语料训练而成，对书面语或日常用语识别较好，但针对口语化表达或特定行业，如司法、证券、电力、医疗等，因为有其专业的术语，往往识别不好。</li>
<li>专用语言模型可以只用特定行业的句子表达来训练，但语料规模一般偏少，需要人为地设计一些类似的句子，尽可能覆盖到实际可能用的表达，使训练出来的统计模型覆盖更全面。</li>
</ul>
<p>直接用语料混合的话，由于专有语料数量少，可能起不到什么作用。因此用各自训练一个语言模型，然后进行模型融合（线性加权）</p>
<p><img src="/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E8%AF%86%E5%88%AB%E5%BC%95%E6%93%8E%E4%BC%98%E5%8C%96/image-20230130190834641.png" alt="image-20230130190834641"></p>
<p>重新训练完语言模型后，要将其与声学模型合并，生成HCLG。</p>
<h2 id="定制声学模型"><a href="#定制声学模型" class="headerlink" title="定制声学模型"></a>定制声学模型</h2><p>如果采集设备比较特殊，跟常用的PC或手机麦克风差异较大，而声学模型的训练数据没有覆盖到这种录音，则识别性能会急剧下降，这也是一种<strong>跨信道问题</strong>。</p>
<p>一种解决方案是扩大声学模型的训练数据覆盖范围，尽量使其包含跟实际场景相配的录音。但这种方案代价较大,需要重新训练 GMM-HMM或DNN-HMM，以及 Chain 模型，周期长，难以匹配项目进度。</p>
<p>还有一种方案是采用迁移学习，基于源领域已有的通用模型，用目标领域的小批量训练数据(建议 50h 以上)重新训练，得到更匹配的声学模型。迁移学习原理很简单，保持DNN 的隐藏层参数不变，只改变输出层(从 Ys改为Y)，然后用目标数据X-重新微调训练。</p>
<h3 id="定制声学模型——迁移学习"><a href="#定制声学模型——迁移学习" class="headerlink" title="定制声学模型——迁移学习"></a>定制声学模型——迁移学习</h3><p>DNN迁移学习：适配不同场景（包括不同终端，不同格式等），迁移完的识别模型就是专有领域的了，也不适用于通用领域。</p>
<p>迁移学习方法：</p>
<ol>
<li>用基础模型作为base，专有数据在上面继续训练；</li>
<li>冻结基础模型的几层神经层，参数更新；</li>
<li>用教师学生模型，软标签，蒸馏。</li>
</ol>
<p><img src="/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E8%AF%86%E5%88%AB%E5%BC%95%E6%93%8E%E4%BC%98%E5%8C%96/image-20230130190918970.png" alt="image-20230130190918970"></p>
<h3 id="8K电话语音识别"><a href="#8K电话语音识别" class="headerlink" title="8K电话语音识别"></a>8K电话语音识别</h3><p>工业界：识别准确率普遍在80~90%，与手机APP识别（16k）差距较大。</p>
<p>信道差异最明显的是 16kHz 采样的麦克风录音与8kHz 采样的电话录音，它们互相之间兼容性不强，<strong>即使把 16 kHz 录音降采样到 8kHz 录音，再去训练声学模型，识别效果也不一定会改善</strong>。由于现在很多APP 应用用手机麦克风采集录音，即采样格式为 16kHz,16bits 宽带录音，所以针对近场手机的场景，识别效果可以很好，准确率大多可达到95%以上。但电话8kHz信道的录音普遍很少，难以训练出一个鲁棒性很强的声学模型，再加上电话通话一般是聊天式的口语化表达，语言模型较难覆盖，因此电话语音识别效果仍不太理想，准确率一般在80%~90%之间，难以超越 90%，和16kHz的录音识别效果差距还较大。</p>
<p>在8kHz的一些受限场景下，语言表达相对固定，采集信道固定，此时仍然的 可以用 16 kHz 声学模型作为基准模型，再用实际场景带标注的录音语料做迁移学习，这在一定程度上可提升识别效果。从 在实际应用中，还存在口音重、语速快、双语混杂等问题，导致识别率急剧下降，对此问题建议采用匹配训练数据的方法来解决。</p>
<p>如何平衡专用语料和通用语料的比重，包括平衡声学模型和语言模型的比重，避免过度偏向某种口音或场景，也是一个难题，需要在实践中不断总结。</p>
<p>声学模型存在问题：</p>
<ul>
<li>采样率8kHz：采集信道与麦克风差异很大，不能直接用16k模型识别；</li>
<li>特种设备：量化编码存在失真；</li>
<li>快语速：识别变差；</li>
</ul>
<p>语言模型存在问题：</p>
<ul>
<li>口语化表达难以覆盖；</li>
<li>通用领域与专业领域较难平衡；</li>
</ul>
<p>可归结为两大原因：</p>
<ol>
<li>信道差异</li>
<li>口语化识别</li>
</ol>
<h3 id="模型优化方案"><a href="#模型优化方案" class="headerlink" title="模型优化方案"></a>模型优化方案</h3><p>改进方案：</p>
<ol>
<li><p>采用数据扩增，进行多类型、多条件训练。</p>
</li>
<li><p>采用更先进的声学模型。</p>
</li>
<li><p>DNN迁移学习。</p>
</li>
</ol>
<p><img src="/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E8%AF%86%E5%88%AB%E5%BC%95%E6%93%8E%E4%BC%98%E5%8C%96/image-20230130191552500.png" alt="image-20230130191552500"></p>
]]></content>
      <categories>
        <category>工程实践</category>
      </categories>
      <tags>
        <tag>《语音识别原理与应用》</tag>
        <tag>工程实践</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第15章 工程应用实践————语音云平台</title>
    <url>/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E8%AF%AD%E9%9F%B3%E4%BA%91%E5%B9%B3%E5%8F%B0/</url>
    <content><![CDATA[<h1 id="语音云平台"><a href="#语音云平台" class="headerlink" title="语音云平台"></a>语音云平台</h1><blockquote>
<p>《语音识别原理与技术》洪青阳 工业应用实践 书、PPT 15.2</p>
</blockquote>
<p>语音云平台可通过RESTful的方式给开发者提供一个通用的HTTP接口。</p>
<p>如图所示，系统通过HTTP的协议来进行调用。客户端采用HTTP Post，发Post请求到服务器，然后获取服务器的响应，根据响应的代码，判断操作是否成功。客户端负责语音的采集，并将采集后的语音上传到服务端，由服务端进行语音识别，并将结果返回到客户端。</p>
<p>部署不是一个识别引擎，so就够了，底层还要有一个服务程序，服务程序来调用识别引擎，服务程序再和外围客户端去交互。</p>
<p><img src="/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E8%AF%AD%E9%9F%B3%E4%BA%91%E5%B9%B3%E5%8F%B0/image-20230130180710118.png" alt="image-20230130180710118"></p>
<p>HTTP协议服务一般通过高级语言，如go、Python或Java等语言实现，接收HTTP多路并发请求，使用多线程技术调用引擎进行识别，并用JSON格式返回识别结果。</p>
<p>HTTP接口协议包括如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">传送字节流</span><br><span class="line">必选字段:</span><br><span class="line">userid: 用户名称，可使用用户手机号码</span><br><span class="line">token: 系统分配</span><br><span class="line"></span><br><span class="line">file: 文件标识</span><br><span class="line">语音缓冲（可以合并传，也可分段传，但不能有间隔符）：</span><br><span class="line">buffer1(录音缓冲区）+</span><br><span class="line">buffer2(录音缓冲区）+</span><br><span class="line">buffer3(录音缓冲区）+</span><br><span class="line">...</span><br><span class="line">bufferN(录音缓冲区）</span><br><span class="line">识别成功服务器返回:</span><br><span class="line">&#123;&quot;result&quot;:&quot;语音识别识别内容文本&quot;,&quot;errCode&quot;:&quot;0&quot;,&quot;wavurl&quot;:&quot;xxx.wav&quot;&#125;</span><br><span class="line">wavurl是识别结果文本对应的语音文件url地址.默认是空&quot;&quot;</span><br><span class="line">识别结果是utf-8 编码。</span><br><span class="line"></span><br><span class="line">识别失败服务器返回：</span><br><span class="line">类似下面这个:&#123;&quot;result&quot;:&quot;&quot;,&quot;errCode&quot;:&quot;-1&quot;,&quot;AsrRetCode&quot;:&quot;5&quot;&#125;</span><br><span class="line">识别失败,会返回errCode!=0 </span><br><span class="line">说明:file内容字节流长度不能小于4000Byte</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>以下是客户端采用C代码实现CURL调用的例子。上传一句话的buffer，然后返回识别结果。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;windows.h&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fentl.h&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;io.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/timeb.h&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;process.h&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;curl/curl.h&quot;</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&quot;curl/easy.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">size_t</span> <span class="title function_">asrwritefunc</span><span class="params">(<span class="type">void</span> *ptr, <span class="type">size_t</span> size, <span class="type">size_t</span> nmemb, <span class="type">int</span> *index)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> count=<span class="number">0</span>;</span><br><span class="line">    <span class="type">char</span> result[<span class="number">2048</span>];</span><br><span class="line">    <span class="type">size_t</span> result len = size * nmemb;</span><br><span class="line">    result[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(result_len&gt;=<span class="number">2000</span>) result_len=<span class="number">2000</span>; </span><br><span class="line">    <span class="keyword">if</span>(result_len&gt;<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">memcpy</span>(result, ptr, result_len); </span><br><span class="line">        result[result_len]=<span class="string">&#x27;\0&#x27;</span>; </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;result=%s&quot;</span>,result);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;result_len=%d&quot;</span>, result_len); </span><br><span class="line">    <span class="keyword">return</span> result_len;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">test_asr</span><span class="params">(<span class="type">int</span> index,<span class="type">char</span> *audiodata,<span class="type">int</span> content_len)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">int</span> boot;</span><br><span class="line">    <span class="type">static</span> <span class="type">char</span> userid[<span class="number">64</span>], token[<span class="number">28</span>]; </span><br><span class="line">    <span class="type">static</span> <span class="type">char</span> ycasr_ur1[<span class="number">128</span>]; </span><br><span class="line">    <span class="type">char</span> tmp[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">if</span>((use_asr&amp;<span class="number">16</span>) == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">-1</span>; </span><br><span class="line">    <span class="keyword">if</span>(boot==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        boot=<span class="number">1</span>;</span><br><span class="line">        GetPrivateProfileString(<span class="string">&quot;SET&quot;</span>,<span class="string">&quot;URL&quot;</span>,<span class="string">&quot;http://127.0.0.1:3998/dotcasr&quot;</span>,ycasr_url,<span class="number">28</span>,config);</span><br><span class="line">        GetPrivateProfileString(<span class="string">&quot;SET&quot;</span>,<span class="string">&quot;USERID&quot;</span>,<span class="string">&quot;13600000001&quot;</span>,userid,<span class="number">32</span>,config);</span><br><span class="line">        GetPrivateProfileString(<span class="string">&quot;SET&quot;</span>,<span class="string">&quot;TOKEN&quot;</span>,<span class="string">&quot;xxxx13600000001&quot;</span>,token,<span class="number">64</span>, config);</span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">    <span class="type">time_t</span> now=time(<span class="literal">NULL</span>);</span><br><span class="line">    <span class="type">char</span> host[MAX_BUFFER_SIZE];</span><br><span class="line">    <span class="built_in">memset</span>(host, <span class="number">0</span>, <span class="keyword">sizeof</span>(host));</span><br><span class="line">    _snprintf(host, <span class="keyword">sizeof</span>(host), <span class="string">&quot;%s&quot;</span>, ycasr_url); </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;host:%s&quot;</span>,host); </span><br><span class="line">    CURL *curl; </span><br><span class="line">    CURLcode res;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">curl_httppost</span> *<span class="title">post</span>=</span><span class="literal">NULL</span>; </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">curl_httppost</span> *<span class="title">last</span>=</span><span class="literal">NULL</span>;</span><br><span class="line">    curl_formadd(&amp;post, &amp;last, CURLFORM_COPYNAME, <span class="string">&quot;userid&quot;</span>, CURLFORM_COPYCONTENTS, userid, CURLFORM_END);</span><br><span class="line">    curl <span class="title function_">formadd</span><span class="params">(&amp;post, &amp;last, CURLFORM_COPYNAME, <span class="string">&quot;token&quot;</span>, CURLFORM_COPYCONTENTS, token, CURLFORM_END)</span>;</span><br><span class="line"></span><br><span class="line">    curl_formadd(&amp;post, &amp;last, CURLFORM_COPYNAME, <span class="string">&quot;file&quot;</span>, </span><br><span class="line">        CURLFORM BUFFER,<span class="string">&quot;upload.wav&quot;</span>, </span><br><span class="line">        CURLFORM BUFFERPTR, audiodata,</span><br><span class="line">        CURLFORM BUFFERLENGTH, content_len, </span><br><span class="line">        CURLFORM_END);</span><br><span class="line">    </span><br><span class="line">    curl = curl_easy_init();</span><br><span class="line">    cur1_easy_setopt(curl, CURLOPT_URL, host); </span><br><span class="line">    curl_easy_setopt(curl, CURLOPT_TIMEOUT, <span class="number">30</span>); </span><br><span class="line">    curl easy <span class="title function_">setopt</span><span class="params">(curl, CURLOPT_HTTPPOST, post)</span>;</span><br><span class="line">    curl <span class="title function_">easy_setopt</span><span class="params">(curl, CURLOPT_WRITEFUNCTION, asrwritefunc)</span>;</span><br><span class="line">    curl_easy_setopt(curl, CURLOPT_WRITEDATA, &amp;index); </span><br><span class="line">    res = curl_easy_perform(curl); </span><br><span class="line">    <span class="keyword">if</span>(res != CURLE OK)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;perform curl error:8d.\n&quot;</span>, res);</span><br><span class="line">        <span class="comment">//return -l;</span></span><br><span class="line">    &#125;</span><br><span class="line">    curl_easy_cleanup(curl); </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">char</span> buffer[<span class="number">256000</span>];</span><br><span class="line">    <span class="type">int</span> c=<span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> res=<span class="number">-1</span>,size=<span class="number">0</span>,index=<span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">    FILE* fp1=fopen(<span class="string">&quot;test.wav&quot;</span>,<span class="string">&quot;r+b&quot;</span>); </span><br><span class="line">    <span class="keyword">if</span>(fp1=<span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;open test.wav fail!&quot;</span>); </span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        fseek(fp1,<span class="number">100</span>,SEEK_SET);<span class="comment">//跳过wav 头 </span></span><br><span class="line">        <span class="keyword">while</span>(!feof(fp1))</span><br><span class="line">        &#123;</span><br><span class="line">            sizemfread(buffer+c,<span class="number">1</span>,<span class="number">8000</span>,fp1);</span><br><span class="line">            <span class="keyword">if</span>(size&lt;<span class="number">0</span>) <span class="keyword">break</span>; </span><br><span class="line">            c=c+size:</span><br><span class="line">            <span class="keyword">if</span>(c&gt;=<span class="number">240000</span>) <span class="keyword">break</span>;    <span class="comment">//最大 240K</span></span><br><span class="line">        &#125;</span><br><span class="line">        fclose(fp1);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(c&gt;<span class="number">8000</span>) res=test_asr(index,buffer,c); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>语音云平台在服务器上运行，一般有强大的计算能力，因此可在其上使用复杂的声学模型和较大的语言模型，以支持各种场景的“任意说”识别，并通过 HTTP接口支持各种客户端调用。除了公有云,语音云平台也应支持私有云部署，以避免数据泄密。</p>
<h3 id="语音云平台—流识别"><a href="#语音云平台—流识别" class="headerlink" title="语音云平台—流识别"></a>语音云平台—流识别</h3><p>语音云平台还可通过流的方式进行语音识别，</p>
<p>如语音云平台的客户端一次可送200ms左右的片段，服务端接收后进行拼接，累计到1s 时长时即可开始识别。这个识别过程也是部分解码，只是令牌传播过程可以显示中间结果。等句子传送结束后，再进行 Lattice 回溯解码，得到最后识别结果。</p>
<p><img src="/2023/01/30/%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/%E8%AF%AD%E9%9F%B3%E4%BA%91%E5%B9%B3%E5%8F%B0/image-20230130182109183.png" alt="image-20230130182109183"></p>
<p>流识别结果跟整句识别略微有差别，但影响不大，能够保证实用性能。流识别方式可以边说边识别，大大缩短时延，有效提升响应速度。</p>
<p>现在工业界部署的云平台，普遍采用流识别方式。</p>
]]></content>
      <categories>
        <category>工程实践</category>
      </categories>
      <tags>
        <tag>《语音识别原理与应用》</tag>
        <tag>工程实践</tag>
      </tags>
  </entry>
  <entry>
    <title>拉格朗日乘子法</title>
    <url>/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/</url>
    <content><![CDATA[<h1 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="headerlink" title="拉格朗日乘子法"></a>拉格朗日乘子法</h1><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV15T411f7DY/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">理解【拉格朗日乘数法】：有等号约束的最优化</a></p>
</blockquote>
<p>拉格朗日乘子法是数学中一种用于求解非线性规划问题的方法。它利用了拉格朗日乘数法的思想，通过把约束条件看作限制变量的函数，并给这些函数乘以一个不等于零的乘数，形成拉格朗日函数，然后对该函数进行极值求解。拉格朗日乘子法是非线性规划的常用方法之一。</p>
<p>先列出公式：</p>
<p>$L(\overrightarrow{\boldsymbol{x}}, \lambda)&#x3D;f(\overrightarrow{\boldsymbol{x}})-\lambda c(\overrightarrow{\boldsymbol{x}}) $</p>
<p>$L(\overrightarrow{\boldsymbol{x}}, \lambda)$ 是拉格朗日函数，$\lambda c(\overrightarrow{\boldsymbol{x}})$ 是拉格朗日乘子</p>
<p>$$<br>\begin{gathered}<br>\nabla L&#x3D;0 \Longleftrightarrow\left{\begin{array}{l}<br>\nabla f(\overrightarrow{\boldsymbol{x}})&#x3D;\lambda \nabla c(\overrightarrow{\boldsymbol{x}}) \<br>c(\overrightarrow{\boldsymbol{x}})&#x3D;0<br>\end{array}\right.<br>\end{gathered}<br>$$<br>举例说明（含约束的优化）：</p>
<p>找空间中的一个平面 $f(x,y)&#x3D;x+y$ 在约束条件为 $x^2+y^2&#x3D;1$ 的圆柱下，求极大、极小值。</p>
<p>由于有了圆的约束，一个无界平面成了空间里的一条闭曲线。</p>
<p>为了方便可视化，把平面看作是一条条线组成，每条线是函数值取相同点连起来的。因此平面的等高线是一条条直线，圆柱的等高线是一圈圈的圆。</p>
<p>蓝线c表示约束条件，各自算出f和c的梯度，如图所示。</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206172949541.png" alt="image-20230206172949541" style="zoom: 33%;">

<p>找出f的极值点，使得在圆上（满足约束条件），又不会让f值再变小、变大了。因此是“与$\nabla c$垂直的方向，并且不与$\nabla f$夹钝角或锐角”。因此是“ 与$\nabla c$垂直的方向，也垂直于$\nabla f$ ”，意味着 f 和 c 的梯度在此处<strong>共线</strong>。</p>
<p>因此是下图白线。</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206173925491.png" alt="image-20230206173925491" style="zoom: 33%;">



<p><strong>极值点的必要条件：函数f和约束c的梯度是共线的</strong> $\nabla f(\overrightarrow x)&#x2F;&#x2F; \nabla c(\overrightarrow x)$ ，即 $\nabla f(\overrightarrow x)&#x3D;\lambda \nabla c(\overrightarrow x)$ ，并且极值点要满足约束条件 $c(\overrightarrow x)&#x3D;0$ 。</p>
<p>把这样求出来的点，看成是 $f(\overrightarrow x)$ 在约束条件 $c(\overrightarrow x)&#x3D;0$ 下的<strong>驻点</strong>。</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206174803618.png" alt="image-20230206174803618" style="zoom:33%;">



<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206174945853.png" alt="image-20230206174945853" style="zoom:33%;">



<p>数值求解这个例子：</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206175120914.png" alt="image-20230206175120914" style="zoom:33%;">

<p>对应极大、极小值</p>
<p>规范定义：</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206175809428.png" alt="image-20230206175809428" style="zoom:33%;">



<p>证明：</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206175544109.png" alt="image-20230206175544109" style="zoom:33%;">





<p>推广到高维空间：</p>
<p>垂直于所有的 $\nabla c$ 张成的空间。</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206180015200.png" alt="image-20230206180015200" style="zoom:33%;">





<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206180056362.png" alt="image-20230206180056362" style="zoom:33%;">



<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206180117641.png" alt="image-20230206180117641" style="zoom:33%;">





<h2 id="题目求解"><a href="#题目求解" class="headerlink" title="题目求解"></a>题目求解</h2><blockquote>
<p>b站 <a href="https://www.bilibili.com/video/BV1mF411h7vf/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">弱爆了，拉格朗日乘子法还不会解吗，学会这个直接送你12分，2022考研数学</a></p>
</blockquote>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206180352859.png" alt="image-20230206180352859" style="zoom:50%;">



<h4 id="解法1："><a href="#解法1：" class="headerlink" title="解法1："></a>解法1：</h4><p>找到有规律的方程，做加减运算，因式分解，讨论里面的因子。</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206181217210.png" alt="image-20230206181217210" style="zoom:50%;">

<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206181106168.png" alt="image-20230206181106168" style="zoom: 45%;">



<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206181403626.png" alt="image-20230206181403626" style="zoom:50%;">



<h4 id="解法2："><a href="#解法2：" class="headerlink" title="解法2："></a>解法2：</h4><p>消元，把 $\lambda$ 约掉。</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206181626968.png" alt="image-20230206181626968" style="zoom: 50%;">



<h4 id="解法3："><a href="#解法3：" class="headerlink" title="解法3："></a>解法3：</h4><p><strong>方法3适用于 目标函数是二次型、约束条件是二次型。</strong></p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206181924126.png" alt="image-20230206181924126" style="zoom:50%;">

<p>函数有非零解，通过行列式等于0，可以求出 $\lambda$ 的表达式，带入 f 函数，得到最大最小值：</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206182003613.png" alt="image-20230206182003613" style="zoom:50%;">







<p>方法3，在更一般的式子下举例：</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206183843154.png" alt="image-20230206183843154" style="zoom:50%;">



<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206183934214.png" alt="image-20230206183934214" style="zoom:50%;">

<p>再把 $L_x$ ，$L_y$ 有非零解，写出来。</p>
<img src="/2023/02/06/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/image-20230206184300534.png" alt="image-20230206184300534" style="zoom:50%;">

]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>拉格朗日插值法</title>
    <url>/2023/02/07/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E6%8F%92%E5%80%BC%E6%B3%95/</url>
    <content><![CDATA[<h1 id="拉格朗日插值法"><a href="#拉格朗日插值法" class="headerlink" title="拉格朗日插值法"></a>拉格朗日插值法</h1><blockquote>
<p>b站：【<a href="https://www.bilibili.com/video/BV1fL4y1T7fL/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">拉格朗日插值】：思想、计算与误差</a></p>
</blockquote>
<p>拉格朗日插值法是一种数学插值方法，<strong>用于确定一个函数在给定点外的值</strong>。这种方法通过在已知点上构造拉格朗日插值多项式来确定该函数的值。</p>
<p>拉格朗日插值法用于解决在没有足够的数学模型的情况下预测函数值的问题，或对具有随机误差的数据进行拟合的问题。它在统计学，工程，物理和生物学等领域都有广泛的应用。</p>
<p>拉格朗日插值法是一种简单易用的插值方法，但它有一个缺点：当数据点数量很大时，拉格朗日插值多项式的计算可能会非常复杂，并且在某些情况下，结果可能不准确。因此，在实际应用中，有时会选择更复杂但更准确的插值方法。</p>
<p>给定5个点，有唯一的4次多项式穿过它们。如何寻找该多项式？</p>
<ol>
<li>待定系数法</li>
</ol>
<p>写出y的形式，有待定的系数，然后带入5个点。<br>$$<br>\begin{aligned}<br>&amp; y&#x3D;a_0+a_1 x+a_2 x^2+a_3 x^3+a_4 x^4: \<br>&amp;<br>\end{aligned}<br>$$<br>带入5个点：<br>$$<br>\left{<br>\begin{aligned}<br> -1&amp;&#x3D;a_0+a_1(-3)+a_2(-3)^2+a_3(-3)^3+a_4(-3)^4 \<br> 1&amp;&#x3D;a_0+a_1(-2)+a_2(-2)^2+a_3(-2)^3+a_4(-2)^4 \<br> -0.5&amp;&#x3D;a_0+a_1 \quad(0)+a_2 \quad(0)^2+a_3\quad(0)^3+a_4 \quad(0)^4 \<br> 0&amp;&#x3D;a_0+a_1 \quad(1)+a_2 \quad(1)^2+a_3 \quad(1)^3+a_4 \quad(1)^4 \<br> 1.5&amp;&#x3D;a_0+a_1 \quad(3)+a_2\quad(3)^2+a_3\quad(3)^3+a_4 \quad(3)^4 \</p>
<p>\end{aligned}<br>\right.<br>$$<br>写成矩阵乘法的形式<br>$$<br>\left[\begin{array}{c}<br>-1.0 \<br>1.0 \<br>-0.5 \<br>0.0 \<br>1.5<br>\end{array}\right]&#x3D;\left[\begin{array}{ccccc}<br>1 &amp; -3 &amp; (-3)^2 &amp; (-3)^3 &amp; (-3)^4 \<br>1 &amp; -2 &amp; (-2)^2 &amp; (-2)^3 &amp; (-2)^4 \<br>1 &amp; 0 &amp; 0^2 &amp; 0^3 &amp; 0^4 \<br>1 &amp; 1 &amp; 1^2 &amp; 1^3 &amp; 1^4 \<br>1 &amp; 3 &amp; 3^2 &amp; 3^3 &amp; 3^4<br>\end{array}\right]\left[\begin{array}{c}<br>a_0 \<br>a_1 \<br>a_2 \<br>a_3 \<br>a_4<br>\end{array}\right]<br>$$<br>其中，这个系数矩阵，叫“范德蒙矩阵（vandermonde matrix）”</p>
<p>当数据点很多时，解这个方程运算量很大。于是引入拉格朗日插值法。</p>
<ol start="2">
<li>拉格朗日插值法</li>
</ol>
<p>多项式全体可以构成线性空间。而其中的部分多项式，比如P3，是次数不超过3（小于等于3）多项式全体构成的空间，P3的维度是4，因为 $1$，$x$，$x^2$，$x^3$，就给出了一组<strong>基</strong>（单项式基 monomial basis）。任何在P3中的多项式，都可以写成这些基的线性组合。</p>
<p>拉格朗日插值，就是把多项式写在一组特殊的基下，它们被称为拉格朗日基函数。</p>
<p>所以我们想求过5个点的拉格朗日基函数，用五个拉格朗日基函数表示（函数是4次多项式），认为第1个基函数，它在第1个点函数值为1（函数值不一定要经过第1个点（和第1个重合）），经过其它4个点时，函数值为0；认为第2个基函数，它在第2个点函数值为1，经过其它4个点时，函数值为0；……以此类推。因此对这五个函数进行伸缩变换，也就是乘一个常数（观测值，也就是5个点的值），就可以经过那5个点，经过变换后的五个基函数加起来，就是我们想要的多项式（4次多项式）。</p>
<img src="/2023/02/07/%E6%95%B0%E5%AD%A6/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E6%8F%92%E5%80%BC%E6%B3%95/image-20230207094409750.png" alt="image-20230207094409750" style="zoom: 25%;">



<p>任务是找到这样的n次多项式p，它在 $x_0$ 到 $x_n$ 这 n+1 个节点处，取值分别是 $y_0$ 到 $y_n$ ：<br>$$<br>p_n\left(x_0\right)&#x3D;y_0, p_n\left(x_1\right)&#x3D;y_1, \ldots, p_n\left(x_n\right)&#x3D;y_n<br>$$</p>
<p>把p写成拉格朗日基函数的线性组合：<br>$$<br>p_n(x)&#x3D;y_0 l_0(x)+y_1 l_1(x)+\cdots+y_n l_n(x)&#x3D;\sum_{j&#x3D;0}^ny_jl_j(x)<br>$$<br>用 $l$ 表示拉格朗日基函数，其中，$l_0$ 只在 $x_0$ 处取1，而在 $x_1$ 到 $x_n$ 处取零，。。。以此类推。<br>$$<br>\begin{aligned}<br>&amp; p_n(x)&#x3D;y_0 \underbrace{l_0(x)}<em>{l_0\left(x_0\right)&#x3D;1,l_0(x_i)&#x3D;0}+y_1 \underbrace{l_1(x)}</em>{l_1\left(x_1\right)&#x3D;1,l_1(x_i)&#x3D;0}+\cdots+y_n \underbrace{l_n(x)}_{l_n\left(x_n\right)&#x3D;1,l_n(x_i)&#x3D;0} \<br>&amp; \begin{array}{lll}<br>\end{array} \<br>&amp;<br>\end{aligned}<br>$$<br>因此，现在的问题简化成了找基函数 $l$。</p>
<p>以第2个基函数 $l_1$ 为例，基函数在第2个点值为1，其它4个点值为0，基函数是4次多项式，有4个根，分别是其它4个点所在位置。</p>
<p>因此第2个基函数的表达式为：$l_1(x)&#x3D;c(x-x_0)(x-x_2)(x-x_3)(x-x_4)$</p>
<p>而经过第2个点，代入：$l_1(1)&#x3D;1$  ，所以 $\large c&#x3D;\frac{1}{(x_1-x_0)(x_1-x_2)(x_1-x_3)(x_1-x_4)}$</p>
<p>所以表达式为 $\large l_1(x)&#x3D;\frac{(x-x_0)(x-x_2)(x-x_3)(x-x_4)}{(x_1-x_0)(x_1-x_2)(x_1-x_3)(x_1-x_4)}$</p>
<p>更一般的拉格朗日基函数表达式：<br>$$<br>l_j(x)&#x3D;\prod_{k&#x3D;0, k \neq j}^n \frac{x-x_k}{x_j-x_k}<br>$$<br>牛呀！</p>
<p>这样就可以写出各个拉格朗日基函数了！也就可以写出最终的表达式了！</p>
<p>这个方法构造性地证明了：过n+1个点（横坐标互异）确定了唯一的不超过n次的多项式 $p_n$ 。（这个结论也可以通过范德蒙矩阵的可逆性证明。）</p>
<p>拉格朗日插值法存在的问题：</p>
<ol>
<li>$O(n^2)$次加法和乘法（基函数表达式n方乘法、p表达式n次求和）。</li>
<li>加入新点要重新计算。</li>
</ol>
<h3 id="改进拉格朗日插值法"><a href="#改进拉格朗日插值法" class="headerlink" title="改进拉格朗日插值法"></a>改进拉格朗日插值法</h3><p>引入节点函数 $l(x)$，$l(x)&#x3D;(x_1-x_0)(x_1-x_1)\cdots(x-x_n)$ ，因此上式中的 $\large l_j(x)&#x3D;\frac{\prod_{k&#x3D;0, k \neq j}^n x-x_k}{\prod_{k&#x3D;0, k \neq j}^n x_j-x_k}$ ，分子只缺少 $(x-x_j)$ 这一项， 因此写成 $\large \frac{l(x)}{x-x_j}$ ，分母是求出来是一个常数（与x无关），因此用权重 $w_j$ 代替，$\large w_j&#x3D;\frac{1}{\prod_{k&#x3D;0, k \neq j}^n x_j-x_k}$。</p>
<p>因此 $\large l_j(x)&#x3D;w_j\cdot \frac{l(x)}{x-x_j}$ 。代入到 $p(x)$ 中：<br>$$<br>\begin{aligned}<br>\large p(x)&amp;&#x3D;\sum_{j&#x3D;0}^ny_jl_j(x) \<br>&amp;&#x3D;\sum_{j&#x3D;0}^n w_j\cdot \frac{l(x)}{x-x_j}y_j \<br>&amp;&#x3D;l(x)\sum_{j&#x3D;0}^n \frac{w_j}{x-x_j}y_j \<br>&amp;&#x3D;\frac{l(x)\sum_{j&#x3D;0}^n \frac{w_j}{x-x_j}y_j}{\sum_{j&#x3D;0}^nl_j(x)}\<br>&amp;&#x3D;\frac{l(x)\sum_{j&#x3D;0}^n \frac{w_j}{x-x_j}y_j}{\sum_{j&#x3D;0}^nw_j\cdot \frac{l(x)}{x-x_j}}\<br>&amp;&#x3D;\frac{\sum_{j&#x3D;0}^n \frac{w_j}{x-x_j}y_j}{\sum_{j&#x3D;0}^n \frac{w_j}{x-x_j}}<br>\end{aligned}<br>$$</p>
<p>第三行提出l(x)到前面；第四行除以一个“1”，也就是基函数的和；第六行消掉分子分母同时出现的l(x)，最后得到：<br>$$<br>p(x)&#x3D;\frac{\sum_{j&#x3D;0}^n \frac{w_j}{x-x_j}y_j}{\sum_{j&#x3D;0}^n \frac{w_j}{x-x_j}}<br>$$<br>称为<strong>质心公式</strong>（barycentric formula）。</p>
<p>举例：</p>
<p>给定四个点 $(-1,1)(0,2)  \left(\frac{1}{2}, 3\right)(1,4)$ ，则质心形式的拉格朗日插值表达式为：</p>
<p>$$</p>
<p>p(x) &#x3D;\frac{\frac{-\frac{1}{3}}{x+1} \cdot 1+\frac{2}{x-0} \cdot 2+\frac{-\frac{8}{3}}{x-\frac{1}{2}} \cdot 3+\frac{1}{x-1} \cdot 4}{\frac{-\frac{1}{3}}{x+1}+\frac{2}{x-0}+\frac{-\frac{8}{3}}{x-\frac{1}{2}}+\frac{1}{x-1}}<br>$$<br>运算量主要在计算权重上，而这些权重不随x变换，只需要计算一次，之后每给定一个x，估值的计算量是 $O(n)$级别。如果增加新的点，也就在估计权重，计算量也比之前减少了。</p>
<p>。。。后面听不懂了。。TODO</p>
<p>待看：b站 <a href="https://www.bilibili.com/video/BV1TR4y1j745/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">【拉格朗日插值法的本质】拉格朗日，孙子，与每个人都能推出来的插值法</a></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>Binarized Neural Networks Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</title>
    <url>/2023/04/28/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Binarized%20Neural%20Networks%20Training%20Deep%20Neural%20Networks%20with%20Weights%20and%20Activations%20Constrained%20to%20+1%20or%20-1/</url>
    <content><![CDATA[<h1 id="Binarized-Neural-Networks-Training-Deep-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-1"><a href="#Binarized-Neural-Networks-Training-Deep-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-1" class="headerlink" title="Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1"></a>Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</h1><blockquote>
<p>Courbariaux, Matthieu, et al. “Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1.” <em>arXiv preprint arXiv:1602.02830</em> (2016). citations：3011</p>
<p>github：Theano framework：<a href="https://github.com/MatthieuCourbariaux/BinaryNet">https://github.com/MatthieuCourbariaux/BinaryNet</a>  </p>
<p>github：Torch framework：<a href="https://github.com/itayhubara/BinaryNet">https://github.com/itayhubara/BinaryNet</a>  </p>
<p><a href="https://ckho.medium.com/ml-paper-challenge-day-24-binarized-neural-networks-training-deep-neural-networks-with-weights-5e9758b62b22">ML Paper Challenge Day 24 — Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1</a></p>
</blockquote>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><p>提出一种参数和激活值都是二值的、并且效果好的神经网络的可能性。它可以用于计算量少、内存小的模型上。</p>
<p>拥有一个所有权值和激活值都是二进制的神经网络的可能性。这个想法应该已经有一段时间了，但这里的突破是他们发现了一种可行的方法来训练它，而且错误率非常低，接近当时的技术水平。</p>
<h3 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h3><p>提出一种训练二值化神经网络Binarized Neural Network的方法，在训练时，使用二值化wight和激活值计算参数梯度。</p>
<p>大部分运算用位运算bit-wise operations替代（逻辑运算），特别适合在低功耗设备上运行。</p>
<h3 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h3><p>在MNIST, CIFAR-10 and SVHN 数据集上效果接近SOTA。</p>
<p>提出了一种运行在GPU上的二进制矩阵乘法，运行MNIST BNN比未优化GPU内核快7倍，并且精度不下降。</p>
<h3 id="存在哪些问题"><a href="#存在哪些问题" class="headerlink" title="存在哪些问题"></a>存在哪些问题</h3><h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><ul>
<li>介绍了一种训练二值化神经网络(bnn)的方法，推理时的模型参数、激活值是二值化的，训练时参数梯度也是用二值化的参数来计算的。</li>
<li>进行了两组实验，框架分别用的Torch7和Theano，证明了BNNs 在MNIST, CIFAR-10 and SVHN数据集上是可以训练的，效果接近SOTA。</li>
<li>证明了在训练和推理阶段，BNN能大幅度地减少内存消耗（大小、访问次数），大部分运算用位运算代替（可能大幅度降低了功耗）。</li>
<li>二值化的CNN会重复使用二值卷积核？？，作者认为专用硬件可以将时间复杂度降低60%。</li>
<li>编写了一个运行在GPU上二进制矩阵乘法，运行MNIST BNN比未优化GPU内核快7倍，并且精度不下降。</li>
</ul>
<h2 id="Binarized-Neural-Networks"><a href="#Binarized-Neural-Networks" class="headerlink" title="Binarized Neural Networks"></a>Binarized Neural Networks</h2><p>基于二值化可以随机进行，或者近似为随机噪声的思想。</p>
<h3 id="Deterministic-vs-Stochastic-Binarization"><a href="#Deterministic-vs-Stochastic-Binarization" class="headerlink" title="Deterministic vs Stochastic Binarization"></a>Deterministic vs Stochastic Binarization</h3><p>想weight和激活值限制为1或-1，就需要找transform方法，将真实值transform到这两个值，transform方法称为binarization function，二值化函数。</p>
<p>第一种二值化函数（deterministic）：<br>$$<br>x^b&#x3D;\operatorname{Sign}(x)&#x3D; \begin{cases}+1 &amp; \text { if } x \geq 0 \ -1 &amp; \text { otherwise }\end{cases}<br>$$<br>其中，Sign是符号函数， $x^b$ 是二值化后的参数 （weight 或 activation）， $x$ 是二值化前的真实值参数。很hard。</p>
<p>第二种二值化函数（stochastic）：<br>$$<br>x^b&#x3D; \begin{cases}+1 &amp; \text { with probability } p&#x3D;\sigma(x), \ -1 &amp; \text { with probability } 1-p,\end{cases}<br>$$<br>其中，$\sigma$ 是 “hard sigmoid” 函数：<br>$$<br>\sigma(x)&#x3D;\operatorname{clip}\left(\frac{x+1}{2}, 0,1\right)&#x3D;\max \left(0, \min \left(1, \frac{x+1}{2}\right)\right)<br>$$<br>举个例子：</p>
<p>x&#x3D;0，   则二值化后等于1的概率是0.5，二值化后等于-1的概率是0.5，都有可能；</p>
<p>x&#x3D;0.2，则二值化后等于1的概率是0.6，二值化后等于-1的概率是0.4；</p>
<p>x&gt;&#x3D;1，则二值化后等于1的概率是1，二值化后等于-1的概率是0，确定是1；</p>
<p>x&#x3D;-0.2，则二值化后等于1的概率是0.4，二值化后等于-1的概率是0.6；</p>
<p>x&lt;&#x3D;-1，则二值化后等于1的概率是0，二值化后等于-1的概率是1，确定是-1；</p>
<p>随机二值化比符号函数更更合理些，但更难实现，因为它需要硬件在量化时生成随机比特。因此，大多使用确定性二值化函数（即符号函数），除了训练过程中的激活值（用随机二值化）。</p>
<p><strong>训练bnn的方法可以看作是Dropout的一种变体，在计算参数梯度时，我们不是将一半的激活值随机设置为零，而是将激活值和权重都二值化。</strong></p>
<h3 id="Gradient-Computation-and-Accumulation"><a href="#Gradient-Computation-and-Accumulation" class="headerlink" title="Gradient Computation and Accumulation"></a>Gradient Computation and Accumulation</h3><h3 id="Propagating-Gradients-Through-Discretization"><a href="#Propagating-Gradients-Through-Discretization" class="headerlink" title="Propagating Gradients Through Discretization"></a>Propagating Gradients Through Discretization</h3><p>straight-through estimator（STE）：用于梯度无穷大（比如sign函数）时梯度计算的问题，方法就是通过一个阈值，比阈值大认为梯度为1，比阈值小认为梯度为0。</p>
<img src="/2023/04/28/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Binarized%20Neural%20Networks%20Training%20Deep%20Neural%20Networks%20with%20Weights%20and%20Activations%20Constrained%20to%20+1%20or%20-1/image-20230428143844153.png" alt="image-20230428143844153" style="zoom:80%;">



<p>其中，$1_{|r|}\le 1$  是hard tanh，分段线性激活函数：<br>$$<br>Htanh(x) &#x3D; Clip(x, −1, 1) &#x3D; \max(−1, \min(1, x))<br>$$<br>提出hard tanh是由于 sign(⋅) 的导数（几乎）处处为零，因此，W 通过 BP 得到的误差 ΔW 为零 ，因此不能直接用来更新权值。</p>
<p>为解决这个问题采用 <strong>straight-through estimator</strong>的方法，该方法其实是一种妥协方法，将sign(x)进行宽松。这样，函数就变成可以求导的了，求导近似函数如下，其实就是在-1和1之间加一个线性变化过程。</p>
<p>算法1流程可以看出，计算梯度时计算的是二值化的参数梯度，但是参数更新时更新的是实值（浮点值）参数，用二值化梯度更新实值参数。</p>
<img src="/2023/04/28/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Binarized%20Neural%20Networks%20Training%20Deep%20Neural%20Networks%20with%20Weights%20and%20Activations%20Constrained%20to%20+1%20or%20-1/image-20230428144803992.png" alt="image-20230428144803992" style="zoom:80%;">

<p>其中，AP2(X)函数求的是与X最接近的2的幂次方。AP2(3.14)&#x3D;4；AP2(2.5)&#x3D;2。&lt;&lt;&gt;&gt;符号代表的位左移和位右移，利用位移优化乘法操作。</p>
<h3 id="Shift-based-Batch-Normalization-基于移位的BN"><a href="#Shift-based-Batch-Normalization-基于移位的BN" class="headerlink" title="Shift based Batch Normalization  基于移位的BN"></a>Shift based Batch Normalization  基于移位的BN</h3><p>BN需要多次乘法（计算标准差并除以），即除以运行方差（训练集激活方差的加权均值）。而基于移位的BN (SBN)，几乎无需乘法即可近似 BN。</p>
<img src="/2023/04/28/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Binarized%20Neural%20Networks%20Training%20Deep%20Neural%20Networks%20with%20Weights%20and%20Activations%20Constrained%20to%20+1%20or%20-1/image-20230428124418819.png" alt="image-20230428124418819" style="zoom:80%;">

<h3 id="Shift-based-AdaMax"><a href="#Shift-based-AdaMax" class="headerlink" title="Shift based AdaMax"></a>Shift based AdaMax</h3><p>ADAM优化算法，ADAM 需要多次乘法 -&gt; 基于移位的 AdaMax</p>
<p>ADAM利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。Adam的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。同样利用<strong>位移</strong>优化乘法操作。</p>
<img src="/2023/04/28/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Binarized%20Neural%20Networks%20Training%20Deep%20Neural%20Networks%20with%20Weights%20and%20Activations%20Constrained%20to%20+1%20or%20-1/image-20230428141815476.png" alt="image-20230428141815476" style="zoom:80%;">

<h3 id="First-Layer"><a href="#First-Layer" class="headerlink" title="First Layer"></a>First Layer</h3><p>在一个BNN中，所有的计算中只使用权值和激活值的二值化值。由于一层的输出是下一层的输入，所以除了第一层之外，所有层的输入都是二进制的。</p>
<p>第一层输入不是二进制也没关系，因为卷积网络的第一层通常是最小的卷积层，无论是在参数方面还是在计算方面。比如图像领域的第一层的输入的channel是3（RGB），但是输出的channel是比如512，因此输入的参数相比于其他层的输入参数来说是很小的。</p>
<p>其次，将连续值输入处理为定点数相对容易，精度为m位。例如，在8位定点输入的常见情况下：<br>$$<br>s&#x3D;x\cdot w^b<br>$$</p>
<p>$$<br>s&#x3D;\sum_{n&#x3D;1}^82^{n-1}(x^n\cdot w^b)<br>$$</p>
<p>其中，$x$ 是1024维的8bit输入，$x_1^8$ 是第一层输入的最高有效位，$w^b$ 是1024维的1-bit weight，$s$是weight sum。trick见algorithm 5：</p>
<p><strong>用位运算代替大部分计算</strong>。</p>
<p>由于图像像素值分布在[0,255]之间，所以可以用8比特来表示，这样就能将输入的实值像素值变成二值化的编码了。整体BNN的流程如下，将乘法运算都变成了XNOR运算，因此运算很快。</p>
<img src="/2023/04/28/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Binarized%20Neural%20Networks%20Training%20Deep%20Neural%20Networks%20with%20Weights%20and%20Activations%20Constrained%20to%20+1%20or%20-1/image-20230428141832586.png" alt="image-20230428141832586" style="zoom:80%;">

<blockquote>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/59202590">二值化神经网络(Binarized Neural Networks, BNN)模型解读</a></p>
<p>csdn：<a href="https://blog.csdn.net/linmingan/article/details/51008830/">深度学习【6】二值网络（Binarized Neural Networks）学习与理解</a></p>
</blockquote>
<p>举个例子说明：假设某一层隐藏层的激活向量二值化后a&#x3D;[1,-1, 1, 1, -1]，同时又有二值化后的权值W&#x3D;[-1,1,1,-1,-1]。在程序中是以a&#x3D;[1,0,1,1,0],W&#x3D;[0,1,1,0,0]表示的。</p>
<p>那么按照正常的乘法应该是：$a1<em>w1+a2</em>w2+a3<em>w3+a4</em>w4+a5<em>w5&#x3D;1</em>-1+-1<em>1+1</em>1+1*-1+-1*-1&#x3D;-1$;</p>
<p>按照作者给出的操作应该是：$a^W&#x3D;[1^0,0^1,1^1,1^0,0^0]&#x3D;11010，popcount(a^w)&#x3D;3$ （popcount的意思是计算一串二进制串中有多少个1）</p>
<p>然后使用$-(2  popcount(a^w) - len(vecor_length))$，这里vector_length &#x3D; 5,因此，最后的结果是-1，与我们直接对a和w做乘加运算的结果相同。</p>
<p>没看懂。。。。。。。。。。。。。</p>
<h2 id="他人小结"><a href="#他人小结" class="headerlink" title="他人小结"></a>他人小结</h2><blockquote>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/24679842">《Binarized Neural Networks: Neural Networks with Weights Constrained to +1 or −1 》阅读笔记</a></p>
</blockquote>
<ol>
<li>在小型任务上，BinaryNet 完全有希望满足精度要求。且将网络应用到移动平台上</li>
<li>BNN除了在训练过程需要保存实值参数外，在预测阶段只需要存储二值化参数，降低了在模型部署的参数存储，但是对于前馈过程，依旧需要进行相同层数的计算，只是整数的乘法相比浮点数的乘法速度更快，所以有优化提高但是优化结果并不明显。</li>
<li>BinaryNet 的训练不太稳定，需要较小的学习率，收敛速度明显慢于实值网络，如果学习率高了容易造成网络震荡。</li>
</ol>
]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Compression Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</title>
    <url>/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Deep%20Compression%20Compressing%20Deep%20Neural%20Networks%20with%20Pruning,%20Trained%20Quantization%20and%20Huffman%20Coding/</url>
    <content><![CDATA[<h1 id="Deep-Compression-Compressing-Deep-Neural-Networks-with-Pruning-Trained-Quantization-and-Huffman-Coding"><a href="#Deep-Compression-Compressing-Deep-Neural-Networks-with-Pruning-Trained-Quantization-and-Huffman-Coding" class="headerlink" title="Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding"></a>Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</h1><blockquote>
<p>Han, Song, Huizi Mao, and William J. Dally. “Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding.” <em>arXiv preprint arXiv:1510.00149</em> (2015). 作者 韩松；citations：8368；ICLR2016 best paper</p>
<p>github：<a href="https://github.com/songhan/Deep-Compression-AlexNet">https://github.com/songhan/Deep-Compression-AlexNet</a></p>
</blockquote>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><p>模型量化可以缓解现有神经网络参数量大、计算量大、内存占用多、无法用在端侧等问题。本文提出一种量化方法，能减小、压缩模型参数。</p>
<h3 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h3><p>使用k-mean聚类，让相近的数值聚类到同一个聚类中心，复用同一个数值，从而达到用更少的数值表示更多的数。</p>
<p>提出三步走的pipeline：1. pruning；2. trained quantization；3. Huffman coding；</p>
<h3 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h3><p>神经网络storage减少到35倍到49倍。（不用存那么大参数量了）。其中，剪枝可以将参数大小减少9倍到13倍；量化把表示每个connection所需要的bit从32降到5，参数大小减少到27倍到31倍（包含剪枝）；再引入哈夫曼编码，将参数大小减少到35倍到49倍。</p>
<p>图像数据集ImageNet dataset来说，AlexNet模型的storage减少了35倍，从240MB到6.9MB，并且acc保持不变。VGG-16模型的storage减少了49倍，从552MB到11.3MB，acc保持不变。因此可以把模型放进片上SRAM  cache了，不需要只能放在片外DRAM memory了。</p>
<p>能有3到4倍的<strong>加速</strong>、3到7倍的功耗节省。</p>
<h3 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h3><h2 id="名词"><a href="#名词" class="headerlink" title="名词"></a>名词</h2><ul>
<li>codebook：量化后的effective weights</li>
<li>connections：其实就是神经元neuron</li>
</ul>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>分析不压缩模型的问题：</p>
<ul>
<li><strong>功耗 Energy consumption</strong>：造成功耗最主要的是来自“向内存访问数据”memory access，读数据是最造成功耗的，比如32bit 浮点计算一个加法花费0.9p焦耳，在32bit SRAM cache里读数据要花费5pJ，但是在32bit DRAM  memory里读数据要花费640pJ！可以看出数据如果能存在cache里好处多多。比如模型的fps（每秒处理帧数，衡量模型实时性）为20，模型连接数为1百万个，如果数据是放在memory上，则每秒的功耗为 $20<em>1G</em>640pJ&#x3D;12.8W$ ，功耗12.8瓦，手机上带不起来。</li>
</ul>
<p>第一步：模型剪枝 prune，只保留重要的connections；</p>
<p>第二步：量化quantize weight，量化后权重可以共享（只保留质心quantized centroids）。</p>
<p>第三步：重训、finetune模型，然后用哈夫曼编码Huffman coding，压缩。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Deep%20Compression%20Compressing%20Deep%20Neural%20Networks%20with%20Pruning,%20Trained%20Quantization%20and%20Huffman%20Coding/image-20230425155847547.png" alt="image-20230425155847547" style="zoom: 67%;">



<h3 id="NETWORK-PRUNING"><a href="#NETWORK-PRUNING" class="headerlink" title="NETWORK PRUNING"></a>NETWORK PRUNING</h3><p>从上图的左边的pruning阶段可以看出，其过程是：</p>
<ol>
<li>正常的训练一个网络；</li>
<li>把一些权值很小的连接进行剪枝：通过一个阈值来剪枝；</li>
<li>retrain 这个剪完枝的稀疏连接的网络；</li>
</ol>
<p>剪枝后的稀疏结构，用compressed sparse row (CSR) 或compressed sparse column (CSC)  来保存。requires 2a + n + 1 numbers, where a is the number of non-zero elements and n is the number of rows or columns.  </p>
<p>为了进一步压缩，对于weight的index（用index保存的话index的长度就是weight数组prune前实际的长度），不再存储绝对位置的index，而是<strong>存储跟上一个有效weight的相对位置</strong>，这样index的字节数就可以被压缩了。</p>
<p>论文中，对于卷积层用 8bits 来保存这个相对位置的index，在全连接层中用 5bits 来保存；</p>
<p>下图是以用3bits保存相对位置为例子，当相对位置超过8（3bits）的时候，需要在相对位置为8的地方填充一个0，防止溢出；</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Deep%20Compression%20Compressing%20Deep%20Neural%20Networks%20with%20Pruning,%20Trained%20Quantization%20and%20Huffman%20Coding/image-20230425162535032.png" alt="image-20230425162535032" style="zoom: 80%;">





<h3 id="TRAINED-QUANTIZATION-AND-WEIGHT-SHARING"><a href="#TRAINED-QUANTIZATION-AND-WEIGHT-SHARING" class="headerlink" title="TRAINED QUANTIZATION AND WEIGHT SHARING"></a>TRAINED QUANTIZATION AND WEIGHT SHARING</h3><p>通过让多个连接共享相同的weight来限制需要存储的有效weight的数量，然后对这些共享的weight进行finetune训练。</p>
<p>Weight sharing ：</p>
<p>假设有4个input neuron，4个output neuron，weight是 4 * 4的矩阵。左下角是weight数值，左下角是梯度矩阵（loss对当前weight的梯度），weight量化成4类（bin）（用4种颜色表示），处在相同类的weight共享、使用同一个值，因此对于weight矩阵来说，就不用存这个weight矩阵，而是存类别矩阵（a small <strong>index</strong> into a table of shared weights），然后再存一个类中心值的table。</p>
<p>做参数更新时，做法是把同一类的所有梯度加起来，乘以学习率，然后对应类的类中心值减去该值，得到新一轮的类中心。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Deep%20Compression%20Compressing%20Deep%20Neural%20Networks%20with%20Pruning,%20Trained%20Quantization%20and%20Huffman%20Coding/image-20230425162552540.png" alt="image-20230425162552540" style="zoom:80%;">

<p>对于AlexNet，卷积层quantization到8bits（256个共享权值），而全连接层quantization到5bits（32个共享权值），并且这样压缩之后的网络没有降低准确率。</p>
<p><strong>压缩率compression rate的计算</strong>：假设有$k$ 类，则只需要 $\log_2(k)$ bit来表示。网络有$n$个神经元，每个神经元用$b$个bit表示，限制只有$k$个共享weight，则压缩率为：<br>$$<br>r&#x3D;\frac{nb}{n\log_2(k)+kb}<br>$$<br>分子：量化前所需的bit：原本的n个神经元b个bit，需要 $nb$ 个bit来保存；</p>
<p>分母：量化后所需的bit：cluster index表所需要的bit（$n\log_2(k)$）加上centroids表所需要的bit（$kb$）</p>
<h4 id="WEIGHT-SHARING"><a href="#WEIGHT-SHARING" class="headerlink" title="WEIGHT SHARING"></a>WEIGHT SHARING</h4><p>每个神经元所属哪类，是通过kmeans确定的，离哪个类中心就属于哪类，然后类中心是参数更新确定的。kmeans的目标函数是最小化within-cluster sum of squares (WCSS)，簇内L2距离：<br>$$<br>\arg\min\sum_{i&#x3D;1}^k\sum_{w\in c_i}|w-c_i|^2<br>$$</p>
<h4 id="INITIALIZATION-OF-SHARED-WEIGHTS"><a href="#INITIALIZATION-OF-SHARED-WEIGHTS" class="headerlink" title="INITIALIZATION OF SHARED WEIGHTS"></a>INITIALIZATION OF SHARED WEIGHTS</h4><p>kmeans的类中心的初始化值会影响聚类结果，从而影响网络预测精度，作者测试了三种初始化方法：</p>
<ol>
<li>**Forgy(random)**：从数据集weight随机选k个观测值，作为初始类中心。</li>
<li><strong>density-based</strong>：将weight的分布函数在y轴上线性间隔，这种方法使两个峰周围的类中心密度更大，但比Forgy方法更分散</li>
<li><strong>linear initialization</strong>：在原始weight的[min, max]之间线性间隔类中心。与前两种初始化方法相比，该初始化方法对权值的分布是不变的，并且是最分散的。</li>
</ol>
<p>CDF：原始的weight的累积分布函数；PDF：原始的weight的概率密度函数；三种不同初始化类中心weight分布情况。如下图所示。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Deep%20Compression%20Compressing%20Deep%20Neural%20Networks%20with%20Pruning,%20Trained%20Quantization%20and%20Huffman%20Coding/image-20230425222128767.png" alt="image-20230425222128767" style="zoom: 67%;">

<p>之前的文献中有这样的结论：数值大的weight比数值小的weight更重要，但是数量更少，因此从概率密度函数来看，分布得多的那些weight，都是不重要的weight。因此从这样的概率密度分布中采样，很容易采样出不重要的weight（Forgy、density-based初始化方法）。</p>
<p>因此，最好的初始化方式是 <strong>linear initialization</strong>！</p>
<h4 id="FEED-FORWARD-AND-BACK-PROPAGATION"><a href="#FEED-FORWARD-AND-BACK-PROPAGATION" class="headerlink" title="FEED-FORWARD AND BACK-PROPAGATION"></a>FEED-FORWARD AND BACK-PROPAGATION</h4><p>在前向和反向传播阶段有间接的weight查找表（looking up the weight table），每个神经元放的是共享权重表的index。</p>
<p>反向传播时，对每个共享权重计算梯度，然后梯度更新，更新这个共享权重值。</p>
<p>梯度计算，属于同一类的梯度求和，公式为：<br>$$<br>\frac{\partial \mathcal{L}}{\partial C_k}&#x3D;\sum_{i, j} \frac{\partial \mathcal{L}}{\partial W_{i j}} \frac{\partial W_{i j}}{\partial C_k}&#x3D;\sum_{i, j} \frac{\partial \mathcal{L}}{\partial W_{i j}} \mathbb{1}\left(I_{i j}&#x3D;k\right)<br>$$</p>
<h4 id="HUFFMAN-CODING"><a href="#HUFFMAN-CODING" class="headerlink" title="HUFFMAN CODING"></a>HUFFMAN CODING</h4><p>哈夫曼编码是一种最优前缀码prefix code的方法，无损压缩。它使用可变长codeword码字对源符号进行编码。该表来自每个符号的出现概率不同。更常见的符号用更少的比特表示。</p>
<p>下图是 AlexNet模型中，最后一个全连接层的量化weight的概率分布和稀疏矩阵index。</p>
<p>下图有32个类中心weight，大多数量化的weight分布在两个峰周围，出现频率不是很均匀，不同类中心的频率差距很大，因此可以根据出现频率用哈夫曼编码。</p>
<p>稀疏矩阵index的diff很少大于20。不同index的出现频率也是差距很大，也可以用哈夫曼编码。</p>
<p>实验表明，哈夫曼编码这些非均匀分布的值节省了20% ~ 30%的模型存储。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Deep%20Compression%20Compressing%20Deep%20Neural%20Networks%20with%20Pruning,%20Trained%20Quantization%20and%20Huffman%20Coding/image-20230425222153365.png" alt="image-20230425222153365" style="zoom:67%;">





<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>TODO</p>
<h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>模型参数量、存储空间压缩的流程为：剪枝、retrain更新迭代 –&gt; kmeans共享权重 量化、更新迭代、存储weight的index结构采用index的diff来存储 –&gt;  哈夫曼编码非均匀分布的weight和index，进一步压缩存储。能够压缩模型所需的存储空间，还能加速，因为模型小了，能放在cache了（模型大的话只能放在memory上），因此相当于减少了功耗。</p>
]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>Knowledge Distillation 视频 李宏毅助教</title>
    <url>/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/</url>
    <content><![CDATA[<h1 id="Knowledge-Distillation-视频-李宏毅助教"><a href="#Knowledge-Distillation-视频-李宏毅助教" class="headerlink" title="Knowledge Distillation 视频 李宏毅助教"></a>Knowledge Distillation 视频 李宏毅助教</h1><blockquote>
<p>PPT：<a href="https://slides.com/arvinliu/model-compression">https://slides.com/arvinliu/model-compression</a></p>
<p>视频：<a href="https://www.bilibili.com/video/BV1JE411g7XF?p=49">P49 Network Compression (1_2) - Knowledge Distillation (选学)1:07:53</a> </p>
</blockquote>
<h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><h3 id="Network-Pruning"><a href="#Network-Pruning" class="headerlink" title="Network Pruning"></a>Network Pruning</h3><p>方法：Network<strong>不重要</strong>的weight或neuron进行删除，再重train一次（不重train直接测试的话，效果不好，原因是模型还不适应没有那些没用的weight….要稍微重train一下）。</p>
<p>原因：&#x3D;&#x3D;<strong>大NN有很多冗参数</strong>&#x3D;&#x3D;，而小NN很难train，那就用大NN删成小NN就好了。</p>
<p>应用：只要他是NN（？）就可以。</p>
<h3 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h3><p>方法：利用一个&#x3D;&#x3D;<strong>已经学好的大model</strong>&#x3D;&#x3D;，来教小model如何做好任务。</p>
<p>原因：让学生直接做对题目太难了，可以让他偷看老师是怎么想&#x2F;解出题目的。</p>
<p>应用：通常只用在Classification，而且学生只能从头学起。</p>
<h3 id="Architecture-Design"><a href="#Architecture-Design" class="headerlink" title="Architecture Design"></a>Architecture Design</h3><p>方法：使用较少的参数来达到原本某些layer的效果。</p>
<p>原因：有些layer可能参数就是很冗，比如DNN就是个明显例子。</p>
<p>应用：就是直接套新的model，或者是利用新的layer来模拟旧的layer。</p>
<h3 id="Parameter-Quantization"><a href="#Parameter-Quantization" class="headerlink" title="Parameter Quantization"></a>Parameter Quantization</h3><p>方法：将原本NN常用的计算单位：float32&#x2F;float64压缩成更小的单位。</p>
<p>原因：对NN来说，LSB可能不是那么重要。（* LSB: Least-Significant Bit, 在这里指小数点的后面其含义。）</p>
<p>应用：对所有已经train好的model使用，或者边train边引诱model去quantize。</p>
<h3 id="Why-Learn’em-all"><a href="#Why-Learn’em-all" class="headerlink" title="Why Learn’em all?"></a>Why Learn’em all?</h3><h3 id="Mixed-it-把这些方法混合"><a href="#Mixed-it-把这些方法混合" class="headerlink" title="Mixed it !把这些方法混合"></a>Mixed it !把这些方法混合</h3><p>例如这样混合：</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421150506780.png" alt="image-20230421150506780" style="zoom: 80%;">

<h2 id="Knowledge-Distillation-1"><a href="#Knowledge-Distillation-1" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h2><h3 id="Main-Question-Distill-what"><a href="#Main-Question-Distill-what" class="headerlink" title="Main Question: Distill what?"></a><strong>Main Question: Distill what?</strong></h3><ul>
<li>Logits（输出值）<ul>
<li>直接匹配logits</li>
<li>学习一个batch里面的logits distribution</li>
<li>…</li>
</ul>
</li>
<li>Feature（中间值）<ul>
<li>直接匹配中间的Feature</li>
<li>学习Feature中间如何转换</li>
<li>…</li>
</ul>
</li>
</ul>
<h3 id="Before-Logits-KD…"><a href="#Before-Logits-KD…" class="headerlink" title="Before Logits KD…"></a>Before Logits KD…</h3><p>You need to know the magic power of soften label. 为什么知识蒸馏在logit上是有用的</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421150704117.png" alt="image-20230421150704117" style="zoom:80%;">



<p>下图的训练标签是“猫”，但这是“incompleteness”的，不完整的，因为还有球、牛仔裤等，是不完全的label。然后可能训练出来的概率是0.7是猫，0.2是球，0.1是牛仔裤，这是很好的，但是模型用的one-hot，认为猫概率要更高，就变成造成“overfit”。</p>
<p>crop是一种augment方法，是取出图片中的一个小片段。举例来说，取出一个矩形，刚好是下图的球，但是label却还是猫，这样就会让model很confuse，造成“inconsistency” 不一致。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421165548774.png" alt="image-20230421165548774" style="zoom:80%;">



<p>对于上述问题，有改进的方法，称为“&#x3D;&#x3D;label refinery&#x3D;&#x3D;” 精细化。</p>
<p>步骤：</p>
<ol>
<li>train一个model，label是groundtruth</li>
<li>train一个model，label是上一个model的输出，发现会提高accuracy</li>
<li>…..重复第2步，直到accuracy不再提高</li>
</ol>
<p><strong>label refinery可以学到label间的关系</strong></p>
<p>注意看这里，每次train的model是一样的，精度却会提高。联想到知识蒸馏，<strong>student model的上界并不是teacher model！！student model的accuracy是有机会超过teacher model的！</strong></p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421165607986.png" alt="image-20230421165607986" style="zoom:80%;">



<h2 id="Logits-Distillation"><a href="#Logits-Distillation" class="headerlink" title="Logits Distillation"></a>Logits Distillation</h2><ol>
<li><strong>baseline Knowledge Distillation</strong></li>
</ol>
<p>除以一个T，让logit不要那么激进，不要和 one-hot一样。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421165645594.png" alt="image-20230421165645594" style="zoom: 80%;">

<ol start="2">
<li><strong>mutual learning</strong></li>
</ol>
<p>train两个model，互相学习logit，当然也要学习真实label。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421165726920.png" alt="image-20230421165726920" style="zoom:80%;">

<p>第1步：先选其中一个net进行参数更新，比如net1，计算y2（teacher）对y1（student）的kl散度，计算y1和真实y的交叉熵。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421165742474.png" alt="image-20230421165742474" style="zoom:80%;">

<p>第2步：选第二个net，net2，计算y1（teacher）对y2（student）的kl散度，以及y2和真实y的交叉熵。</p>
<p>第3步：重复上述两步。</p>
<p>效果：</p>
<ul>
<li>当net1和net2的结构相同时：net1和net2都会比单独训net1或net2效果好。（类似 label refinery）</li>
<li>当net1比net2结构大、参数多时：net2会训得比单独训net2效果好，net1也不一定比单独训net1效果差（我们常规会想，net2得acc不高，net1去学，相当于teacher去学student，那应该会造成不好的影响，但实际上不一定会更差，因为net2让net1看见更丰富的东西）</li>
</ul>
<blockquote>
<p>More Details: <a href="https://slides.com/arvinliu/kd_mutual">https://slides.com/arvinliu/kd_mutual</a></p>
</blockquote>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421165804386.png" alt="image-20230421165804386" style="zoom:80%;">



<ol start="3">
<li><strong>born again 再次重生</strong></li>
</ol>
<p>Similar with label refinery很像。仅差异于：</p>
<ul>
<li>初始Model是KD来的，是训一个teacher，后面都是student。</li>
<li>born again迭代使用Cross Entropy，而label refinery使用的是kl散度。</li>
<li>最后Ensemble 所有Student Model。</li>
</ul>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421165944076.png" alt="image-20230421165944076" style="zoom:80%;">



<p>什么情况发生时，会让知识蒸馏失败or效果没有想象中的好呢：</p>
<ul>
<li>teacher模型参数、架构远大于student模型，student学不来teacher</li>
</ul>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421170023167.png" alt="image-20230421170023167" style="zoom:80%;">



<ul>
<li>解决student学不来teacher的方法：用一个参数量介于Teacher&amp;Student的TA（teacher assistant）做中间人来帮助Student学习，以此避免model差距过大学不好。</li>
</ul>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421170043641.png" alt="image-20230421170043641" style="zoom:80%;">









<h2 id="Feature-Distillation"><a href="#Feature-Distillation" class="headerlink" title="Feature Distillation"></a>Feature Distillation</h2><p>直接让student看teacher的输出，student可能无法理解，于是让student看teacher中间feature 到底在想什么。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421170244286.png" alt="image-20230421170244286" style="zoom:80%;">

<ol>
<li><strong>FitNet</strong></li>
</ol>
<p>先让Student学习如何产生Teacher的中间Feature，之后再使用Baseline KD。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421170306412.png" alt="image-20230421170306412" style="zoom:80%;">

<p>具体步骤：</p>
<p>步骤1：fit feature：选出student net前几层的输出，经过一个仿射变换（目的是变换shape），然后与teacher前几层的输出之间做MSE。</p>
<p>因此student和teacher中间的feature就有了一定关联。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421171514027.png" alt="image-20230421171514027" style="zoom:80%;">

<p>步骤2：fit logit：使用baseline kd，就是让student y学习teacher y。</p>
<p>实验小结论：teacher和student的结构越接近，效果越好。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421171540203.png" alt="image-20230421171540203" style="zoom:80%;">

<p>fitnet存在的问题：</p>
<ol>
<li>Model capacity is different 模型的性能不同，student学中间feature真的能学得会吗？（一般来说feature维度比log高，认为会更难学）</li>
<li>There’s lots of redundancy in Teacher Net. teacher模型有很多冗余。</li>
</ol>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230423133246941.png" alt="image-20230423133246941" style="zoom:80%;">



<p>解决方法：把teacher net的中间feature相成一个3维的feature map，如果有方法能做knowledge compression，压缩得更小。就能减少冗余，学到更精实的东西、并且好学一点（feature维度少一些）。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230423133319106.png" alt="image-20230423133319106" style="zoom:80%;">

<p>knowledge compression压缩方法：用<strong>attention map</strong>当作是压缩后的中间feature。</p>
<p>让teacher不同的中间层输出attention map，比如输出3张attention map，让student也输出3张attention map，让两两的attention map彼此接近。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421171705047.png" alt="image-20230421171705047" style="zoom:80%;">

<p>但是模型里面可能没有attention 层的，那么要怎么获得attention map呢：</p>
<ul>
<li>将(W, H, C)的weight各自平方后加成(W, H)的矩阵 T。（？）</li>
<li>Attention map &#x3D;T&#x2F;norm(M)。归一化一下。</li>
</ul>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421171721784.png" alt="image-20230421171721784" style="zoom:80%;">



<h3 id="Can-we-learn-something-from-batch"><a href="#Can-we-learn-something-from-batch" class="headerlink" title="Can we learn something from batch?"></a>Can we learn something from batch?</h3><p>前面讲的logit或feature都是一对一的，如何在batch里做？</p>
<h3 id="Relational-Distillation-关系上的蒸馏"><a href="#Relational-Distillation-关系上的蒸馏" class="headerlink" title="Relational Distillation 关系上的蒸馏"></a>Relational Distillation 关系上的蒸馏</h3><p>对batch里样本之间进行蒸馏</p>
<ul>
<li>Individual KD : 以每个sample为单位做知识蒸馏。</li>
<li>Relational KD: 以sample之间的关系做知识蒸馏。</li>
</ul>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421171804675.png" alt="image-20230421171804675" style="zoom:80%;">

<p>样本和样本之间的关系是某种“知识”。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421173108988.png" alt="image-20230421173108988" style="zoom:80%;">



<p>实现relational kd：</p>
<ul>
<li>Distance-wise KD 以距离为取样去蒸馏。 s1与sn的距离要接近 t1与tn的距离（L1、L2距离）</li>
<li>Angle-wise KD。以角度为取样去蒸馏。s1到si与sj的角度要接近t1到ti于tj的角度。（t13向量与t23向量的cos值，与s13向量与s23向量的cos值之间的huber损失函数）</li>
</ul>
<p>达到整个结构性的蒸馏。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421173210990.png" alt="image-20230421173210990" style="zoom:80%;">

<h3 id="Why-not-distill-relational-information-between-feature-所以feature蒸馏也同理，可以对不同样本之间feature的关系蒸馏"><a href="#Why-not-distill-relational-information-between-feature-所以feature蒸馏也同理，可以对不同样本之间feature的关系蒸馏" class="headerlink" title="Why not distill relational information between feature? 所以feature蒸馏也同理，可以对不同样本之间feature的关系蒸馏"></a>Why not distill relational information between feature? 所以feature蒸馏也同理，可以对不同样本之间feature的关系蒸馏</h3><p>Of course you can.</p>
<p>假设model中有两个feature，分别是circle和vertical line数量。feature当作是向量，计算不同样本的feature向量之间的<strong>余弦相似度</strong>。</p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421173335629.png" alt="image-20230421173335629" style="zoom:80%;">

<p>student学习teacher的<strong>cosine similarity table</strong> </p>
<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421173401192.png" alt="image-20230421173401192" style="zoom:80%;">





<img src="/2023/04/23/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Knowledge%20Distillation%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%E5%8A%A9%E6%95%99/image-20230421174538615.png" alt="image-20230421174538615" style="zoom:80%;">







<h2 id="Paper-Reference"><a href="#Paper-Reference" class="headerlink" title="Paper Reference"></a>Paper Reference</h2><ul>
<li>Knowledge Distillation<ul>
<li>Distilling the Knowledge in a Neural Network (NIPS 2014)</li>
<li>Deep Mutual Learning (CVPR 2018)</li>
<li>Born Again Neural Networks (ICML 2018)</li>
<li>Label Refinery: Improving ImageNet Classification through Label Progression</li>
<li>Improved Knowledge Distillation via Teacher Assistant (AAAI 2020)</li>
<li>FitNets : Hints for Thin Deep Nets (ICLR2015)</li>
<li>Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer (ICLR 2017)</li>
<li>Relational Knowledge Distillation (CVPR 2019)</li>
<li>Similarity-Preserving Knowledge Distillation (ICCV 2019)</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>Network Compression 视频 李宏毅</title>
    <url>/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/</url>
    <content><![CDATA[<h1 id="Network-Compression-视频-李宏毅"><a href="#Network-Compression-视频-李宏毅" class="headerlink" title="Network Compression 视频 李宏毅"></a>Network Compression 视频 李宏毅</h1><blockquote>
<p>课程视频(B站)：<a href="https://www.bilibili.com/video/BV1JE411g7XF">李宏毅2020机器学习深度学习(完整版)国语</a> P43-P50</p>
<p>课程官网：<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html">http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html</a></p>
<p>课程笔记(知乎)：<a href="https://www.zhihu.com/column/c_1325525429269671936">https://www.zhihu.com/column/c_1325525429269671936</a></p>
<p>网友github代码：<a href="https://github.com/chouxianyu/LHY_ML2020_Codes">https://github.com/chouxianyu/LHY_ML2020_Codes</a></p>
<p>github：<a href="https://github.com/jacobgil/pytorch-pruning">https://github.com/jacobgil/pytorch-pruning</a> 待看！！！</p>
</blockquote>
<h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><ul>
<li>Network Pruning</li>
<li>Knowledge Distillation</li>
<li>Parameter Quantization</li>
<li>Architecture Design</li>
<li>Dynamic Computation</li>
</ul>
<h2 id="Network-Pruning-剪枝"><a href="#Network-Pruning-剪枝" class="headerlink" title="Network Pruning 剪枝"></a>Network Pruning 剪枝</h2><blockquote>
<p><a href="https://www.bilibili.com/video/BV1JE411g7XF?p=43">P43 Network Compression (1_6)08:24</a></p>
</blockquote>
<h3 id="Network-can-be-pruned"><a href="#Network-can-be-pruned" class="headerlink" title="Network can be pruned"></a>Network can be pruned</h3><ul>
<li><p>网络一般都是“over-parameterized”，对于任务来说训练太多参数。 看一些neuron的output总是0，或者一些weight很接近0，对output无影响</p>
</li>
<li><p>剪掉的weight、neuron是没意义的解空间，不影响最优解（和最优解的距离不变）。</p>
</li>
<li><p>neuron理解为上一层经过某些连接的输出；weight是连接的值，就是神经元之间连接上的权重。</p>
</li>
</ul>
<h3 id="剪枝流程"><a href="#剪枝流程" class="headerlink" title="剪枝流程"></a>剪枝流程</h3><ol>
<li>有一个训好的大network</li>
<li>评估neuron或weight的重要性（直接看weight的数值，接近0不重要，很正或很负重要；neuron的output总是0不重要）</li>
<li>把pruned后的network再去训练集finetue一下（recover）（因为pruned会使得模型精度下降，要finetune补回来、恢复回来）</li>
</ol>
<p>迭代地进行，一次pruned一点点参数，再finetune，再pruned，再finetune，直到模型参数符合要求（因为一次pruned太多，recover不回来）。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419110903497.png" alt="image-20230419110903497" style="zoom:80%;">



<blockquote>
<p><a href="https://www.bilibili.com/video/BV1JE411g7XF?p=44">P44 Network Compression (2_6)12:44</a></p>
</blockquote>
<h3 id="Why-Pruning"><a href="#Why-Pruning" class="headerlink" title="Why Pruning?"></a>Why Pruning?</h3><p>为什么不直接train一个小network：因为小network比较难train，有文章理论上证明只要network够大，能找到global optimize全局最优。</p>
<ul>
<li>How about simply train a smaller network?</li>
<li>It is widely known that smaller network is more difficult to learn successfully.<ul>
<li>Larger network is easier to optimize?<br><a href="https://www.youtube.com/watch?v=_VuWvQUMQVk">https://www.youtube.com/watch?v=_VuWvQUMQVk</a></li>
<li>Lottery Ticket Hypothesis 大乐透假设<br><a href="https://arxiv.org/abs/1803.03635">https://arxiv.org/abs/1803.03635</a></li>
</ul>
</li>
</ul>
<p>Lottery Ticket Hypothesis 大乐透假设：</p>
<p>不同随机初始化有时候train得起来，有时候train不起来。一个巨大的network想象成由很多小的network所组成，每一个是sub network，每一个小network就是一种可能的初始化，这些小network有的train得起来，有的train不起来，而大的network之所以能够train得起来，是因为大的network里面只要有某一个小的network能够train起来，整个network就train起来，然后把大network做pruned，取出小network。</p>
<p>这解释了下图右下，取大network的初始化一样的参数的小network初始化能够train起来。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419110936001.png" alt="image-20230419110936001" style="zoom:80%;">





<p>不需要大乐透假说？直接train能train起来：</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419110949757.png" alt="image-20230419110949757" style="zoom:80%;">



<h3 id="Weight-pruning"><a href="#Weight-pruning" class="headerlink" title="Weight pruning"></a>Weight pruning</h3><p>直接把pruned的weight挖空，不利于gpu加速计算（gpu对象是矩阵），所以做法是把要pruned的weight<strong>置0</strong>。但是补0后的network模型大小没有变化。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111007726.png" alt="image-20230419111007726" style="zoom:80%;">



<p>pruning得即使很多（95%都pruned掉了），精度也没怎么掉，但是加速变慢了（小于1）有些pruning了结果还更慢了。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111034391.png" alt="image-20230419111034391" style="zoom:80%;">



<h3 id="Neuron-pruning"><a href="#Neuron-pruning" class="headerlink" title="Neuron pruning"></a>Neuron pruning</h3><p>相比于weight pruning，neuron pruning是一种更好的方式，把neuron前面和后面连接的weight拿掉，直接拿掉某一个hidden neuron。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111054816.png" alt="image-20230419111054816" style="zoom:80%;">







<h2 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h2><blockquote>
<p><a href="https://www.bilibili.com/video/BV1JE411g7XF?p=45">P45 Network Compression (3_6)08:33</a></p>
</blockquote>
<p>Knowledge Distillation：<a href="https://arxiv.org/pdf/1503.02531.pdf">https://arxiv.org/pdf/1503.02531.pdf</a></p>
<p>Do Deep Nets Really Need to be Deep?<a href="https://arxiv.org/pdf/1312.6184.pdf">https://arxiv.org/pdf/1312.6184.pdf</a>  </p>
<p>能学会1长得和7很像，1也长得像9</p>
<p>论文里做了一个有趣的实验：训练集里没给student看过7的数据，但是蒸馏后，student也可能能分类出7，因为student知道7和1、7和9挺像。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111117580.png" alt="image-20230419111117580" style="zoom:80%;">





<p>打比赛通常是ensemble很多，用集成方法组合多个模型。</p>
<p>知识蒸馏的teacher model把ensemble的模型<strong>并起来</strong>，比如输出是多个模型的平均，这个输出让student model去学习，最后student就能学到接近ensemble的结果。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111135634.png" alt="image-20230419111135634" style="zoom:80%;">



<p>temperature</p>
<p>通常 $T&gt;1$ ，提出temperature的目的就是不希望因为teacher model输出概率很“确定”，比如接近1或0，这样就很像label，这样和直接让student学习数据，学习label（0、1） 没区别，就失去了用teacher model的意义，于是用一个temperature缓解一下。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111153649.png" alt="image-20230419111153649" style="zoom:80%;">



<p>李宏毅实践发现Knowledge Distillation<strong>没有</strong>特别有用。</p>
<h2 id="Parameter-Quantization"><a href="#Parameter-Quantization" class="headerlink" title="Parameter Quantization"></a>Parameter Quantization</h2><blockquote>
<p><a href="https://www.bilibili.com/video/BV1JE411g7XF?p=46">P46 Network Compression (4_6)06:37</a></p>
</blockquote>
<ol>
<li>Using less bits to represent a value  </li>
<li>Weight clustering</li>
</ol>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111215941.png" alt="image-20230419111215941" style="zoom:80%;">

<p>聚类，比如聚成4类，就用2个bit就能表示4个类，然后每个类的值（table）用所属类的值的平均值表示。</p>
<p>这样可能不够精准</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111236504.png" alt="image-20230419111236504" style="zoom:80%;">

<ol start="3">
<li>Represent frequent clusters by less bits, represent rare clusters by more bits<ul>
<li>e.g. Huffman encoding  哈夫曼编码，把比较常出现的token用较少的bit表示，比较少出现的token用较多的bit表示</li>
</ul>
</li>
</ol>
<h3 id="Binary-Weights"><a href="#Binary-Weights" class="headerlink" title="Binary Weights"></a>Binary Weights</h3><blockquote>
<p>Binary Connect: <a href="https://arxiv.org/abs/1511.00363">https://arxiv.org/abs/1511.00363</a></p>
<p>Binary Network: <a href="https://arxiv.org/abs/1602.02830">https://arxiv.org/abs/1602.02830</a></p>
<p>XNOR-net: <a href="https://arxiv.org/abs/1603.05279">https://arxiv.org/abs/1603.05279</a>  </p>
</blockquote>
<p>Your weights are always +1 or -1  </p>
<ul>
<li>Binary Connect</li>
</ul>
<p>流程：随机初始化参数，然后找到参数<strong>最接近</strong>的二值化参数，计算该二值化参数的梯度，认为是原参数的梯度（非二值化），然后用这个梯度作为原参数的更新方向，更新后的参数值，再去找最接近的二值化参数，再去计算该二值化参数的梯度，再用这个梯度更新real value 参数。直到迭代完了，最后这个最接近real value的二值化参数，作为最终的参数使用。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111323712.png" alt="image-20230419111323712" style="zoom:80%;">





<h3 id="binary-connect-结果"><a href="#binary-connect-结果" class="headerlink" title="binary connect 结果"></a>binary connect 结果</h3><blockquote>
<p><a href="https://arxiv.org/abs/1511.00363">https://arxiv.org/abs/1511.00363</a>  </p>
</blockquote>
<p>论文发现用binary connect结果居然还变好了，一开始认为参数二值化可能会更差，没想到更好，分析是binary connect有点像<strong>正则</strong>，起到正则作用，二值化。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111341304.png" alt="image-20230419111341304" style="zoom:80%;">











<h2 id="Architecture-Design"><a href="#Architecture-Design" class="headerlink" title="Architecture Design"></a>Architecture Design</h2><blockquote>
<p><a href="https://www.bilibili.com/video/BV1JE411g7XF?p=47">P47 Network Compression (5_6)11:53</a></p>
</blockquote>
<p>应该是实践中最有效的做法</p>
<h3 id="Low-rank-approximation"><a href="#Low-rank-approximation" class="headerlink" title="Low rank approximation"></a>Low rank approximation</h3><p>fully connect：</p>
<p>中间插入一层（没有激活函数，纯linear），是做SVD奇异值分解。</p>
<p>参数大小来说 $W&gt;U+V$ ，因此减少了参数量；</p>
<p>但是 $W$ 能做到 $U<em>V$ 所做不到的事（解空间），因为 $K\ge rank(U</em>V)$ 也就是 $U*V$的秩小于等于K，但 W没有限制。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111357322.png" alt="image-20230419111357322" style="zoom: 80%;">



<h3 id="Review-Standard-CNN"><a href="#Review-Standard-CNN" class="headerlink" title="Review: Standard CNN"></a>Review: Standard CNN</h3><p>feature的channel有几个，filter的channel就要有几个，然后根据filter的数量，得到output的数量</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111414978.png" alt="image-20230419111414978" style="zoom:80%;">



<h3 id="Depthwise-Separable-Convolution"><a href="#Depthwise-Separable-Convolution" class="headerlink" title="Depthwise Separable Convolution"></a>Depthwise Separable Convolution</h3><h4 id="1-Depthwise-Convolution"><a href="#1-Depthwise-Convolution" class="headerlink" title="1. Depthwise Convolution"></a>1. Depthwise Convolution</h4><p>每个filter负责一个channel的input（之前每个filter负责所有channel的input，所以每个filter是三维的（有channel通道））现在没有channel通道了，二维的。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419111437116.png" alt="image-20230419111437116" style="zoom:80%;">



<ul>
<li>Filter number &#x3D; Input channel number  </li>
<li>Each filter only considers one channel.  </li>
<li>The filters are $k\times k$ matrices</li>
<li>There is no interaction between channels</li>
</ul>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419110529312.png" alt="image-20230419110529312" style="zoom:80%;">



<h4 id="2-Pointwise-Convolution"><a href="#2-Pointwise-Convolution" class="headerlink" title="2. Pointwise Convolution"></a>2. Pointwise Convolution</h4><p>前一个步骤（Depthwise Convolution）得到的feature map，用1 * 1 filter去扫，卷积核是1 * 1，channel和feature map的channel数量一样。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230419110507038.png" alt="image-20230419110507038" style="zoom: 80%;">

<p>总共用了18+8&#x3D;26个参数。</p>
<blockquote>
<p><a href="https://www.bilibili.com/video/BV1JE411g7XF?p=48">P48 Network Compression (6_6)13:09</a></p>
</blockquote>
<ul>
<li><p>普通卷积：比如要得到（右上图形）橙色的左上角的值，是由（左上图形）左上18个值和filter做dot product再求和得到的。</p>
</li>
<li><p>ds卷积：（左下图形）feature map 被第二层filler作用时，feature map的参数是“<strong>共用的</strong>”，既给橙色filler用、又给黄色filler用。因此参数量少了。</p>
<p>不同filler间，共用同样的参数。</p>
</li>
</ul>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230421133120061.png" alt="image-20230421133120061" style="zoom: 80%;">



<p>参数计算：</p>
<ul>
<li>普通cnn：有几个output channel，就有几个filler</li>
</ul>
<p>一般O是512、128等，1&#x2F;O可忽略，因此可以缩小到1&#x2F;K^2，比如1&#x2F;9。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230421133140058.png" alt="image-20230421133140058" style="zoom: 80%;">

<p>待看的论文：</p>
<ul>
<li>SqueezeNet：<a href="https://arxiv.org/abs/1602.07360">https://arxiv.org/abs/1602.07360</a></li>
<li>MobileNet：<a href="https://arxiv.org/abs/1704.04861">https://arxiv.org/abs/1704.04861</a> 用在手机上</li>
<li>ShuffleNet：<a href="https://arxiv.org/abs/1707.01083">https://arxiv.org/abs/1707.01083</a></li>
<li>Xception：<a href="https://arxiv.org/abs/1610.02357">https://arxiv.org/abs/1610.02357</a></li>
</ul>
<h2 id="Dynamic-Computation"><a href="#Dynamic-Computation" class="headerlink" title="Dynamic Computation"></a>Dynamic Computation</h2><p>要想在设备上用，但是每个设备的资源不一样，要怎么样在不同设备上都能用一个好的模型呢</p>
<blockquote>
<p><a href="https://arxiv.org/abs/1703.09844">https://arxiv.org/abs/1703.09844</a></p>
</blockquote>
<ol>
<li>Train multiple classifiers 训练一批网络模型，根据设备资源的不同，选择其中某个模型。</li>
<li>Classifiers at the intermedia layer 取模型的不同中间层输出，看输出的分类器是否满足效果需求，看中间层就输出是否满足设备资源的需求。（虽然比如模型是20层，这样功耗比较高，但如果不拿完，就是比如只做前面15层，拿15层的输出做分类，可能功耗没那么高，并且效果也还行）</li>
</ol>
<p>左下图的意思是，拿初始几层（接近input特征）的输出做分类的结果，不太好，越往后面层拿，效果会越好。因为初始几层input，CNN抽出来的pattern比较简单。</p>
<p>右下图的意思是：本来的模型是只有最后一层有分类器，现在中间好多层都接了分类器，这样多个分类器训练出来的模型效果是不好的。尤其是初始几层就接分类器，会更影响模型效果。（后面几层接分类器，不是很影响效果），这是因为中间层接分类器，会影响到原来整个模型的布局，比如一开始模型就是希望初始几层是抽取初级特征，现在初始几层就接分类器了，相当于让初级特征强行学习高级特征，就会破坏原来布局。</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230421141557284.png" alt="image-20230421141557284" style="zoom:80%;">

<blockquote>
<p><a href="https://arxiv.org/abs/1703.09844">https://arxiv.org/abs/1703.09844</a></p>
</blockquote>
<p>MSD net</p>
<img src="/2023/04/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Compression%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230421141611270.png" alt="image-20230421141611270" style="zoom:80%;">









]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>Network Pruning 视频 李宏毅助教</title>
    <url>/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/</url>
    <content><![CDATA[<h1 id="Network-Pruning-视频-李宏毅助教"><a href="#Network-Pruning-视频-李宏毅助教" class="headerlink" title="Network Pruning 视频 李宏毅助教"></a>Network Pruning 视频 李宏毅助教</h1><blockquote>
<p>PPT：<a href="https://slides.com/arvinliu/model-compression">https://slides.com/arvinliu/model-compression</a> 、 <a href="https://slides.com/arvinliu/model-compression/fullscreen?print-pdf=true#/0/1">https://slides.com/arvinliu/model-compression/fullscreen?print-pdf=true#/0/1</a> 、 <a href="https://slides.com/arvinliu/model-compression/fullscreen?print-pptx=true#/0/2">https://slides.com/arvinliu/model-compression/fullscreen?print-pptx=true#/0/2</a></p>
<p>视频：<a href="https://www.bilibili.com/video/BV1JE411g7XF?p=50">P50 Network Compression (2_2) - Network Pruning (选学)39:33</a></p>
</blockquote>
<p>对于dense全连接来说，少1个参数，总参数量（矩阵参数）从 $a * b + b * c &#x3D; (a + c) * b$，变为  $(a + c) * (b -1)$ 个weight.</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230421174655789.png" alt="image-20230421174655789" style="zoom:80%;">



<p>对于CNN来说，kernel size $k<em>k$，参数原本是 $(a+c)<em>b</em>k</em>k$ ，少一个参数，变为 $(a+c)*(b-1)<em>k</em>k$ 个 weight。</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230421174715246.png" alt="image-20230421174715246" style="zoom:80%;">





<h2 id="Network-Pruning"><a href="#Network-Pruning" class="headerlink" title="Network Pruning"></a>Network Pruning</h2><h3 id="Main-Question-Prune-what-要对“不重要的”剪枝"><a href="#Main-Question-Prune-what-要对“不重要的”剪枝" class="headerlink" title="Main Question: Prune what? 要对“不重要的”剪枝"></a>Main Question: Prune what? 要对“不重要的”剪枝</h3><h4 id="Which-is-most-important"><a href="#Which-is-most-important" class="headerlink" title="Which is most important?"></a>Which is most important?</h4><h5 id="How-to-evaluate-importance-如何评估重要性"><a href="#How-to-evaluate-importance-如何评估重要性" class="headerlink" title="How to evaluate importance? 如何评估重要性"></a>How to evaluate importance? 如何评估重要性</h5><ul>
<li>Evaluate by Weight 通过weight大小来衡量重不重要</li>
<li>Evaluate by Activation 通过neuron经过激活函数是不是为0来评估重要性</li>
<li>Evaluate by Gradient 通过梯度值来评估重要性 对neuron算梯度，值很大说明更重要</li>
</ul>
<h3 id="After-Evalutaion-要prune多少呢"><a href="#After-Evalutaion-要prune多少呢" class="headerlink" title="After Evalutaion? 要prune多少呢"></a>After Evalutaion? 要prune多少呢</h3><ul>
<li>Sort by importance and prune by rank. 按重要性排序</li>
<li>prune by handcrafted threshold. 按一个阈值手动prune</li>
<li>prune by generated threshold 自动生成阈值prune</li>
</ul>
<p>1）每一层都prune固定比例 x%（这个方式不太实用，因为model一般是金字塔型，顶层参数少，因为prune要多一些）</p>
<p>2） 每一层prune的比例不同。（autoML）</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230421174844154.png" alt="image-20230421174844154" style="zoom:80%;">



<h1 id="Evaluate-Importance-衡量基准"><a href="#Evaluate-Importance-衡量基准" class="headerlink" title="Evaluate Importance 衡量基准"></a>Evaluate Importance 衡量基准</h1><ol>
<li><strong>sum of L1 norm</strong> （这里的对象是weight，prune weight）</li>
</ol>
<p>卷积过程，得到输出neuron，输入是feature map，kernel size $k*k$，所以第一个橙色的weight，计算sum，第二个蓝色的weight计算后的的sum。所以根据sum的L1或L2大小，来决定要prune掉谁。</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230421174910562.png" alt="image-20230421174910562" style="zoom:80%;">



<ol start="2">
<li><strong>Filter pruning via geometric media</strong> 几何中心上prune</li>
</ol>
<p>根据输出的分布，把分布边缘的weight prune掉</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233426616.png" alt="image-20230422233426616" style="zoom:80%;">



<p>但是这样存在一定危险：</p>
<ol>
<li>当分布的方差很小时，砍掉会很影响效果，不能轻易砍（prune）；</li>
<li>norm要接近0才能砍，当发现不接近0，就是说这些都对结果很有贡献，就不能轻易砍。</li>
</ol>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233448565.png" alt="image-20230422233448565" style="zoom:80%;">

<p>改进方法：<strong>FPGM</strong>：出发点是“小的norm对model一定没用吗？大的norm对model一定有用吗”</p>
<p>找出对model都有贡献，并且彼此都不太一样的filter。如果很像的filter（比如norm值很接近），这种filter可以删掉其中一个。</p>
<p>就是虽然filter 的norm值大或小，也许都对model有贡献。但是如果重复的filter，这种filter才是对model没有贡献，要被prune掉的。</p>
<p>怎么找重复filter ：通过几何中心。</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233505323.png" alt="image-20230422233505323" style="zoom:80%;">



<p>找几何中心，把不是几何中心的prune掉。？？？</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233526366.png" alt="image-20230422233526366" style="zoom:80%;">



<h3 id="Other-parameters-we-can-use-上面讲的是prune-conv的weight，下面讲prune其他weight："><a href="#Other-parameters-we-can-use-上面讲的是prune-conv的weight，下面讲prune其他weight：" class="headerlink" title="Other parameters we can use? 上面讲的是prune conv的weight，下面讲prune其他weight："></a>Other parameters we can use? 上面讲的是prune conv的weight，下面讲prune其他weight：</h3><ul>
<li><strong>Network Slimming</strong><ul>
<li>BN层中，$\gamma$ is a learnable vector. $\gamma$ 是一个可学习向量，因此可以根据$\gamma$向量里每个元素的值大小，从而评估weight的重要性，因为weight重要一点，$\gamma$对应值也会大一点。</li>
<li>We can just use this parameters to evaluate importance.</li>
<li><a href="https://colab.research.google.com/drive/1CIn-Qqn9LBz-0f71Skm4vmdTDnE17uwy?authuser=2#scrollTo=bdUtCxBBcH0B">colab tutorial</a> (only pruned by gamma)</li>
</ul>
</li>
</ul>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233556827.png" alt="image-20230422233556827" style="zoom:80%;">



<p>但是如果$\gamma$的值都不接近零，这样强行根据$\gamma$值去prune会造成精度下降。因此要做归一化一下。对$\gamma$做L1-penalty。（？）</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233621537.png" alt="image-20230422233621537" style="zoom:80%;">



<ul>
<li><strong>average percentage of zeros （APoZ）</strong></li>
</ul>
<p>经过relu激活函数后很多值是0，prune按照0的比例来做决定。把非零的值sum起来（是数量sum还是数值sum？）？然后根据0的比例来决定prune多少。比如0的比例很高，则可以prune的也可以多一些。</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233637790.png" alt="image-20230422233637790" style="zoom:80%;">



<p>0的比例还挺高的：</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233651602.png" alt="image-20230422233651602" style="zoom:80%;">



<h1 id="More-About-Lottery-Ticket-Hypothesis"><a href="#More-About-Lottery-Ticket-Hypothesis" class="headerlink" title="More About Lottery Ticket Hypothesis"></a>More About Lottery Ticket Hypothesis</h1><img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233724553.png" alt="image-20230422233724553" style="zoom:80%;">

<p>作者用L1 norm的值（其实就是weight值取绝对值）大小来决定prune哪些weight。</p>
<p>问题1：会不会有这么一种可能：最后train完大数值的那些weight，也许是因为它们的初始值就大？那么初始值小的weight，最后如果train完也变成大weight，那么这类weight（初始小、train完大）是否会更有意义呢？</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233812747.png" alt="image-20230422233812747" style="zoom:80%;">

<p>实验对比</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233829593.png" alt="image-20230422233829593" style="zoom:80%;">

<p>实验结果</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233849055.png" alt="image-20230422233849055" style="zoom:80%;">



<p>问题2：什么影响了winning ticket参数</p>
<p><strong>Question</strong>: Why winning tickets can perform better accuracy?</p>
<p><strong>Experiment:</strong> 做了如下实验</p>
<ul>
<li>sign: 改变sign函数<ul>
<li>rewind init sign 把sign函数rewind（颠倒）</li>
<li>random 随机把sign正负值颠倒</li>
</ul>
</li>
<li>value:<ul>
<li>rewind init value	把值颠倒</li>
<li>reshuffle weight in same layer</li>
<li>constant α (std of initializer)</li>
<li>random</li>
</ul>
</li>
</ul>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233913423.png" alt="image-20230422233913423" style="zoom:80%;">

<p>实验结果：</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233938836.png" alt="image-20230422233938836" style="zoom:80%;">

<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><h3 id="Experiment-1-Choose-Which-Mask"><a href="#Experiment-1-Choose-Which-Mask" class="headerlink" title="Experiment 1: Choose Which Mask"></a>Experiment 1: Choose Which Mask</h3><ul>
<li>Usual L1-norm pruning :</li>
</ul>
<h3 id="Experiment-2-Remain-what-properties-in-w"><a href="#Experiment-2-Remain-what-properties-in-w" class="headerlink" title="Experiment 2: Remain what properties in $w$"></a>Experiment 2: Remain what properties in $w$</h3><ul>
<li>Under same architecture, <strong>init sign</strong> is important. 用sign函数更重要，sign函数曲线不要轻易改变长相</li>
</ul>
<h3 id="Based-on-Experiment-1-amp-2-we-can-construct-a-“supermask”"><a href="#Based-on-Experiment-1-amp-2-we-can-construct-a-“supermask”" class="headerlink" title="Based on Experiment 1 &amp; 2, we can construct a “supermask”."></a>Based on Experiment 1 &amp; 2, we can construct a “supermask”.</h3><img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422233958304.png" alt="image-20230422233958304" style="zoom:80%;">

<blockquote>
<p>详情见：Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask (ICML 2019)</p>
</blockquote>
<h1 id="Rethink-vs-Lottery"><a href="#Rethink-vs-Lottery" class="headerlink" title="Rethink vs Lottery"></a>Rethink vs Lottery</h1><p>Recap 它的观点和上述相反，它认为weight和neuron不重要，重要的是架构、构造（structure、architecture），经过prune后再finetune的结果，可能没有在这个架构下（和prune后相同的架构）随机初始化来的好。</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422234017228.png" alt="image-20230422234017228" style="zoom:80%;">

<ul>
<li>Rethink val：架构更重要，random init好</li>
<li>Lottery Ticket：weight更重要，random init不好</li>
</ul>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422234033439.png" alt="image-20230422234033439" style="zoom:80%;">



<p>？？？</p>
<p>对于Lottery Ticket来说：<strong>学习率lr要小</strong>，weight和train后的weight要接近</p>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230422234049299.png" alt="image-20230422234049299" style="zoom:80%;">

<ul>
<li>Rethink val：prune的是neuron&#x2F;feature map</li>
<li>Lottery Ticket：prune的是weight</li>
</ul>
<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230423092000001.png" alt="image-20230423092000001" style="zoom:80%;">





<img src="/2023/04/24/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Network%20Pruning%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85%20%E5%8A%A9%E6%95%99/image-20230423092023886.png" alt="image-20230423092023886" style="zoom:80%;">





<h2 id="Paper-Reference"><a href="#Paper-Reference" class="headerlink" title="Paper Reference"></a>Paper Reference</h2><ul>
<li>Network Pruning<ul>
<li>Pruning Filters for Efficient ConvNets (ICLR 2017)</li>
<li>Learning Efficient Convolutional Networks Through Network Slimming (ICCV 2017)</li>
<li>Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration (CVPR 2019)</li>
<li>Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures</li>
<li>The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (ICLR 2019)</li>
<li>Rethinking the value of network pruning (ICLR 2019)</li>
<li>Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask (ICML 2019)</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</title>
    <url>/2023/05/21/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/Quantization%20and%20Training%20of%20Neural%20Networks%20for%20Efficient%20Integer-Arithmetic-Only%20Inference/</url>
    <content><![CDATA[<h1 id="Quantization-and-Training-of-Neural-Networks-for-Efficient-Integer-Arithmetic-Only-Inference"><a href="#Quantization-and-Training-of-Neural-Networks-for-Efficient-Integer-Arithmetic-Only-Inference" class="headerlink" title="Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"></a>Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</h1><p>量化感知论文</p>
<blockquote>
<p>Jacob, Benoit, et al. “Quantization and training of neural networks for efficient integer-arithmetic-only inference.” <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>. 2018. citations:2302</p>
</blockquote>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><p>解决在精度和端侧延迟要求的前提下，如何进行模型压缩、模型量化的问题，使之能用在端侧。</p>
<h3 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h3><p>提出一种量化方案，能实现推理过程是全整数计算的。</p>
<p>同时提出一种训练流程，以保持端到端模型量化后的准确性。</p>
<h3 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h3><p>improving the latency-vs-accuracy tradeoffs of MobileNets on common mobile hardware ，端侧用的手机，即使在mobilenet这种实时率很高的小模型上也是有改进的。实验用CPU运行imagenet分类和coco目标检测证明了。</p>
<h3 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h3><p>。</p>
<h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><ul>
<li>提供了一种量化方案，将权重和激活量化为8位整数，仅将几个参数(偏差向量)量化为32位整数；</li>
<li>提供了一个量化的推理框架，它可以有效地在只有整数运算的硬件上实现，比如高通的Hexagon，在ARM NEON上展示了高效、准确的实现。</li>
<li>提供一个量化的训练框架，共同设计了一个量化推理过程，以最大限度地减少量化对实际模型的精度损失。</li>
<li>将我们的框架应用于基于MobileNets的高效分类和检测系统，并在流行的ARM cpu上提供基准测试结果。在最先进的MobileNet架构中，延迟与精度之间的权衡有了显著的改善，在ImageNet分类、COCO目标检测等任务中得到了证明。</li>
<li>提出的量化方案侧重于提高移动cpu上的推理速度和准确性的权衡。</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在最小精度损失的情况下减少cnn的模型大小和推理时间，大致分为两类：</p>
<ol>
<li>第一类，修改模型结构：代表为MobileNetb、SqueezeNet、ShuffleNet和DenseNet设计了利用计算的新颖网络架构&#x2F;内存高效操作。</li>
<li>第二类，将模型中的weight从fp32量化为更小的bit-depth 表示。 代表为Ternary weight networks (TWN)、Binary Neural Networks<br>(BNN)、XNOR-net</li>
</ol>
<p>这两类量化方法在权衡延迟和准确性方面缺乏两个方面：</p>
<ol>
<li><p>之前的方法没有在合理的基线架构上进行评估。之前实验里对象是, AlexNet、VGG、GoogleNet这种本身就过度参数化、很多冗余的大模型，因此量化很容易就能压缩很多。</p>
<p>一个更有意义的挑战将是量化模型架构，这些架构在权衡延迟和准确性方面已经很有效，例如MobileNets。</p>
</li>
<li><p>许多量化方法不能在实际硬件上提供可验证的效率改进。一些方法只关注如何减少设备上的存储空间大小，而较少关注计算效率。一些方法可以将乘法和加法都通过有效的位移位和位计数操作来实现，但是精度会掉很多。</p>
</li>
</ol>
<h2 id="Quantized-Inference"><a href="#Quantized-Inference" class="headerlink" title="Quantized Inference"></a>Quantized Inference</h2><h3 id="Quantization-scheme"><a href="#Quantization-scheme" class="headerlink" title="Quantization scheme"></a>Quantization scheme</h3><p>提出的量化方案在推理过程中使用纯整数运算实现，在训练过程中使用浮点运算实现，两种实现彼此保持高度对应。</p>
<p>首先通过提供量化方案的数学上严格的定义来实现这一点，并分别将该方案用于整数算术推理和浮点训练。</p>
<p>其中：$r$ 为数学实数（浮点数），$q$ 为量化值。量化方法是整数q到实数r的仿射映射：<br>$$<br>r&#x3D;S(q-Z)<br>$$<br>$S$ 是scale缩放因子，一般也是浮点型，和 $r$ 类型一样；</p>
<p>$Z$ 是zero point，和 $q$ 类型一致，含义是当实值 $r&#x3D;0$ 时，对应的 $q$ 取多少。这一要求的动机是神经网络运算符的有效实现通常需要在边界周围对数组进行0 padding？是不是设置一个实值阈值，阈值外的实值映射的量化值是0？</p>
<p>对每个激活数组和每个权重数组中的所有值使用一组量化参数；</p>
<p>上述可以用一种数据结构来表示，称为quantized buffer。在TensorFlow Lite的 Converter的实际数据结构是这个<a href="https://github.com/tensorflow/tensorflow/blob/4952f981be07b8bf508f8226f83c10cdafa3f0c4/tensorflow/contrib/lite/toco/model.h">头文件</a>中的QuantizationParams和Array。（这个仍然包含浮点数的数据结构不会出现在实际的量化设备上推理代码中）</p>
<p>在神经网络中，每个激活数组和权重数组都有一个这样的缓冲区实例，C++表示为（使用c++语法是因为它允许明确的类型传递）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> QType&gt; <span class="comment">// e.g. QType=uint8</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">QuantizedBuffer</span> &#123;</span><br><span class="line">vector&lt;QType&gt; q; <span class="comment">// the quantized values</span></span><br><span class="line"><span class="type">float</span> S; <span class="comment">// the scale</span></span><br><span class="line">QType Z; <span class="comment">// the zero-point</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<h3 id="Integer-arithmetic-only-matrix-multiplication"><a href="#Integer-arithmetic-only-matrix-multiplication" class="headerlink" title="Integer-arithmetic-only matrix multiplication"></a>Integer-arithmetic-only matrix multiplication</h3><p>如何<strong>仅使用整数运算运行推理过程</strong>？因为公式1里有浮点数$S$，怎么变为纯整数运算呢？这里考虑两个$N\times N$ 的实值矩阵 $r_1$ 和 $r_2$，乘积表示为 $r_3&#x3D;r_1r_2$，里面元素记为 $r_\alpha^{(i,j)}$ （$\alpha&#x3D;1,2,3$ ，$1\le i,j\le N$），每个矩阵的量化参数记为 $(S_\alpha , Z_\alpha)$ ，量化值记为 $q_\alpha^{(i,j)}$ 。上式变为：<br>$$<br>r_\alpha^{(i, j)}&#x3D;S_\alpha\left(q_\alpha^{(i, j)}-Z_\alpha\right)<br>$$<br>根据矩阵乘法的定义，我们有：<br>$$<br>S_3\left(q_3^{(i, k)}-Z_3\right)&#x3D;\sum_{j&#x3D;1}^N S_1\left(q_1^{(i, j)}-Z_1\right) S_2\left(q_2^{(j, k)}-Z_2\right)<br>$$<br>可以写成：<br>$$<br>q_3^{(i, k)}&#x3D;Z_3+M \sum_{j&#x3D;1}^N\left(q_1^{(i, j)}-Z_1\right)\left(q_2^{(j, k)}-Z_2\right)<br>$$<br>其中乘数 $M$ 定义为：<br>$$<br>M:&#x3D;\frac{S_1 S_2}{S_3}<br>$$<br>也就是说，计算过程是：计算两个实数矩阵的乘积 $r_1r_2$，它对应的乘积后的量化结果 $q_3$，然后根据上述公式(4)，可以看到里面只有一个浮点数$M$，其他都是整数，而这个浮点数M是可以<strong>离线计算、事先计算好的</strong>（因为$S_1$、$S_2$、$S_3$ 是常数），因此这个乘积量化结果很容易计算。经验地发现$M$总是在区间 $(0,1)$ 内，因此可以用标准化形式表示它：<br>$$<br>M&#x3D;2^{-n}M_0<br>$$<br>其中，$M_0$ 在区间 $ [0.5,1]$ 内，$n$ 为非负整数。规范化乘数$M_0$现在可以很好地表示为定点乘数（例如int16或int32，具体取决于硬件能力）。？？？</p>
<p>例如，如果使用int32，则表示$M_0$的整数是最接近 $2^{31}M_0$ 的int32值。由于$M_0 \ge 0.5$，该值始终至少为$2^{30}$，因此将始终具有至少30位的相对精度。</p>
<p>因此，乘以 $M_0$ 可以实现为定点乘法。？？？</p>
<p>同时，乘$2^{−n}$可以通过有效的位移实现（尽管需要有正确的四舍五入行为）。</p>
<p>本节中讨论的计算是在TensorFlow Lite<a href="https://github.com/tensorflow/tensorflow/blob/4952f981be07b8bf508f8226f83c10cdafa3f0c4/tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h#L493-L534">参考代码</a>中实现的，用于全连接层。</p>
<p>因此这种方法是“仅使用整数运算运行推理过程”。</p>
<ul>
<li><input disabled type="checkbox"> TODO 没看懂</li>
</ul>
<h3 id="Efficient-handling-of-zero-points"><a href="#Efficient-handling-of-zero-points" class="headerlink" title="Efficient handling of zero-points"></a>Efficient handling of zero-points</h3><p>为了有效地实现对公式(4)的求值，而不必执行$2N^3$次减法（$\sum_j$是2N次，外部遍历i、k，因此是$2N<em>N</em>N&#x3D;2N^3$次），也无需将乘法的操作数展开为16位整数。公式(4)展开为：<br>$$<br>q_3^{(i, k)}&#x3D; Z_3+M\left(N Z_1 Z_2-Z_1 a_2^{(k)}\right.  \left.-Z_2 \bar{a}<em>1^{(i)}+\sum</em>{j&#x3D;1}^N q_1^{(i, j)} q_2^{(j, k)}\right)<br>$$<br>where<br>$$<br>a_2^{(k)}:&#x3D;\sum_{j&#x3D;1}^N q_2^{(j, k)}, \quad \bar{a}<em>1^{(i)}:&#x3D;\sum</em>{j&#x3D;1}^N q_1^{(i, j)} .<br>$$<br>每一个 $a_2^{(k)}$ 或 $\bar{a}_1^{(i)}$ 只需要$N$次加法来计算，所以总共只加了$2 N^2$次（分开看，每个N次加法，$a_2^{(k)}$遍历k，一共$N^2$次；$\bar{a}<em>1^{(i)}$ 遍历i，一共$N^2$次；因此一共$2N^2$次）。  (7)求值的其余cost几乎全部集中在核心整数矩阵乘法累加上：<br>$$<br>\sum</em>{j&#x3D;1}^N q_1^{(i, j)} q_2^{(j, k)}<br>$$</p>
<p>上式进行了$2N^3$次运算，实际上，公式(7)中的其他项都是$O(N^2)$在$O$中有一个小常数。</p>
<p>与zero point $Z$ 有关的项的计算量都很小，因此将问题减少到其实只要算与其他无零点量化方案中必须计算的相同的核心整数矩阵乘法累积（公式(9)）。</p>
<h3 id="Implementation-of-a-typical-fused-layer"><a href="#Implementation-of-a-typical-fused-layer" class="headerlink" title="Implementation of a typical fused layer"></a>Implementation of a typical fused layer</h3><p>推理代码中融合运算符的粒度(接受8位量化输入并产生8位量化输出)必须与训练图中“伪量化 fake quantization”运算符的位置匹配。</p>
<p>对于在ARM和x86 CPU架构上的实现，使用gemmlowp库。GemmWithOutputPipeline 入口点提供了对现在描述的融合操作的支持。（这里用TensorFlow Lite中实现）例如卷积运算符(<a href="https://github.com/tensorflow/tensorflow/blob/4952f981be07b8bf508f8226f83c10cdafa3f0c4/tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h#L248-L314">参考代码</a>是自带的，优化代码调用gemmlowp)。</p>
<p>在神经网络里，上面的 $q_1$ 矩阵可以用来对应的weight、$q_2$对应activations，累积uint8值的乘积需要一个32位的累加器，我们选择一个有符号类型的累加器。(9)式可以写为：<br>$$<br>\mathbf{int}32 +&#x3D; \mathbf{uint}8 * \mathbf{uint}8<br>$$</p>
<p>（uint8范围0-255，相乘范围0-65535，为什么不用uint16？？）</p>
<p>scale参数$S_{bias}$也是用乘法表示<br>$$<br>S_{bias}&#x3D;S_1S_2, Z_{bias}&#x3D;0<br>$$<br>…TODO</p>
]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>模型压缩系列视频</title>
    <url>/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/</url>
    <content><![CDATA[<h1 id="模型压缩系列视频"><a href="#模型压缩系列视频" class="headerlink" title="模型压缩系列视频"></a>模型压缩系列视频</h1><blockquote>
<p>PPT：<a href="https://github.com/chenzomi12/DeepLearningSystem/tree/main/Inference">https://github.com/chenzomi12/DeepLearningSystem/tree/main/Inference</a></p>
</blockquote>
<h2 id="模型压缩架构和流程介绍！量化-x2F-剪枝-x2F-蒸馏-x2F-二值化4件套"><a href="#模型压缩架构和流程介绍！量化-x2F-剪枝-x2F-蒸馏-x2F-二值化4件套" class="headerlink" title="模型压缩架构和流程介绍！量化&#x2F;剪枝&#x2F;蒸馏&#x2F;二值化4件套"></a>模型压缩架构和流程介绍！量化&#x2F;剪枝&#x2F;蒸馏&#x2F;二值化4件套</h2><blockquote>
<p><a href="https://www.bilibili.com/video/BV1384y187tL/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">模型压缩架构和流程介绍！量化&#x2F;剪枝&#x2F;蒸馏&#x2F;二值化4件套！【推理系统】模型压缩第01篇</a></p>
</blockquote>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230507220556976.png" alt="image-20230507220556976" style="zoom: 50%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230507220704102.png" alt="image-20230507220704102" style="zoom: 50%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230507220907579.png" alt="image-20230507220907579" style="zoom:50%;">



<h2 id="低比特量化基本原理！"><a href="#低比特量化基本原理！" class="headerlink" title="低比特量化基本原理！"></a>低比特量化基本原理！</h2><blockquote>
<p><a href="https://www.bilibili.com/video/BV1VD4y1n7AR/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">低比特量化基本原理！【推理引擎】模型压缩系列第02篇</a></p>
</blockquote>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230507224628987.png" alt="image-20230507224628987" style="zoom: 80%;">











<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508194307800.png" alt="image-20230508194307800" style="zoom:60%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508195909966.png" alt="image-20230508195909966" style="zoom:50%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508195940356.png" alt="image-20230508195940356" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508200045451.png" alt="image-20230508200045451" style="zoom:50%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508200143051.png" alt="image-20230508200143051" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508200217006.png" alt="image-20230508200217006" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508200234426.png" alt="image-20230508200234426" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508200408514.png" alt="image-20230508200408514" style="zoom:50%;">

<h3 id="量化原理"><a href="#量化原理" class="headerlink" title="量化原理"></a>量化原理</h3><img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508200649585.png" alt="image-20230508200649585" style="zoom:60%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508203322288.png" alt="image-20230508203322288" style="zoom:80%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508210615108.png" alt="image-20230508210615108" style="zoom: 80%;">



<p>下图第二种是截断的方法，设置一个原始值的范围，映射到-127到127，超出这个范围的值就不要了。</p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508210727207.png" alt="image-20230508210727207" style="zoom: 60%;">



<p>第一种int类型表示，第二种uint类型表示；</p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508211019684.png" alt="image-20230508211019684" style="zoom: 60%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508212535898.png" alt="image-20230508212535898" style="zoom: 60%;">

<p>求S和Z： </p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508212647603.png" alt="image-20230508212647603" style="zoom:60%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508212859096.png" alt="image-20230508212859096" style="zoom:60%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508213015902.png" alt="image-20230508213015902" style="zoom:80%;">









<h1 id="感知量化训练QAT原理！伪量化节点计算方式！"><a href="#感知量化训练QAT原理！伪量化节点计算方式！" class="headerlink" title="感知量化训练QAT原理！伪量化节点计算方式！"></a>感知量化训练QAT原理！伪量化节点计算方式！</h1><blockquote>
<p><a href="https://www.bilibili.com/video/BV1s8411w7b9/?spm_id_from=333.788">感知量化训练QAT原理！伪量化节点计算方式！【推理引擎】模型压缩系列第03篇</a></p>
</blockquote>
<p>QAT：引入fake quant，作用是引入误差，视为“量化误差”，然后finetune模型，来适应这个误差。</p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508214253802.png" alt="image-20230508214253802" style="zoom:60%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508224027206.png" alt="image-20230508224027206" style="zoom:60%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508224218305.png" alt="image-20230508224218305" style="zoom:60%;">



<p>正向传播中做了两个工作：1.记录最大最小值；2.量化模拟的操作（fp32量化成int8）</p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508224402509.png" alt="image-20230508224402509" style="zoom:60%;">

<p>反向传播，直通，output导数等于intput的导数。但是做了一个截断操作</p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508224627487.png" alt="image-20230508224627487" style="zoom:60%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508224817292.png" alt="image-20230508224817292" style="zoom:60%;">



<p>每个step都会有不同的min和max。</p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508224848066.png" alt="image-20230508224848066" style="zoom:60%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508225002427.png" alt="image-20230508225002427" style="zoom:50%;">







<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508231725541.png" alt="image-20230508231725541" style="zoom:50%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508231813277.png" alt="image-20230508231813277" style="zoom: 67%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508232838532.png" alt="image-20230508232838532" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508232815032.png" alt="image-20230508232815032" style="zoom:50%;">



<h3 id="AI框架工作流程"><a href="#AI框架工作流程" class="headerlink" title="AI框架工作流程"></a>AI框架工作流程</h3><img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508232941798.png" alt="image-20230508232941798" style="zoom:60%;">



<h3 id="QAT的衍生研究"><a href="#QAT的衍生研究" class="headerlink" title="QAT的衍生研究"></a>QAT的衍生研究</h3><img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508233312042.png" alt="image-20230508233312042" style="zoom:50%;">

<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508233354434.png" alt="image-20230508233354434" style="zoom:50%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230508233411652.png" alt="image-20230508233411652" style="zoom:50%;">





<h2 id="训练后量化PTQ深度解读！与量化部署核心原理！"><a href="#训练后量化PTQ深度解读！与量化部署核心原理！" class="headerlink" title="训练后量化PTQ深度解读！与量化部署核心原理！"></a>训练后量化PTQ深度解读！与量化部署核心原理！</h2><blockquote>
<p><a href="https://www.bilibili.com/video/BV1HD4y1n7E1/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">训练后量化PTQ深度解读！与量化部署核心原理！【推理引擎】模型压缩系列第04篇</a></p>
</blockquote>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509094833732.png" alt="image-20230509094833732" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509094921765.png" alt="image-20230509094921765" style="zoom:50%;">







<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509095233870.png" alt="image-20230509095233870" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509095357276.png" alt="image-20230509095357276" style="zoom: 67%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509095503992.png" alt="image-20230509095503992" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509095548097.png" alt="image-20230509095548097" style="zoom:50%;">



<p>设置不同量化里的saturation阈值，然后得到不同的量化结果，也就得到不同的量化分布，再用kl散度选最小的那个量化分布。</p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509100917464.png" alt="image-20230509100917464" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509111623431.png" alt="image-20230509111623431" style="zoom:50%;">



<h3 id="端侧量化推理部署"><a href="#端侧量化推理部署" class="headerlink" title="端侧量化推理部署"></a>端侧量化推理部署</h3><p>conv2D过程有int8 * int8，再用int8会溢出，因此用int32 </p>
<p>2^8 *2 ^8 &#x3D; 2^16？</p>
<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509111658013.png" alt="image-20230509111658013" style="zoom:50%;">





<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509132458541.png" alt="image-20230509132458541" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509132544390.png" alt="image-20230509132544390" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509132634249.png" alt="image-20230509132634249" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509132940350.png" alt="image-20230509132940350" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509133008345.png" alt="image-20230509133008345" style="zoom:50%;">



<img src="/2023/05/09/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%B3%BB%E5%88%97%E8%A7%86%E9%A2%91/image-20230509133032018.png" alt="image-20230509133032018" style="zoom:50%;">
]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>模型量化 商汤 视频</title>
    <url>/2023/04/25/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%20%E5%95%86%E6%B1%A4%20%E8%A7%86%E9%A2%91/</url>
    <content><![CDATA[<h1 id="模型量化-商汤-视频"><a href="#模型量化-商汤-视频" class="headerlink" title="模型量化 商汤 视频"></a>模型量化 商汤 视频</h1><p>2023.4.25</p>
<blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1t54y1d777/?from=search&seid=8380176989930547254&vd_source=5e9891722f2b62adca440a5e92121b5b">【商汤泰坦公开课】模型量化的那些事</a> 2020.4.9</p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/132561405">模型量化了解一下？</a>  视频的对应文字稿版本</p>
</blockquote>
<p>本次课程由商汤研究院–链接与编译团队的两位研究员分享团队在模型量化方面的的一系列研究工作，其中包含CVPR  2020、ICCV 2019等多篇与北航刘祥龙老师团队合作的论文成果：</p>
<p> 1、如何训练极低比特(&lt;4bit)的网络 </p>
<p>2、如何训练高效的二值化网络 </p>
<p>3、如何用量化技术来加速模型训练 </p>
<p>4、模型量化在实际场景的落地 </p>
<p>5、模型量化与网络结构搜索结合</p>
<img src="/2023/04/25/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%20%E5%95%86%E6%B1%A4%20%E8%A7%86%E9%A2%91/image-20230425112749497.png" alt="image-20230425112749497" style="zoom: 50%;">



<h3 id="模型量化的几个结论和问题"><a href="#模型量化的几个结论和问题" class="headerlink" title="模型量化的几个结论和问题"></a>模型量化的几个结论和问题</h3><ul>
<li>一般模型量化算法都能压缩参数，但是&#x3D;&#x3D;压缩了参数大小并没有什么用&#x3D;&#x3D;。</li>
<li>&#x3D;&#x3D;许多量化算法都无法提升速度&#x3D;&#x3D;，量化算法在什么条件下的可以提升速度？</li>
<li>&#x3D;&#x3D;许多量化算法都无法降低内存占用&#x3D;&#x3D;，量化算法在什么条件下可以降低内存占用？</li>
<li>如何生产一个量化模型？</li>
<li>是什么阻碍了量化模型的落地？</li>
</ul>
<p>量化与反量化</p>
<img src="/2023/04/25/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%20%E5%95%86%E6%B1%A4%20%E8%A7%86%E9%A2%91/v2-52618ac0bf3518080b77f7fc49f7323e_r.jpg" alt="img" style="zoom:80%;">



<p>衡量算法速度的指标：理论峰值性能</p>
<p>量化是否一定能加速计算？回答是否定的，许多量化算法都无法带来实质性加速。</p>
<p>引入一个概念：理论计算峰值。在高性能计算领域，这概念一般被定义为：单位时钟周期内能完成的计算个数 乘上 芯片频率。</p>
<p>什么样的量化方法可以带来潜在、可落地的速度提升呢？我们总结需要满足两个条件：</p>
<p>1、量化数值的计算在部署硬件上的峰值性能更高 。</p>
<p>2、量化算法引入的额外计算（overhead）少 。</p>
<p>要准确理解上述条件，需要有一定的高性能计算基础知识，限于篇幅就不展开讨论了。现直接给出如下结论：已知提速概率较大的量化方法主要有如下三类，</p>
<p>1、<strong>二值化</strong>，其可以用简单的位运算来同时计算大量的数。对比从nvdia gpu到x86平台，1bit计算分别有5到128倍的理论性能提升。且其只会引入一个额外的量化操作，该操作可以享受到SIMD（单指令多数据流）的加速收益。</p>
<p>2、<strong>线性量化</strong>，又可细分为非对称，对称和ristretto几种。在nvdia gpu，x86和arm平台上，均支持8bit的计算，效率提升从1倍到16倍不等，其中tensor core甚至支持4bit计算，这也是非常有潜力的方向。由于线性量化引入的额外量化&#x2F;反量化计算都是标准的向量操作，也可以使用SIMD进行加速，带来的额外计算耗时不大。</p>
<p>3、<strong>对数量化</strong>，一个比较特殊的量化方法。可以想象一下，两个同底的幂指数进行相乘，那么等价于其指数相加，降低了计算强度。同时加法也被转变为索引计算。但没有看到有在三大平台上实现对数量化的加速库，可能其实现的加速效果不明显。只有一些专用芯片上使用了对数量化。</p>
<img src="/2023/04/25/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%20%E5%95%86%E6%B1%A4%20%E8%A7%86%E9%A2%91/v2-2a4223b3022be115bb8b7e5ccca8acde_r.jpg" alt="img" style="zoom:80%;">







<p>简单看一下二值化和线性量化两种方式，分别是下图中右上角的图和右下角的图。</p>
<p>总结一下，要使用量化技术来提升模型运行速度，需要满足两个条件：</p>
<p>1、选择适合部署的量化方案。</p>
<p>2、在部署平台上使用经过深度优化的量化计算库（必要的时候，可能需要撸起袖子自己上）。</p>
<p>首先保证你实现的低比特计算效率超过原先浮点计算，否则为何要承担精度损失的风险而使用并不加速的量化模型呢。但低比特计算效率超过浮点计算其实并不容易，因为大家在浮点的计算库上已经做了非常多细致的优化比如winograd，间接卷积等等。</p>
<p>为了最大限度保证实用性，后面的论文所有工作都是基于二值化、线性量化两种前提来做的，并且绝大部分工作都报告最终实际的加速效果。这也是链接与编译团队做研究的一个风格。</p>
<img src="/2023/04/25/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%20%E5%95%86%E6%B1%A4%20%E8%A7%86%E9%A2%91/v2-a4f481df63477b7af50dcf571d3121ad_r.jpg" alt="img" style="zoom:80%;">







<p>模型量化还有一个潜在的好处是降低运行时内存占用，这个特性无论是在移动端还是云端都是具有现实意义的。降低运行时内存占用比降低参数量更有意义。如果降低内存占用，可以得到如下好处：</p>
<ul>
<li>降低访存量，存在提升速度的可能 。</li>
<li>在同样硬件环境下，同时处理更多视频或者视频路数 。</li>
<li>训练更大的模型。</li>
</ul>
<p><strong>我们分析下运行时内存都是被什么东西占用的</strong>：</p>
<ul>
<li>大家关心的参数weight其实只占很少一部分。</li>
<li>大部分内存占用来自激活值activation。</li>
<li>如果你做低比特量化只关注卷积的话（很多论文其实也是只量化了卷积），那么是无法带来内存占用降低的。</li>
</ul>
<p><strong>如何才能用量化降低内存占用</strong>，只有一个方式：</p>
<ul>
<li>将尽可能多的layer的激活值都进行量化 。比如 pooling、relu、concat等激活值。</li>
<li>在这个方向上之前商汤的一位实习生李润东也有一个工作，做了除了卷积之外更多层的量化。Fully Quantized Network for Object Detection, Li Rundong, CVPR2019</li>
<li>但是这样做会带来更多的精度损失，这可能也是大家需要关心的。</li>
</ul>
<img src="/2023/04/25/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%20%E5%95%86%E6%B1%A4%20%E8%A7%86%E9%A2%91/v2-637b9153cfc3465aecc066343c98a02f_r.jpg" alt="img" style="zoom:80%;">

<p><strong>生产量化模型</strong></p>
<p>生产一个量化模型的有以下几种方法，借鉴了ICCV2019上一篇data-free量化论文的定义。</p>
<p><strong>如果将浮点模型转变为量化模型</strong>：</p>
<p>L1：data free：直接将一个浮点参数直接转化成量化数，一般会带来很大的精度损失，但使用上非常简单。</p>
<p>L2：calibration：基于数据校准的方案，很多芯片都会提供这样的功能，比如tensorRT，高通，寒武纪等。它需要转模型的时候提供一些真实的计算数据。</p>
<p>L3：finetune：基于训练finetune的方案，有很多论文都是使用这种方法，它的好处是可以带来更大的精度提升，缺点是需要修改训练代码，实施周期比较长。</p>
<p>上图描述了一种实用的pipeline流程，一般会优先使用不进行finetune的offline方法，也就是离线方案。当离线方案精度损失过于严重，我们才会进行基于finetune的方法，来做进一步的抢救。</p>
<blockquote>
<p>data-free quantization through weight equlization and bias correction, Qualcomm, ICCV2019</p>
</blockquote>
<img src="/2023/04/25/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%20%E5%95%86%E6%B1%A4%20%E8%A7%86%E9%A2%91/v2-ff854c348a7fb09ac5c3424395c2fcfd_r.jpg" alt="img" style="zoom:80%;">





<p><strong>量化模型的落地</strong></p>
<p>最后聊聊阻碍模型量化算法落地的几个问题，核心当然是精度问题。我们发现虽然学术界大家很早就开始做量化，但现在算法还无法大规模落地。主要存在几个Gap：</p>
<p>1、可落地的线性量化方案无法很好的刻画一些分布，比如高斯分布</p>
<p>2、比特数越低，精度损失就越大，实用性就越差</p>
<p>3、任务越难，精度损失越大，比如识别任务，就比分类任务要难非常多</p>
<p>4、小模型会比大模型更难量化</p>
<p>5、某些特定结构，如depthwise，对量化精度十分不友好</p>
<p>6、常见的对部署友好的方法比如merge BN，全量化，都会给精度带来更大的挑战</p>
<p>除了精度外，软硬件支持不好也是一个阻碍：</p>
<ul>
<li>不同的硬件支持的低比特指令是不一样的，同样训练得到的低比特模型，无法直接部署在所有硬件上。</li>
<li>除了硬件之外，不同软件库实现的量化方案和细节也不一样，量化细节里包括量化位置、是否支持perchannel、是否混合精度等等。即使硬件支持了量化，但你会发现不是所有硬件可以在低比特上提供更好的速度提升， 造成这个状况的主要原因有多个，一方面是指令集峰值提升可能本身就并不多，而要引入较多的额外计算，另一方面也取决于软件工程师优化指令的水平，同时由于网络结构灵活多样，不一定能在不同网络结构上达到同样好的加速比，需要优化足够多的的corner case才可以解决。</li>
</ul>
<p>相信大家对模型量化的概念和落地难点有了一个系统性的认识。我的部分就到这里结束了，下面是大家最期待的论文解读时间。</p>
<img src="/2023/04/25/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%20%E5%95%86%E6%B1%A4%20%E8%A7%86%E9%A2%91/v2-cc80dbe2114757d0d93d551d0d90cebf_r.jpg" alt="img">







<h2 id="论文解读"><a href="#论文解读" class="headerlink" title="论文解读"></a>论文解读</h2><p><strong>低比特量化：</strong></p>
<p><strong>Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit Neural Networks （ICCV 2019）</strong></p>
<p>由于量化函数本身是离散不可导的，导致其无法像标准神经网络一样使用反向传播计算梯度，一个常用的做法是使用梯度直通估计器（STE），即在反向过程中忽略量化这一步骤产生的影响，而这也就自然的带来了梯度不准确的问题。权重经过STE拿到的梯度跟它应该拿到的梯度是不匹配的。ICLR 2020年有一篇论文通过实验具体的分析了这一现象，发现随着比特数的降低，不匹配的现象更加明显。</p>
<p>。。。。TODO</p>
]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>模型量化(quantization)——模型压缩方法之一瞥 视频</title>
    <url>/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/</url>
    <content><![CDATA[<h1 id="模型量化-quantization-——模型压缩方法之一瞥-视频"><a href="#模型量化-quantization-——模型压缩方法之一瞥-视频" class="headerlink" title="模型量化(quantization)——模型压缩方法之一瞥 视频"></a>模型量化(quantization)——模型压缩方法之一瞥 视频</h1><p>2023.4.27</p>
<blockquote>
<p>b站：一了梁 <a href="https://www.bilibili.com/video/BV15t4y197Dj/?spm_id_from=333.788.recommend_more_video.-1&vd_source=5e9891722f2b62adca440a5e92121b5b">模型量化(quantization)——模型压缩方法之一瞥</a> 2020.7</p>
</blockquote>
<p>量化对weight的值离散化，用更少的bit去保存weight，模型大小下降了，计算量“可能会变少”，这里用的可能，是因为由于实际计算时，有一个反量化回浮点型的过程（减去零点，乘以缩放因子）因此多了一些运算，所以计算量是可能会变少（变少是因为整型与浮点型计算相比好运算一点？）。</p>
<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427143357597.png" alt="image-20230427143357597" style="zoom:50%;">



<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427143427881.png" alt="image-20230427143427881" style="zoom:50%;">





<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427144436962.png" alt="image-20230427144436962" style="zoom:50%;">





<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427145149292.png" alt="image-20230427145149292" style="zoom: 67%;">







<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427150333852.png" alt="image-20230427150333852" style="zoom:50%;">







<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427152222073.png" alt="image-20230427152222073" style="zoom:50%;">





<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427153056151.png" alt="image-20230427153056151" style="zoom: 50%;">





<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427153130277.png" alt="image-20230427153130277" style="zoom: 67%;">







<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96(quantization)%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E7%9E%A5%20%E8%A7%86%E9%A2%91/image-20230427153305246.png" alt="image-20230427153305246" style="zoom:67%;">

]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型压缩方法（三）：量化 视频</title>
    <url>/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/</url>
    <content><![CDATA[<h1 id="深度学习模型压缩方法（三）：量化-视频"><a href="#深度学习模型压缩方法（三）：量化-视频" class="headerlink" title="深度学习模型压缩方法（三）：量化 视频"></a>深度学习模型压缩方法（三）：量化 视频</h1><p>2023.4.26</p>
<blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV1bL411U747/?spm_id_from=333.788.recommend_more_video.0&vd_source=5e9891722f2b62adca440a5e92121b5b">深度学习模型压缩方法（三）：量化</a> </p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/619914824">https://zhuanlan.zhihu.com/p/619914824</a></p>
</blockquote>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li>量化概念</li>
<li>量化方法</li>
<li>校准方法</li>
</ul>
<h2 id="量化概念"><a href="#量化概念" class="headerlink" title="量化概念"></a>量化概念</h2><img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426150720366.png" alt="image-20230426150720366" style="zoom: 50%;">

<p>量化过程：浮点值除以缩放因子，再做四舍五入，再做clamp操作</p>
<h3 id="量化分类"><a href="#量化分类" class="headerlink" title="量化分类"></a>量化分类</h3><ul>
<li>线性量化：也称为均匀量化，相邻两个量化值之间的差距是固定的。</li>
<li>非线性量化：量化值之间的间隔不固定。网络中值的分布往往不均匀（分布会类似高斯分布），因此非线性量化可以更好的捕获分布相关的信息。数据多的地方，量化间隔小，量化精度高。因此非线性量化的效果理论上比线性量化更好。</li>
</ul>
<p>非线性量化的通用硬件加速比较困难，而且实现更加复杂，因此线性量化更加常用。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426150841073.png" alt="image-20230426150841073" style="zoom: 50%;">



<h3 id="对称量化与非对称量化"><a href="#对称量化与非对称量化" class="headerlink" title="对称量化与非对称量化"></a>对称量化与非对称量化</h3><p>根据浮点值的零点是否映射到量化值的零点，可以将量化分为对称量化和非对称量化。</p>
<p><strong>对称量化</strong>：对称量化中浮点值的零点直接映射到量化值的零点，因此不需要其他参数来调整零点的映射的位置，与量化相关的参数只有缩放因子s。<strong>对于有符号数的量化（int8），对称量化表示的浮点值范围是关于原点对称的（左图）。对于无符号数量化（uint8），对称量化可以表示的大于等于0的浮点范围。</strong></p>
<p><strong>非对称量化</strong>：非对称量化有一个额外的参数Z调整零点的映射，<strong>这个参数通常称为零点</strong>。非对称量化表示的范围没有严格的限制，可以根据浮点值的范围，选取任意的想要表示的范围。因此非对称量化的效果通常比对称量化好，但是需要额外存储以及推理时计算零点相关的内容。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426172440830.png" alt="image-20230426172440830" style="zoom:50%;">



<h3 id="量化分类-1"><a href="#量化分类-1" class="headerlink" title="量化分类"></a>量化分类</h3><p>量化参数：就是缩放因子s，零点z！</p>
<h3 id="量化粒度"><a href="#量化粒度" class="headerlink" title="量化粒度"></a>量化粒度</h3><p>根据<strong>量化参数（缩放因子s，零点z）</strong>的共享范围，可以将量化分为逐层量化和逐通道量化。</p>
<p><strong>逐层量化</strong>：在逐层量化中，<strong>每个网络层中的所有filter共享相同的量化参数</strong>。所要表示的浮点值范围的选择需要考虑当前层所有的filter来确定。对每层中所有的filter采用相同的范围，对应的缩放因子和零点也是相同的（缩放因子和零点是根据所要表示的浮点值范围和整型值位宽计算得到）。这种方法的实现比较简单，但是它的效果并不是很好，因为不同filter的范围可能会有很大差异。对于范围较小的filter可能会因为同层中存在范围较大的filter而使得其量化效果较差。</p>
<p><strong>逐通道量化</strong>：逐通道量化是一种更细粒度的量化方法。在这种方法中，为每层的各个filter单独地计算需要表示的范围以及量化参数。这种方法能够更好的保留每个filter的信息，产生的量化效果也较好。</p>
<h4 id="精度选择"><a href="#精度选择" class="headerlink" title="精度选择"></a>精度选择</h4><p>根据网络中量化位宽的不同，可以将量化分为统一精度量化和混合精度量化。</p>
<p><strong>统一精度</strong>：在统一精度量化中，所有量化的网络层均采用相同的位宽（相同的整型类型）。这是一种比较简单的精度选择方法，不需要考虑不同层对量化的敏感度。但是采用这种方法，在对网络进行量化或量化到较低精度时，可能会引起网络准确率的显著下降。</p>
<p><strong>混合精度</strong>：在混合精度量化中，不同的网络层可以量化到不同的位宽。核心思想是将<strong>不适合量化的层保留在较高精度（比如int16、int32），适合量化的层进行更加激进的量化</strong>。使网络整体处于较低位宽，并尽量缓解网络准确率的下降。混合精度量化中需要解决的问题与统一精度类似。但是混合精度量化需要额外关注一点，就是如何决定不同网络层的量化位宽。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426172910660.png" alt="image-20230426172910660" style="zoom: 50%;">



<h2 id="量化方式"><a href="#量化方式" class="headerlink" title="量化方式"></a>量化方式</h2><p>分为两大类：</p>
<ol>
<li>训练后量化</li>
<li>量化感知</li>
</ol>
<h3 id="训练后量化"><a href="#训练后量化" class="headerlink" title="训练后量化"></a>训练后量化</h3><p>训练后量化直接对已训练完成的模型进行量化，无需复杂的fine-tuning或训练过程，因此训练后量化的开销较小。训练后量化无需或只需要一小部分数据驱动量化，因此能很好地应用于数据敏感的场景。但是训练后量化的模型精度下降可能要高于量化感知训练。训练后量化可以分为权重量化和全量化两种。</p>
<p><strong>权重量化</strong>：在权重量化中，仅对模型的权重进行量化操作，以整型形式存储模型权重，可以压缩模型的大小。在推理阶段首先将量化的权重反量化为浮点形式，推理过程仍然为浮点计算，无法加速推理过程。</p>
<p><strong>全量化</strong>：在全量化中对模型权重和激活值进行量化，不仅可以压缩模型大小，减少推理过程的内存占用，而且因为激活值和权重都为整型数据，因此可以使用高效的整型运算单元加速推理过程。全量化可以分为两种形式：静态量化和动态量化。</p>
<ul>
<li><strong>静态量化</strong>：静态量化中离线计算好模型权重和激活的量化参数，推理的时候不再调整直接使用。对激活值量化需要获取激活值的分布信息，因此，静态量化中需要提供一定的数据来推理网络，收集网络的激活值信息，确定相关的量化参数。</li>
<li><strong>动态量化</strong>：在动态量化中，激活值相关的量化参数是在推理阶段实时计算的。虽然效果更好，但是会给推理带来额外的开销。</li>
</ul>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426173313067.png" alt="image-20230426173313067" style="zoom:50%;">



<h3 id="量化感知训练"><a href="#量化感知训练" class="headerlink" title="量化感知训练"></a>量化感知训练</h3><p>伪量化算子：对数值量化然后反量化得到的输出</p>
<p>量化感知训练在训练好的模型上插入<strong>伪量化算子（对数值量化然后反量化）</strong>，<strong>模拟量化产生的误差</strong>。然后在训练数据集更新权重并调整对应的量化参数，或者直接将量化参数作为可学习的参数在反向传播中更新。这种方法得到的量化模型精度较高，但是<strong>因为需要训练过程，因此开销较大，而且对于数据的要求相对于训练后量化也更高。</strong></p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426173946136.png" alt="image-20230426173946136" style="zoom:50%;">





<p>在这种方法中主要考虑的一个问题在<strong>计算梯度时如何处理量化操作中的不可微分的部分（round操作）</strong>。一种传统的方法是使用staright through estimator（STE）将伪量化算子的梯度设置为1，也就是输入的梯度等于输出的梯度。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426174304410.png" alt="image-20230426174304410" style="zoom:60%;">





<h2 id="校准方法"><a href="#校准方法" class="headerlink" title="校准方法"></a>校准方法</h2><p>校准是调整与确定量化参数的过程。以有符号数对称量化为例，缩放因子 $\large s&#x3D;\frac{threshold}{2^{b-1}-1}$ ，其中b是整型类型的位宽。因为是对称量化，因此这里只是用正半轴上的值计算缩放因子，以INT8为例，我们利用的整型范围是[-127,127]，表示的原始值范围为[-threshold,threshold]。因为量化位宽往往是提前确定好的，因此确定缩放因子就是确定我们想要表示的浮点值的范围。</p>
<p><strong>global</strong>：最简单的阈值选择方法，直接<strong>指定一个全局的值，作为所有网络层的量化阈值</strong>。但是每层之间值的范围多少有差距，因此这种方法很难找到适合所有层的量化阈值。</p>
<p><strong>max</strong>：也是相对简单阈值选择方法，将浮点值的最大绝对值作为量化阈值，这种方法能够表示整个浮点值的范围，但是可能无法充分利用整型值的范围。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426174844803.png" alt="image-20230426174844803" style="zoom:50%;">

<p><strong>percentile</strong>：通过分位数确定量化阈值。网络中的值往往不是均匀分布的，大部分是中间多两边少的“钟”型分布，此外还可能存在一些离群点，如果量化要表示所有的浮点值，反而可能会降低量化的精度。因此通过分位数确定阈值，虽然损失了部分数值的信息，但量化效果可能会更好。</p>
<img src="/2023/04/26/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%87%8F%E5%8C%96%20%E8%A7%86%E9%A2%91/image-20230426174915674.png" alt="image-20230426174915674" style="zoom:50%;">

<p><strong>mse</strong>：这种方法的目标是最小化量化前后数值之间的差距。通过选择多个候选阈值，记录不同阈值下对浮点值模拟量化的结果，并计算结果与原始的浮点值之间的均方误差，选择使均方误差最小的值作为最终的threshold。</p>
<p><strong>KL-divergence</strong>：这种方法的目标是最小化量化前后数值分布之间的差距。和均方误差类似，通过选择多个候选阈值，记录不同阈值下模拟量化值的分布信息，并计算与原始分布之间的KL散度，选择使KL散度最小的值作为最终的threshold。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Gholami A, Kim S, Dong Z, et al. A survey of quantization methods for efficient neural network inference[J]. arXiv preprint arXiv:2103.13630, 2021.<br>[2] Nagel M, Fournarakis M, Amjad R A, et al. A white paper on neural network quantization[J]. arXiv preprint arXiv:2106.08295, 2021.<br>[3] Krishnamoorthi R. Quantizing deep convolutional networks for efficient inference: A whitepaper[J]. arXiv preprint arXiv:1806.08342, 2018.<br>[4] Jacob B, Kligys S, Chen B, et al. Quantization and training of neural networks for efficient integer-arithmetic-only inference[C]&#x2F;&#x2F;Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 2704-2713.<br>[5] <a href="https://link.zhihu.com/?target=https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf</a><br>[6] <a href="https://zhuanlan.zhihu.com/p/548174416">https://zhuanlan.zhihu.com/p/548174416</a><br>[7] <a href="https://www.bilibili.com/video/BV1fB4y1m7fJ/">https://www.bilibili.com/video/BV1fB4y1m7fJ/</a></p>
]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型压缩概述</title>
    <url>/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%A6%82%E8%BF%B0%20%E8%A7%86%E9%A2%91/</url>
    <content><![CDATA[<h1 id="深度学习模型压缩概述"><a href="#深度学习模型压缩概述" class="headerlink" title="深度学习模型压缩概述"></a>深度学习模型压缩概述</h1><p>2023.4.27</p>
<blockquote>
<p>b站：先进编译实验室 <a href="https://www.bilibili.com/video/BV1ht4y1P73i/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">深度学习模型压缩概述</a> 魏铭康</p>
</blockquote>
<p>模型压缩方法：</p>
<ul>
<li>剪枝：修建不重要的网络连接</li>
<li>量化：将连续型数据量化为低位宽离散数据</li>
<li>知识蒸馏：大模型指导小模型学习</li>
<li>低秩分解：通过低秩矩阵近似原矩阵</li>
<li>轻量化网络：使用轻量化卷积核代替传统卷积</li>
<li>网络结构搜索：自动化地设计优异网络模型</li>
</ul>
<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%A6%82%E8%BF%B0%20%E8%A7%86%E9%A2%91/image-20230427113852965.png" alt="image-20230427113852965" style="zoom:50%;">



<h3 id="低秩分解"><a href="#低秩分解" class="headerlink" title="低秩分解"></a>低秩分解</h3><p>分解方法：</p>
<ul>
<li>SVD分解</li>
<li>CP分解：把n维张量分解成r个2维张量（r是矩阵的秩）</li>
<li>Tucker分解</li>
<li>Tensor Train分解</li>
</ul>
<p>CP分解：</p>
<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%A6%82%E8%BF%B0%20%E8%A7%86%E9%A2%91/image-20230427121107496.png" alt="image-20230427121107496" style="zoom:50%;">

<p>CP分解：</p>
<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%A6%82%E8%BF%B0%20%E8%A7%86%E9%A2%91/image-20230427121052117.png" alt="image-20230427121052117" style="zoom:50%;">





<h3 id="轻量化网络"><a href="#轻量化网络" class="headerlink" title="轻量化网络"></a>轻量化网络</h3><img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%A6%82%E8%BF%B0%20%E8%A7%86%E9%A2%91/image-20230427121300243.png" alt="image-20230427121300243" style="zoom:50%;">



<img src="/2023/04/27/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%A6%82%E8%BF%B0%20%E8%A7%86%E9%A2%91/image-20230427121834452.png" alt="image-20230427121834452" style="zoom:50%;">

]]></content>
      <categories>
        <category>模型压缩</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模型压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>CRF视频 李宏毅</title>
    <url>/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/</url>
    <content><![CDATA[<h1 id="CRF视频-李宏毅"><a href="#CRF视频-李宏毅" class="headerlink" title="CRF视频 李宏毅"></a>CRF视频 李宏毅</h1><blockquote>
<p>李宏毅机器学习(2017) <a href="https://www.bilibili.com/video/BV13x411v7US?p=35">P35 24- Structured Learning - Sequence Labeling1:43:31</a> 结构化预测-序列标注</p>
</blockquote>
<p>HMM的问题：不能保证正确的 $\hat y$ 代入 $P(x,\hat y)$ 一定小于错误的 $y$ 代入的 $P(x,y)$。</p>
<p>举例，根据训练数据集统计得到，N后接V有9次，V后接a有9次，N后接D有1次，D后接a有1次，虽然数据集里没有 N-&gt;V-&gt;a的情况出现过，但是假设已知前一个词性是N，输出word是a，猜测当前词性的时候，我们会根据概率猜测是V，而不是D，虽然数据集里有出现过N-&gt;D-&gt;a的数据情况，但是HMM居然会猜测出、脑补出数据集没有的情况。</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105163909907.png" alt="image-20230105163909907" style="zoom:50%;">

<p>但是这种脑补能力，在数据集特别小的情况下，效果不一定差，可能还比其他的方法好。</p>
<p>HMM产生这种脑补能力的原因是 构成 P(x,y) 的两项 P(y) 和 P(x,y) 是分开训练（或者统计）的，二者没有联系、<strong>独立</strong>的，因为无法保证正确的 P(x,y) 和错误的 P(x,y) 之间的关系。</p>
<h2 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h2><p>假设 P(x,y)正比于 一个指数函数 $exp(w \cdot \phi(x,y))$ 。</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105173335468.png" alt="image-20230105173335468" style="zoom:50%;">

<p>分母对y求和，所以和y无关，可以用一个只和x有关的函数 Z(x) 来简化。</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105175039773.png" alt="image-20230105175039773" style="zoom:50%;">

<p>举例说明为什么这个公式成立：</p>
<p>这里的 $N_{s,t}(x,y) $ 是当前句子里能产生某 (s,t) pair的次数。</p>
<p>s是tag，对应y；t是word，对应x；</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105175437435.png" alt="image-20230105175437435" style="zoom:50%;">



<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105181504783.png" alt="image-20230105181504783" style="zoom:50%;">



<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105181518147.png" alt="image-20230105181518147" style="zoom: 50%;">





<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105181533693.png" alt="image-20230105181533693" style="zoom:50%;">



<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105183109361.png" alt="image-20230105183109361" style="zoom:50%;">

<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105183144443.png" alt="image-20230105183144443" style="zoom:50%;">



<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105183158243.png" alt="image-20230105183158243" style="zoom:50%;">

<p>这里CRF分成两部分，但是也可以不止两部分，是很灵活的，可以由我们任意定义。</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230105183250365.png" alt="image-20230105183250365" style="zoom:50%;">

<p>这里O(w)是整个序列，所以是每个位置的p(y|x)累加后的P越大越好（每个位置的p(y|x)越大越好是交叉熵的思路）</p>
<p>CRF希望找到一个weight，能让看到过的pair出现的概率大（第一项），没看过的pair出现的概率小（减掉的第二项）</p>
<p>而HMM对于 求能让y最大的P(y|x)，虽然也是转换成让y最大的P(x,y)，但是转换成P(y)*P(x|y)后P(y)和P(x|y)是分开算的。</p>
<p>因为这里是最大化一个函数，因此不是用梯度下降，而是梯度上升，</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106093247099.png" alt="image-20230106093247099" style="zoom:50%;">

<p>这里 $\theta$ 就是 weight $w$ 。求目标函数的梯度：</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106093355700.png" alt="image-20230106093355700" style="zoom:50%;">



<p>梯度的计算过程：</p>
<p>$\hat y$ 是真实标签（是word对应真实的那个tag） </p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106093609656.png" alt="image-20230106093609656" style="zoom:50%;">



<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106093636292.png" alt="image-20230106093636292" style="zoom:50%;">



<p>这里exp(a)对w的导数等于 $\exp(a)\partial a&#x2F;\partial w$ ，$ P(x,y)$ 等于 $\exp(w \cdot \phi(x,y))$ ，$P(y|x)&#x3D;P(x,y)&#x2F;\sum_{y’} P(x,y’)$ 。</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106093428964.png" alt="image-20230106093428964" style="zoom:50%;">

<p>这里第二项是遍历所有可能的tag。</p>
<p>因为是梯度上升，所以如果导数是正的，则参数weight w会增大；导数是负的，w会减小。因此右边第一项N越大，w越大，第二项越大，w越小。这里不要只想成参数，要还是想成权重，所以是如果训练集有的pair（第一项），权重增加，在训练集没有但是比如概率挺大（第二项），这个（s,t) pair的权重要减小。</p>
<p>由之前的定义，上一张图只算了一个$w_{s,t}$ 的偏微分（还有不同的part 比如 $w_{s,s’}$ ），因此写成vector形式，对整个vector w来说，  <strong>$N_{s,t}$ 的向量 用 $ \phi$ 表示</strong>。</p>
<p>对整个vector来说（考虑不同的 $(s,t)$ 组合（就是也可以是 $(s,s’)$ ））：</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106113726590.png" alt="image-20230106113726590" style="zoom:50%;">

<p>对某个样本 $(x^n,\hat y^n)$ 来说，更新公式写成vector形式，正确的出现次数 减去 其他出现的次数乘以概率</p>
<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106114741214.png" alt="image-20230106114741214" style="zoom:50%;">





<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106115351208.png" alt="image-20230106115351208" style="zoom:50%;">







<img src="/2023/01/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CRF%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106120341374.png" alt="image-20230106120341374" style="zoom:50%;">

]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>CVAE论文</title>
    <url>/2022/12/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CVAE%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="CVAE"><a href="#CVAE" class="headerlink" title="CVAE"></a>CVAE</h1><blockquote>
<p>Sohn, Kihyuk, Honglak Lee, and Xinchen Yan. “Learning structured output representation using deep conditional generative models.” <em>Advances in neural information processing systems</em> 28 (2015). citations：2250 </p>
<p><a href="http://ijdykeman.github.io/ml/2016/12/21/cvae.html">http://ijdykeman.github.io/ml/2016/12/21/cvae.html</a> （翻译：<a href="https://www.cnblogs.com/sddai/p/10523431.html%EF%BC%89">https://www.cnblogs.com/sddai/p/10523431.html）</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/79871846">Conditional VAE</a></p>
</blockquote>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>提出一种生成模型的训练方法，该模型在随机梯度变分 Bayes框架下进行有效训练，此外，我们提供了新的策略来构建robust的结构化预测 算法，是一个深度条件 生成模型，用于使用高斯潜变量进行结构化输出预测。例如在 训练中输入噪声注入和多尺度预测目标。												</p>
<p>structured output 我理解的是多种特征、属性都有一点的结构化输出</p>
<p>multi-modal distribution 我理解就是组成output分布的多种特征、属性，多种特征的分布组成了多模态分布</p>
<p>在分割精度、条件对数似然估计和生成样本的可视化方面表现出色</p>
<p>对生成模型（或者说预测任务）的要求有两个：1.可以形成好的概率分布probabilistic inference（生成的样本和训练样本的分布是接近的）；2. 可以生成出不一样的样本，不能生成出来的样本都很接近，要是不一样的。</p>
<p>提出conditional variational auto-encoder (CVAE).CVAE是一个有条件的  有向图模型（z生成x，有个方向），其输入观测调节了产生输出的高斯潜变量 的先验 p(z)</p>
<p>主要改进如下：</p>
<ul>
<li>提出了cvae，我们提出了CVAE及其在SGVB框架中可有效训练的变体， ，并引入了新的策略来增强结构化预测模型的鲁棒性。</li>
<li>我们用高斯随机神经元 证明了我们提出的算法在建模结构化输出变量的多模态分布方面的有效性</li>
<li>我们在CUB和LFW数据集上实现了强大的语义对象分割性能。</li>
</ul>
<p>目标不仅是估计 $p(x)$ ，并且是在某个条件，比如s下的x发生的概率，p(x|s)，目标变成也要知道条件s对x会起到什么影响。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>recognition network：$q_\phi(z|x)$ 或者 $q_\phi(z|x,y)$  x（或x,y）条件下预测出的z的分布；</p>
<p>prior network  ：$p_\theta(z)$ 或者 $p_\theta(z|x)$ x条件下z的真实分布、先验分布；</p>
<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><p>The stochastic feed-forward neural network (SFNN)随机前馈神经网络(SFNN)是一个条件有向图模型 ，它结合了实值确定性神经元和二元随机神经元。</p>
<p>SFNN使用广义EM的蒙特卡罗变体进行训练，从前馈建议分布中提取多个样本 ，并用不同的重要性权重对它们进行加权</p>
<p>作者提出的叫做Gaussian stochastic neural network，用高斯隐变量替换了sfnn里的二元随机神经元binary stochastic neurons.</p>
<h2 id="Preliminary-Variational-Auto-encoder"><a href="#Preliminary-Variational-Auto-encoder" class="headerlink" title="Preliminary: Variational Auto-encoder"></a>Preliminary: Variational Auto-encoder</h2><p>回顾VAE，VAE用似然的variational lower bound作为目标函数，公式为<br>$$<br>\begin{aligned}<br>\log p_\theta(\mathbf{x}) &amp; &#x3D;K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}) | p_\theta(\mathbf{z} \mid \mathbf{x})\right)+\mathbb{E}<em>{q_\phi(\mathbf{z} \mid \mathbf{x})}\left[-\log q_\phi(\mathbf{z} \mid \mathbf{x})+\log p_\theta(\mathbf{x}, \mathbf{z})\right] \<br>&amp; \geq-K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}) | p_\theta(\mathbf{z})\right)+\mathbb{E}</em>{q_\phi(\mathbf{z} \mid \mathbf{x})}\left[\log p_\theta(\mathbf{x} \mid \mathbf{z})\right]<br>\end{aligned}<br>$$<br>其中，$q_\phi(\mathbf{z} \mid \mathbf{x})$ 是 recognition model，用来近似真实后验 $p_\theta(\mathbf{z} \mid \mathbf{x})$ 。recognition model结构是MLP。</p>
<p>假设z服从高斯分布，则 $-K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}) | p_\theta(\mathbf{z})\right)$ 可以忽略，$\mathbb{E}_{q_\phi(\mathbf{z} \mid \mathbf{x})}\left[\log p_\theta(\mathbf{x} \mid \mathbf{z})\right]$ 可以用 $L$ 个 $z$ 样本表示，则带有高斯隐变量的VAE目标写成：</p>
<p>$$<br>\widetilde{\mathcal{L}}<em>{\mathrm{VAE}}(\mathbf{x} ; \theta, \phi)&#x3D;-K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}) | p_\theta(\mathbf{z})\right)+\frac{1}{L} \sum</em>{l&#x3D;1}^L \log p_\theta\left(\mathbf{x} \mid \mathbf{z}^{(l)}\right)<br>$$<br>其中，$\mathbf{z}^{(l)}&#x3D;g_\phi\left(\mathbf{x}, \epsilon^{(l)}\right), \epsilon^{(l)} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ 。用了重参数技巧，把  $q_\phi(\mathbf{z} \mid \mathbf{x})$ 函数用 $g_\phi\left(\mathbf{x}, \epsilon\right)$ 函数代替，这个 $g_\phi(\cdot, \cdot)$ 是一个deterministic、differentiable的函数，里头的参数是data $\mathbf{x}$ 和 noise variable $\epsilon$ 。这种trick允许误差通过高斯隐变量反向传播，这在VAE训练中是必不可少的，因为它由多个mlp组成，用于识别和生成模型。因此，使用随机梯度下降(SGD)可以有效地训练VAE。</p>
<h2 id="Deep-Conditional-Generative-Models-for-Structured-Output-Prediction"><a href="#Deep-Conditional-Generative-Models-for-Structured-Output-Prediction" class="headerlink" title="Deep Conditional Generative Models for Structured Output Prediction"></a>Deep Conditional Generative Models for Structured Output Prediction</h2><p>如下图所示 Fig1(a) 展示了x拟合y的分布，$p_\theta(y|x)$ ，Fig1(b)、Fig1(c)、Fig1(d)展示了三种conditional generative model (CGM)  。</p>
<p>Fig1(b) 是先验网络和生成网络、decoder，说的是x条件下生成z的真实分布，z和x共同作用生成y，我们输入给定的数据点x，由于生成z会有随机性，$p_\theta(y|x,z)$ 允许建模多种模式，因此生成的y也有随机性，y有很多种可能生成的样子，是一个one-to-many过程；</p>
<p>z的先验来自x，也可以放宽限制，把 $p_\theta(z)$ 写成 $p_\theta(z|x)$  。</p>
<p>Fig1(c)是识别网络、encoder；</p>
<img src="/2022/12/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CVAE%E8%AE%BA%E6%96%87/image-20221208092952774.png" alt="image-20221208092952774" style="zoom: 67%;">

<p>Deep CGMs 用 maximize the conditional log-likelihood训练，通常很难直接计算目标函数，因此也像VAE一样用SGVB框架（求导）训练。</p>
<p>variational lower bound of the model 写为：<br>$$<br>\log p_\theta(\mathbf{y} \mid \mathbf{x}) \geq-K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y}) | p_\theta(\mathbf{z} \mid \mathbf{x})\right)+\mathbb{E}<em>{q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y})}\left[\log p_\theta(\mathbf{y} \mid \mathbf{x}, \mathbf{z})\right]<br>$$<br>empirical lower bound 写为：<br>$$<br>\widetilde{\mathcal{L}}</em>{\mathrm{CVAE}}(\mathbf{x}, \mathbf{y} ; \theta, \phi)&#x3D;-K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y}) | p_\theta(\mathbf{z} \mid \mathbf{x})\right)+\frac{1}{L} \sum_{l&#x3D;1}^L \log p_\theta\left(\mathbf{y} \mid \mathbf{x}, \mathbf{z}^{(l)}\right)<br>$$<br>其中，$\mathbf{z}^{(l)}&#x3D;g_\phi\left(\mathbf{x,y}, \epsilon^{(l)}\right), \epsilon^{(l)} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ , $L$ 是样本数。</p>
<p>这种模型称为 conditional variational auto-encoder (CVAE) ，识别模型变成了 $q_\phi(z|x,y)$ ，生成模型变成了 $p_\theta (y|x,z)$ 。如Fig1(d)是一个CVAE结构，有一个循环结构，给定数据x，有一个初始预测的 $\hat y$ ，$q_\phi(z|x,\hat y)$ 采样出 z，再  $p_\theta (y|x,z)$ 生成 $y$ （重建）。</p>
<p>上式的推导过程为：</p>
<p>在条件VAE中，我们假设要建模的变量是 $y$ ，条件是 $x$ 。隐变量 $z$ 的近似分布 $q_\phi(z \mid x, y)$ 和真 实后验概率 $p_\theta(z \mid x, y)$ 之间的 KL-divergence 记为:<br>$$<br>\begin{aligned}<br> K L\left[q_\phi(z \mid x, y) | p_\theta(z \mid x, y)\right]  &amp;&#x3D;\int q_\phi(z \mid x, y) \log \frac{q_\phi(z \mid x, y)}{p_\theta(z \mid x, y)} d \phi \<br>&amp;&#x3D;\int q_\phi(z \mid x, y) \log \frac{q_\phi(z \mid x, y) p_\theta(y \mid x) p_\theta(x)}{p_\theta(z, x, y)} d \phi<br>\end{aligned}<br>$$<br>展开:<br>$$<br>\begin{aligned}<br>&amp; &#x3D;\int q_\phi(z \mid x, y) \log _\phi(z \mid x, y) d \phi+\int q_\phi(z \mid x, y) \operatorname{logp}_\theta(y \mid x) d \phi+  \int q_\phi(z \mid x, y) \operatorname{logp}_\theta(x) d \phi  -\int q_\phi(z \mid x, y) \operatorname{logp}_\theta(z, x, y) d \phi<br>\end{aligned}<br>$$<br>其中，第二项:<br>$$<br>\int q_\phi(z \mid x, y) \log p_\theta(y \mid x) d \phi&#x3D;\log <em>\theta(y \mid x)<br>$$<br>其余三项合并，原式<br>$$<br>K L\left[q_\phi(z \mid x, y)|| p_\theta(z \mid x, y)\right]&#x3D;\log <em>\theta(y \mid x)+\int q_\phi(z \mid x, y) \log \frac{q_\phi(z \mid x, y)}{p_\theta(y \mid x, z) p_\theta(z \mid x)} d \phi<br>$$<br>由于左侧 $K L \geq 0$ ，因此:<br>$$<br>\begin{aligned}<br>&amp; \log <em>\theta(y \mid x) \geq-\int q_\phi(z \mid x, y) \log \frac{q_\phi(z \mid x, y)}{p_\theta(y \mid x, z) p_\theta(z \mid x)} d \phi \<br>&amp; &#x3D;\mathbb{E}</em>{q_\phi(z \mid x, y)}\left[\log p_\theta(y \mid x, z)+\log p_\theta(z \mid x)-q_\phi(z \mid x, y)\right] d \phi \<br>&amp; &#x3D;\mathbb{E}</em>{q_\phi(z \mid x, y)}\left[\log <em>\theta(y \mid x, z)\right]-\mathbb{E}</em>{q_\phi(z \mid x, y)}\left[\log q_\phi(z \mid x, y)-\log <em>\theta(z \mid x)\right] \<br>&amp; &#x3D;\mathbb{E}</em>{q_\phi(z \mid x, y)}\left[\log <em>\theta(y \mid x, z)\right]-K L\left[q_\phi(z \mid x, y)|| p_\theta(z \mid x)\right]<br>\end{aligned}<br>$$<br>左侧 $\log <em>\theta(y \mid x)$ 是基于条件 $x$ 的后验概率，右侧是条件VAE的ELBO:<br>$$<br>E L B O&#x3D;\mathbb{E}</em>{q_\phi(z \mid x, y)}\left[\log p_\theta(y \mid x, z)\right]-K L\left[q_\phi(z \mid x, y) | p_\theta(z \mid x)\right]<br>$$<br>第一项是对隐变量 $z \sim p_\phi(z \mid x, y)$ 的期望下的极大似然估计，第二项是 $q_\phi$ 与先验的KL约束。同 样，第一项也要通过采样来估计，具体而言:<br>$$<br>\widetilde{\mathcal{L}}</em>{\mathrm{CVAE}}(\mathbf{x}, \mathbf{y} ; \theta, \phi)&#x3D;-K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y}) | p_\theta(\mathbf{z} \mid \mathbf{x})\right)+\frac{1}{L} \sum</em>{l&#x3D;1}^L \log p_\theta\left(\mathbf{y} \mid \mathbf{x}, \mathbf{z}^{(l)}\right)<br>$$</p>
<h3 id="Output-inference-and-estimation-of-the-conditional-likelihood"><a href="#Output-inference-and-estimation-of-the-conditional-likelihood" class="headerlink" title="Output inference and estimation of the conditional likelihood"></a>Output inference and estimation of the conditional likelihood</h3><p>推理的时候，评估模型预测准确度时，用z的期望（不采样z）作为样本z（不是直接采样一个z） $\mathbf{y}^*&#x3D;\arg \max _{\mathbf{y}} p_\theta\left(\mathbf{y} \mid \mathbf{x}, \mathbf{z}^<em>\right), \mathbf{z}^</em>&#x3D;\mathbb{E}[\mathbf{z} \mid \mathbf{x}] ^2$</p>
<p>计算这个期望可以用采样多个z的平均值，那么生成的样本变成 $\mathbf{y}^*&#x3D;\arg \max <em>{\mathbf{y}} \frac{1}{L} \sum</em>{l&#x3D;1}^L p_\theta\left(\mathbf{y} \mid \mathbf{x}, \mathbf{z}^{(l)}\right), \mathbf{z}^{(l)} \sim p_\theta(\mathbf{z} \mid \mathbf{x})$ 。</p>
<p>还有一种估计CGM的方法，是比较测试集的条件似然conditional likelihood，直接从prior network（ $p_\theta(z|x)$ ）里采样z个样本（这里z 的先验依赖于x），取似然平均，称为 Monte Carlo (MC) sampling  ：<br>$$<br>p_\theta(\mathbf{y} \mid \mathbf{x}) \approx \frac{1}{S} \sum_{s&#x3D;1}^S p_\theta\left(\mathbf{y} \mid \mathbf{x}, \mathbf{z}^{(s)}\right), \quad \mathbf{z}^{(s)} \sim p_\theta(\mathbf{z} \mid \mathbf{x})<br>$$<br>但是这个方法需要样本数很多才准。因此作者提出用**重要性采样 **importance sampling 来估计条件似然：</p>
<p>这里impotance sampling原理是 $\mathbb{E}<em>{p(a)}[\tau]&#x3D;\mathbb{E}</em>{p(b)}[\frac{p(a)}{p(b)}\tau]$<br>$$<br>p_\theta(\mathbf{y} \mid \mathbf{x}) \approx \frac{1}{S} \sum_{s&#x3D;1}^S \frac{p_\theta\left(\mathbf{y} \mid \mathbf{x}, \mathbf{z}^{(s)}\right) p_\theta\left(\mathbf{z}^{(s)} \mid \mathbf{x}\right)}{q_\phi\left(\mathbf{z}^{(s)} \mid \mathbf{x}, \mathbf{y}\right)}, \quad \mathbf{z}^{(s)} \sim q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y})<br>$$<br>由上面的KL散度可知，$q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y})$ 和 $p_\theta(\mathbf{z} \mid \mathbf{x})$ 越接近越好，越接近说明采样的样本z更接近真实分布，可以用来衡量该样本对结果准确度的重要性。</p>
<h3 id="Learning-to-predict-structured-output"><a href="#Learning-to-predict-structured-output" class="headerlink" title="Learning to predict structured output"></a>Learning to predict structured output</h3><p>用SGVB框架训练有个问题，就是训练时最优化了 $q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y})$ ，但是测试、推理时用的是 $p_\theta(\mathbf{z} \mid \mathbf{x})$ ，（ 先验网络函数在训练里没有更新、$\theta$ 更新是通过生成网络 $p_\theta(y|x,z)$ 更新的 ），因此，可以在训练目标中<strong>加大KL散度项的权重</strong>，也就是让  $q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y})$ 和 $p_\theta(\mathbf{z} \mid \mathbf{x})$ 分布更接近，这样可以让训练和测试时隐变量z编码的差异没那么大。即 $-(1+\beta) K L\left(q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y}) | p_\theta(\mathbf{z} \mid \mathbf{x})\right)$ with $\beta \geq 0$。 加大权重虽然想法很好，但是在实验中发现没什么效果。</p>
<p>因此要找别的方法来减少训练和测试之间的差异，作者通过让 $q_\phi(\mathbf{z} \mid \mathbf{x}, \mathbf{y})&#x3D;p_\theta(\mathbf{z} \mid \mathbf{x})$ ，也就是识别网络和预测网络用同一个网络。</p>
<p>则目标函数变成：<br>$$<br>\widetilde{\mathcal{L}}<em>{\mathrm{GSNN}}(\mathbf{x}, \mathbf{y} ; \theta, \phi)&#x3D;\frac{1}{L} \sum</em>{l&#x3D;1}^L \log p_\theta\left(\mathbf{y} \mid \mathbf{x}, \mathbf{z}^{(l)}\right), \text { where } \mathbf{z}^{(l)}&#x3D;g_\theta\left(\mathbf{x}, \epsilon^{(l)}\right), \epsilon^{(l)} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})<br>$$<br>称这种模型叫 Gaussian stochastic neural network (GSNN)  。结合CVAE和GSMN两种模型，就是两种都用，目标函数变成：<br>$$<br>\widetilde{\mathcal{L}}<em>{hybrid}&#x3D;\alpha\widetilde{\mathcal{L}}</em>{CVAE}+(1-\alpha)\widetilde{\mathcal{L}}_{GSNN}<br>$$</p>
<h3 id="CVAE-for-image-segmentation-and-labeling"><a href="#CVAE-for-image-segmentation-and-labeling" class="headerlink" title="CVAE for image segmentation and labeling"></a>CVAE for image segmentation and labeling</h3><p>针对语义分割任务（属于 structured output prediction task  ）（语音分割应该是每个像素有某类语义），作者对于训练预测网络，提出两种训练方法：</p>
<ol>
<li>multi-scale prediction objective 多尺度预测目标（或者说output，预测出多个尺度的输出）；</li>
<li>structured input noise 结构化输入噪声；</li>
</ol>
<h4 id="Training-with-multi-scale-prediction-objective"><a href="#Training-with-multi-scale-prediction-objective" class="headerlink" title="Training with multi-scale prediction objective"></a>Training with multi-scale prediction objective</h4><p>训练过程中，如下图所示，预测出原始输出的1&#x2F;4、预测出原始输出的1&#x2F;2、预测出原始输出，每个scale预测都有对应scale真实的重建误差。</p>
<p>比如要训练一张图片，一次前向传播中，就输出了1&#x2F;4图片、1&#x2F;2图片和整张图片。</p>
<img src="/2022/12/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CVAE%E8%AE%BA%E6%96%87/image-20221208115448455.png" alt="image-20221208115448455" style="zoom:67%;">



<h4 id="Training-with-input-omission-noise"><a href="#Training-with-input-omission-noise" class="headerlink" title="Training with input omission noise"></a>Training with input omission noise</h4><p>给网络输入噪声是一种正则化方法，作者给输入input加噪，相当于给重建目标增加了难度。具体地，输入比如是图片，那么给输入图片随机一部分mask成0，相当于输入信息变少了（加噪了），给模型增加了难度，可以使得模型的泛化性变好。</p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>数据集 MNIST，任务是visual object segmentation and labeling  图像分割、图像标记。</p>
<p>为了强调通过随机神经网络进行概率推断对于结构化输出变量的重要性，做了一个实验，是将图片分成四个象限，输入三个象限，让模型预测第四个象限、更大胆点，让模型预测更多的象限，随着模型要预测的东西越多（本来只要预测图片的一小部分，逐渐到要预测整张图片），生成的图片和输入图片就会越不同。</p>
<img src="/2022/12/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CVAE%E8%AE%BA%E6%96%87/image-20221208145203584.png" alt="image-20221208145203584" style="zoom:67%;">

<p>CVAE预测得更真实</p>
<p><img src="/2022/12/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CVAE%E8%AE%BA%E6%96%87/image-20221208144045383.png" alt="image-20221208144045383"></p>
<h3 id="Visual-Object-Segmentation-and-Labeling"><a href="#Visual-Object-Segmentation-and-Labeling" class="headerlink" title="Visual Object Segmentation and Labeling"></a>Visual Object Segmentation and Labeling</h3><p>todo</p>
<h3 id="Object-Segmentation-with-Partial-Observations"><a href="#Object-Segmentation-with-Partial-Observations" class="headerlink" title="Object Segmentation with Partial Observations"></a>Object Segmentation with Partial Observations</h3><img src="/2022/12/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CVAE%E8%AE%BA%E6%96%87/image-20221208145555694.png" alt="image-20221208145555694" style="zoom:67%;">

]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Denoising Diffusion Probabilistic Models论文</title>
    <url>/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="Denoising-Diffusion-Probabilistic-Models"><a href="#Denoising-Diffusion-Probabilistic-Models" class="headerlink" title="Denoising Diffusion Probabilistic Models"></a>Denoising Diffusion Probabilistic Models</h1><blockquote>
<p>Ho, Jonathan, Ajay Jain, and Pieter Abbeel. “Denoising diffusion probabilistic models.” <em>Advances in Neural Information Processing Systems</em> 33 (2020): 6840-6851.citations 871 UC Berkeley  </p>
<p>github：<a href="https://github.com/hojonathanho/diffusion">https://github.com/hojonathanho/diffusion</a>  </p>
</blockquote>
<h2 id="一些名词"><a href="#一些名词" class="headerlink" title="一些名词"></a>一些名词</h2><p>denoising score matching and annealed Langevin dynamics  </p>
<p>progressive lossy compression  </p>
<p>生成图片的方式有energy-based modeling 和 score matching 。</p>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>本文提出一种生成模型，叫扩散概率模型 diffusion probabilistic models  ，以生成图片为例，可以通过生成图片的方法来 “denoising”，去噪，能从纯噪声中生成清晰的图片（去噪了）。</p>
<p>扩散模型概述：扩散模型对输入构建了一个马尔科夫链（有隐变量、隐状态的状态转移过程，一步步地，有时间步，一开始不理解为什么有时间步，过程可以用类似自回归的那种时间步来帮助理解，其实不是时间步（也算时间步，迭代了多少次），而是状态转移了多少次），不断加入随机噪声直至其成为无法辨识的纯噪声为止的前向过程，基于变分推断来生成样本，模型学习的是如何从噪声分布里出发，逐渐去除噪声将图片还原至原始的数据分布中。</p>
<p>训练时做的事情是一直加噪让模型学，推理时是反过来reverse 从噪声恢复出图片。</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>扩散过程和逆扩散过程如下图所示，从左到右是逆扩散过程，从右到左是扩散过程。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221212170957805.png" alt="image-20221212170957805" style="zoom:67%;">



<p>一个逐渐加噪声的过程，一共加了T次噪声。输入样本数据 $\mathbf{x}_0 \sim q\left(\mathbf{x}_0\right)$ ，逐渐加入的噪声（隐变量）记为 $\mathbf{x}_1, \ldots, \mathbf{x}<em>T$ ，和输入样本维度相同。扩散模型是隐变量模型，数据分布写为  $p_\theta\left(\mathbf{x}<em>0\right):&#x3D;\int p_\theta\left(\mathbf{x}</em>{0: T}\right) d \mathbf{x}</em>{1: T}$ 。</p>
<p>&#x3D;&#x3D;逆扩散过程&#x3D;&#x3D;：联合分布  $p_\theta\left(\mathbf{x}_{0: T}\right)$ 称为 reverse process，逆扩散过程  ，定义为马尔科夫链，里面有可学习的高斯转移，一开始的位置在 $T$ 时刻（终点，全变成纯噪声了）$p\left(\mathbf{x}_T\right)&#x3D;\mathcal{N}\left(\mathbf{x}_T ; \mathbf{0}, \mathbf{I}\right)$ ，$T$ 时刻的分布是服从标准正态分布的噪声。联合分布 reverse process 写为：</p>
<p>（ “:&#x3D;” 表示 “定义为” ）<br>$$<br>p_\theta\left(\mathbf{x}<em>{0: T}\right):&#x3D;p\left(\mathbf{x}<em>T\right) \prod</em>{t&#x3D;1}^T p_\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right), \quad p_\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right):&#x3D;\mathcal{N}\left(\mathbf{x}</em>{t-1} ; \boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right), \boldsymbol{\Sigma}_\theta\left(\mathbf{x}_t, t\right)\right)<br>$$</p>
<p>前一时间步的条件下当前时间步的概率 $p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)$ <strong>之所以可以写成高斯分布的形式</strong>，是因为终点 $x_T$ 是一个高斯分布的噪声，而变化量 $\beta$ 在(0,1)之间，因此每次的变化量很小，可以认为变化后还是高斯分布。</p>
<p>逆扩散过程是我们在“推理”阶段用的，输入高斯噪声，根据分布，采样出样本来。</p>
<p>&#x3D;&#x3D;扩散过程&#x3D;&#x3D;：扩散模型的近似后验概率分布 $q\left(\mathbf{x}<em>{1: T} \mid \mathbf{x}<em>0\right)$ ， 称为 forward process 或者 diffusion process，扩散过程，这是一个固定的马尔科夫链，逐渐添加进高斯噪声到原始数据里，每一时刻添加噪声后，方差变化量为  $\beta_1, \ldots, \beta_T$ 。近似估计 forward process 写为：<br>$$<br>q\left(\mathbf{x}</em>{1: T} \mid \mathbf{x}<em>0\right):&#x3D;\prod</em>{t&#x3D;1}^T q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right), \quad q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right):&#x3D;\mathcal{N}\left(\mathbf{x}<em>t ; \sqrt{1-\beta_t} \mathbf{x}</em>{t-1}, \beta_t \mathbf{I}\right)<br>$$<br>每个时间步 $t$ 的样本 $x_t$ 来自于 前一个时间步 $t-1$ 的样本服从的高斯分布 $\mathcal{N}\left(\sqrt{1-\beta_t} \mathbf{x}</em>{t-1}, \beta_t  \mathbf{I}\right)$ 中采样而来。这里和vae一样高斯采样用了是重参数技巧，先从标准正态分布中采样，然后乘以方差加上均值得到采样样本。</p>
<p>可以看到，正向<strong>扩散过程不含参数</strong>，只和数据有关。</p>
<p>最优化似然的变分下界来训练：<br>$$<br>\mathbb{E}\left[-\log p_\theta\left(\mathbf{x}<em>0\right)\right] \leq \mathbb{E}<em>q\left[-\log \frac{p_\theta\left(\mathbf{x}</em>{0: T}\right)}{q\left(\mathbf{x}</em>{1: T} \mid \mathbf{x}_0\right)}\right]&#x3D;\mathbb{E}<em>q\left[-\log p\left(\mathbf{x}<em>T\right)-\sum</em>{t \geq 1} \log \frac{p_\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_t\right)}{q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)}\right]&#x3D;: L<br>$$<br>$\beta_t$ 可以通过reparameterization 来得到，或者作为固定超参，是不通过网络更新的已知量，是一个逐渐增长的值（有点像学习率反过来）。（因为 $\beta$ 是越来越大的，所以逆扩散过程是一开始几步都像噪声，看不出什么，直到很多步（快走到 $x_0$），才逐渐变化明显）</p>
<p>这里高斯分布采样也用了重参数技巧，为了方便先用一个变量 $\alpha$ 替换 $\beta$ （变量代换） ，$\alpha_t:&#x3D;1-\beta_t$，$\bar{\alpha}<em>t:&#x3D;\prod</em>{s&#x3D;1}^t \alpha_s$ ，因此均值 $\sqrt{\bar{\alpha}_t} \mathbf{x}_0$ 变为 $\sqrt{\bar{\alpha}_t} \mathbf{x}_0$ ， 方差 $\beta_t \mathbf{I}$ 变为 $\left(1-\bar{\alpha}_t\right) \mathbf{I}$ ，从数据点 $x_0$ 扩散过程到 某个时间步 $x_t$ 的条件概率为：<br>$$<br>q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)&#x3D;\mathcal{N}\left(\mathbf{x}_t ; \sqrt{\bar{\alpha}_t} \mathbf{x}_0,\left(1-\bar{\alpha}_t\right) \mathbf{I}\right)<br>$$</p>
<h2 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h2><blockquote>
<p>b站 <a href="https://www.bilibili.com/video/BV1b541197HX/?spm_id_from=333.788&vd_source=5e9891722f2b62adca440a5e92121b5b">54、Probabilistic Diffusion Model概率扩散模型理论与完整PyTorch代码详细解读</a></p>
</blockquote>
<p>马尔科夫链 简化了概率公式，让当前变量的概率和前一时刻有关， 更前面就无关了。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221213142752987.png" alt="image-20221213142752987" style="zoom:67%;">





<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221213144704383.png" alt="image-20221213144704383" style="zoom: 67%;">

<p>根据 JS琴生不等式 $\log \mathbb E \ge \mathbb E \log$ （ $\varphi(E(X))\le E(\varphi(X))$ ，$\varphi$ 是凸函数（-log才是凸函数））</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221213145018270.png" alt="image-20221213145018270" style="zoom:67%;">

<p>多层VAE（和diffusion还挺像的）</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221213154721745.png" alt="image-20221213154721745" style="zoom:67%;">



<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221213155822450.png" alt="image-20221213155822450" style="zoom:67%;">

<p><strong>扩散过程</strong></p>
<p>（isotropic 各向同性，就是朝各方向分布都是一样的）</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221213161640754.png" alt="image-20221213161640754" style="zoom: 80%;">



<p>服从高斯分布的变量 $\mathcal{N}\left(x_t;\sqrt \alpha_t x_{t-1}, (1-\alpha_t)\mathbf{I}\right)$ 可以写成 <strong>标准正态分布的变量乘以标准差加均值的形式</strong>，也就是 $\mathbf{x}<em>t  &#x3D;\sqrt{1-\alpha_t} \mathbf{z}</em>{t-1} + \sqrt{\alpha_t} \mathbf{x}<em>{t-1}$，其中$z</em>{t-1}$ 是一个标准正态分布，第二项是均值。</p>
<h4 id="两个分布求和"><a href="#两个分布求和" class="headerlink" title="两个分布求和"></a>两个分布求和</h4><p>事先需要知道两个正态分布求和后，均值和方差变成什么样。：两个正态分布 $X \sim N\left(\mu_1, \sigma_1\right)$ 和 $Y \sim N\left(\mu_2, \sigma_2\right)$ 的叠加后的分布 $a X+b Y$ 的均值为 $a \mu_1+b \mu_2$, 方差为 $a^2 \sigma_1^2+b^2 \sigma_2^2$ 。 </p>
<p>下图公式等号第二行，继续展开，将第一行的 $x_{t-1}$ 展开成关于 $x_{t-2}$ 的表达式，和第一行类似。最后全部展开后可以写成只用 $x_0$ 和正态分布$z$来表达的式子。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221213171901197.png" alt="image-20221213171901197" style="zoom:80%;">

<p>什么时候的t会是接近于 $x_t$ 是各向同性高斯分布（就是终点T），什么时候才会到达呢，通过计算 $\sqrt{\bar{\alpha}_t}$ 什么时候接近于0了、 $\left(1-\bar{\alpha}_t\right) $接近于1了，（$\alpha$是常数，逐渐减小，可以类比成学习率那样的，（$\beta$ 越来越大，逐渐增大））就达到正态分布了（ $\mathcal{N}\left(0,\mathbf{I}\right)$ ）	。</p>
<h4 id="五-逆扩散过程："><a href="#五-逆扩散过程：" class="headerlink" title="五 逆扩散过程："></a>五 逆扩散过程：</h4><p>这里 $p_\theta(x_{t-1}|x_t)$ 怎么拟合到高斯分布呢，如果按照之间GMM的做法，GMM的做法是要找一批 $x_t$ 数据，通过最大似然拟合 $x_{t-1}$ 的高斯分布，然后还要找一批 $x_{t-1}$ 数据，拟合 $x_{t-2}$ 的高斯分布，这样就非常麻烦。因此不按GMM的做法，而是从条件概率的表达式出发。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214102706826.png" alt="image-20221214102706826" style="zoom:80%;">



<h4 id="六-后验的扩散条件概率，算均值和方差"><a href="#六-后验的扩散条件概率，算均值和方差" class="headerlink" title="六 后验的扩散条件概率，算均值和方差"></a>六 后验的扩散条件概率，算均值和方差</h4><p>注意这里后验扩散条件概率 $q(x_{t-1}|x_t,x_0)$ 条件有一项是 $x_0$ 。</p>
<p>这里第一行 $q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right) &#x3D;q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}, \mathbf{x}<em>0\right) \frac{q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_0\right)}{q\left(\mathbf{x}_t \mathbf{x}<em>0\right)}$ 的表达式，可以理解为贝叶斯公式 $q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right) &#x3D;q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right) \frac{q\left(\mathbf{x}</em>{t-1}\right)}{q\left(\mathbf{x}_t \right)}$ 然后两边都加上条件 $x_0$ 。</p>
<p>然后最后表达式，由于$a x^2+b x&#x3D;a\left(x+\frac{b}{2 a}\right)^2+C$ ，该分布均值为 $-\frac{b}{2a}$ ， 方差为 $\frac{1}{a}$ 。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214172925086.png" alt="image-20221214172925086" style="zoom:80%;">

<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214172903748.png" alt="image-20221214172903748" style="zoom:80%;">



<p>$q(x_{t-1}|x_t,x_0)$ 均值 $ \tilde \mu_t(x_t,x_0)$ ，方差 $\tilde \beta_t$ 。</p>
<p>$q(x_{t-1}|x_t,x_0)$ 的均值为 $\tilde \mu_t &#x3D; \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline \alpha_t}}z_t)$ ，方差为 $\tilde \beta_t &#x3D;\frac{1-\overline \alpha_{t-1}}{1-\overline\alpha_t}\beta_t$ 。均值和 $x_t$ 、$z_t$ 有关，方差只和 $\beta$ 有关。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214114907047.png" alt="image-20221214114907047" style="zoom:80%;">

  

<h4 id="七-目标数据的似然函数"><a href="#七-目标数据的似然函数" class="headerlink" title="七 目标数据的似然函数"></a>七 目标数据的似然函数</h4><p>第三行 $\log p_\theta(x_0)$ 和 $q$ 无关，提到期望外面。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214151839564.png" alt="image-20221214151839564" style="zoom:80%;">

<p>其中 $\mathbb E_{q(x_0)}\log p_\theta(x_0)$ 就是交叉熵。</p>
<p>下图第三行到第四行用了一个马尔可夫过程，也就是 $q(x_t|x_{t-1},x_0)&#x3D;q(x_t|x_{t-1})$ 近似认为只能前一时刻有关。用贝叶斯公式的时候也是可以把 $x_0$ 当作条件，因此 $q(x_{t-1},x_t|x_0)&#x3D;q(x_t|x_{t-1},x_0)q(x_{t-1}|x_0)&#x3D;q(x_{t-1}|x_t,x_0)q(x_t|x_0)$ 。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214152742669.png" alt="image-20221214152742669" style="zoom:80%;">



<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214173050972.png" alt="image-20221214173050972" style="zoom:80%;">

<p>最后一行第一项是不含参的（不含参指的是和优化目标无关）（q不含参，$x_T$ 是噪声，已知的高斯分布）。写成kl散度形式，外面还有一个期望，可以理解成这个期望不影响，因为里面的KL散度是一个值，一个值的期望还是这个值。第一项直接已知了。第三项可以放到第二项中（ $q(x_0|x_1,x_0)&#x3D;1$ ）。就剩下中间第二项。</p>
<p>把上面的中间项 $L_{t-1}$ 单独写一下，根据高斯分布的kl散度表达式，把之间计算过的 $q(x_{t-1}|x_t,x_0)$ 的均值为 $ \tilde \mu_t(x_t,x_0) &#x3D; \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline \alpha_t}}z_t)$  ，以及 $p_\theta(x_{t-1}|x_t)$ 的均值为 $\mu_\theta(x_t,t)$ 带入。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214173143628.png" alt="image-20221214173143628" style="zoom:80%;">

<p>q和p的方差都是常数（q均值方差都和 $\beta$ 有关，常数；p方差是计算出来发现 只与 $\beta$ 有关，也是常数），kl散度表达式变成只和均值有关。</p>
<p>公式 $L_{t-1}-C$ 的第一行，把 $x_0$ 写成均值加上一个标准分布乘以方差（ $x_0$ 的高斯公式然后均值只和 $x_t$有关）上面已经算过，$x_0$ 和 $x_t$ 的关系是是 $\mathbf{x}_0&#x3D;\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t} \mathbf{z}_t\right)$ 。把 $z_t$ 替换成 $\epsilon $ ， 式子里的 $\epsilon$ 就是服从标准正态分布的变量。第二行其实就是把上面的 $\tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right)&#x3D;\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \mathbf{z}_t\right)$ 抄下来。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221215111217406.png" alt="image-20221215111217406" style="zoom:80%;">





<p>想让两个均值尽可能接近，当相等时，$\mu_\theta(x_t,t)&#x3D;\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t, t\right)\right)$ ，带入到上式，可以得到只剩下 $\epsilon$ 和 $\epsilon_\theta $ （前面有一些系数提到外面），根据上面可知 $x_t$ 和 $x_0$ 的关系是 $x_t&#x3D;\sqrt {\overline \alpha _t}x_0+\sqrt{1-\overline\alpha_t}z_t$ ， 把 $x_0 $ 替换 $x_t$ 带入到 $\epsilon_\theta(x_t,t)$ 公式中。</p>
<p>因此得到 $\epsilon_\theta(x_0,t)$  是和 $x_0$ 和 $t$ 有关的变量。</p>
<p>由于 $\mu_\theta(x_t,t)$ 是 $p_\theta(x_{t-1}|x_t)$ 的均值，因此知道了 $\mu_\theta(x_t,t)$ 表达式（下式），和方差，通过生成随机噪声 $\epsilon$， 也就可以采样出  $x_{t-1}$ 来，逐步采样，直到采样出 $x_0$ ， 也就是原始数据。</p>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221215114958747.png" alt="image-20221215114958747" style="zoom:80%;">



<ul>
<li>training训练过程，从输入数据中挑一个数据 $x_0$ ，再从一个范围里选一个数 $t$ ， 再从标准正态分布中采样一个变量 $\epsilon$ ， 然后目标函数为  $\left|\epsilon-\boldsymbol{\epsilon}_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}, t\right)\right|^2$ ，更新多轮直到收敛。（这里 $T$ 是一个大概通过 $\beta$ 能估算出来的值，大概可以直到多少轮可以变成标准正态分布。）</li>
<li>sampling过程（推理阶段），要做T次（这个值可以给一个想要的数），迭代不同次数，出来的结果 $x_0$ 不同。每次从标准正态分布采样作为 $x_T$ ，迭代T步，每步做的操作是：从标准正态分布中采样 $z$ ， 然后计算前一个时刻的 $x_{t-1}$ （来自 $p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}<em>t\right)&#x3D;\mathcal{N}\left(\mathbf{x}</em>{t-1} ; \boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right), \boldsymbol{\Sigma}_\theta\left(\mathbf{x}_t, t\right)\right)$ ）。迭代了很多步后，最后一个输出作为生成的东西 $x_0$ 。（这里 方差怎么算的？）</li>
</ul>
<img src="/2022/12/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Denoising%20Diffusion%20Probabilistic%20Models%E8%AE%BA%E6%96%87/image-20221214174748619.png" alt="image-20221214174748619">





]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>GLOW论文</title>
    <url>/2022/12/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Glow%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="GLOW"><a href="#GLOW" class="headerlink" title="GLOW"></a>GLOW</h1><blockquote>
<p>Kingma, Durk P., and Prafulla Dhariwal. “Glow: Generative flow with invertible 1x1 convolutions.” <em>Advances in neural information processing systems</em> 31 (2018). citations：1977  openai</p>
<p>github：<a href="https://github.com/openai/glow">https://github.com/openai/glow</a></p>
<p><a href="https://www.bilibili.com/video/BV1Gb411n7dE?p=59">【李宏毅深度学习】P59 Flow-based Generative Model </a></p>
<p>csdn ：<a href="https://blog.csdn.net/daydayjump/article/details/87924066?spm=1001.2101.3001.6650.12&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-12-87924066-blog-115493648.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-12-87924066-blog-115493648.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=13">论文笔记（六）【Glow: Generative Flow with Invertible 1 x 1 Convolutions】</a></p>
</blockquote>
<h4 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h4><p>生成高分辨率自然图像，以及其他生成任务；</p>
<h4 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h4><p>基于flow的生成方法，提出基于1×1卷积的flow方法，叫做glow；</p>
<h4 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h4><p>第一个可以有效生成高分辨率自然图像的基于似然的模型。</p>
<h4 id="存在什么问题"><a href="#存在什么问题" class="headerlink" title="存在什么问题"></a>存在什么问题</h4><p>生成质量不够高？</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>生成模型的方法统称为likelihood-based method，可以分为三类：</p>
<ol>
<li>Autoregressive models 自回归模型，优点是简单，缺点是不能并行处理，计算量和输入长度成正比，不适用于输入长度很高的任务；</li>
<li>Variational autoencoders（VAEs），目标是lower bound on the log-likelihoood of the data，可以并行，优化比较麻烦；</li>
<li>Flow-based generative models 相比于前两种，有几个优点：<ol>
<li>Exact latent-variable inference and log-likelihood evaluation. 精确隐变量推断和对数似然估计。在VAE中，只能推断出与数据点对应的隐变量的近似值，而GAN没有encoder，不能进行latent的推断。由于flow-based model可逆，输出是一个精确值（而不是一个分布，再采样），优化目标也是数据的似然值，而不是lower bound。</li>
<li>Efficient inference and efficient synthesis. 相比于自回归模型，flow在训练和生成过程都可以并行化。</li>
<li>Useful latent space for downstream tasks.   </li>
<li>Significant potential for memory savings.  计算梯度的计算量在不同深度是constant，而不是linear；</li>
</ol>
</li>
</ol>
<h2 id="背景：Flow-based-Generative-Models"><a href="#背景：Flow-based-Generative-Models" class="headerlink" title="背景：Flow-based Generative Models"></a>背景：Flow-based Generative Models</h2><p>对于一个不知道分布情况的数据，我们希望数据经过模型出来的概率值尽可能大，说明模型的输出分布接近数据分布。</p>
<p>数据x，x是高维任意向量，服从某个未知分布，模型输出 $p_\theta (x)$，数据集 $D$ ，log似然目标函数等于最小化：</p>
<ul>
<li>对于离散变量 x：</li>
</ul>
<p>$$<br>\mathcal{L}(\mathcal{D})&#x3D;\frac{1}{N} \sum_{i&#x3D;1}^N-\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right)<br>$$</p>
<ul>
<li>对于连续变量 x：</li>
</ul>
<p>$$<br>\mathcal{L}(\mathcal{D}) \simeq \frac{1}{N} \sum_{i&#x3D;1}^N-\log p_{\boldsymbol{\theta}}\left(\tilde{\mathbf{x}}^{(i)}\right)+c<br>$$</p>
<p>其中 $\tilde{\mathbf{x}}^{(i)}&#x3D;\mathbf{x}^{(i)}+u$ ，$u$ 是服从 $u \sim \mathcal{U}(0, a)$ 的均匀分布； $c&#x3D;-M \cdot \log a$，$a$ 取决于数据的离散程度；$M$ 是 $\mathbf{x}$ 的维度；</p>
<p>对于大部分flow模型来说，生成过程可以定义为：<br>$$<br>\begin{array}{r}<br>\mathbf{z} \sim p_{\boldsymbol{\theta}}(\mathbf{z}) \<br>\end{array}<br>$$<br>$$<br>\mathbf{x}&#x3D;\mathbf{g}_{\boldsymbol{\theta}}(\mathbf{z})<br>$$</p>
<p>其中，$\mathbf{z}$ 是latent variable，隐变量；$p_{\boldsymbol{\theta}}(\mathbf{z})$ 一个很简单、常见的密度函数，比如球形多高斯分布 $p_{\boldsymbol{\theta}}(\mathbf{z})&#x3D;\mathcal{N}(\mathbf{z} ; 0, \mathbf{I})$ ；$\mathbf{g}_{\boldsymbol{\theta}}(..)$ 是可逆的，也被称为 <strong>bijective</strong> 双射（？），因此给一个数据点 $\mathbf{x}$ ，就可以推断出 隐变量 $z$，通过 $\mathbf{z}&#x3D;\mathbf{f}<em>\theta(\mathbf{x})&#x3D;\mathbf{g}<em>\theta^{-1}(\mathbf{x})$ ；为了简化，下面 $\mathrm{f}</em>{\boldsymbol{\theta}}$ 和 $\mathbf{g}</em>{\boldsymbol{\theta}}$ 的公式都省略 $\theta$；</p>
<p>$\mathbf{f}$ （$\mathbf{g}$ 也是）是由一系列transform组成的函数：$\mathbf{f}&#x3D;\mathbf{f}_1 \circ \mathbf{f}_2 \circ \cdots \circ \mathbf{f}_K$ ，因此 $\mathbf{x}$ 和 $\mathbf{z}$ 之间的关系可以写为：<br>$$<br>\mathbf{x} \stackrel{\mathbf{f}_1}{\longleftrightarrow} \mathbf{h}_1 \stackrel{\mathbf{f}_2}{\longleftrightarrow} \mathbf{h}_2 \cdots \stackrel{\mathbf{f}_K}{\longleftrightarrow} \mathbf{z}<br>$$<br>这样的可逆变换序列也称为（归一化）流 <strong>flow</strong>。</p>
<p>通过变换下公式4，数据 $\mathbf{x}$ 的概率密度函数（pdf）可以写成：（参考李宏毅视频里的 $p_\theta (x)&#x3D;p_\theta (z)|det(dz&#x2F;dx)|$ ）<br>$$<br>\begin{aligned}<br>\log p_{\boldsymbol{\theta}}(\mathbf{x}) &amp;&#x3D;\log p_{\boldsymbol{\theta}}(\mathbf{z})+\log |\operatorname{det}(d \mathbf{z} &#x2F; d \mathbf{x})| \<br>&amp;&#x3D;\log p_{\boldsymbol{\theta}}(\mathbf{z})+\sum_{i&#x3D;1}^K \log \left|\operatorname{det}\left(d \mathbf{h}<em>i &#x2F; d \mathbf{h}</em>{i-1}\right)\right|<br>\end{aligned}<br>$$</p>
<p>其中，定义 $\mathbf{h}_0 \triangleq \mathbf{x}$ ， $\mathbf{h}_K \triangleq \mathbf{z}$ ， 标量值 $\log \left|\operatorname{det}\left(d \mathbf{h}<em>i &#x2F; d \mathbf{h}</em>{i-1}\right)\right|$ 是 jacobian矩阵 $\left(d \mathbf{h}<em>i &#x2F; d \mathbf{h}</em>{i-1}\right)$ 的行列式绝对值 取log，也叫 log-determinant；</p>
<p>思路是只选择那些 jacobian $d \mathbf{h}<em>i &#x2F; d \mathbf{h}</em>{i-1}$ 是三角阵的transform，对于这些transform来说，log-determinant 就会很简单，可以写作：<br>$$<br>\log \left|\operatorname{det}\left(d \mathbf{h}<em>i &#x2F; d \mathbf{h}</em>{i-1}\right)\right|&#x3D;\operatorname{sum}\left(\log \left|\operatorname{diag}\left(d \mathbf{h}<em>i &#x2F; d \mathbf{h}</em>{i-1}\right)\right|\right)<br>$$<br>其中，sum() 是所有vector元素求和，log()是element-wise log，diag()是jacobian矩阵的对角阵；</p>
<h2 id="Glow"><a href="#Glow" class="headerlink" title="Glow"></a>Glow</h2><p>基于flow-based的生成模型，它没用之前flow-based模型中的生成器排列方式，在排列方式做了改进，用的1×1卷积；</p>
<p><img src="/2022/12/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Glow%E8%AE%BA%E6%96%87/image-20221201161933655.png" alt="image-20221201161933655"></p>
<p>multi-scale architecture，结构包含actnorm 👉 invertible 1 × 1 convolution  👉 coupling layer ；</p>
<h3 id="Actnorm-scale-and-bias-layer-with-data-dependent-initialization"><a href="#Actnorm-scale-and-bias-layer-with-data-dependent-initialization" class="headerlink" title="Actnorm: scale and bias layer with data dependent initialization"></a>Actnorm: scale and bias layer with data dependent initialization</h3><p>作用是normalization，但是用batch norm会不可逆，因此用activation norm；对每个channel进行缩放和bias（缩放和bias通过仿射变换实现），和BN一样有参数，初始化0均值单位方差；</p>
<p>an actnorm layer (for activation normalizaton), that performs an affine transformation of the activations using a scale and bias parameter per channel,  </p>
<p>。。</p>
<h3 id="Invertible-1-×-1-convolution"><a href="#Invertible-1-×-1-convolution" class="headerlink" title="Invertible 1 × 1 convolution"></a>Invertible 1 × 1 convolution</h3><p>之前生成器堆叠都是固定的排列、堆叠顺序，这里提出一个代替固定排列的方法，是用参数可更新的可逆1×1卷积实现排列，并且这个排列不是固定的，因为里头的参数是会变化、会更新、会学习的。这里1×1卷积起到的作用打乱channel各个维度数据；</p>
<p>这里需要输入输出的channel数量一样。</p>
<p>输入是 $h \times w \times c$ 的tensor，卷积权重矩阵 $\mathbf{W}$ 是 $c \times c$ 的，则 可逆的 $1 \times 1$ convolution 的 log-determinant计算公式为：<br>$$<br>\log \left|\operatorname{det}\left(\frac{d \operatorname{conv} 2 \mathrm{D}(\mathbf{h} ; \mathbf{W})}{d \mathbf{h}}\right)\right|&#x3D;h \cdot w \cdot \log |\operatorname{det}(\mathbf{W})|<br>$$<br>$\operatorname{det}(\mathbf{W})$ 的计算复杂度为 $\mathcal{O}\left(c^3\right)$， 而计算conv2D的复杂度为 $\mathcal{O}\left(h \cdot w \cdot c^2\right)$ ，初始化det为0？，收敛也是到0.</p>
<h4 id="LU-Decomposition"><a href="#LU-Decomposition" class="headerlink" title="LU Decomposition"></a>LU Decomposition</h4><p>$\operatorname{det}(\mathbf{W})$ 的计算复杂度为 $\mathcal{O}\left(c^3\right)$ 可以通过LU分解减少到 $\mathcal{O}(c)$ ：<br>$$<br>\mathbf{W}&#x3D;\mathbf{P L}(\mathbf{U}+\operatorname{diag}(\mathbf{s}))<br>$$<br>其中 $\mathbf{P}$ is a permutation matrix, $\mathbf{L}$ 是对角线上有1的下三角矩阵， $\mathbf{U}$ 是一个对角线上为零的上三角矩阵，  $\mathbf{s}$  是一个 vector。</p>
<p>log-determinant公式简化为：<br>$$<br>\log |\operatorname{det}(\mathbf{W})|&#x3D;\operatorname{sum}(\log |\mathbf{s}|)<br>$$</p>
<h2 id="Affine-Coupling-Layers"><a href="#Affine-Coupling-Layers" class="headerlink" title="Affine Coupling Layers"></a>Affine Coupling Layers</h2><p>下表列出了三个component的函数关系、逆函数的表达式，以及行列式的计算公式；（可参考李宏毅flow视频）</p>
<p>可以看出，行列式计算公式很简单，因此p(x)到p(z)关系很好求；</p>
<p><img src="/2022/12/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Glow%E8%AE%BA%E6%96%87/image-20221202103230674.png" alt="image-20221202103230674"></p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>基于IAF的MAF不能并行，自回归AR也不能并行，合成速度慢；GAN缺少latent-space encoders，输入不是特征x，并且优化困难；</p>
<h2 id="Quantitative-Experiments"><a href="#Quantitative-Experiments" class="headerlink" title="Quantitative Experiments"></a>Quantitative Experiments</h2><p>评价指标是平均负log似然 the average negative log-likelihood (bits per dimension) on the CIFAR-10  （越小越好）</p>
<p><img src="/2022/12/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Glow%E8%AE%BA%E6%96%87/image-20221202095427969.png" alt="image-20221202095427969"></p>
<h2 id="Qualitative-Experiments"><a href="#Qualitative-Experiments" class="headerlink" title="Qualitative Experiments"></a>Qualitative Experiments</h2><p>todo</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="Simple-python-implementation-of-the-invertible-1-×-1-convolution"><a href="#Simple-python-implementation-of-the-invertible-1-×-1-convolution" class="headerlink" title="Simple python implementation of the invertible 1 × 1 convolution"></a>Simple python implementation of the invertible 1 × 1 convolution</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Invertible 1x1 conv</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">invertible_1x1_conv</span>(<span class="params">z, logdet, forward=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="comment"># Shape</span></span><br><span class="line">    h, w, c = z.shape[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sample a random orthogonal matrix to initialise weights</span></span><br><span class="line">    w_init = np.linalg.qr(np.random.randn(c, c))[<span class="number">0</span>]</span><br><span class="line">    w = tf.get_variable(<span class="string">&quot;W&quot;</span>, initializer=w_init)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute log determinant</span></span><br><span class="line">    dlogdet = h * w * tf.log(<span class="built_in">abs</span>(tf.matrix_determinant(w)))</span><br><span class="line">    <span class="keyword">if</span> forward:</span><br><span class="line">        <span class="comment"># Forward computation</span></span><br><span class="line">        _w = tf.reshape(w, [<span class="number">1</span>, <span class="number">1</span>, c, c])</span><br><span class="line">        z = tf.nn.conv2d(z, _w, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], <span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">        logdet += dlogdet</span><br><span class="line">        <span class="keyword">return</span> z, logdet</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Reverse computation</span></span><br><span class="line">        _w = tf.matrix_inverse(w)</span><br><span class="line">        _w = tf.reshape(_w, [<span class="number">1</span>, <span class="number">1</span>, c, c])</span><br><span class="line">        z = tf.nn.conv2d(z, _w, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], <span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">        logdet -= dlogdet</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> z, logdet</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Flow 视频 李宏毅</title>
    <url>/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/</url>
    <content><![CDATA[<h1 id="Flow"><a href="#Flow" class="headerlink" title="Flow"></a>Flow</h1><blockquote>
<p><a href="https://www.bilibili.com/video/BV1Gb411n7dE?p=59">【李宏毅深度学习】P59 Flow-based Generative Model </a></p>
</blockquote>
<p>李宏毅的视频中说的生成器：</p>
<p>输入z，输出生成的样本x，比如人脸生成，经过生成器输出的是一张人脸（x是高维向量，里面每个元素是pixel）；（我们常见的network一般是x到y之间的映射，输出的是p(y|x)，这里的network（generator）代表的是概率分布p，输出的是x）；</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129170650732.png" alt="image-20221129170650732"></p>
<h2 id="Math-background"><a href="#Math-background" class="headerlink" title="Math background"></a>Math background</h2><h3 id="Jacobian"><a href="#Jacobian" class="headerlink" title="Jacobian"></a>Jacobian</h3><p>如果 $f$ 和 $f^{-1}$ 是可逆关系Invertible  ，即 $ff^{-1}&#x3D;I$ ，则他们各自的jacobian也有可逆关系，即 $J_fJ_{f^{-1}}&#x3D;I$ 。</p>
<p>jacobian定义是，输入z向量，输出x向量（输入输出维度不用相同），则jacobian为每个输出对每个输入的偏导数，jacobian的不同行是不同输出，不同列是不同输入；</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129170211549.png" alt="image-20221129170211549"></p>
<h3 id="Determinant"><a href="#Determinant" class="headerlink" title="Determinant"></a>Determinant</h3><p>行列式的关系有 $det(A)&#x3D;1&#x2F;det(A^{-1})$ ，因此jacobian矩阵也适用，得到 $det(J_f)&#x3D;1&#x2F;det(J_{f^{-1}})$ ；</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129170154700.png" alt="image-20221129170154700"></p>
<p><strong>行列式物理意义</strong>：行列式绝对值 想象成<strong>高维空间的体积</strong></p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129170145425.png" alt="image-20221129170145425"></p>
<h3 id="Change-of-Variable-Theorem"><a href="#Change-of-Variable-Theorem" class="headerlink" title="Change of Variable Theorem"></a>Change of Variable Theorem</h3><p>样本z（服从 $\pi(z)$ 分布）送入生成器&#x2F;变换后得到样本x，$x&#x3D;f(z)$，x也有一个分布，叫$p(x)$，我们想知道 $p(x)$ 与 $\pi(z)$ 之间有什么关系。</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129170135548.png" alt="image-20221129170135548"></p>
<p>假设z服从简单的均匀分布（这里上下界为0和1，也就是在[0,1]之间有值）；</p>
<p>这里 $p(x)$ 与 $\pi(z)$ 是概率密度函数；</p>
<p>积分&#x3D;1；</p>
<h4 id="想知道一维-p-x-与-pi-z-之间的关系："><a href="#想知道一维-p-x-与-pi-z-之间的关系：" class="headerlink" title="想知道一维 $p(x)$ 与 $\pi(z)$ 之间的关系："></a>想知道一维 $p(x)$ 与 $\pi(z)$ 之间的关系：</h4><p>矩形面积为 $p(x’)\Delta x$ ，当 $\Delta x$ 很小时，写为 $\delta x$，因此可以得到 $\large p(x’)&#x3D;\pi(z’)|\frac{dz}{dx}|$ ；</p>
<p>加绝对值是因为微分出来可能有正有负，但是 $p(x)$ 与 $\pi(z)$关系不变，因此就直接加绝对值了；</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129170038835.png" alt="image-20221129170038835"></p>
<p>上述是x、z一维的情况；当x、z是二维时：</p>
<h4 id="想知道二维-p-x-与-pi-z-之间的关系："><a href="#想知道二维-p-x-与-pi-z-之间的关系：" class="headerlink" title="想知道二维 $p(x)$ 与 $\pi(z)$ 之间的关系："></a>想知道二维 $p(x)$ 与 $\pi(z)$ 之间的关系：</h4><p>积分这里看成体积，等于面积乘以概率密度（想成是高），这里面积就是行列式，左右两边积分都等于1，所以有：<br>$$<br>p\left(x^{\prime}\right)\left|\operatorname{det}\left[\begin{array}{ll}<br>\Delta x_{11} &amp; \Delta x_{21} \<br>\Delta x_{12} &amp; \Delta x_{22}<br>\end{array}\right]\right|&#x3D;\pi\left(z^{\prime}\right) \Delta z_1 \Delta z_2<br>$$<br>原始分布还是均匀分布（矩形）</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129165952183.png" alt="image-20221129165952183"></p>
<p>其中，$\Delta x_{11}$ 表示 $z_1$ 改变时，$x_1$ 的改变量；$\Delta x_{21}$ 表示 $z_1$ 改变时，$x_2$ 的改变量；$\Delta x_{12}$ 表示 $z_1$ 改变时，$x_2$ 的改变量；$\Delta x_{22}$ 表示 $z_2$ 改变时，$x_2$ 的改变量；</p>
<p><strong>想知道 $p(x)$ 与 $\pi(z)$ 之间的关系：</strong></p>
<p>矩阵做转置transpose，不会改变行列式</p>
<p>公式变换后：</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129171236957.png" alt="image-20221129171236957"></p>
<p>$p(x)$ 与 $\pi(z)$ 之间的关系为：<br>$$<br>p(x’)|det(J_f)|&#x3D;\pi(z’)<br>$$</p>
<p>$$<br>p(x’)&#x3D;\pi(z’)|det(J_{f^-1})|<br>$$</p>
<h2 id="Flow-1"><a href="#Flow-1" class="headerlink" title="Flow"></a>Flow</h2><p>Flow-based generative models 目标是最大似然估计，根据变量变换关系，可以得到：</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221129222418689.png" alt="image-20221129222418689"></p>
<p>（i是第i个样本）</p>
<p>但是这里有一个问题，就是维度一高，计算行列式会很困难，我们虽然能知道jacobian（就是z的变换对x的影响），但是行列式很难求；因此需要好好设计生成器，让生成器的jacobian很容易求行列式；</p>
<p>因为要用到 $G^{-1}$ 所以生成器要是可逆的，并且是好算的、能算的；为了确保G是可逆的，输入z和输出w的维度要是一样的；</p>
<p>因此生成器的条件为：</p>
<ol>
<li>生成器的jacobian很容易求行列式；</li>
<li>生成器要是可逆的；</li>
<li>生成器的输入输出维度相同；（其他生成模型，比如GAN、VAE都是输入维度小于输出的，低维映射到高维）</li>
</ol>
<p>可以看出，对生成器G的限制是很多的，这样子生成器的能力就很有限了；</p>
<p>为了克服该缺点，采用叠加多个G的方法，增大G的能力：</p>
<img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221130002350890.png" alt="image-20221130002350890">

<p>其中， $z^i$ 并不是等于 $G_1^{-1}(x^i)$ ，而是等于  $z^i&#x3D;G_1^{-1}(\cdots G_K^{-1})(x^i))$ ，因为x是最终输出，只有两个G的话是 $x&#x3D;G_2(G_1(z))$ ，因此  $z&#x3D;G_1^{-1}G_2^{-1}(x)$ ；</p>
<p>先考虑一个G的情况：</p>
<p>实际上训练（目标）的是G的逆，而不是G，训练的时候，从真实数据中采样的x作为输入，简单的分布采样z作为输出，训练x到z的映射，然后实际用时，生成器取逆，输入简单分布z，输出样本x；</p>
<p>要最大化似然，第一项、第二项都要最大。第一项最大发生在 $\pi(z)$ 等于0，由于是正态分布（normal distribution）（这里z是正态分布，也是简单分布，不是前面例子的均匀分布），当z等于0时，概率密度 $\pi(z)$ 最大。当z是0向量时，不管输入x是什么，输出z都是0，那么就没有梯度回传，因此G逆的jacobian $J_{G^{-1}}$ 等于0矩阵，因此行列式等于0，$log|det(J_{G^{-1}})|$ 等于负无穷大。</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221130004025703.png" alt="image-20221130004025703"></p>
<p>因此，要给予某种限制，使得第二项 $log|det(J_{G^{-1}})|$  不会接近负无穷大，也就是 $det(J_{G^{-1}})$ 不接近0；</p>
<h3 id="Coupling-layer"><a href="#Coupling-layer" class="headerlink" title="Coupling layer"></a>Coupling layer</h3><p>这里有两篇论文（NICE、Real NVP）提出了解决思路：通过一个coupling layer，其中，这个coupling layer是这样的：z的第1维到第d维直接copy到x，作为x的第1维到第d维，同时也通过两个变换 F 和 H ，得到和z的第d+1维到D维同样维度大小的两个向量，记作 $\beta$ 和 $\gamma$ ，再将z的第d+1维到D维与 $\beta$ element-wise 乘，再加上 $\gamma$，也是element-wise 加，得到x的第d+1维到第D维；</p>
<p><img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221201094831393.png" alt="image-20221201094831393"></p>
<p>其中，z有一部分直接复制给x，因此是可逆的，F和H不要求是不是可逆，可以非常复杂；</p>
<p>因此，从x推到z的表达式为：<br>$$<br>\begin{aligned}<br>z_{i\le d}&#x3D;&amp; x_i \<br>z_{i&gt; d}&#x3D;&amp;\frac{x_i-\gamma_i}{\beta_i}<br>\end{aligned}<br>$$</p>
<img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221201095626840.png" alt="image-20221201095626840" style="zoom:50%;">







<p>求该coupling layer的jacobian：</p>
<img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221201100050032.png" alt="image-20221201100050032" style="zoom:50%;">

<p>左上角直接copy的，因此是jacobian为单位阵；</p>
<p>右上角 $x_1$ 到 $x_d$ 与 $z_{d+1}$ 到 $z_D$ 无关，因此x对z的偏导等于0，jacobian为0矩阵；</p>
<p>左下角我们先不关注，这是因为jacobian有这么一个性质，一个矩阵的jacobian，当左上角是单位阵时，该矩阵的jacobian与右下角的jacobian等价，因此我们只需要求右下角的jacobian；</p>
<p>右下角是对角阵，因为 $x_{i&gt;d}&#x3D;\beta_i z_i+\gamma_i$ ，因此 $x_i$ 只和 $z_i$ 有关，和其他维度无关，因此只有对角线有值，其他都是0，是对角阵；</p>
<p><strong>当一个矩阵是对角阵，该矩阵的行列式计算方法是把对角线的元素乘起来</strong>，因此该coupling layer jacobian的行列式为：<br>$$<br>\begin{aligned}<br>\operatorname{det}\left(J_G\right)<br>&amp;&#x3D;\frac{\partial x_{d+1}}{\partial z_{d+1}} \frac{\partial x_{d+2}}{\partial z_{d+2}} \cdots \frac{\partial x_{\mathrm{D}}}{\partial z_{\mathrm{D}}} \<br>&amp;&#x3D;\beta_{d+1} \beta_{d+2} \cdots \beta_D<br>\end{aligned}<br>$$<br>因此，尽管F、H可能是很复杂的网络，但是最后需要的行列式计算是很容易计算得到的，这才是能够实用的（如果计算公式太复杂，就不实用了）</p>
<p>模型使用coupling layer时，经常是堆叠多个coupling layer，如下图所示。</p>
<p>上面这种堆叠方法是直接堆叠，会造成上半部分的z直接copy到最后，因此简单分布也会被带到末尾，这是我们不希望的。</p>
<p>因此采用下面这种堆叠方法，交替堆叠，使得copy的简单分布部分不会被传到末尾；</p>
<img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221201102620104.png" alt="image-20221201102620104" style="zoom:50%;">



<p>还有其他做法，如下图所示：</p>
<p>图片生成过程，如何把图片拆为一半copy、一半transform呢？可以有两种拆法：</p>
<ol>
<li>image的横轴+纵轴&#x3D;偶数时，copy；等于奇数时，transform；（奇偶可以换）；</li>
<li>image的channel某几个做copy，某几个做transform；</li>
</ol>
<img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221201103039247.png" alt="image-20221201103039247" style="zoom:50%;">



<h3 id="1×1-Convolution"><a href="#1×1-Convolution" class="headerlink" title="1×1 Convolution"></a>1×1 Convolution</h3><p>可以<strong>调换不同位置</strong>，这个调换是模型自己调换的（通过weight），不是人为的。</p>
<img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221201104051509.png" alt="image-20221201104051509" style="zoom:50%;">

<p>将同一位置，不同channel的元素z组成向量，乘以W矩阵，得到对应位置的输出x；</p>
<p>举例：比如z的同一个位置的不同channel组成向量 $[1,2,3]^T$ ，（这个故意对应channel顺序），经过3×3矩阵W后输出x为 $[3,1,2]^T$ ，因此channel顺序就打乱了、调换了。因此说通过一个1×1卷积，可以起到调换位置的作用，shuffle channel。（这里1×1的我理解的是卷积核大小为1×1，channel等于输入的channel）</p>
<p>1×1conv作用后的jacobian：</p>
<img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221201105512654.png" alt="image-20221201105512654" style="zoom:50%;">



<p>z输入是d维，输出d维，他们的jacobian矩阵为d×d维，由多个3×3的W组成，只有对角，因为对应位置的z只与相同位置的x相关，与其他位置不相关。</p>
<p>根据线性代数，行列式表达式为 $(det(W))^{d\times d}$ ；</p>
<img src="/2022/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Flow%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221201110234981.png" alt="image-20221201110234981" style="zoom:50%;">

]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</title>
    <url>/2023/04/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-Task%20Learning%20Using%20Uncertainty%20to%20Weigh%20Losses%20for%20Scene%20Geometry%20and%20Semantics/</url>
    <content><![CDATA[<h1 id="Multi-Task-Learning-Using-Uncertainty-to-Weigh-Losses-for-Scene-Geometry-and-Semantics"><a href="#Multi-Task-Learning-Using-Uncertainty-to-Weigh-Losses-for-Scene-Geometry-and-Semantics" class="headerlink" title="Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics"></a>Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</h1><blockquote>
<p>Kendall, Alex, Yarin Gal, and Roberto Cipolla. “Multi-task learning using uncertainty to weigh losses for scene geometry and semantics.” <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>. 2018. citations 2258</p>
<p>网友复现 github：<a href="https://github.com/ranandalon/mtl">https://github.com/ranandalon/mtl</a></p>
</blockquote>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><p>多任务学习loss如何平衡的问题。</p>
<h3 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h3><ul>
<li>每个任务的同方差不确定性 homoscedastic  uncertainty。将同方差不确定性解释为任务相关的加权。文章中展示了如何推导出一个的多任务损失函数，该函数可以学习平衡各种回归和分类损失。</li>
<li>使用 shared representation（共享encoder输出特征）可以在各种指标（度量）上都能改善性能。</li>
<li>就用一个模型，进行多任务，可以让模型在不同的独立的任务输出之间保持一致，同时减少计算量。</li>
</ul>
<h3 id="本文贡献"><a href="#本文贡献" class="headerlink" title="本文贡献"></a>本文贡献</h3><ol>
<li>利用同方差任务不确定性，同时学习不同数量和单位的各种分类和回归损失的多任务损失。</li>
<li>语义分割、实例分割和深度回归的统一架构。</li>
<li>证明了损失加权在多任务深度学习中的重要性，以及与等效的单独训练模型相比如何获得更好的性能。</li>
</ol>
<h3 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h3><p>与单独学习每个任务相比，本文方法可以学习优化这些权重，从而获得更好的性能。</p>
<p>应用场景的例子是用的 语义分割 semantic segmentation （classify objects at a pixel level  ）、实例分割instance segmentation（回归任务）  、pixel-wise metric depth（depth regression，是一个回归任务  ），同时训练这三个任务。</p>
<h3 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h3><p>。。。</p>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>多任务，这里应用场景的例子是用的 语义分割 semantic segmentation （classify objects at a pixel level  ）、实例分割instance segmentation  、pixel-wise metric depth  ，同时训练这三个任务。</p>
<img src="/2023/04/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-Task%20Learning%20Using%20Uncertainty%20to%20Weigh%20Losses%20for%20Scene%20Geometry%20and%20Semantics/image-20230403102151154.png" alt="image-20230403102151154" style="zoom:80%;">





<p>w&#x3D;0和w&#x3D;1是单独训练模型的情况，w在0-1中间值是联合训练：</p>
<img src="/2023/04/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-Task%20Learning%20Using%20Uncertainty%20to%20Weigh%20Losses%20for%20Scene%20Geometry%20and%20Semantics/image-20230403155801322.png" alt="image-20230403155801322" style="zoom:80%;">



<h3 id="Homoscedastic-uncertainty-as-task-dependent-uncertainty"><a href="#Homoscedastic-uncertainty-as-task-dependent-uncertainty" class="headerlink" title="Homoscedastic uncertainty as task-dependent uncertainty"></a>Homoscedastic uncertainty as task-dependent uncertainty</h3><p>在贝叶斯建模中，有两种主要的不确定性可以建模：</p>
<ul>
<li><strong>Epistemic uncertainty</strong>  认知不确定性。是模型中的不确定性，它捕获了我们的模型由于缺乏训练数据而不知道的东西。这可以用增加的训练数据来解释。</li>
<li><strong>Aleatoric uncertainty</strong>  偶然不确定性。捕捉我们对于数据无法解释的信息的不确定性，可以解释为能够越来越精确地观察所有解释变量。分为两个子类：<ul>
<li><strong>Data-dependent</strong> 或 <strong>Heteroscedastic uncertainty</strong>   是一种依赖于输入数据并被预测为模型输出的 Aleatoric uncertainty。</li>
<li><strong>Task-dependent</strong> 或 <strong>Homoscedastic uncertainty</strong>  不依赖输入数据的 Aleatoric uncertainty，相反，它是一个对所有输入数据保持不变的量，在不同的任务之间变化。因此，它可以被描述为任务相关的不确定性。</li>
</ul>
</li>
</ul>
<p>任务不确定性捕获任务之间的相对置信度，反映回归或分类任务固有的不确定性。它还取决于任务的表示或度量单位。这里用的是 Homoscedastic uncertainty。</p>
<p><code>同方差</code> 指的是假定数据输入一定的情况下，真实的分布与任务的输出之间有一个恒定的方差。</p>
<blockquote>
<p>知乎：<a href="https://www.zhihu.com/question/278182454/answer/398539763?spm=a2c6h.12873639.article-detail.126.15ab6f734hQZYB">Homoskedasticity同方差性与Heteroskedasticity异方差性的区别是什么？</a></p>
</blockquote>
<h3 id="Multi-task-likelihoods"><a href="#Multi-task-likelihoods" class="headerlink" title="Multi-task likelihoods"></a>Multi-task likelihoods</h3><p>推导了一个基于最大化具有同方差不确定性的高斯似然的多任务损失函数。神经网络输入 $\mathbf x$，经过权重 $\mathbf W$，得到输出 $\mathbf f^\mathbf W(\mathbf x)$。</p>
<p>对于回归任务，定义输出的似然值服从一个均值是模型输出的高斯分布，即：<br>$$<br>p\left(\mathbf{y} \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)&#x3D;\mathcal{N}\left(\mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma^2\right)<br>$$<br>其中，$\sigma$ 是观测噪声，是一个标量。</p>
<p>对于分类任务，通常通过一个softmax函数压缩模型输出，并从产生的概率向量中取样：<br>$$<br>p\left(\mathbf{y} \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)&#x3D;\operatorname{Softmax}\left(\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) .<br>$$<br>定义 $\mathrm{f}^{\mathrm{W}}(\mathrm{x})$ 作为充分统计量 sufficient statistics，则多任务似然概率可以分解为：<br>$$<br>p\left(\mathbf{y}_1, \ldots, \mathbf{y}_K \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)&#x3D;p\left(\mathbf{y}_1 \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \ldots p\left(\mathbf{y}_K \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)<br>$$<br>输出 $\mathbf{y}_1, \ldots, \mathbf{y}_K$ 是不同任务的输出。</p>
<p>最大似然推断，用最大化 $\log$ 似然值。</p>
<p>对于回归任务，$\log$ 似然值：<br>$$<br>\log p\left(\mathbf{y} \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \propto-\frac{1}{2 \sigma^2}\left|\mathbf{y}-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right|^2-\log \sigma<br>$$<br>$\sigma$ 是模型的观测噪声参数，<strong>捕捉在输出中有多少噪声</strong>（通过方差来看出输出的变化程度？）。最大log似然估计，参数是 $\mathbf{W}$ 和 $\sigma$。</p>
<p>现在假设模型输出由两个向量 $\mathbf{y}_1$ 和 $\mathbf{y}_2$ 组成，每个向量都服从高斯分布：<br>$$<br>\begin{aligned}<br>p\left(\mathbf{y}_1, \mathbf{y}_2 \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) &amp; &#x3D;p\left(\mathbf{y}_1 \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \cdot p\left(\mathbf{y}_2 \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \<br>&amp; &#x3D;\mathcal{N}\left(\mathbf{y}_1 ; \mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma_1^2\right) \cdot \mathcal{N}\left(\mathbf{y}_2 ; \mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma_2^2\right)<br>\end{aligned}<br>$$<br>最小化多任务loss， $\mathcal{L}\left(\mathbf{W}, \sigma_1, \sigma_2\right)$：<br>$$<br>\begin{aligned}<br>\mathcal{L}\left(\mathbf{W}, \sigma_1, \sigma_2\right) &amp;&#x3D;-\log p\left(\mathbf{y}_1, \mathbf{y}_2 \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \<br>&amp; \propto \frac{1}{2 \sigma_1^2}\left|\mathbf{y}_1-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right|^2+\frac{1}{2 \sigma_2^2}\left|\mathbf{y}_2-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right|^2+\log \sigma_1 \sigma_2 \<br>&amp; &#x3D;\frac{1}{2 \sigma_1^2} \mathcal{L}_1(\mathbf{W})+\frac{1}{2 \sigma_2^2} \mathcal{L}_2(\mathbf{W})+\log \sigma_1 \sigma_2<br>\end{aligned}<br>$$<br>其中，第一个任务输出变量的loss为 $\mathcal{L}_1(\mathbf{W})&#x3D;\left|\mathbf{y}_1-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right|^2$ ， $\mathcal{L}_2(\mathbf{W})$ 也是类似的。</p>
<p>&#x3D;&#x3D;将最后一个关于$\sigma_1$ 和 $\sigma_2$的最小化目标解释为基于数据自适应地学习损失 $\mathcal{L}_1(\mathbf{W})$ 和 $\mathcal{L}_2(\mathbf{W})$ 的相对权重。&#x3D;&#x3D;</p>
<p>当输出 $y_1$ 的噪声参数 $\sigma_1$ 增大，则 $\mathcal{L}_1(\mathbf{W})$ 的权重要减小。目标中的最后一项阻止噪声增加太多（有效地忽略数据），它充当噪声项的正则器。</p>
<p>我的理解是：loss function里的方差项大时，也就是输出似然值变化大，我们希望输出似然值变化不要那么大，要朝着变化小的方向更新，于是这个任务的权重调小一点。                  </p>
<p>对于分类任务，通过一个softmax函数调整分类似然来压缩模型输出的缩放scaled版本<br>$$<br>p\left(\mathbf{y} \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma\right)&#x3D;\operatorname{Softmax}\left(\frac{1}{\sigma^2} \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)<br>$$<br>$\sigma$是一个正数的标量。解释为 Boltzmann distribution (也成为 Gibbs distribution) ，输入缩放到 $\sigma^2$ （通常也叫做 temperature）。这个标量要么是固定的，要么是可以学习的，其中参数的大小决定了离散分布的“均匀”(平坦)程度。这与它的不确定性有关，以熵来衡量。该输出的对数似然可以写成<br>$$<br>\begin{aligned}<br>\log p\left(\mathbf{y}&#x3D;c \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma\right) &amp; &#x3D;\frac{1}{\sigma^2} f_c^{\mathbf{W}}(\mathbf{x}) \<br>&amp; -\log \sum_{c^{\prime}} \exp \left(\frac{1}{\sigma^2} f_{c^{\prime}}^{\mathbf{W}}(\mathbf{x})\right)<br>\end{aligned}<br>$$<br>其中， $f_{c^{\prime}}^{\mathbf{W}}(\mathbf{x})$ 是向量 $\mathbf{f}^{\mathbf{W}}(\mathbf{x})$ 的第 $c^{\prime}$ 个元素。</p>
<p>假设模型的多个输出由连续输出 $y_1$ 和离散输出 $y_2$ 组成，分别用高斯似然和软最大似然建模。就像之前的联合损失一样，$\mathcal{L}\left(\mathbf{W}, \sigma_1, \sigma_2\right)$：<br>$$<br>\begin{aligned}<br>\mathcal{L}\left(\mathbf{W}, \sigma_1, \sigma_2\right)&amp; &#x3D;-\log p\left(\mathbf{y}_1, \mathbf{y}_2&#x3D;c \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right) \<br>&amp; &#x3D;-\log \mathcal{N}\left(\mathbf{y}_1 ; \mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma_1^2\right) \cdot \operatorname{Softmax}\left(\mathbf{y}_2&#x3D;c ; \mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma_2\right) \<br>&amp; &#x3D;\frac{1}{2 \sigma_1^2}\left|\mathbf{y}<em>1-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right|^2+\log \sigma_1-\log p\left(\mathbf{y}<em>2&#x3D;c \mid \mathbf{f}^{\mathbf{W}}(\mathbf{x}), \sigma_2\right) \<br>&amp; &#x3D;\frac{1}{2 \sigma_1^2} \mathcal{L}<em>1(\mathbf{W})+\frac{1}{\sigma_2^2} \mathcal{L}<em>2(\mathbf{W})+\log \sigma_1 \<br>&amp; \qquad \quad+\log \frac{\sum</em>{c^{\prime}} \exp \left(\frac{1}{\sigma_2^2} f</em>{c^{\prime}}^{\mathbf{W}}(\mathbf{x})\right)}{\left(\sum</em>{c^{\prime}} \exp \left(f</em>{c^{\prime}}^{\mathbf{W}}(\mathbf{x})\right)\right)^{\frac{1}{\sigma_2^2}}} \<br>&amp; \approx \frac{1}{2 \sigma_1^2} \mathcal{L}_1(\mathbf{W})+\frac{1}{\sigma_2^2} \mathcal{L}_2(\mathbf{W})+\log \sigma_1+\log \sigma_2,<br>\end{aligned}<br>$$<br>其中， $\mathcal{L}_1(\mathbf{W})&#x3D;\left|\mathbf{y}_1-\mathbf{f}^{\mathbf{W}}(\mathbf{x})\right|^2$ 是 $\mathbf{y}_1$ loss的欧氏距离， $\mathcal{L}_2(\mathbf{W})&#x3D;-\log \operatorname{Softmax}\left(\mathbf{y}_2, \mathbf{f}^{\mathbf{W}}(\mathbf{x})\right)$ 是 $\mathbf{y}_2$ 的交叉熵（ $\mathbf{f}^{\mathrm{W}}(\mathrm{x})$ 没缩放）</p>
<p>（验算了一下是对的）</p>
<p>最优化参数 $\mathbf{W}$ 、 $\sigma_1$ 、$\sigma_2$ 。上式的最后一行是做了简化：假设 $\frac{1}{\sigma_2} \sum_{c^{\prime}} \exp \left(\frac{1}{\sigma_2^2} f_{c^{\prime}}^{\mathbf{W}}(\mathbf{x})\right) \approx$ $\left(\sum_{c^{\prime}} \exp \left(f_{c^{\prime}}^{\mathbf{W}}(\mathbf{x})\right)\right)^{\frac{1}{\sigma_2^2}}$ ，当 $\sigma_2 \rightarrow 1$ 时等号成立。</p>
<p>感觉这一步简化是比较难想到的。。。</p>
<p>最后一个目标可以看作是学习每个输出的损失的相对权重。由 $\frac{1}{2 \sigma_1^2} \mathcal{L}_1(\mathbf{W})$ 可知， 大缩放数值值$\sigma_2$ 会降低 $\mathcal{L}_2(\mathbf{W})$的贡献，反之亦然。缩放值由方程的最后一项决定。当将$\sigma_2$设置太大时，目标将被惩罚。</p>
<h2 id="pytorch版代码实现"><a href="#pytorch版代码实现" class="headerlink" title="pytorch版代码实现"></a>pytorch版代码实现</h2><p>pytorch实现一：</p>
<blockquote>
<p>阿里云社区 <a href="https://developer.aliyun.com/article/1170913">【多任务学习】Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gen_data</span>(<span class="params">N</span>):</span><br><span class="line">    X = np.random.randn(N, <span class="number">1</span>)</span><br><span class="line">    w1 = <span class="number">2.</span></span><br><span class="line">    b1 = <span class="number">8.</span></span><br><span class="line">    sigma1 = <span class="number">1e1</span>  <span class="comment"># ground truth</span></span><br><span class="line">    Y1 = X.dot(w1) + b1 + sigma1 * np.random.randn(N, <span class="number">1</span>)</span><br><span class="line">    w2 = <span class="number">3</span></span><br><span class="line">    b2 = <span class="number">3.</span></span><br><span class="line">    sigma2 = <span class="number">1e0</span>  <span class="comment"># ground truth</span></span><br><span class="line">    Y2 = X.dot(w2) + b2 + sigma2 * np.random.randn(N, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> X, Y1, Y2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TrainData</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, feature_num, X, Y1, Y2</span>):</span><br><span class="line"></span><br><span class="line">        self.feature_num = feature_num</span><br><span class="line"></span><br><span class="line">        self.X = torch.tensor(X, dtype=torch.float32)</span><br><span class="line">        self.Y1 = torch.tensor(Y1, dtype=torch.float32)</span><br><span class="line">        self.Y2 = torch.tensor(Y2, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.feature_num</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.X[idx,:], self.Y1[idx,:], self.Y2[idx,:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiTaskLossWrapper</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, task_num, model</span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiTaskLossWrapper, self).__init__()</span><br><span class="line">        self.model = model</span><br><span class="line">        self.task_num = task_num</span><br><span class="line">        self.log_vars = nn.Parameter(torch.zeros((task_num)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, targets</span>):</span><br><span class="line"></span><br><span class="line">        outputs = self.model(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">        precision1 = torch.exp(-self.log_vars[<span class="number">0</span>])</span><br><span class="line">        loss = torch.<span class="built_in">sum</span>(precision1 * (targets[<span class="number">0</span>] - outputs[<span class="number">0</span>]) ** <span class="number">2.</span> + self.log_vars[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        precision2 = torch.exp(-self.log_vars[<span class="number">1</span>])</span><br><span class="line">        loss += torch.<span class="built_in">sum</span>(precision2 * (targets[<span class="number">1</span>] - outputs[<span class="number">1</span>]) ** <span class="number">2.</span> + self.log_vars[<span class="number">1</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        loss = torch.mean(loss)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss, self.log_vars.data.tolist()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MTLModel</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_hidden, n_output</span>):</span><br><span class="line">        <span class="built_in">super</span>(MTLModel, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.net1 = nn.Sequential(nn.Linear(<span class="number">1</span>, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_output))</span><br><span class="line">        self.net2 = nn.Sequential(nn.Linear(<span class="number">1</span>, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_output))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> [self.net1(x), self.net2(x)]</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">feature_num = <span class="number">100</span></span><br><span class="line">nb_epoch = <span class="number">2000</span></span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line">hidden_dim = <span class="number">1024</span></span><br><span class="line"></span><br><span class="line">X, Y1, Y2 = gen_data(feature_num)</span><br><span class="line">pylab.figure(figsize=(<span class="number">3</span>, <span class="number">1.5</span>))</span><br><span class="line">pylab.scatter(X[:, <span class="number">0</span>], Y1[:, <span class="number">0</span>])</span><br><span class="line">pylab.scatter(X[:, <span class="number">0</span>], Y2[:, <span class="number">0</span>])</span><br><span class="line">pylab.show()</span><br><span class="line"></span><br><span class="line">train_data = TrainData(feature_num, X, Y1, Y2)</span><br><span class="line">train_data_loader = DataLoader(train_data, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">model = MTLModel(hidden_dim, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">mtl = MultiTaskLossWrapper(<span class="number">2</span>, model)</span><br><span class="line">mtl</span><br><span class="line"></span><br><span class="line"><span class="comment"># https://github.com/keras-team/keras/blob/master/keras/optimizers.py</span></span><br><span class="line"><span class="comment"># k.epsilon() = keras.backend.epsilon()</span></span><br><span class="line">optimizer = torch.optim.Adam(mtl.parameters(), lr=<span class="number">0.001</span>, eps=<span class="number">1e-07</span>)</span><br><span class="line"></span><br><span class="line">loss_list = []</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(nb_epoch):</span><br><span class="line">    cumulative_loss = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> X, Y1, Y2 <span class="keyword">in</span> train_data_loader:</span><br><span class="line"></span><br><span class="line">        loss, log_vars = mtl(X, [Y1, Y2])</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        cumulative_loss += loss.item()</span><br><span class="line"></span><br><span class="line">    loss_list.append(cumulative_loss/batch_size)</span><br><span class="line">pylab.plot(loss_list)</span><br><span class="line">pylab.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(log_vars)</span><br><span class="line">[<span class="number">4.2984442710876465</span>, -<span class="number">0.2037072628736496</span>]</span><br><span class="line"><span class="comment"># Found standard deviations (ground truth is 10 and 1):</span></span><br><span class="line"><span class="built_in">print</span>([math.exp(log_var) ** <span class="number">0.5</span> <span class="keyword">for</span> log_var <span class="keyword">in</span> log_vars])</span><br><span class="line">[<span class="number">8.578183137529612</span>, <span class="number">0.9031617364804738</span>]</span><br></pre></td></tr></table></figure>



<p>pytorch实现二：</p>
<blockquote>
<p>csdn：<a href="https://blog.csdn.net/u010212101/article/details/115701136">【论文阅读】Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DynamicWeightedLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DynamicWeightedLoss, self).__init__()</span><br><span class="line">        params = torch.ones(num, requires_grad=<span class="literal">True</span>)</span><br><span class="line">        self.params = torch.nn.Parameter(params)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, *x</span>):</span><br><span class="line">        loss_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, loss <span class="keyword">in</span> <span class="built_in">enumerate</span>(x):</span><br><span class="line">            loss_sum += torch.exp(-self.params[i]) * loss </span><br><span class="line">            + self.params[i]</span><br><span class="line">        <span class="keyword">return</span> loss_sum</span><br></pre></td></tr></table></figure>





<h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>多任务loss间权重如何设置呢，手调太费时，能不能通过loss值的变化大小来反馈给权重呢，要怎么衡量loss值变化呢，衡量变化，也就是衡量不确定性，很容易想到熵是衡量不确定性的。（然后我现在暂时还不知道，为什么是这样）就是对于分类任务，softmax输出乘以一个方差倒数（这个在蒸馏里是temperature），认为是“软最大似然”，这个物理意义为方差的参数$\sigma$ ，用来衡量不确定性，如果某一个任务loss变化大，则方差（不同任务的相对权重）设置为小一点；对于回归任务，认为模型似然服从高斯分布，高斯分布的均值是模型输出（因为没有softmax，所以模型输出不是后验概率），方差是 $\sigma$，然后和分类任务差不多，如果某一个任务loss变化大，则方差（不同任务的相对权重）设置为小一点。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM视频 李宏毅</title>
    <url>/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/</url>
    <content><![CDATA[<h1 id="SVM视频-李宏毅"><a href="#SVM视频-李宏毅" class="headerlink" title="SVM视频 李宏毅"></a>SVM视频 李宏毅</h1><blockquote>
<p>李宏毅机器学习(2017) <a href="https://www.bilibili.com/video/BV13x411v7US?p=31">P31 20- Support Vector Machine (SVM)</a></p>
<p>2023.1.12</p>
</blockquote>
<p>SVM 由 hinge loss 和 kernel 构成</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106161238543.png" alt="image-20230106161238543" style="zoom: 33%;">

<h2 id="hinge-loss"><a href="#hinge-loss" class="headerlink" title="hinge loss"></a>hinge loss</h2><p>二分类 </p>
<p>step 1. 输入到输出的关系是 当f(x)&gt;0 , y&#x3D;1; 当f(x)&lt;0，y&#x3D;-1；数据集标签只有1或-1；</p>
<p>step 2. 设置loss function，如果直接用$\delta$ 函数，不可微，于是用一个可微函数 l， 统计输出和真实标签是否一致的次数。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106161340195.png" alt="image-20230106161340195" style="zoom:50%;">

<p>如果把真实输出标签 $\hat y^n$ 、模型输出 $f(x)$ 和 loss值做成一张图。我们希望 $\hat y^n \cdot f(x)$ 越同向时，loss越小，也就是 当 $y^n$ 为正数时，希望 $f(x)$ 也是正数，并且 $f(x)$ 越大（ $\hat y^n \cdot f(x)$值越大 ）loss值越小；当 $y^n$ 为负数时，希望 $f(x)$ 也是负数，并且 $f(x)$ 越负（ $\hat y^n \cdot f(x)$ 值越大 ） loss值越小；</p>
<p>在图上表示为，横轴值越大，纵轴值越小。</p>
<p>直接用 $\delta$ 函数作为loss 小于0时loss为1，大于0时loss为0，不可微分。因此用其他不同的函数作为loss function。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106161718947.png" alt="image-20230106161718947" style="zoom:50%;">



<p>当loss function设置为 平方loss （square loss）$l(f(x),y)&#x3D;(yf(x)-1)^2$ 是<strong>不合理</strong>的，因为虽然满足y&#x3D;1 f(x)越接近1 loss越小，y&#x3D;-1 f(x)越接近-1 loss越小的条件，但是当 yf(x) 很大时，loss也会很大，这不是我们希望的。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106163449648.png" alt="image-20230106163449648" style="zoom:50%;">



<p>把 yf(x)乘积用sigmoid封装一下，再进行square loss，于是loss function 写作 $l(f(x),y)&#x3D;(\sigma(yf(x))-1)^2$ 。（下图的蓝线）</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106164613584.png" alt="image-20230106164613584" style="zoom:50%;">



<p>loss function 也可以用 sigmoid+ce：先做sigmoid再做CE。（比sigmoid+square更好）</p>
<p>其中 CE的函数是 $\log(1&#x2F;p)&#x3D;-\log(p)$ ，这里p是做完sigmoid的函数，也就是 $\sigma(f(x))$ ，所以loss function 是 $-\log(\sigma(f(x)))&#x3D;-\log(1&#x2F;1+e^{-f(x)})&#x3D;\log(1+e^{-yf(x)})$ 。这里y&#x3D;-1时 $1-\sigma(f(x))&#x3D;\sigma(-f(x))$ 。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106165418155.png" alt="image-20230106165418155" style="zoom:50%;">



<p>hinge loss：</p>
<p>只要 y&#x3D;1 时 f(x)&gt;1 或 y&#x3D;-1时 f(x)&lt;-1，loss就等于0，此时f(x)变化不会对loss有改进、有帮助了。</p>
<p>penalty区域表示虽然 y(f(x))同向，但是还不够好，还要更好（loss还可以下降）。这个”更好”的位置叫做”margin“（这里是1）。</p>
<p>注意下面的好还要更好，指的是右下角图里sigmoid+ce和hinge loss的对比（黑点），对于sigmoid+ce来说，已经在good enough区域了，但是loss还是可以下降的（还可以更好），对于hinge来说，在good enough区域，loss下降不了了。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106171214437.png" alt="image-20230106171214437" style="zoom:50%;">





<p>Linear SVM</p>
<p>linear指的是function是linear的。</p>
<p>二分类，f(x)&gt;0是一个类，f(x)&lt;0是一个类。</p>
<p>loss function是凸函数。</p>
<p><strong>loss function用hinge loss就是 SVM，如果loss function用cross entropy就是LR逻辑回归。</strong></p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106172350809.png" alt="image-20230106172350809" style="zoom:50%;">



<p>linear svm的梯度下降推导：</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106175953527.png" alt="image-20230106175953527" style="zoom:50%;">



<p>linear SVM另一种常见的写法：</p>
<p>把 l(f) 公式里用 $\varepsilon $表示，因为  $\varepsilon$ 的公式是 $\max(0,1-yf(x))$ ，所以认为$ \varepsilon$ 既$\ge$第一项，又 $\ge$第二项，这本身和原公式是不等价的，因为 $ \varepsilon$  可以取很大的数来满足 $\ge$ 的条件，但是max公式里无法得到一个$ \varepsilon$使得这个 $ \varepsilon$可以是一个很大的数。但是！由于这里的目标是<strong>最小化</strong> loss function，因此这里的 “max” 和 “$\ge$” 的条件是可以等价的。（最小化，限制了$ \varepsilon$不能取很大的数，最大就是max中的最大值）。</p>
<p>$ \varepsilon \ge 0$ ，$ \varepsilon \ge 1-\hat yf(x)$ 条件。可以写成 $\hat yf(x) \ge 1- \varepsilon^n $ ，这个是常见的SVM公式，物理意义是 yf(x)大于等于一个margin，这个margin是soft的，本来是“1”，但有时候没办法都满足大于等于1，因此margin稍微做一个放宽，减一个 $\varepsilon$，margin变成 $1- \varepsilon$ 。</p>
<p>因为 $\varepsilon$ 会放宽 margin ，这里 $ \varepsilon$ 叫 slack variable，物理意义是放宽、松弛margin。这个松弛变量是正的，因为如果是负的变成更严格的条件了。</p>
<p>由于是有约束的，用quadradic programming 方法来解。也可以和上文一样用梯度下降来解。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106180009368.png" alt="image-20230106180009368" style="zoom:50%;">



<h2 id="kernel-method"><a href="#kernel-method" class="headerlink" title="kernel method"></a>kernel method</h2><p><strong>这里认为（能最小化loss的）权重w是不同数据点的加权求和</strong> 写作 $w^*&#x3D;\sum_n\alpha_n^*x^n$</p>
<p>解释理由是w初始化0，更新过程是w是一个有关数据点x加权求和的结果。</p>
<p>因为hige loss的很多点出来会是0，因此有很多数据点x对应的权重为0，对结果不起作用，如果权重$\alpha$不等于0，它对结果起作用，称为support vector。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230106180325878.png" alt="image-20230106180325878" style="zoom:50%;">

<p>这里n是训练集，$\alpha$是不同weight，k是不同维度。把k维合成一个向量w。这里 $c^n(w)$ 是loss的偏微分。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230206100841565.png" alt="image-20230206100841565" style="zoom: 50%;">



<p>这里把列向量 $X^T$ 乘以x（内积），得到的列向量记为 $K(x^n, x)$，称为kernel function。</p>
<p>计算 $f(x)$ 时，是将此数据点 $x$ ，与数据集的所有 $X$ 计算内积。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230206101142084.png" alt="image-20230206101142084" style="zoom:50%;">







<p>直接先做x和z的kernel funciton，会比各自做feature transform，再做inner product更快。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230206112108738.png" alt="image-20230206112108738" style="zoom:50%;">



<p>举例：</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230206112537325.png" alt="image-20230206112537325" style="zoom:50%;">



<p>举例：</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230206113700910.png" alt="image-20230206113700910" style="zoom:50%;">







<p>可以理解成是做了一次神经网络，神经网络的参数个数等于数据集的大小n，输入向量 $x$ （多维特征）乘以神经元参数值$x^n$（这个$x^n$是$x_1$、$x_2$、$x_3$、…），得到 $x^n \cdot x$ 向量（下图画的x到x1有好多线，如果只有一条线，是x只有一维，如果多条线，是x是多维特征），然后经过kernel function（比如tanh），然后和$\alpha$进行加权求和，得到某一个数据x下的f(x)。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230206120110190.png" alt="image-20230206120110190" style="zoom:50%;">





<p>kernel function：投影到高维后的内积，物理含义像“相似性”。我们不用把输入特征x映射（变换）到某一个向量，因为这可能不好表示（这个向量不一定能表示这个输入特征），但是如果可以直接在高维空间中得到二者的相似性，这是我们更想要知道的。</p>
<p>判断哪些kernel function是可以的：通过mercer theory进行检查。</p>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230206122348191.png" alt="image-20230206122348191" style="zoom:50%;">



<p>SVM related methods</p>
<ul>
<li>Support Vector Regression (SVR)<ul>
<li>[Bishop chapter 7.1.4]</li>
</ul>
</li>
<li>Ranking SVM<ul>
<li>[Alpaydin, Chapter 13.11]</li>
</ul>
</li>
<li>One-class SVM<ul>
<li>[Alpaydin, Chapter 13.11]</li>
</ul>
</li>
</ul>
<img src="/2023/01/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/SVM%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20230206123519579.png" alt="image-20230206123519579" style="zoom:50%;">

]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Multi-Task Learning as Multi-Objective Optimization</title>
    <url>/2023/04/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-Task%20Learning%20as%20Multi-Objective%20Optimization/</url>
    <content><![CDATA[<h1 id="Multi-Task-Learning-as-Multi-Objective-Optimization"><a href="#Multi-Task-Learning-as-Multi-Objective-Optimization" class="headerlink" title="Multi-Task Learning as Multi-Objective Optimization"></a>Multi-Task Learning as Multi-Objective Optimization</h1><blockquote>
<p>Sener, Ozan, and Vladlen Koltun. “Multi-task learning as multi-objective optimization.” <em>Advances in neural information processing systems</em> 31 (2018).</p>
<p>github：<a href="https://github.com/isl-org/MultiObjectiveOptimization">https://github.com/isl-org/MultiObjectiveOptimization</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/68846373">NIPS2018 - 用多目标优化解决多任务学习</a></p>
</blockquote>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><p>多任务学习loss用线性加权的话，对于存在竞争关系的任务的多任务学习来说，并不有效。要找一个多任务loss方程，能让存在或不存在竞争关系的多任务都能有效学习、优化。</p>
<h3 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h3><p>提出在<strong>多任务学习</strong>中的<strong>基于梯度</strong>的<strong>多目标优化方法</strong>。</p>
<p>找Pareto optimal solutions最优解。提出基于frank-wolfe的优化器，可以将MGDA多目标优化算法扩展到能求高维梯度。</p>
<p>提出MGDA优化目标的上界，可以通过单一的向后传递计算，而没有显式的任务特定梯度。</p>
<p>相当于解决了MGDA多目标优化算法的两个问题，使得该优化方法能</p>
<h3 id="本文贡献"><a href="#本文贡献" class="headerlink" title="本文贡献"></a>本文贡献</h3><p>提出基于frank-wolfe、基于梯度的优化器，可以将MGDA多目标优化算法扩展到能求高维梯度。</p>
<p>提出MGDA优化目标的上界，可以通过单一的向后传递计算，而没有显式的任务特定梯度。</p>
<p>证明使用提出的这个上界，能产生Pareto 最优解。</p>
<h3 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h3><p>本文的应用场景是：用MultiMNIST数据集分类不同数字。用CelebA数据集分类不同label。用Cityscapes数据集做semantic segmentation、instance segmentation 和 depth estimation。任务数量2-40个，都明显优于baseline。</p>
<h3 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h3><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><p>multi-objective optimization  多目标优化：在多个条件下求Pareto 最优解的问题 The problem of finding Pareto optimal solutions given multiple criteria；   </p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>之前人们提出了的多目标优化算法：</p>
<ul>
<li>multiple-gradient descent algorithm (MGDA)  它使用基于梯度的优化，并可证明收敛到帕累托集中的一点(Désidéri, 2012)  MGDA非常适合用于深度网络的多任务学习。它可以使用每个任务的梯度，并解决优化问题，以决定共享参数的更新。但MGDA存在两个问题：<ul>
<li>高维梯度不好求。</li>
<li>该算法需要显式计算每个任务的梯度，这导致向后传递的数量呈线性缩放，并将训练时间大致乘以任务数量。</li>
</ul>
</li>
</ul>
<p>多任务学习通常通过硬参数共享或软参数共享来实现。在硬参数共享中，一部分参数在任务之间共享，而另一部分参数属于特定任务。在软参数共享中，所有参数都是任务特定的，但它们都通过贝叶斯先验进行联合约束，或者一个联合dictionary。本文关注硬参数共享。</p>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>多任务学习之所以比单任务学习效果好，作者认为是多个任务共享了“inductive bias”归纳偏置。</p>
<p>提出基于frank - wolfe的优化器，可以扩展到高维问题。</p>
<p>此外，我们为MGDA优化目标提供了一个上界，并表明它可以通过单一的向后传递计算，而没有显式的任务特定梯度，从而使该方法的计算开销可以忽略不计。</p>
<h3 id="Multi-Task-Learning-as-Multi-Objective-Optimization-1"><a href="#Multi-Task-Learning-as-Multi-Objective-Optimization-1" class="headerlink" title="Multi-Task Learning as Multi-Objective Optimization"></a>Multi-Task Learning as Multi-Objective Optimization</h3><p>经验风险最小化公式：<br>$$<br>\min <em>{\substack{\boldsymbol{\theta}^{s h} \ \boldsymbol{\theta}^1, \ldots, \boldsymbol{\theta}^T}} \sum</em>{t&#x3D;1}^T c^t \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)<br>$$<br>其中，$c^t$是不同任务的权重（ static or dynamically），$\boldsymbol{\theta}^{s h}$ 是共享权重，$\boldsymbol{\theta}^t$ 是任务特定的权重。</p>
<p>$\hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)$ 是任务 $t$ 的 empirical loss，表达式为：$\hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right) \triangleq \frac{1}{N} \sum_i \mathcal{L}\left(f^t\left(\mathbf{x}_i ; \boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right), y_i^t\right)$。</p>
<p>（这个定义可以通过用null标签扩展 $y^t$ 来扩展到只有部分标记的情况。）</p>
<p>但是！训练过程中会出现这么一种情况：共享参数在更新时，某一个参数值下，会变得更适合任务1，而在另一个参数值下，会更适合任务2。某个参数下，在一个任务loss降、另一个任务loss上升。所以要先知道任务之间的重要度（pairwise importance of tasks，两两重要性）</p>
<p>怎么优化呢？多任务学习可以表述为这样的多目标优化：优化一组可能相互冲突的目标（conflicting objectives）。</p>
<p>本文也是用这个思路，用向量值损失 $\mathbf{L}$（vector-valued loss）来表示MTL的多目标优化公式：<br>$$<br>\min _{\substack{\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^1, \ldots, \boldsymbol{\theta}^T}} \mathbf{L}\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^1, \ldots, \boldsymbol{\theta}^T\right)&#x3D;\min _{\substack{\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^1, \ldots, \boldsymbol{\theta}^T}}\left(\hat{\mathcal{L}}^1\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^1\right), \ldots, \hat{\mathcal{L}}^T\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^T\right)\right)^{\boldsymbol{\top}}<br>$$<br>多目标优化的目标是实现 Pareto 最优。</p>
<ul>
<li><strong>定义1</strong> (Pareto optimality for MTL)<ul>
<li>(a) 如果有解 $\boldsymbol{\theta}$ 优于 $\overline{\boldsymbol{\theta}}$ ，是使得对于所有任务 $t$ ，都有 $\hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right) \leq \hat{\mathcal{L}}^t\left(\overline{\boldsymbol{\theta}}^{\text {sh }}, \overline{\boldsymbol{\theta}}^t\right)$ ，并且 $\mathbf{L}\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^1, \ldots, \boldsymbol{\theta}^T\right) \neq \mathbf{L}\left(\overline{\boldsymbol{\theta}}^{s h}, \overline{\boldsymbol{\theta}}^1, \ldots, \overline{\boldsymbol{\theta}}^T\right)$</li>
<li>(b) 如果没有解 $\boldsymbol{\theta}$ 能优于 $\boldsymbol{\theta}^{\star}$ ，则 $\boldsymbol{\theta}^{\star}$ 称为Pareto 最优。</li>
</ul>
</li>
</ul>
<p>Pareto 最优解的集合称为Pareto 集合 $\left(\mathcal{P}<em>\theta\right)$ ，image  称为 Pareto front $\left(\mathcal{P}</em>{\mathbf{L}}&#x3D;{\mathbf{L}(\boldsymbol{\theta})}_{\boldsymbol{\theta} \in \mathcal{P}_\theta}\right)$ 。</p>
<p>本文关注基于梯度的多目标优化，因为它与基于梯度的MTL直接相关。</p>
<p>在第3.1节中总结如何使用梯度下降来执行多目标优化。然后，我们在第3.2节中建议在非常大的参数空间上执行多目标优化的实用算法。最后，在第3.3节中，我们提出了直接为大容量深度网络设计的多目标优化的有效解决方案。</p>
<p>我们的方法适用于非常大的模型和大量的任务，开销可以忽略不计。</p>
<h4 id="Multiple-Gradient-Descent-Algorithm-总结如何使用梯度下降来执行多目标优化"><a href="#Multiple-Gradient-Descent-Algorithm-总结如何使用梯度下降来执行多目标优化" class="headerlink" title="Multiple Gradient Descent Algorithm  总结如何使用梯度下降来执行多目标优化"></a>Multiple Gradient Descent Algorithm  总结如何使用梯度下降来执行多目标优化</h4><p>multiple gradient descent algorithm (MGDA)  利用了 Karush-Kuhn-Tucker (KKT)  条件来优化。</p>
<p>为任务特定参数和共享参数声明KKT条件：</p>
<ul>
<li><p>存在 $\alpha^1, \ldots, \alpha^T \geq 0$ 使得 $\sum_{t&#x3D;1}^T \alpha^t&#x3D;1$ 并且 $\sum_{t&#x3D;1}^T \alpha^t \nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)&#x3D;0$</p>
</li>
<li><p>对于所有任务 $t, \nabla_{\boldsymbol{\theta}^t} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)&#x3D;0$</p>
</li>
</ul>
<p>任何满足这些条件的解都被称为Pareto 不动点。虽然每一个Pareto 最优点都是Pareto不动点，但反过来可能就不是这样了。</p>
<p>优化问题：<br>$$<br>\min <em>{\alpha^1, \ldots, \alpha^T}\left{\left|\sum</em>{t&#x3D;1}^T \alpha^t \nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)\right|<em>2^2 \mid \sum</em>{t&#x3D;1}^T \alpha^t&#x3D;1, \alpha^t \geq 0 \quad \forall t\right}<br>$$<br>要么 该优化问题的解为0，并且得到的点满足KKT条件；要么 解是能给出一个下降方向，可以改善所有任务的。</p>
<p>因此，由此产生的MTL算法将对特定任务参数进行梯度下降，然后求解(3)，并将解 $\left(\sum_{t&#x3D;1}^T \alpha^t \nabla_{\boldsymbol{\theta}^{s h}}\right)$作为共享参数的梯度更新。</p>
<h4 id="Solving-the-Optimization-Problem-建议在非常大的参数空间上执行多目标优化的实用算法"><a href="#Solving-the-Optimization-Problem-建议在非常大的参数空间上执行多目标优化的实用算法" class="headerlink" title="Solving the Optimization Problem   建议在非常大的参数空间上执行多目标优化的实用算法"></a>Solving the Optimization Problem   建议在非常大的参数空间上执行多目标优化的实用算法</h4><p>这里非常大的参数空间指的是共享参数的维度。</p>
<p>以两个任务为例，最优化问题可以写成：$\min <em>{\alpha \in[0,1]}\left|\alpha \nabla</em>{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^1\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^1\right)+(1-\alpha) \nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^2\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^2\right)\right|_2^2$ 。</p>
<p>$\alpha$ 有解析解，是一元二次函数。</p>
<p>也就是上面这个最小化公式对 $\alpha$ 求导等于0，得到 $\alpha$的解析，（其中 $\nabla_{\boldsymbol{\theta}^{s h}} L^1$ 和 $\nabla_{\boldsymbol{\theta}^{s h}} L^2$ 与 $\alpha$ 无关）：<br>$$<br>\hat{\alpha}&#x3D;\left[\frac{\left(\nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^2\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^2\right)-\nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^1\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^1\right)\right)^{\top} \nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^2\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^2\right)}{\left|\nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^1\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^1\right)-\nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^2\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^2\right)\right|<em>2^2}\right]</em>{+, \underset{T}{1}}<br>$$<br>（验证是对的）</p>
<p>这里的 $\alpha$ 理解成 $\alpha^1$ ，所以是更新 $\alpha^1$ 。</p>
<p>其中，$[\cdot]<em>{+,{^1_T}}$ 表示剪裁到 $[0,1] ， 当 $$[\alpha]</em>{+,{^1_T}}&#x3D; \max(min(a; 1); 0)  $ 。这里用了 Frank-Wolfe 算法，因为line search有解析解。使用Frank-Wolfe来解决约束优化问题，使用(4)作为line search的一部分（两个任务）。给出了算法2中Frank-Wolfe求解器的所有更新方程：</p>
<p>$\theta_t$ 的梯度和 $\alpha_t$ 无关， $\alpha_t$ 只作用在 $\theta_{sh}$ 的梯度上。 </p>
<img src="/2023/04/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-Task%20Learning%20as%20Multi-Objective%20Optimization/image-20230412100413392.png" alt="image-20230412100413392" style="zoom:67%;">







<img src="/2023/04/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-Task%20Learning%20as%20Multi-Objective%20Optimization/image-20230411213051491.png" alt="image-20230411213051491" style="zoom:80%;">











<h4 id="Efficient-Optimization-for-Encoder-Decoder-Architectures-提出了直接为大容量深度网络设计的多目标优化的有效解决方案。"><a href="#Efficient-Optimization-for-Encoder-Decoder-Architectures-提出了直接为大容量深度网络设计的多目标优化的有效解决方案。" class="headerlink" title="Efficient Optimization for Encoder-Decoder Architectures  提出了直接为大容量深度网络设计的多目标优化的有效解决方案。"></a>Efficient Optimization for Encoder-Decoder Architectures  提出了直接为大容量深度网络设计的多目标优化的有效解决方案。</h4><p>上面方法有一个比较耗时的地方：$\nabla_{\boldsymbol{\theta}^{s h}}\hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)$ 是通过反向传播计算得到的，一直要计算到对共享参数求导，每个任务都要计算，这样就很耗时了。</p>
<p>作者提出一种只要反向计算一次的方法，就是把优化的公式改了，变成求目标的上界了。</p>
<p>假设模型表达式为：<br>$$<br>f^t\left(\mathbf{x} ; \boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)&#x3D;\left(f^t\left(\cdot ; \boldsymbol{\theta}^t\right) \circ g\left(\cdot ; \boldsymbol{\theta}^{s h}\right)\right)(\mathbf{x})&#x3D;f^t\left(g\left(\mathbf{x} ; \boldsymbol{\theta}^{s h}\right) ; \boldsymbol{\theta}^t\right)<br>$$<br>其中 $g$ 是共享参数函数，  $f^t$ 是任务特定函数。 表示为 $\mathbf{Z}&#x3D;\left(\mathbf{z}_1, \ldots, \mathbf{z}_N\right)$, 其中 $\mathbf{z}_i&#x3D;g\left(\mathbf{x}_i ; \boldsymbol{\theta}^{\text {sh }}\right)$, 也就是经过共享参数函数的输出向量。</p>
<p>用链式法则直接推导出下面的上界：<br>$$<br>\left|\sum_{t&#x3D;1}^T \alpha^t \nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)\right|<em>2^2 \leq\left|\frac{\partial \mathbf{Z}}{\partial \boldsymbol{\theta}^{s h}}\right|<em>2^2\left|\sum</em>{t&#x3D;1}^T \alpha^t \nabla</em>{\mathbf{Z}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)\right|_2^2<br>$$<br>其中 $\left|\frac{\partial \mathbf{Z}}{\partial \boldsymbol{\theta}^{s h}}\right|_2$ 是 $\mathbf{Z}$ 的雅可比矩阵的矩阵范数。</p>
<p>这个上界的两个理想性质是：</p>
<ol>
<li>$\nabla_{\mathbf{Z}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)$ 只需计算一次后向传播？</li>
<li>$\left|\frac{\partial \mathbf{Z}}{\partial \boldsymbol{\theta}^{s h}}\right|_2^2$ 不是关于 $\alpha^1, \ldots, \alpha^T$ 的函数，因此当用作优化目标时，可以删除。</li>
</ol>
<p>把公式里的 $\left|\sum_{t&#x3D;1}^T \alpha^t \nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)\right|_2^2$ 项替换成上界，并且删掉 $\left|\frac{\partial \mathbf{Z}}{\partial \boldsymbol{\theta}^{s h}}\right|_2^2$ 项（因为它不影响优化）</p>
<p>优化问题变成：<br>$$<br>\min <em>{\alpha^1, \ldots, \alpha^T}\left{\left|\sum</em>{t&#x3D;1}^T \alpha^t \nabla_{\mathbf{Z}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)\right|<em>2^2 \mid \sum</em>{t&#x3D;1}^T \alpha^t&#x3D;1, \alpha^t \geq 0 \quad \forall t\right}<br>$$<br>作者把这个问题称为MGDA-UB（(Multiple Gradient Descent Algorithm – Upper Bound）（多重梯度下降算法-上界）。</p>
<p>具体使用起来，就是把上面的算法2（Algorithm 2）流程中计算对共享参数的梯度改成计算对$Z$的梯度，然后 $Z$ 对 $\theta^{sh}$ 的梯度只需要求一次。</p>
<p>作者还证明了一下，这个上界的写法，也是能得到Pareto最优解的（让人们用着放心）：</p>
<p>定理1 ：假设 $\frac{\partial \mathbf{Z}}{\partial \theta^{\text {sh }}}$ 是满秩的。如果 $\alpha^{1, \ldots, T}$ 是 MGDA-UB 的解，下列情况之一是正确的：</p>
<ol>
<li>$\sum_{t&#x3D;1}^T \alpha^t \nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)&#x3D;0$ 并且当前参数是 Pareto stationary 不动点。</li>
<li>$\sum_{t&#x3D;1}^T \alpha^t \nabla_{\boldsymbol{\theta}^{s h}} \hat{\mathcal{L}}^t\left(\boldsymbol{\theta}^{s h}, \boldsymbol{\theta}^t\right)$ 是能减小所有目标的下降方向。</li>
</ol>
<p>只要 $\frac{\partial \mathbf{Z}}{\partial \boldsymbol{\theta}^{s h}}$ 是满秩的，优化上界对应于使用定义的Mahalonobis范数最小化梯度凸组合的范数。非奇点假设是合理的，因为奇点意味着任务是线性相关的，没有必要进行权衡。</p>
<p>总之，本文方法可以证明，可以用可以忽略不计的计算开销找到一个帕累托不动点，并且可以应用于任何具有encoder-decoder模型的深度多目标问题。</p>
<p>证明如下：</p>
<img src="/2023/04/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-Task%20Learning%20as%20Multi-Objective%20Optimization/image-20230412103646281.png" alt="image-20230412103646281" style="zoom: 67%;">



<img src="/2023/04/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Multi-Task%20Learning%20as%20Multi-Objective%20Optimization/image-20230412103704067.png" alt="image-20230412103704067" style="zoom: 67%;">



<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>TODO</p>
<h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>用多目标优化来做多任务学习，模型里有共享特征和各个任务所独自的特征。通过多目标最优化目标函数转换为求Pareto最优，要找能使得多个目标都能最小化的权重分配，通过不同任务之间参数梯度的关系，来更新权重。但这样还不够简单，因为目标函数每个任务都要反向传播很长，就是计算量很多，根据链式法则有一些可以优化，复用的地方，也是本文的创新点，通过优化目标变成优化上界，来减少反向传播的计算量（复用了）。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>VAE 视频 李宏毅</title>
    <url>/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/</url>
    <content><![CDATA[<h1 id="VAE-视频-李宏毅"><a href="#VAE-视频-李宏毅" class="headerlink" title="VAE 视频 李宏毅"></a>VAE 视频 李宏毅</h1><blockquote>
<p><a href="https://www.bilibili.com/video/BV1Ux411S7Yk?p=17&vd_source=5e9891722f2b62adca440a5e92121b5b">李宏毅机器学习(2016) P17.无监督学习——深度生成模型</a></p>
<p><a href="https://www.bilibili.com/video/BV13x411v7US/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">李宏毅机器学习(2017) p28 17- unsupervised learning - deep generative models</a></p>
<p>openai 写的 generative model的博客：<a href="https://openai.com/blog/generative-models/">https://openai.com/blog/generative-models/</a></p>
</blockquote>
<p>回顾 Autoencoder：</p>
<p>image经过encoder，生成一个向量code，再经过decoder，输出一张图片，目标是输入输出尽可能接近；</p>
<p>使用时，输入随意一个向量code到decoder中，看输出什么image；</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221202115750027.png" alt="image-20221202115750027" style="zoom:50%;">



<p>VAE示意图：</p>
<p>autoencoder只用一个向量code，vae则是把code做了一系列操作：</p>
<p>encoder输出一个和code维度相同的向量，记作 $m$ ；encoder同时也输出一个和code维度相同的向量，记作 $\sigma$ ；然后实现准备一个均匀分布，从中随机采样出一个向量（维度和code相同），记作 $e$ ，然后将 $\sigma$ 取exp，与均匀分布样本 $e$ 相乘，再加上 $m$，这里都是element-wise，对应元素相乘、加；</p>
<p>VAE的目标从autoencoder的一个目标增加到两个，一个是和AE一样的最小化重建误差，还有一个是最小化 一个和 $\sigma$ 有关的误差；</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221202115951114.png" alt="image-20221202115951114" style="zoom:50%;">

<p>但是VAE生成出来的图片很模糊，这还能用吗？VAE的优势是什么呢？</p>
<p>取中间向量code的其中两个维度出来，画成直角坐标系，在坐标系上不同的地方取点，然后和之前8维再形成code，送入decoder，观察输出image；</p>
<p>这样做的目的是想看看这两个维度选取不一样的值，对于最终图片的影响。如果图片按某种趋势变化，可以侧面反映出某一个维度的作用、物理含义；比如图片逐渐旋转，可以表示出某一个维度起到的作用是旋转图片；从而改变这个维度的值，就能控制输出图片朝着我们想要的方向生成；</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221202140646680.png" alt="image-20221202140646680" style="zoom:50%;">

<p>如下图所示，横轴代表code的某一维的不同值，纵轴也是代表code的某一维的不同值；</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221202141718600.png" alt="image-20221202141718600" style="zoom:50%;">

<p>那么为什么VAE具有这种效果，也就是说，为什么取某个维度的左右两边不同值，就能起到朝某个趋势变化的作用呢？</p>
<p>原本的autoencoder中，如下面的例子，输入满月图，中间code是某个值a，输入半月图，中间code是某个值b，当我们把code人为取一个a和b中间的值，送入decoder，是否输出的是一个介于满月和半月的图片呢？答案是否定的，因为NN是一个非线性过程，code并不具有线性关系，也就是不具有code和输出的一个趋势变换的关系，不是说code取一个中间值，就能输出一个介于两者之间的图片的；</p>
<p>那么为什么VAE能实现呢？这是因为VAE在训练时，decoder的输入，也就是中间变量code，它并不是一个单个、唯一的值，而是一个小的范围，也就是code+小范围的noise才是decoder的输入。我们希望（训练目标）是输入code a + 小范围noise（code a’ ）时，输出的都是满月；输入code b + 小范围noise（code b’）时，输出都是半月，因此，可能会出现这么一种情况，这两个范围分别取到某个值时，code a + noise a &#x3D; code b + noise b，两个code’ 是相等的，输出对应的既是满月、又是半月，称为“image overlap”，那么输出是要学的是满月还是半月呢？答案是模型要尽可能学到在该输入下，能生成满月的能力，也要学到能生成半月的能力，因此，输入a和b中间值时（从ab范围中sample一个值），输出的就是一个既像满月、又像半月的图片，也就是半满月。因此，VAE具有“趋势性”（我取的），它的code中间值是有物理意义的。</p>
<p><img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221202141948165.png" alt="image-20221202141948165"></p>
<p>基于上述VAE能起到的作用解释，为了给一点物理涵义，这里把几个变量都赋予意义：$m$ 认为是和autoencoder一样的向量code（original code）；变换后的$c$ 认为是加了noise的code；$\sigma$ 认为是noise的方差（其实是 $\exp(\sigma)$ 才表示方差），代表噪声应该要有多大。而因为NN出来可正可负，加exp确保是正值，$\exp(\sigma)$ 表示方差；因此，正态分布中采样的样本 $e$ 乘以方差（本来标准正态每个维度方差相同，乘以一个不同的方差），得到不同方差的正态分布，结果也是一个正态分布模样的样本，理解成噪声。加上 $m$ 就是 原始code + noise了。</p>
<p>方差 $\exp(\sigma)$ 决定了noise的大小，而 $\sigma$ 来自 NN，因此是NN encoder决定了noise的大小，这也是可学习、可更新的参数；</p>
<p>由于是模型自己学的参数，只用最小化重建误差作为目标的话，就会出现方差（ $\exp(\sigma)$ ）等于0的结果，因为方差越小，重建误差越小，这样就没有noise了。因此要新增加一个目标函数，在最小化重建误差的同时，也要限制方差不可以太小。</p>
<p>具体实现“限制方差不可以太小”的目标表达式为：$\sum_{i&#x3D;1}^3(exp(\sigma_i)-(1+\sigma_i)+(m_i)^2)$</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221202142940904.png" alt="image-20221202142940904" style="zoom:50%;">

<p>解释表达式：</p>
<p>蓝线是 $\exp(\sigma_i)$ ，红线是 $1+\sigma_i$ ，绿线是 $\exp(\sigma_i) - (1+\sigma_i)$ ，目标minimize也就是绿线希望取最小值，也就是 $\sigma_i$ 接近0时，此时方差 $\exp(\sigma_i)$ 接近1，方差代表噪声（一部分），因此不会噪声等于0的情况了。（之所以要最小化它，是想让 $\sigma$ 有小，但也别太小（小到0）或者直接限制 $\sigma$ 大于等于0，这样 $\exp(\sigma)$ 也不会趋近于0啊？）</p>
<p>$(m_i)^2$ 是正则项，提高泛化性。</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221202170229264.png" alt="image-20221202170229264" style="zoom:50%;">



<p>以上是定性分析。下面是公式分析。</p>
<p>每个生成器输出，比如图像，想象成是高维空间上的一个点，比如20×20的图片，想象成是400维空间中的一个点。</p>
<p>如果能估计出 $P(x)$ ，采样出的样本就比较是我们所希望的，<strong>因为 $P(x)$ 做采样时会倾向于采样出 $P(x)$ 中概率高的那些样本</strong>。</p>
<p>比如下图的 $P(x)$ 分布，概率高的地方采样都比较像宝可梦，概率低的地方采样比较不像，概率高的地方更容易采样，因此这个 $P(x)$ 估计是合理的。</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221205093748168.png" alt="image-20221205093748168" style="zoom:50%;">



<p>可以用混合高斯分布来估计概率分布</p>
<p>把估计的概率分布 $P(x)$ 近似为 $\sum_mP(m)P(x|m)$ ，其中， $P(m)$ 是不同高斯分布的权重weight，$P(x|m)$ 是不同的高斯分布，$m$ 代表第几个高斯；</p>
<p>采样 $x$ 的过程就变成：</p>
<ol>
<li>从一系列权重分布 $P(m)$ 中采样出某一个值，代表采样出第 $m$ 个高斯（比如从[0.2,0.3,0.4,0.1]的权重向量中（其实应该是权重分布），按照权重分布选出某一个权重，比如0.4，对应第3个）；</li>
<li>从这第 $m$ 个高斯分布中采样出样本，记作 $x$；（比如从第3个高斯分布中采样出一个样本来）</li>
</ol>
<p>虽然概率分布写作不同高斯的不同weight求和，但是采样的时候，是先根据weight采样出第几个高斯、再从该高斯中采样出样本，作为最终采样的样本；</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221205095132363.png" alt="image-20221205095132363" style="zoom:50%;">

<p>用混合高斯分布来估计概率分布，可以看到，采样的时候，其实是从某一个具体的高斯中采样的，x看作是某一类中采样了（称作cluster），这样似乎并不好，更好的做法是用（distributed representation）中采样，就是x并不属于某一个class或cluster，而是用一个vector来描述它各个不同维度、面向的特质。</p>
<p>VAE可以理解为 混合高斯分布的distributed representation版本；VAE的具体做法、流程是：</p>
<p>从一个标准高斯分布中采样出一个样本 $z$  （ $z\sim N(0,I)$ ） （$z$ 是向量vector，<strong>向量 $z$ 的每个维度表示一种特质attribute</strong>，每一维之间相互独立）（采样出来的是连续变量，可以取高斯分布中的任意值），然后变量 $z$ 送入到某一个函数，输出两个向量，一个是均值向量，一个是方差向量（方差是矩阵，这里只取对角阵），根据该均值 $\mu (z)$ 和方差 $\sigma(z)$，就得到了一个高斯分布 $z\sim N(\mu(z),\sigma(z))$ ，这个高斯分布的均值就是这个 $\mu (z)$，方差就是这个 $\sigma(z)$ ，然后再从这个高斯分布中采样，采样出来的样本叫做 $x$ 。</p>
<p>因此z是连续变量、无穷多个可能，由z得到的高斯分布也是连续的，也就是说<strong>有无限个、无穷多个高斯分布</strong>（而不是离散的，用有限个高斯分布去估计 $P(x)$ ）。不同的z对应到不同的高斯分布。每个z都有对应的高斯分布。</p>
<p>用这种方式估计出来的 $P(x)$ 写成的表达式为： $P(x)&#x3D;\int_zP(z)P(x|z)dz$ 。即先从标准正态 $P(z)$ 中采样 $z$ ，再根据 $z$ 得到均值方差，得到高斯分布 $P(x|z)$ ，再采样得到 $x$ 。</p>
<p>这里变量 $z$ 送入到某一个函数，函数用的神经网络NN。</p>
<p>$z$ 服从的分布这里是高斯分布，也可以用别的分布。p(z)简单（高斯）不影响p(x)可以是一个很复杂的分布，因为p(x|z)是用NN拟合，NN拟合能力很强。之所以p(z)用高斯，因为高斯常见，z的attribute特质用高斯分布来描述比较合理。</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221205095944153.png" alt="image-20221205095944153" style="zoom:50%;">



<p>目标是找到、估计一个分布，使得 $P(x)$ 最大，也就是最大似然估计。</p>
<p>我们现在有的是数据、观测值 $x$ ，为了最大似然估计，我们需要另一个分布，叫 $q(z|x)$，让x从某个高斯分布中采样出z来（z不是纯靠前面的标准正态 $P(z)$ 采样的了，而是通过 $q(z|x)$ 中采样的了）。</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221205151712109.png" alt="image-20221205151712109" style="zoom:50%;">

<p>数学推导一下：</p>
<p>目标是最大化观测值x的似然。这里 $logP(x)&#x3D;logP(x)\int_zq(z|x)dz&#x3D;\int_zq(z|x)logP(x)dz$ （ $\int_zq(z|x)dz&#x3D;1$ ），x给定下的z。</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221205152007417.png" alt="image-20221205152007417" style="zoom:50%;">



<p>得到：<br>$$<br>\log P(x) \geq \int_z q(z \mid x) \log \left(\frac{P(x \mid z) P(z)}{q(z \mid x)}\right) d z<br>$$<br>称为 <strong>lower bound</strong>，$L_b$ 。</p>
<p>之所以要引入 $q(z|x)$ ，把目标函数写成和 $P(x|z)$ 、 $q(z|x)$ 有关的形式，是因为最大化 $logP(x)$ 变成了 $L_b$ 。而在 $x$ 给定下， $q(z|x)$ 的变化不影响 $logP(x)$，（$logP(x)$不变），因此此时最大化 $L_b$ ，改变 $q(z|x)$ 使得 $L_b$ 尽可能接近 $logP(x)$ （减少KL散度距离）；再然后， $L_b$ 更大时，由于 $logP(x)$ 一定大于等于 $L_b$ ，所以 $logP(x)$ 也会更大，逐渐最大似然。</p>
<p>如果只用 $P(x|z)$ 这一项，而不是两项都用，可能会出现 $L_b$ 增加，$logP(x)$ 减少的情况（但还是满足$logP(x)$ 大于等于 $L_b$ ）。</p>
<p>？不理解为什么不能直接最大化logP(x)而是要转成最大化L_b。 ？</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221205153652816.png" alt="image-20221205153652816" style="zoom:50%;">

<p>进一步展开公式，将 $L_b$ 展开，可以写成两个式子</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221205163038825.png" alt="image-20221205163038825" style="zoom:50%;">



<p>左式的目标变成最小化 $KL(q(z|x)||P(z))$ ，也就是让 $q(z|x)$ 接近标准正态分布 $P(z)$ ；</p>
<p>右式的目标变成最大化从 $q(z|x)$ 分布中采样 $z$ ，再由 $z\sim N(\mu(z),\sigma(z))$ 中采样出 $x$，使得该高斯函数的均值最接近 $x$ ；</p>
<img src="/2022/12/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%20%E8%A7%86%E9%A2%91%20%E6%9D%8E%E5%AE%8F%E6%AF%85/image-20221205163213233.png" alt="image-20221205163213233" style="zoom:50%;">





<p>可以看出，VAE的目标是尽可能接近数据集的数据，作为生成器可能是不够真实的。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ websocket</title>
    <url>/2023/03/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/C++%20websocket/</url>
    <content><![CDATA[<h1 id="C-websocket"><a href="#C-websocket" class="headerlink" title="C++ websocket"></a>C++ websocket</h1><blockquote>
<p>stackoverflow <a href="https://stackoverflow.com/questions/69051106/c-or-c-websocket-client-working-example">C or C++ websocket client working example</a></p>
<p><a href="https://www.boost.org/doc/libs/develop/libs/beast/example/websocket/client/sync-ssl/websocket_client_sync_ssl.cpp">https://www.boost.org/doc/libs/develop/libs/beast/example/websocket/client/sync-ssl/websocket_client_sync_ssl.cpp</a></p>
<p><a href="https://www.boost.org/doc/libs/master/libs/beast/example/websocket/server/async/websocket_server_async.cpp">https://www.boost.org/doc/libs/master/libs/beast/example/websocket/server/async/websocket_server_async.cpp</a></p>
<p><a href="https://www.boost.org/doc/libs/master/libs/beast/doc/html/beast/examples.html">https://www.boost.org/doc/libs/master/libs/beast/doc/html/beast/examples.html</a></p>
</blockquote>
<p>用到的库为：<code>#include &quot;boost/beast/websocket.hpp&quot;</code></p>
<p>参考wenet里用的是boost的库，这里也用boost学习C++的websocket。</p>
<h3 id="Simple-WebSocket-Client"><a href="#Simple-WebSocket-Client" class="headerlink" title="Simple WebSocket Client"></a>Simple WebSocket Client</h3><blockquote>
<p><a href="https://www.boost.org/doc/libs/master/libs/beast/doc/html/beast/quick_start/websocket_client.html">https://www.boost.org/doc/libs/master/libs/beast/doc/html/beast/quick_start/websocket_client.html</a></p>
</blockquote>
<p>一个websocket 客户端 C++版本的例子，用boost实现</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/beast/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/beast/websocket.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/asio/connect.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/asio/ip/tcp.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> beast = boost::beast;         <span class="comment">// from &lt;boost/beast.hpp&gt;</span></span><br><span class="line"><span class="keyword">namespace</span> http = beast::http;           <span class="comment">// from &lt;boost/beast/http.hpp&gt;</span></span><br><span class="line"><span class="keyword">namespace</span> websocket = beast::websocket; <span class="comment">// from &lt;boost/beast/websocket.hpp&gt;</span></span><br><span class="line"><span class="keyword">namespace</span> net = boost::asio;            <span class="comment">// from &lt;boost/asio.hpp&gt;</span></span><br><span class="line"><span class="keyword">using</span> tcp = boost::asio::ip::tcp;       <span class="comment">// from &lt;boost/asio/ip/tcp.hpp&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Sends a WebSocket message and prints the response</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// Check command line arguments.</span></span><br><span class="line">        <span class="keyword">if</span>(argc != <span class="number">4</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            std::cerr &lt;&lt;</span><br><span class="line">                <span class="string">&quot;Usage: websocket-client-sync &lt;host&gt; &lt;port&gt; &lt;text&gt;\n&quot;</span> &lt;&lt;</span><br><span class="line">                <span class="string">&quot;Example:\n&quot;</span> &lt;&lt;</span><br><span class="line">                <span class="string">&quot;    websocket-client-sync echo.websocket.org 80 \&quot;Hello, world!\&quot;\n&quot;</span>;</span><br><span class="line">            <span class="keyword">return</span> EXIT_FAILURE;</span><br><span class="line">        &#125;</span><br><span class="line">        std::string host = argv[<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">auto</span> <span class="type">const</span>  port = argv[<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">auto</span> <span class="type">const</span>  text = argv[<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// The io_context is required for all I/O</span></span><br><span class="line">        net::io_context ioc;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// These objects perform our I/O</span></span><br><span class="line">        tcp::resolver resolver&#123;ioc&#125;;</span><br><span class="line">        websocket::stream&lt;tcp::socket&gt; ws&#123;ioc&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Look up the domain name</span></span><br><span class="line">        <span class="keyword">auto</span> <span class="type">const</span> results = resolver.<span class="built_in">resolve</span>(host, port);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Make the connection on the IP address we get from a lookup</span></span><br><span class="line">        <span class="keyword">auto</span> ep = net::<span class="built_in">connect</span>(ws.<span class="built_in">next_layer</span>(), results);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Update the host_ string. This will provide the value of the</span></span><br><span class="line">        <span class="comment">// Host HTTP header during the WebSocket handshake.</span></span><br><span class="line">        <span class="comment">// See https://tools.ietf.org/html/rfc7230#section-5.4</span></span><br><span class="line">        host += <span class="string">&#x27;:&#x27;</span> + std::<span class="built_in">to_string</span>(ep.<span class="built_in">port</span>());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Set a decorator to change the User-Agent of the handshake</span></span><br><span class="line">        ws.<span class="built_in">set_option</span>(websocket::stream_base::<span class="built_in">decorator</span>(</span><br><span class="line">            [](websocket::request_type&amp; req)</span><br><span class="line">            &#123;</span><br><span class="line">                req.<span class="built_in">set</span>(http::field::user_agent,</span><br><span class="line">                    std::<span class="built_in">string</span>(BOOST_BEAST_VERSION_STRING) +</span><br><span class="line">                        <span class="string">&quot; websocket-client-coro&quot;</span>);</span><br><span class="line">            &#125;));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Perform the websocket handshake</span></span><br><span class="line">        ws.<span class="built_in">handshake</span>(host, <span class="string">&quot;/&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Send the message</span></span><br><span class="line">        ws.<span class="built_in">write</span>(net::<span class="built_in">buffer</span>(std::<span class="built_in">string</span>(text)));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// This buffer will hold the incoming message</span></span><br><span class="line">        beast::flat_buffer buffer;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Read a message into our buffer</span></span><br><span class="line">        ws.<span class="built_in">read</span>(buffer);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Close the WebSocket connection</span></span><br><span class="line">        ws.<span class="built_in">close</span>(websocket::close_code::normal);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If we get here then the connection is closed gracefully</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// The make_printable() function helps print a ConstBufferSequence</span></span><br><span class="line">        std::cout &lt;&lt; beast::<span class="built_in">make_printable</span>(buffer.<span class="built_in">data</span>()) &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">catch</span>(std::exception <span class="type">const</span>&amp; e)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Error: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">return</span> EXIT_FAILURE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<h3 id="websocket-server"><a href="#websocket-server" class="headerlink" title="websocket server"></a>websocket server</h3><p>服务器端</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Copyright (c) 2016-2019 Vinnie Falco (vinnie dot falco at gmail dot com)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Distributed under the Boost Software License, Version 1.0. (See accompanying</span></span><br><span class="line"><span class="comment">// file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Official repository: https://github.com/boostorg/beast</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Example: WebSocket server, asynchronous</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/beast/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/beast/websocket.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/asio/dispatch.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/asio/strand.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> beast = boost::beast;         <span class="comment">// from &lt;boost/beast.hpp&gt;</span></span><br><span class="line"><span class="keyword">namespace</span> http = beast::http;           <span class="comment">// from &lt;boost/beast/http.hpp&gt;</span></span><br><span class="line"><span class="keyword">namespace</span> websocket = beast::websocket; <span class="comment">// from &lt;boost/beast/websocket.hpp&gt;</span></span><br><span class="line"><span class="keyword">namespace</span> net = boost::asio;            <span class="comment">// from &lt;boost/asio.hpp&gt;</span></span><br><span class="line"><span class="keyword">using</span> tcp = boost::asio::ip::tcp;       <span class="comment">// from &lt;boost/asio/ip/tcp.hpp&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Report a failure</span></span><br><span class="line"><span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">fail</span><span class="params">(beast::error_code ec, <span class="type">char</span> <span class="type">const</span>* what)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cerr &lt;&lt; what &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; ec.<span class="built_in">message</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Echoes back all received WebSocket messages</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">session</span> : <span class="keyword">public</span> std::enable_shared_from_this&lt;session&gt;</span><br><span class="line">&#123;</span><br><span class="line">    websocket::stream&lt;beast::tcp_stream&gt; ws_;</span><br><span class="line">    beast::flat_buffer buffer_;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// Take ownership of the socket</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span></span></span><br><span class="line"><span class="function">    <span class="title">session</span><span class="params">(tcp::socket&amp;&amp; socket)</span></span></span><br><span class="line"><span class="function">        : ws_(std::move(socket))</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get on the correct executor</span></span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">run</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// We need to be executing within a strand to perform async operations</span></span><br><span class="line">        <span class="comment">// on the I/O objects in this session. Although not strictly necessary</span></span><br><span class="line">        <span class="comment">// for single-threaded contexts, this example code is written to be</span></span><br><span class="line">        <span class="comment">// thread-safe by default.</span></span><br><span class="line">        net::<span class="built_in">dispatch</span>(ws_.<span class="built_in">get_executor</span>(),</span><br><span class="line">            beast::<span class="built_in">bind_front_handler</span>(</span><br><span class="line">                &amp;session::on_run,</span><br><span class="line">                <span class="built_in">shared_from_this</span>()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start the asynchronous operation</span></span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">on_run</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// Set suggested timeout settings for the websocket</span></span><br><span class="line">        ws_.<span class="built_in">set_option</span>(</span><br><span class="line">            websocket::stream_base::timeout::<span class="built_in">suggested</span>(</span><br><span class="line">                beast::role_type::server));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Set a decorator to change the Server of the handshake</span></span><br><span class="line">        ws_.<span class="built_in">set_option</span>(websocket::stream_base::<span class="built_in">decorator</span>(</span><br><span class="line">            [](websocket::response_type&amp; res)</span><br><span class="line">            &#123;</span><br><span class="line">                res.<span class="built_in">set</span>(http::field::server,</span><br><span class="line">                    std::<span class="built_in">string</span>(BOOST_BEAST_VERSION_STRING) +</span><br><span class="line">                        <span class="string">&quot; websocket-server-async&quot;</span>);</span><br><span class="line">            &#125;));</span><br><span class="line">        <span class="comment">// Accept the websocket handshake</span></span><br><span class="line">        ws_.<span class="built_in">async_accept</span>(</span><br><span class="line">            beast::<span class="built_in">bind_front_handler</span>(</span><br><span class="line">                &amp;session::on_accept,</span><br><span class="line">                <span class="built_in">shared_from_this</span>()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">on_accept</span><span class="params">(beast::error_code ec)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(ec)</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">fail</span>(ec, <span class="string">&quot;accept&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Read a message</span></span><br><span class="line">        <span class="built_in">do_read</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">do_read</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// Read a message into our buffer</span></span><br><span class="line">        ws_.<span class="built_in">async_read</span>(</span><br><span class="line">            buffer_,</span><br><span class="line">            beast::<span class="built_in">bind_front_handler</span>(</span><br><span class="line">                &amp;session::on_read,</span><br><span class="line">                <span class="built_in">shared_from_this</span>()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">on_read</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        beast::error_code ec,</span></span></span><br><span class="line"><span class="params"><span class="function">        std::<span class="type">size_t</span> bytes_transferred)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        boost::<span class="built_in">ignore_unused</span>(bytes_transferred);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// This indicates that the session was closed</span></span><br><span class="line">        <span class="keyword">if</span>(ec == websocket::error::closed)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(ec)</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">fail</span>(ec, <span class="string">&quot;read&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Echo the message</span></span><br><span class="line">        ws_.<span class="built_in">text</span>(ws_.<span class="built_in">got_text</span>());</span><br><span class="line">        ws_.<span class="built_in">async_write</span>(</span><br><span class="line">            buffer_.<span class="built_in">data</span>(),</span><br><span class="line">            beast::<span class="built_in">bind_front_handler</span>(</span><br><span class="line">                &amp;session::on_write,</span><br><span class="line">                <span class="built_in">shared_from_this</span>()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">on_write</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        beast::error_code ec,</span></span></span><br><span class="line"><span class="params"><span class="function">        std::<span class="type">size_t</span> bytes_transferred)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        boost::<span class="built_in">ignore_unused</span>(bytes_transferred);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(ec)</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">fail</span>(ec, <span class="string">&quot;write&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Clear the buffer</span></span><br><span class="line">        buffer_.<span class="built_in">consume</span>(buffer_.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Do another read</span></span><br><span class="line">        <span class="built_in">do_read</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Accepts incoming connections and launches the sessions</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">listener</span> : <span class="keyword">public</span> std::enable_shared_from_this&lt;listener&gt;</span><br><span class="line">&#123;</span><br><span class="line">    net::io_context&amp; ioc_;</span><br><span class="line">    tcp::acceptor acceptor_;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">listener</span>(</span><br><span class="line">        net::io_context&amp; ioc,</span><br><span class="line">        tcp::endpoint endpoint)</span><br><span class="line">        : <span class="built_in">ioc_</span>(ioc)</span><br><span class="line">        , <span class="built_in">acceptor_</span>(ioc)</span><br><span class="line">    &#123;</span><br><span class="line">        beast::error_code ec;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Open the acceptor</span></span><br><span class="line">        acceptor_.<span class="built_in">open</span>(endpoint.<span class="built_in">protocol</span>(), ec);</span><br><span class="line">        <span class="keyword">if</span>(ec)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">fail</span>(ec, <span class="string">&quot;open&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Allow address reuse</span></span><br><span class="line">        acceptor_.<span class="built_in">set_option</span>(net::socket_base::<span class="built_in">reuse_address</span>(<span class="literal">true</span>), ec);</span><br><span class="line">        <span class="keyword">if</span>(ec)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">fail</span>(ec, <span class="string">&quot;set_option&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Bind to the server address</span></span><br><span class="line">        acceptor_.<span class="built_in">bind</span>(endpoint, ec);</span><br><span class="line">        <span class="keyword">if</span>(ec)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">fail</span>(ec, <span class="string">&quot;bind&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Start listening for connections</span></span><br><span class="line">        acceptor_.<span class="built_in">listen</span>(</span><br><span class="line">            net::socket_base::max_listen_connections, ec);</span><br><span class="line">        <span class="keyword">if</span>(ec)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">fail</span>(ec, <span class="string">&quot;listen&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start accepting incoming connections</span></span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">run</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">do_accept</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">do_accept</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// The new connection gets its own strand</span></span><br><span class="line">        acceptor_.<span class="built_in">async_accept</span>(</span><br><span class="line">            net::<span class="built_in">make_strand</span>(ioc_),</span><br><span class="line">            beast::<span class="built_in">bind_front_handler</span>(</span><br><span class="line">                &amp;listener::on_accept,</span><br><span class="line">                <span class="built_in">shared_from_this</span>()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function">    <span class="title">on_accept</span><span class="params">(beast::error_code ec, tcp::socket socket)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(ec)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">fail</span>(ec, <span class="string">&quot;accept&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Create the session and run it</span></span><br><span class="line">            std::<span class="built_in">make_shared</span>&lt;session&gt;(std::<span class="built_in">move</span>(socket))-&gt;<span class="built_in">run</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Accept another connection</span></span><br><span class="line">        <span class="built_in">do_accept</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// Check command line arguments.</span></span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">4</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt;</span><br><span class="line">            <span class="string">&quot;Usage: websocket-server-async &lt;address&gt; &lt;port&gt; &lt;threads&gt;\n&quot;</span> &lt;&lt;</span><br><span class="line">            <span class="string">&quot;Example:\n&quot;</span> &lt;&lt;</span><br><span class="line">            <span class="string">&quot;    websocket-server-async 0.0.0.0 8080 1\n&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> EXIT_FAILURE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">auto</span> <span class="type">const</span> address = net::ip::<span class="built_in">make_address</span>(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">auto</span> <span class="type">const</span> port = <span class="built_in">static_cast</span>&lt;<span class="type">unsigned</span> <span class="type">short</span>&gt;(std::<span class="built_in">atoi</span>(argv[<span class="number">2</span>]));</span><br><span class="line">    <span class="keyword">auto</span> <span class="type">const</span> threads = std::<span class="built_in">max</span>&lt;<span class="type">int</span>&gt;(<span class="number">1</span>, std::<span class="built_in">atoi</span>(argv[<span class="number">3</span>]));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The io_context is required for all I/O</span></span><br><span class="line">    net::io_context ioc&#123;threads&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create and launch a listening port</span></span><br><span class="line">    std::<span class="built_in">make_shared</span>&lt;listener&gt;(ioc, tcp::endpoint&#123;address, port&#125;)-&gt;<span class="built_in">run</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Run the I/O service on the requested number of threads</span></span><br><span class="line">    std::vector&lt;std::thread&gt; v;</span><br><span class="line">    v.<span class="built_in">reserve</span>(threads - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i = threads - <span class="number">1</span>; i &gt; <span class="number">0</span>; --i)</span><br><span class="line">        v.<span class="built_in">emplace_back</span>(</span><br><span class="line">        [&amp;ioc]</span><br><span class="line">        &#123;</span><br><span class="line">            ioc.<span class="built_in">run</span>();</span><br><span class="line">        &#125;);</span><br><span class="line">    ioc.<span class="built_in">run</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
        <tag>socket通信</tag>
      </tags>
  </entry>
  <entry>
    <title>VAE论文</title>
    <url>/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<h1 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h1><blockquote>
<p>Kingma, Diederik P., and Max Welling. “Auto-encoding variational bayes.” <em>arXiv preprint arXiv:1312.6114</em> (2013). citations：23824 阿姆斯特丹大学</p>
<p>b站视频 <a href="https://www.bilibili.com/video/BV1q64y1y7J2/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">[论文简析]VAE: Auto-encoding Variational Bayes[1312.6114]</a></p>
</blockquote>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>目的是想要在有连续隐变量的条件下估计数据分布。提出基于自编码器和基于变分贝叶斯的方法，能够通过梯度下降的变分贝叶斯就能实现估计数据分布。</p>
<p>两个贡献：</p>
<ol>
<li>证明了变分下界的重参数化产生一个可以使用标准随机梯度方法直接优化的下界估计量。</li>
<li>证明了对于每个数据点具有连续潜在变量的独立同分布数据集，通过使用所提出的下限估计量将近似推理模型(也称为识别模型)拟合到棘手的后验，可以使后验推理特别有效。</li>
</ol>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>想要做的是：有一个高维的数据x，和相对低维的变量z，想根据z条件下、根据参数 $\theta$ 估计出 $p_\theta (x|z)$ ；并且生成的数据点x，又能在参数 $\phi$ 的条件下，估计出$q_\phi (z|x)$ 来。</p>
<p>想要找到 $p_{\theta^*}(x|z)$ 和 $p_{\theta^*}(z)$ 之间的是如何映射的，映射关系。（*表示groundtruth）</p>
<img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221205174352023.png" alt="image-20221205174352023" style="zoom:50%;">



<p>概念：variational  ，变分，我理解就是在观测值x的条件下的隐变量z的某个特性；比如变分估计，就是 $q(z|x)$ 。</p>
<p>把x理解为数据样本，比如图像，z理解为特征，比如图像的颜色、大小等。x一般比z的维度高。</p>
<h3 id="Problem-scenario"><a href="#Problem-scenario" class="headerlink" title="Problem scenario"></a>Problem scenario</h3><ol>
<li><p>Intractability:  想要求的是数据分布 marginal likelihood   $p_\theta (x)&#x3D;\int p_\theta(z)p_\theta(x|z)dz$  这是intractable，因为很高维，可能是好多个积分，很难求的、很难估计的（用mean-field VB  方法不好求解），估计隐变量的真实后验密度函数pdf  $p_\theta(z|x)&#x3D;p_\theta(x|z)p_\theta(z)&#x2F;p_\theta (x)$ 也是intractable （所以不能用em求解这种带隐变量的概率分布问题）。但在NN里是可以实现的，可以用一个NN去拟合 $p_\theta(z|x)$ ，去接近这个分布。</p>
</li>
<li><p>A large dataset:   用minibatch进行参数更新，才不会使得参数更新太慢，相比于Monte Carlo EM  这种逐数据更新的方式来说要快得多。</p>
</li>
</ol>
<p>解决了相关问题：</p>
<ol>
<li>有效近似了ML最大似然估计、MAP最大后验估计里面的参数 $\theta$ 。</li>
<li>在给定观测值 $x$ 的条件下，有效近似了隐变量 $z$ 的后验概率 $p(z|x)$ 。</li>
<li>有效近似了 $x$ 的 marginal inference ，因此可以生成样本 $x$ ， 估计了 $p(x)$ 。（在计算机视觉的应用包括图像去噪、图像插值和超分辨）</li>
</ol>
<p>为了解决以上3个问题，需要引入一个recognition model   $q_\phi(z|x)$ ，它是 $p_\theta(z|x)$ 的近似（ $p_\theta(z|x)$ 很难算）（mean-field variational inference  方法里也提过用一个近似q，但是这个近似q的参数是单独算出来的），VAE提出了一种新的计算方法、目标，是把 $\phi$ （recognition model 的参数）和 $\theta$ （generative model 的参数）在一个目标里学习、更新参数。只要 $q_\phi(z|x)$ 和 $p_\theta(z|x)$ 很接近，就相当于把 $p_\theta(z|x)$  估计出来了，而衡量两个分布之间相似程度的方法有KL散度，只要两个分布很接近，即KL散度很小，那么q也就是我们想要的p了，因此目标有一个是最小化KL散度。</p>
<p>把隐变量 $z$ 向量称为“code”，把 recognition model $q_\phi(z|x)$ 称为probabilistic encoder  ，把 generative model  $p_\theta(x|z)$ 称为probabilistic decoder  。</p>
<p>encoder $q_\phi(z|x)$：给定一个数据点 $x$ ，它服从一个分布（比如高斯分布），从中采样出向量code $z$；</p>
<p>decoder $p_\theta(x|z)$：给定向量code $z$ ，服从一个分布，从中采样出 $x$ ；</p>
<h3 id="The-variational-bound"><a href="#The-variational-bound" class="headerlink" title="The variational bound"></a>The variational bound</h3><p>开始进行公式推导。</p>
<p>参考李宏毅PPT的推导：</p>
<p>1</p>
<img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206114625872.png" alt="image-20221206114625872" style="zoom:50%;">



<p>2</p>
<img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206114438846.png" alt="image-20221206114438846" style="zoom:50%;">

<p>3</p>
<img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206114417218.png" alt="image-20221206114417218" style="zoom:50%;">

<p>总marginal likelihood  由多个独立样本点的marginal likelihood 组成：$\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(1)}, \cdots, \mathbf{x}^{(N)}\right)&#x3D;\sum_{i&#x3D;1}^N \log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right)$ 。可以写成：（参考李宏毅的推导）<br>$$<br>\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right)&#x3D;D_{K L}\left(q_{\boldsymbol{\phi}}\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right) | p_{\boldsymbol{\theta}}\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right)\right)+\mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)<br>$$</p>
<p>（ $\mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)$ 即李宏毅PPT的 $L_b$ ）</p>
<p>第一项是近似分布和真实分布之间的KL散度距离，非负的；第二项称为 (variational) lower bound，是数据点i的marginal likelihood 的下界，</p>
<p><strong>左边 $\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right) $ 是一个常数（x给定了），想要最小化KL散度，也就是最大化lower bound。</strong></p>
<p>variational lower bound ：<br>$$<br>\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right) \geq \mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)&#x3D;\mathbb{E}<em>{q</em>{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[-\log q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})+\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})\right]<br>$$<br>也可以写成：<br>$$<br>\mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)&#x3D;-D_{K L}\left(q_{\boldsymbol{\phi}}\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right) | p_{\boldsymbol{\theta}}(\mathbf{z})\right)+\mathbb{E}<em>{q</em>{\boldsymbol{\phi}}\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)} \mid \mathbf{z}\right)\right]<br>$$<br>第一项叫做regularization loss，是让估计的q接近z的先验分布；第二项叫 reconstruction loss，当在z条件下采样出的x与真实的数据x越接近，该概率会越大，和autoencoder一样，因此叫做重建误差。</p>
<p>想求<strong>偏导、最优化</strong> $\mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)$  ，同时更新variational parameters $\phi$ 和 generative parameters $\theta$ 。但是lower bound的梯度（即 $\phi$）算起来有点问题，自然的想到用蒙特卡洛方法：$\nabla_{\boldsymbol{\phi}} \mathbb{E}<em>{q_\phi(\mathbf{z})}[f(\mathbf{z})]&#x3D;\mathbb{E}</em>{q_\phi(\mathbf{z})}\left[f(\mathbf{z}) \nabla_{q_{\boldsymbol{\phi}}(\mathbf{z})} \log q_{\boldsymbol{\phi}}(\mathbf{z})\right] \simeq \frac{1}{L} \sum_{l&#x3D;1}^L f(\mathbf{z}) \nabla_{q_{\boldsymbol{\phi}}\left(\mathbf{z}^{(l)}\right)} \log q_{\boldsymbol{\phi}}\left(\mathbf{z}^{(l)}\right)$ where $\mathbf{z}^{(l)} \sim q_{\boldsymbol{\phi}}\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right)$ 。</p>
<p>蒙特卡洛推导过程：</p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206150822009.png" alt="image-20221206150822009"></p>
<p>这个梯度估计量会有很高的方差、不稳定。</p>
<p>因此作者提出SGVB估计方法，来进行参数求导。</p>
<h3 id="参数求导-The-SGVB-estimator-and-AEVB-algorithm"><a href="#参数求导-The-SGVB-estimator-and-AEVB-algorithm" class="headerlink" title="参数求导 The SGVB estimator and AEVB algorithm"></a>参数求导 The SGVB estimator and AEVB algorithm</h3><p>VAE提出一种实用的估计下界及其导数、求参数的方法。</p>
<p>原本是直接求导，但是把求导项 $\nabla_\theta \mathbb{E}_{p_\theta(z)}\left[f_\theta(z)\right]$ 展开，发现有一项 $\int_z f_\theta(z) \nabla_\theta p_\theta(z) d z$ 不好求。</p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206151849341.png" alt="image-20221206151849341"></p>
<p>因此作者想了一个方法，重参数技巧  reparameterization trick  。引入一个独立变量 $\epsilon$ （和 $\theta$ 、 $\phi$  、x、z 都无关），用它来产生“随机性”，之后 <strong>随机性都由 $\epsilon$ 来产生</strong>。</p>
<p>之前抽样的随机性，这是没法用反向传播的，现在随机性用 $\epsilon$ ，就可以反向传播了。</p>
<p>已知 $\widetilde{\mathbf{z}} \sim q_\phi(\mathbf{z} \mid \mathbf{x})$ ，重参数化，用一个可微函数，条件是 $x$ 和噪声 $\epsilon$ 的函数 $g$ ，来表示原来的 $q$ ：<br>$$<br>\widetilde{\mathbf{z}}&#x3D;g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}, \mathbf{x}) \quad \text { with } \quad \boldsymbol{\epsilon} \sim p(\boldsymbol{\epsilon})<br>$$<br>此时再用蒙特卡洛法估计期望，就可以写成：<br>$$<br>\mathbb{E}<em>{q_\phi\left(\mathbf{z} \mid \mathbf{x}^{(i)}\right)}[f(\mathbf{z})]&#x3D;\mathbb{E}</em>{p(\boldsymbol{\epsilon})}\left[f\left(g_{\boldsymbol{\phi}}\left(\boldsymbol{\epsilon}, \mathbf{x}^{(i)}\right)\right)\right] \simeq \frac{1}{L} \sum_{l&#x3D;1}^L f\left(g_\phi\left(\boldsymbol{\epsilon}^{(l)}, \mathbf{x}^{(i)}\right)\right) \quad \text { where } \quad \boldsymbol{\epsilon}^{(l)} \sim p(\boldsymbol{\epsilon})<br>$$<br>用到公式(2)，得到一般随机梯度变分贝叶斯（SGVB）估计  $\widetilde{\mathcal{L}}^A\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right) \simeq \mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)$ :<br>$$<br>\begin{aligned}<br>&amp; \widetilde{\mathcal{L}}^A\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)&#x3D;\frac{1}{L} \sum_{l&#x3D;1}^L \log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}, \mathbf{z}^{(i, l)}\right)-\log q_{\boldsymbol{\phi}}\left(\mathbf{z}^{(i, l)} \mid \mathbf{x}^{(i)}\right) \<br>&amp; \text { where } \quad \mathbf{z}^{(i, l)}&#x3D;g_{\boldsymbol{\phi}}\left(\boldsymbol{\epsilon}^{(i, l)}, \mathbf{x}^{(i)}\right) \quad \text { and } \quad \boldsymbol{\epsilon}^{(l)} \sim p(\boldsymbol{\epsilon})<br>\end{aligned}<br>$$</p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206153613903.png" alt="image-20221206153613903"></p>
<p>由于引入了 $\epsilon$ ，原L_b公式写为：</p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206153745705.png" alt="image-20221206153745705"></p>
<h4 id="根据高斯公式展开，能发现lower-bound的一些性质。"><a href="#根据高斯公式展开，能发现lower-bound的一些性质。" class="headerlink" title="根据高斯公式展开，能发现lower bound的一些性质。"></a>根据高斯公式展开，能发现lower bound的一些性质。</h4><p>由于 $\large D_{KL}(q_\phi(z|x^{(i)})||p_\theta(z))&#x3D;\int_zq_\phi(z|x)log(\frac{p_\theta(z)}{q_\phi(z|x)})&#x3D;\int_zq_\phi(z|x)log(p_\theta(z))-\int_zq_\phi(z|x)log(q_\phi(z|x))$</p>
<p>第一项 $\int_zq_\phi(z|x)log(p_\theta(z))$ 带入高斯公式：</p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206153956085.png" alt="image-20221206153956085"></p>
<p>第二项 $\int_zq_\phi(z|x)log(q_\phi(z|x))$ 代入高斯公式：</p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206154144826.png" alt="image-20221206154144826"></p>
<p>上面就是KL表达式，L_b 还有第二项；第二项参数更新用MSE loss（或者比如BCE loss），让产生的样本x和真实样本尽可能接近（和autoencoder一样）：</p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206155025433.png" alt="image-20221206155025433"></p>
<p>更新流程为：</p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206132704893.png" alt="image-20221206132704893"></p>
<p><img src="/2022/12/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VAE%E8%AE%BA%E6%96%87/image-20221206162145590.png" alt="image-20221206162145590"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN提出论文</title>
    <url>/2022/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="GAN提出论文"><a href="#GAN提出论文" class="headerlink" title="GAN提出论文"></a>GAN提出论文</h1><blockquote>
<p>&#x3D;&#x3D;Creswell, Antonia, et al. “Generative adversarial networks: An overview.” <em>IEEE signal processing magazine</em> 35.1 (2018): 53-65.&#x3D;&#x3D;citation：51486</p>
<p>github：<a href="http://www.github.com/goodfeli/adversarial">http://www.github.com/goodfeli/adversarial</a>  </p>
<p>跟着李沐学AI视频 <a href="https://www.bilibili.com/video/BV1rb4y187vD/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">GAN论文逐段精读【论文精读】</a> </p>
</blockquote>
<h4 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h4><ul>
<li>解决了深度学习在生成模型上效果不够好的问题；不够好的原因是最大化似然函数时需要对概率分布进行很多近似，近似带来很多计算；不需要用马尔科夫链中采样，方法更简单；（其实看不太懂到底解决什么问题，相比之前的方法不一样，主要是之前的方法我也不熟）；</li>
<li>不再去近似 似然函数，而是用其他方法来得到生成模型；</li>
</ul>
<h4 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h4><ul>
<li>提出了一个通过对抗过程来生成模型的新<strong>框架</strong>，叫GAN；同时训练两个模型，一个叫生成器 $G$，一个叫判别器 $D$；生成器捕捉数据的分布，目标是最大化判别器出错的概率（通过神经网络传递随机噪声，来生成样本）；判别器估计样本有多大的概率来自于真实数据（判断该样本是来自模型分布还是数据分布）；训练好的生成器是一个能够恢复训练样本分布的模型，训练好的判别器输出等于1&#x2F;2的（分不出是生成还是真实）；</li>
<li>判别器的训练逻辑：对于判别器而言，当输入为真实音频x时，应该输出数值1；当输入为合成音频G(z)时，应该输出数值0。生成器的训练逻辑：当生成器的输出G(z)作为判别器的输入时，使得判别器的输出为1；</li>
</ul>
<h4 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h4><p>- </p>
<h4 id="存在什么问题"><a href="#存在什么问题" class="headerlink" title="存在什么问题"></a>存在什么问题</h4><ul>
<li>难训练，生成器和判别器要均衡好，收敛不稳定；</li>
<li>loss会有数值问题；</li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ul>
<li><p>在提出该框架之前的做法：之前的方法总是想构造一个分布函数出来，分布函数提供一些参数让它可以学习，这些参数通过最大化似然函数来做（学习一些分布 使得知道是什么分布，学习参数，比如均值、方差）；这样的坏处是采样一个分布的时候算起来比较难，特别是当维度比较高的时候；因为这些方   法计算困难，最近有一些工作提出了“generative machines”，不再去构造分布，而是学一个模型来去近似这个结果，好处是算起来容易，坏处是不知道是什么分布；</p>
</li>
<li><p>与该框架很像的一些工作：</p>
<ul>
<li>VAE</li>
<li>predictability minimization  </li>
<li>adversarial examples：构造一些假样本，和真样本很像，来糊弄判别器，从而测试算法稳定性</li>
</ul>
</li>
</ul>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>生成器是一个MLP的情况下，输入是随机噪声（通常是高斯分布），它可以映射到任何一个我们想去拟合的分布；</p>
<p>判别器是一个MLP的情况下，。。</p>
<p>输入多维随机变量 $x$，生成器输出分布 $p_G$，假设输入噪声分布 $p_z(z)$，生成器的传递函数为 $G(z;\theta_g)$ （学习从 $z$ 到 $x$ 的映射）；判别器传递函数 $D(x;\theta_d)$ ，输出一个概率数值（一个标量），表示有多大概率输入$x$是来自真实数据（而不是 $p_g$）；训练判别器，最大化判别是训练样本还是从生成器采样的样本的正确率，同时训练生成器，生成器的目标是：最小化 $log(1-D(G(z)))$ （$D(G(z))$是生成器采样送入判别器，判别器输出为0（判断成真实样本）的概率，$D(G(z))$越接近0，$log(1-D(G(z)))$ 就越接近0；$D(G(z))$越接近1，$log(1-D(G(z)))$ 就越接近负无穷，因此生成器的目标是最小化 $log(1-D(G(z)))$，也就是尽可能让判别器出错；</p>
<p>two-player minmax game with value function $V(D, G)$：<br>$$<br>\min <em>G \max <em>D V(D, G)&#x3D;\mathbb{E}</em>{\boldsymbol{x} \sim p</em>{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})]+\mathbb{E}<em>{\boldsymbol{z} \sim p</em>{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z})))]<br>$$<br>最大化D，假设D训练得很好，$D(x)$ 接近1，所以$logD(x)$接近0，$D(G(z))$ 接近0，$log(1-D(G(z)))$ 接近0；而只要D训练得不好，就是负数，因此D的目标是最大化value function；</p>
<p>最小化G，假设G训练得很好，$D(G(z))$ 接近1， $log(1-D(G(z)))$ 接近负无穷（最小了）；而只要G训练得不好，就接近0，因此G的目标是最小化value function；</p>
<p>达到均衡：到某个点都无法提高了，对于G来说 $p_g&#x3D;p_{data}$ 后就无法提高了，对于D来说是 $D(x)&#x3D;\frac{1}{2}$ 附近（判别器区分不出来了，输入什么输出都是1&#x2F;2）；</p>
<img src="/2022/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221118162014687.png" alt="image-20221118162014687">



<h2 id="目标函数及求解"><a href="#目标函数及求解" class="headerlink" title="目标函数及求解"></a>目标函数及求解</h2><p>伪代码：</p>
<p>Algorithm 1  ：</p>
<p><img src="/2022/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221121103640372.png" alt="image-20221121103640372"></p>
<p>判别器迭代k步，生成器迭代1步；k：让判别器有足够的更新（k不能太小），但也别更新太好了（k也不能太大），因为如果判别器没有足够更新，loss负无穷大，这个G更新意义不大；而如果判别器更新得太充分，loss为0，参数不更新了；</p>
<p>训练早期：一开始D很容易判断正确，因此一开始 $log(1-D(G(z)))$ 等于0，G难更新，因此训练早期更新G别用最小化 $log(1-D(G(z)))$，用最大化 $logD(G(z))$ （但是早期 $logD(G(z))$ 等于负无穷大，也会有数值问题，后续工作会改进）；</p>
<p>怎么判断GAN收敛了呢？一个收敛，另一个还没收敛算收敛吗？两个都在抖动算收敛吗？整体来说<strong>GAN收敛很不稳定</strong>，后续也有很多改进工作；</p>
<h2 id="理论结果"><a href="#理论结果" class="headerlink" title="理论结果"></a>理论结果</h2><p>目标有全局最优解，当且仅当生成器学到的分布和真实数据分布相等 $p_g&#x3D;p_{data}$，</p>
<h3 id="Global-Optimality-of-pg-x3D-p-data"><a href="#Global-Optimality-of-pg-x3D-p-data" class="headerlink" title="Global Optimality of $pg &#x3D; p_{data}$"></a>Global Optimality of $pg &#x3D; p_{data}$</h3><p>假设判别器D已训练好，任意的生成器G。</p>
<p><strong>Proposition 1</strong>.  给定G，最优的D为：<br>$$<br>D_G^*(x)&#x3D;\frac{p_{data}(x)}{p_{data}(x)+p_g(x)}<br>$$<br>其中，$p_{data}(x)$  是真实分布下输出概率值，$p_g(x)$ 是生成器拟合分布下，输入x后输出概率值；</p>
<p>对任意x，最优判别器输出概率为1&#x2F;2（ $p_{data}(x)$ 和 $p_g(x)$ 完全相等时）；表示判别器什么都分不开，表示这两个分布是重合的；</p>
<p>（这个思路在工程上很有意义：如何判断两块数据是不是来自同一分布：只要训练一个二分类器，如果能区分开，则不是一个分布，如果区分不开，则是一个分布。举例子来说，我们想知道训练的模型在新环境适不适用，只需要采集新环境的数据，通过训练一个二分类器，看原本的训练数据，与新环境的数据是不是同一个分布（通过看分类器能不能区分）就知道模型适不适用了）</p>
<h4 id="证明Proposition-1"><a href="#证明Proposition-1" class="headerlink" title="证明Proposition 1"></a>证明Proposition 1</h4><p>证明公式(2)： 对任意生成器G下的 判别器D的训练准则 是 最大化value fucntion $V(G,D)$</p>
<p>期望定义公式： $\mathbb{E}_{\boldsymbol{x} \sim p}f(x)&#x3D;\int_xp(x)f(x)dx$ ，带入上面的公式(1)后：</p>
<p>如果生成器训练得好，$x&#x3D;g(z)$，$p_g(x)&#x3D;p_z(z)$<br>$$<br>\begin{equation}<br>\begin{aligned}<br>V(G, D)&amp;&#x3D;\int_{\boldsymbol{x}} p_{\text {data }}(\boldsymbol{x}) \log (D(\boldsymbol{x})) d x+\int_{\boldsymbol{z}} p_{\boldsymbol{z}}(\boldsymbol{z}) \log (1-D(g(\boldsymbol{z}))) d z \<br>&amp;&#x3D;\int_{\boldsymbol{x}} p_{\text {data }}(\boldsymbol{x}) \log (D(\boldsymbol{x})) + p_{\boldsymbol{g}}(\boldsymbol{x}) \log (1-D(\boldsymbol{x})) d x<br>\end{aligned}<br>\end{equation}<br>$$<br>$p_{data}(x)$ 替换为 $a$，$p_g(x)$ 替换为 $b$，$D(x)$ 替换为 $y$，则表达式为 $a\log y+b\log (1-y)$ ，可以画出是一个凸函数（横轴为y），有一个最大值，求最大值，在[0,1]间最大值为 $y &#x3D; \large \frac{a}{a+b}$（通过求导可知），也就是上面的公式(2)；</p>
<p>带入D的最优解到value function中，现在是一个关于G的函数了（D用的最优解），value function要最大化D：<br>$$<br>\begin{aligned}<br>C(G) &amp;&#x3D;\max <em>D V(G, D) \<br>&amp;&#x3D;\mathbb{E}</em>{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_G^*(\boldsymbol{x})\right]+\mathbb{E}<em>{\boldsymbol{z} \sim p</em>{\boldsymbol{z}}}\left[\log \left(1-D_G^*(G(\boldsymbol{z}))\right)\right] \<br>&amp;&#x3D;\mathbb{E}<em>{\boldsymbol{x} \sim p</em>{\text {data }}}\left[\log D_G^*(\boldsymbol{x})\right]+\mathbb{E}<em>{\boldsymbol{x} \sim p_g}\left[\log \left(1-D_G^*(\boldsymbol{x})\right)\right] \<br>&amp;&#x3D;\mathbb{E}</em>{\boldsymbol{x} \sim p_{\text {data }}}\left[\log \frac{p_{\text {data }}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_g(\boldsymbol{x})}\right]+\mathbb{E}<em>{\boldsymbol{x} \sim p_g}\left[\log \frac{p_g(\boldsymbol{x})}{p</em>{\text {data }}(\boldsymbol{x})+p_g(\boldsymbol{x})}\right]<br>\end{aligned}<br>$$<br>现在要最小化G；</p>
<p><strong>理论1 Theorem 1</strong>.  全局最小值C(G)，当且仅当 $p_g(x)&#x3D;p_{data}(x)$ ，此时 $C(G)&#x3D;-\log 4$ ；</p>
<h4 id="证明-Theorem-1"><a href="#证明-Theorem-1" class="headerlink" title="证明 Theorem 1"></a>证明 Theorem 1</h4><p>证明 对于 $p_g(x)&#x3D;p_{data}(x)$，$D_G^*(x)&#x3D;\frac{1}{2}$，带入C(G)公式得到 $C(G)&#x3D;\log(\frac{1}{2})+\log(\frac{1}{2})&#x3D;-\log(4)$，这也是C(G)的最优值；</p>
<p>$$\mathbb{E}<em>{\boldsymbol{x} \sim p</em>{\text {data }}}[-\log2]+\mathbb{E}<em>{\boldsymbol{x} \sim p</em>{\text {g }}}[-\log2]&#x3D;-\log4$$</p>
<p>KL散度可以衡量两个分布，定义为 $KL(p|q)&#x3D;\mathbb E_{x\sim p}\log \frac{p(x)}{q(x)}$ ，已知p的情况下，需要多少bit能把q描述出来；对任意x采样自p分布，用该公式可以衡量两分布距离；</p>
<p>$p_{data}(x)+p_g(x)$不是一个分布，因为积分&#x3D;2，而$\frac{1}{2}(p_{data}(x)+p_g(x))$是一个分布，因为积分&#x3D;1，把上面公式(4)写为 </p>
<p>$C(G)&#x3D;\mathbb{E}<em>{x\sim p</em>{data}}[\log\frac{p_{data}(x)}{\frac{1}{2}(p_{data}(x)+p_g(x))}]-log(2)+\mathbb{E}<em>{x\sim p</em>{g}}[\log\frac{p_{g}(x)}{\frac{1}{2}(p_{data}(x)+p_g(x))}]-log(2)$</p>
<p>$p_{data}(x)$、$p_{g}(x)$、$p_{data}(x)+p_{g}(x)$ 都是分布，因此可以用KL散度公式，得到：<br>$$<br>C(G)&#x3D;-\log (4)+K L\left(p_{\text {data }} | \frac{p_{\text {data }}+p_g}{2}\right)+K L\left(p_g | \frac{p_{\text {data }}+p_g}{2}\right)<br>$$<br>该形式叫Jensen–Shannon divergence  ，JS散度，琴森香农散度，与KL散度区别是，JS散度里的p、q分布是对称的，可互换，KL散度不能；</p>
<p>KL散度值大于等于0，等于0的情况是两分布相等，即 $p_{data}&#x3D; \large \frac{p_{data}(x)+p_{g}(x)}{2}$ 、  $p_{g}&#x3D;\large \frac{p_{data}(x)+p_{g}(x)}{2}$ ，最优解等价于 $p_{data}&#x3D;p_g$</p>
<h3 id="Convergence-of-Algorithm-1"><a href="#Convergence-of-Algorithm-1" class="headerlink" title="Convergence of Algorithm 1"></a>Convergence of Algorithm 1</h3><p>算法1的收敛性证明。</p>
<p>如果G和D有足够的容量，在算法1的每一步，都允许判别器在给定G的情况下达到最优，并更新 $p_g$ ，</p>
<p>$\mathbb{E}<em>{\boldsymbol{x} \sim p</em>{\text {data }}}\left[\log D_G^*(\boldsymbol{x})\right]+\mathbb{E}<em>{\boldsymbol{x} \sim p_g}\left[\log \left(1-D_G^*(\boldsymbol{x})\right)\right]$ ，那么 $p_g$ 会收敛到 $p</em>{data}$ 。</p>
<p>证明：证明过程是泛函分析里的知识点，我看不很懂；凸函数什么的。TODO</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>todo</p>
<h2 id="后续工作"><a href="#后续工作" class="headerlink" title="后续工作"></a>后续工作</h2><ol>
<li>conditional GAN，条件GAN。由于该方法没有限制，随便给一个z去生成，因此后续可以给一些限制，去更可控地得到想要的输出，$p(x|c)$ ，给G和D的输入是在一定条件下的；</li>
<li>Learned approximate inference 通过训练辅助网络对给定x的z进行预测。这类似于wake-sleep algorithm，但优点是在生成器训练完成后，可以对固定的生成器训练？；</li>
<li>。。</li>
<li>Semi-supervised learning  半监督学习。从判别器或者推理网提取的特征可以用来改善模型；</li>
<li>提高效率方向。通过设计更好的方法来协调G和D，或者在训练过程中确定样本z更好的分布，可以大大加快训练的速度。</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaScript socket</title>
    <url>/2023/03/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/JavaScript%20socket/</url>
    <content><![CDATA[<h1 id="JavaScript-socket"><a href="#JavaScript-socket" class="headerlink" title="JavaScript socket"></a>JavaScript socket</h1><blockquote>
<p>阮一峰 <a href="http://www.ruanyifeng.com/blog/2017/05/websocket.html">WebSocket 教程</a></p>
</blockquote>
<h2 id="客户端的简单示例"><a href="#客户端的简单示例" class="headerlink" title="客户端的简单示例"></a>客户端的简单示例</h2><p>javascript脚本：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">var ws = new WebSocket(<span class="string">&quot;wss://echo.websocket.org&quot;</span>);</span><br><span class="line"></span><br><span class="line">ws.onopen = function(evt) &#123; </span><br><span class="line">  console.<span class="built_in">log</span>(<span class="string">&quot;Connection open ...&quot;</span>); </span><br><span class="line">  ws.send(<span class="string">&quot;Hello WebSockets!&quot;</span>);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ws.onmessage = function(evt) &#123;</span><br><span class="line">  console.<span class="built_in">log</span>( <span class="string">&quot;Received Message: &quot;</span> + evt.data);</span><br><span class="line">  ws.close();</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ws.onclose = function(evt) &#123;</span><br><span class="line">  console.<span class="built_in">log</span>(<span class="string">&quot;Connection closed.&quot;</span>);</span><br><span class="line">&#125;;      </span><br></pre></td></tr></table></figure>

<p>打开连接、接收消息、关闭连接。</p>
<p>下面进行详细展开。</p>
<h2 id="客户端的-API"><a href="#客户端的-API" class="headerlink" title="客户端的 API"></a>客户端的 API</h2><p>WebSocket 客户端的 API 如下。</p>
<h3 id="WebSocket-构造函数"><a href="#WebSocket-构造函数" class="headerlink" title="WebSocket 构造函数"></a>WebSocket 构造函数</h3><p>WebSocket 对象作为一个构造函数，用于新建 WebSocket 实例。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> ws = <span class="keyword">new</span> <span class="title class_">WebSocket</span>(<span class="string">&#x27;ws://localhost:8080&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>执行上面语句之后，客户端就会与服务器（浏览器）进行连接。</p>
<p>实例对象的所有属性和方法清单，参见<a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSocket">这里</a>。</p>
<h3 id="webSocket-readyState"><a href="#webSocket-readyState" class="headerlink" title="webSocket.readyState"></a>webSocket.readyState</h3><p><code>readyState</code>属性返回实例对象的当前状态，共有四种。</p>
<ul>
<li>CONNECTING：值为0，表示正在连接。</li>
<li>OPEN：值为1，表示连接成功，可以通信了。</li>
<li>CLOSING：值为2，表示连接正在关闭。</li>
<li>CLOSED：值为3，表示连接已经关闭，或者打开连接失败。</li>
</ul>
<p>下面是一个示例。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">switch</span> (ws.<span class="property">readyState</span>) &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="title class_">WebSocket</span>.<span class="property">CONNECTING</span>:</span><br><span class="line">    <span class="comment">// do something</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> <span class="title class_">WebSocket</span>.<span class="property">OPEN</span>:</span><br><span class="line">    <span class="comment">// do something</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> <span class="title class_">WebSocket</span>.<span class="property">CLOSING</span>:</span><br><span class="line">    <span class="comment">// do something</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> <span class="title class_">WebSocket</span>.<span class="property">CLOSED</span>:</span><br><span class="line">    <span class="comment">// do something</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="attr">default</span>:</span><br><span class="line">    <span class="comment">// this never happens</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h3 id="webSocket-onopen"><a href="#webSocket-onopen" class="headerlink" title="webSocket.onopen"></a>webSocket.onopen</h3><p>实例对象的<code>onopen</code>属性，用于指定连接成功后的回调函数。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">ws.<span class="property">onopen</span> = <span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">  ws.<span class="title function_">send</span>(<span class="string">&#x27;Hello Server!&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>如果要指定多个回调函数，可以使用<code>addEventListener</code>方法。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">ws.<span class="title function_">addEventListener</span>(<span class="string">&#x27;open&#x27;</span>, <span class="keyword">function</span> (<span class="params">event</span>) &#123;</span><br><span class="line">  ws.<span class="title function_">send</span>(<span class="string">&#x27;Hello Server!&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



<h3 id="webSocket-onclose"><a href="#webSocket-onclose" class="headerlink" title="webSocket.onclose"></a>webSocket.onclose</h3><p>实例对象的<code>onclose</code>属性，用于指定连接关闭后的回调函数。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">ws.<span class="property">onclose</span> = <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> code = event.<span class="property">code</span>;</span><br><span class="line">  <span class="keyword">var</span> reason = event.<span class="property">reason</span>;</span><br><span class="line">  <span class="keyword">var</span> wasClean = event.<span class="property">wasClean</span>;</span><br><span class="line">  <span class="comment">// handle close event</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ws.<span class="title function_">addEventListener</span>(<span class="string">&quot;close&quot;</span>, <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> code = event.<span class="property">code</span>;</span><br><span class="line">  <span class="keyword">var</span> reason = event.<span class="property">reason</span>;</span><br><span class="line">  <span class="keyword">var</span> wasClean = event.<span class="property">wasClean</span>;</span><br><span class="line">  <span class="comment">// handle close event</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



<h3 id="webSocket-onmessage"><a href="#webSocket-onmessage" class="headerlink" title="webSocket.onmessage"></a>webSocket.onmessage</h3><p>例对象的<code>onmessage</code>属性，用于指定收到服务器数据后的回调函数。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">ws.<span class="property">onmessage</span> = <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> data = event.<span class="property">data</span>;</span><br><span class="line">  <span class="comment">// 处理数据</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ws.<span class="title function_">addEventListener</span>(<span class="string">&quot;message&quot;</span>, <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> data = event.<span class="property">data</span>;</span><br><span class="line">  <span class="comment">// 处理数据</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



<p>注意，服务器数据可能是文本，也可能是二进制数据（<code>blob</code>对象或<code>Arraybuffer</code>对象）。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">ws.<span class="property">onmessage</span> = <span class="keyword">function</span>(<span class="params">event</span>)&#123;</span><br><span class="line">  <span class="keyword">if</span>(<span class="keyword">typeof</span> event.<span class="property">data</span> === <span class="title class_">String</span>) &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Received data string&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(event.<span class="property">data</span> <span class="keyword">instanceof</span> <span class="title class_">ArrayBuffer</span>)&#123;</span><br><span class="line">    <span class="keyword">var</span> buffer = event.<span class="property">data</span>;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Received arraybuffer&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>除了动态判断收到的数据类型，也可以使用<code>binaryType</code>属性，显式指定收到的二进制数据类型。</p>
<h3 id="webSocket-send"><a href="#webSocket-send" class="headerlink" title="webSocket.send()"></a>webSocket.send()</h3><p>实例对象的<code>send()</code>方法用于向服务器发送数据。</p>
<p>发送文本的例子。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">ws.<span class="title function_">send</span>(<span class="string">&#x27;your message&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>发送 Blob 对象的例子。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> file = <span class="variable language_">document</span></span><br><span class="line">  .<span class="title function_">querySelector</span>(<span class="string">&#x27;input[type=&quot;file&quot;]&#x27;</span>)</span><br><span class="line">  .<span class="property">files</span>[<span class="number">0</span>];</span><br><span class="line">ws.<span class="title function_">send</span>(file);</span><br></pre></td></tr></table></figure>



<p>发送 ArrayBuffer 对象的例子。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Sending canvas ImageData as ArrayBuffer</span></span><br><span class="line"><span class="keyword">var</span> img = canvas_context.<span class="title function_">getImageData</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">400</span>, <span class="number">320</span>);</span><br><span class="line"><span class="keyword">var</span> binary = <span class="keyword">new</span> <span class="title class_">Uint8Array</span>(img.<span class="property">data</span>.<span class="property">length</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; img.<span class="property">data</span>.<span class="property">length</span>; i++) &#123;</span><br><span class="line">  binary[i] = img.<span class="property">data</span>[i];</span><br><span class="line">&#125;</span><br><span class="line">ws.<span class="title function_">send</span>(binary.<span class="property">buffer</span>);</span><br></pre></td></tr></table></figure>



<h3 id="webSocket-bufferedAmount"><a href="#webSocket-bufferedAmount" class="headerlink" title="webSocket.bufferedAmount"></a>webSocket.bufferedAmount</h3><p>实例对象的<code>bufferedAmount</code>属性，表示还有多少字节的二进制数据没有发送出去。它可以用来判断发送是否结束。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> data = <span class="keyword">new</span> <span class="title class_">ArrayBuffer</span>(<span class="number">10000000</span>);</span><br><span class="line">socket.<span class="title function_">send</span>(data);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (socket.<span class="property">bufferedAmount</span> === <span class="number">0</span>) &#123;</span><br><span class="line">  <span class="comment">// 发送完毕</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="comment">// 发送还没结束</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="webSocket-onerror"><a href="#webSocket-onerror" class="headerlink" title="webSocket.onerror"></a>webSocket.onerror</h3><p>实例对象的<code>onerror</code>属性，用于指定报错时的回调函数。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">socket.<span class="property">onerror</span> = <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="comment">// handle error event</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">socket.<span class="title function_">addEventListener</span>(<span class="string">&quot;error&quot;</span>, <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="comment">// handle error event</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



<h2 id="服务端的实现"><a href="#服务端的实现" class="headerlink" title="服务端的实现"></a>服务端的实现</h2><p>WebSocket 服务器的实现，可以查看维基百科的<a href="https://en.wikipedia.org/wiki/Comparison_of_WebSocket_implementations">列表</a>。</p>
<p>常用的 Node 实现有以下三种。</p>
<ul>
<li><a href="https://github.com/uWebSockets/uWebSockets">µWebSockets</a></li>
<li><a href="http://socket.io/">Socket.IO</a></li>
<li><a href="https://github.com/theturtle32/WebSocket-Node">WebSocket-Node</a></li>
</ul>
<p>具体的用法请查看它们的文档，这里不详细介绍了。</p>
<h2 id="WebSocketd"><a href="#WebSocketd" class="headerlink" title="WebSocketd"></a>WebSocketd</h2><p>下面，我要推荐一款非常特别的 WebSocket 服务器：<a href="http://websocketd.com/">Websocketd</a>。</p>
<p>它的最大特点，就是后台脚本不限语言，标准输入（stdin）就是 WebSocket 的输入，标准输出（stdout）就是 WebSocket 的输出。</p>
<p>![img](JavaScript socket.assets&#x2F;bg2017051504.png)</p>
<p>举例来说，下面是一个 Bash 脚本<code>counter.sh</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 1</span><br><span class="line"><span class="built_in">sleep</span> 1</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 2</span><br><span class="line"><span class="built_in">sleep</span> 1</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 3</span><br></pre></td></tr></table></figure>



<p>命令行下运行这个脚本，会输出1、2、3，每个值之间间隔1秒。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ bash ./counter.sh</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td></tr></table></figure>



<p>现在，启动<code>websocketd</code>，指定这个脚本作为服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ websocketd --port=8080 bash ./counter.sh</span><br></pre></td></tr></table></figure>



<p>上面的命令会启动一个 WebSocket 服务器，端口是<code>8080</code>。每当客户端连接这个服务器，就会执行<code>counter.sh</code>脚本，并将它的输出推送给客户端。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var ws = new WebSocket(&#x27;ws://localhost:8080/&#x27;);</span><br><span class="line"></span><br><span class="line">ws.onmessage = function(event) &#123;</span><br><span class="line">  console.log(event.data);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>上面是客户端的 JavaScript 代码，运行之后会在控制台依次输出1、2、3。</p>
<p>有了它，就可以很方便地将命令行的输出，发给浏览器。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ websocketd --port=8080 <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>



<p>上面的命令会执行<code>ls</code>命令，从而将当前目录的内容，发给浏览器。使用这种方式实时监控服务器，简直是轻而易举（<a href="https://github.com/joewalnes/web-vmstats">代码</a>）。（<strong>这个Web VMStat可以看见linux里的内存、cpu、io等的使用情况，挺不错的</strong>）也可以直接在命令行里敲 <code>vmstat 1</code></p>
<p>![img](JavaScript socket.assets&#x2F;bg2017051505.jpg)</p>
<p>更多的用法可以参考<a href="https://github.com/joewalnes/websocketd/tree/master/examples/bash">官方示例</a>。</p>
<ul>
<li>Bash 脚本<a href="https://github.com/joewalnes/websocketd/blob/master/examples/bash/greeter.sh">读取客户端输入</a>的例子</li>
<li>五行代码实现一个最简单的<a href="https://github.com/joewalnes/websocketd/blob/master/examples/bash/chat.sh">聊天服务器</a></li>
</ul>
<p>![img](JavaScript socket.assets&#x2F;bg2017051506.png)</p>
<p>websocketd 的实质，就是命令行的 WebSocket 代理。只要命令行可以执行的程序，都可以通过它与浏览器进行 WebSocket 通信。下面是一个 Node 实现的回声服务<a href="https://github.com/joewalnes/websocketd/blob/master/examples/nodejs/greeter.js"><code>greeter.js</code></a>。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">process.<span class="property">stdin</span>.<span class="title function_">setEncoding</span>(<span class="string">&#x27;utf8&#x27;</span>);</span><br><span class="line"></span><br><span class="line">process.<span class="property">stdin</span>.<span class="title function_">on</span>(<span class="string">&#x27;readable&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> chunk = process.<span class="property">stdin</span>.<span class="title function_">read</span>();</span><br><span class="line">  <span class="keyword">if</span> (chunk !== <span class="literal">null</span>) &#123;</span><br><span class="line">    process.<span class="property">stdout</span>.<span class="title function_">write</span>(<span class="string">&#x27;data: &#x27;</span> + chunk);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>



<p>启动这个脚本的命令如下。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ websocketd --port=8080 node ./greeter.js</span><br></pre></td></tr></table></figure>



<p>官方仓库还有其他<a href="https://github.com/joewalnes/websocketd/tree/master/examples">各种语言</a>的例子。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="http://cjihrig.com/blog/how-to-use-websockets/">How to Use WebSockets</a></li>
<li><a href="https://www.tutorialspoint.com/websockets/websockets_send_receive_messages.htm">WebSockets - Send &amp; Receive Messages</a></li>
<li><a href="https://www.html5rocks.com/en/tutorials/websockets/basics/">Introducing WebSockets: Bringing Sockets to the Web</a></li>
</ul>
]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
        <tag>socket通信</tag>
      </tags>
  </entry>
  <entry>
    <title>python socket</title>
    <url>/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/</url>
    <content><![CDATA[<h1 id="python-socket"><a href="#python-socket" class="headerlink" title="python socket"></a>python socket</h1><blockquote>
<p>b站 奇乐编程学院  <a href="https://www.bilibili.com/video/BV1eg411G7pW/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">TCP&#x2F;IP网络通信之Socket编程入门</a></p>
</blockquote>
<h2 id="单线程socket，socket入门代码"><a href="#单线程socket，socket入门代码" class="headerlink" title="单线程socket，socket入门代码"></a>单线程socket，socket入门代码</h2><p>下面是一个socket例子，实现的是服务器接收到来自客户端的数据，又原封不动发送给客户端的功能。</p>
<p>服务器端：</p>
<p>服务器端绑定bind的ip地址可以是任意的，表示服务器端监听任意ip地址，也就是可以接收任意客户端的信息。</p>
<p>只有在客户端连接的端口号是bind里设置的端口号时，才会和服务器端连接上。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下面是一个socket例子，实现的是服务器接收到来自客户端的数据，又原封不动发送给客户端的功能。 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="comment"># AF_INET 表示我们使用的是IPv4的地址家族（address family）</span></span><br><span class="line"><span class="comment"># SOCK_STREAM 表示我们使用的是TCP协议（TCP是“流式”协议）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里是服务器端的操作：</span></span><br><span class="line"><span class="keyword">with</span> socket.socket(socket.AF_INET, socket.SOCK_STREAM) <span class="keyword">as</span> s:</span><br><span class="line">    s.bind((<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">1234</span>))   </span><br><span class="line">    <span class="comment"># bind()将我们创建的socket关联到我们主机的某一个网卡（也叫网络接口 network interface）和端口上。</span></span><br><span class="line">    <span class="comment"># 网卡可以用ip地址指定</span></span><br><span class="line">    <span class="comment"># 这里用 0.0.0.0 地址，表示主机上的任意网卡都可以使用这个socket进行通信。</span></span><br><span class="line">    <span class="comment"># 表示服务器端监听任意ip地址，也就是任意客户端的信息</span></span><br><span class="line">    <span class="comment"># 只有在客户端连接的端口号是1234时，才会和服务器端连接上。</span></span><br><span class="line"></span><br><span class="line">    s.listen()  <span class="comment"># 将socket置为监听状态，并等待客户端的连接</span></span><br><span class="line"></span><br><span class="line">    c, addr = s.accept() <span class="comment"># 接受来自任意客户端的连接，并返回一个新的socket c，以及客户端的ip地址。</span></span><br><span class="line">    <span class="comment"># 这个c是一个与之前s不同的socket</span></span><br><span class="line">    <span class="comment"># socket s主要用于监听，server socket</span></span><br><span class="line">    <span class="comment"># socket c用于与连接的客户端进行通信，client socket</span></span><br><span class="line">    <span class="keyword">with</span> c:</span><br><span class="line">        <span class="built_in">print</span>(addr, <span class="string">&quot;connected.&quot;</span>) <span class="comment"># 打印客户端的IP地址</span></span><br><span class="line">		<span class="comment"># 这里这个写法，暗示服务器端只能同时处理一个客户端的请求，先作为入门这样看，下面可以看到改进的并发版本。</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            data = c.recv(<span class="number">1024</span>) <span class="comment"># 一直调用recv()接收客户端来的信息</span></span><br><span class="line">            <span class="comment"># 1024代表一次性接受数据的最大长度，1024个字节</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            c.sendall(data) <span class="comment"># 原封不动将数据传回给客户端</span></span><br></pre></td></tr></table></figure>



<p>保存的该python文件，比如为server.py，然后在终端执行 <code>python server.py</code>，就启动了服务器端socket。</p>
<p>在新打开一个终端，输入 <code>nc 127.0.0.1 1234</code>  （127.0.0.1 是一个回送地址（lookback address），代表本地计算机，1234是端口号）。</p>
<p>按下回车，就可以看见服务器端收到了一个新连接，显示<code>(&#39;127.0.0.1&#39;, 53046) connected</code> ，表示接收到ip为127.0.0.1的客户端，客户端端口为53046.</p>
<p>然后在客户端窗口中随便输入字符串，服务器也会原封不动的发送回来。</p>
<img src="/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/image-20230201162825199.png" alt="image-20230201162825199" style="zoom:67%;">





<p>客户端：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> socket.socket(socket.AF_INET,socket.SOCK_STREAM) <span class="keyword">as</span> s:</span><br><span class="line">    s.connect((<span class="string">&quot;127.0.0.1&quot;</span>,<span class="number">1234</span>))   <span class="comment"># 传入服务器端的ip和端口号</span></span><br><span class="line">    s.sendall(<span class="string">b&quot;hello&quot;</span>)             <span class="comment"># 发送一条信息给服务器端，这里参数是字节序列，要加b（不是字符串）</span></span><br><span class="line">    data = s.recv(<span class="number">1024</span>)             <span class="comment"># 接收服务器返回的消息</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;received:&quot;</span>, <span class="built_in">repr</span>(data))</span><br></pre></td></tr></table></figure>



<p>结果为：</p>
<p><img src="/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/image-20230201164000502.png" alt="image-20230201164000502"></p>
<h2 id="多线程的socket服务器"><a href="#多线程的socket服务器" class="headerlink" title="多线程的socket服务器"></a>多线程的socket服务器</h2><p>服务器并发的与多个客户端进行通信</p>
<h3 id="1-通过创建线程来响应不同客户端的请求"><a href="#1-通过创建线程来响应不同客户端的请求" class="headerlink" title="1. 通过创建线程来响应不同客户端的请求"></a>1. 通过创建线程来响应不同客户端的请求</h3><p>服务器端：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 下面是一个多线程的socket例子，实现的是服务器接收到来自客户端的数据，又原封不动发送给客户端的功能。 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_client</span>(<span class="params">c, addr</span>):</span><br><span class="line">    <span class="built_in">print</span>(addr, <span class="string">&quot;connected.&quot;</span>) <span class="comment"># 打印客户端的IP地址</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = c.recv(<span class="number">1024</span>) <span class="comment"># 一直调用recv()接收客户端来的信息</span></span><br><span class="line">        <span class="comment"># 1024代表一次性接受数据的最大长度，1024个字节</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        c.sendall(data) <span class="comment"># 原封不动将数据传回给客户端</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># AF_INET 表示我们使用的是IPv4的地址家族（address family）</span></span><br><span class="line"><span class="comment"># SOCK_STREAM 表示我们使用的是TCP协议（TCP是“流式”协议）</span></span><br><span class="line"><span class="comment"># 这里是服务器端的操作：</span></span><br><span class="line"><span class="keyword">with</span> socket.socket(socket.AF_INET, socket.SOCK_STREAM) <span class="keyword">as</span> s:</span><br><span class="line">    s.bind((<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">1234</span>))   </span><br><span class="line">    <span class="comment"># bind()将我们创建的socket关联到我们主机的某一个网卡（也叫网络接口 network interface）和端口上。</span></span><br><span class="line">    <span class="comment"># 网卡可以用ip地址指定</span></span><br><span class="line">    <span class="comment"># 这里用 0.0.0.0 地址，表示主机上的任意网卡都可以使用这个socket进行通信。</span></span><br><span class="line"></span><br><span class="line">    s.listen()  <span class="comment"># 将socket置为监听状态，并等待客户端的连接</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        c, addr = s.accept() <span class="comment"># 在循环中不停调用accept接受来自客户端的连接</span></span><br><span class="line">        <span class="comment"># 接受来自任意客户端的连接，并返回一个新的socket c，以及客户端的ip地址。</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 为了避免程序的阻塞（block），创建一个新线程</span></span><br><span class="line">        t = threading.Thread(target=handle_client, args=(c,addr))   <span class="comment"># 新线程是 handle_client() </span></span><br><span class="line">        <span class="comment"># 将客户端的socket c和地址传递给这个线程</span></span><br><span class="line"></span><br><span class="line">        t.start()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 然后线程中的代码和单线程中的一样。</span></span><br></pre></td></tr></table></figure>



<p>结果：</p>
<img src="/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/image-20230201172243140.png" alt="image-20230201172243140" style="zoom:67%;">



<p>多线程局限性：由于python的 GIL（<a href="https://python.land/python-concurrency/the-python-gil%EF%BC%89">https://python.land/python-concurrency/the-python-gil）</a> 的存在，python中的线程其实做不到真正的并发，并且线程自身也会占用额外的系统资源（线程内存开销、线程切换开销）</p>
<p>除了线程之外，还可以使用基于事件驱动的selectors来实现多个连接的并发，或者通过更高层的asyncio来实现异步的socket代码。</p>
<h2 id="简易HTTP服务器"><a href="#简易HTTP服务器" class="headerlink" title="简易HTTP服务器"></a>简易HTTP服务器</h2><p>HTTP是TCP协议的一个典型应用，也是浏览器与服务器交互的主要方式。通常服务器会监听80端口，然后等待客户端的连接（也就是浏览器比如搜索一个网址，是向服务器发起一次请求）。</p>
<p>客户端在连上服务器以后，首先需要指定要访问的资源，然后客户端会提供一系列额外的信息，这些信息每一条都是以冒号分隔的键&#x2F;值对，信息是比如浏览器版本等，这些额外信息称作消息的头部（header）。随后是一个空行，再之后是消息的主体（body）（如果有的话）。</p>
<p>服务器在收到消息后，会以同样格式来响应客户端的请求，首先第一行是一个状态行（status line），里面包含一个状态码，比如200代表请求成功，404代表请求的资源不存在。接着同样是一系列键&#x2F;值对，里面包含了请求资源的类型，服务器信息等。再后面是一个空行，再之后是消息的主体（body）（如果有的话）。</p>
<img src="/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/image-20230201175329315.png" alt="image-20230201175329315" style="zoom: 67%;">

<p>http socket的例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line">WEBROOT = <span class="string">&quot;webroot&quot;</span>	<span class="comment"># 这里webroot指的是这个例子的python文件当前路径下里面的子文件夹，也可以是其它文件夹名称</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_client</span>(<span class="params">c, addr</span>):</span><br><span class="line">    <span class="built_in">print</span>(addr, <span class="string">&quot;connected.&quot;</span>) <span class="comment"># 打印客户端的IP地址</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> c:</span><br><span class="line">        request = c.recv(<span class="number">1024</span>) <span class="comment"># 一直调用recv()接收客户端来的信息   # request是信息</span></span><br><span class="line">        <span class="comment"># 1024代表一次性接受数据的最大长度，1024个字节</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Parse HTTP headers</span></span><br><span class="line">        headers = request.split(<span class="string">b&quot;\r\n&quot;</span>)   <span class="comment"># 将消息拆分成一行一行的字符串，存放在header这个列表中</span></span><br><span class="line">        <span class="comment"># HTTP标准中定义的换行符是“回车+换行” </span></span><br><span class="line">        file = headers[<span class="number">0</span>].split()[<span class="number">1</span>].decode()   <span class="comment"># 提取出请求的文件名</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load file content</span></span><br><span class="line">        <span class="comment"># 如果用户请求的是根路径，直接返回index.html文件</span></span><br><span class="line">        <span class="keyword">if</span> file == <span class="string">&quot;/&quot;</span>:</span><br><span class="line">            file = <span class="string">&quot;/index.html&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读取文件内容，并返回一个状态号为200的消息</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(WEBROOT + file, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                content = f.read()</span><br><span class="line">            response = <span class="string">b&quot;HTTP/1.0 200 OK\r\n\r\n&quot;</span> + content</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果请求的文件不存在</span></span><br><span class="line">        <span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">            response = <span class="string">b&quot;HTTP/1.0 404 NOT FOUND\r\n\r\nFile not found&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Send HTTP response</span></span><br><span class="line">        c.sendall(response)</span><br><span class="line"></span><br><span class="line"><span class="comment"># AF_INET 表示我们使用的是IPv4的地址家族（address family）</span></span><br><span class="line"><span class="comment"># SOCK_STREAM 表示我们使用的是TCP协议（TCP是“流式”协议）</span></span><br><span class="line"><span class="comment"># 这里是服务器端的操作：</span></span><br><span class="line"><span class="keyword">with</span> socket.socket(socket.AF_INET, socket.SOCK_STREAM) <span class="keyword">as</span> s:</span><br><span class="line">    s.bind((<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">80</span>))   <span class="comment"># 这里好像只能是80端口，表示浏览器监听的？</span></span><br><span class="line">    <span class="comment"># bind()将我们创建的socket关联到我们主机的某一个网卡（也叫网络接口 network interface）和端口上。</span></span><br><span class="line">    <span class="comment"># 网卡可以用ip地址指定</span></span><br><span class="line">    <span class="comment"># 这里用 0.0.0.0 地址，表示主机上的任意网卡都可以使用这个socket进行通信。</span></span><br><span class="line"></span><br><span class="line">    s.listen()  <span class="comment"># 将socket置为监听状态，并等待客户端的连接</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        c, addr = s.accept() <span class="comment"># 在循环中不停调用accept接受来自客户端的连接</span></span><br><span class="line">        <span class="comment"># 接受来自任意客户端的连接，并返回一个新的socket c，以及客户端的ip地址。</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 为了避免程序的阻塞（block），创建一个新线程</span></span><br><span class="line">        t = threading.Thread(target=handle_client, args=(c,addr))   <span class="comment"># 新线程是 handle_client() </span></span><br><span class="line">        <span class="comment"># 将客户端的socket c和地址传递给这个线程</span></span><br><span class="line"></span><br><span class="line">        t.start()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 然后线程中的代码和单线程中的一样。</span></span><br></pre></td></tr></table></figure>



<p>在该python文件（比如socket_http.py）当前路径下，有一个子文件夹，取名叫webroot，里面有一些网页，代表客户端搜索不同的网址，会连接到服务器的哪些个网页里（这里服务器的路径指的就是该python文件）。</p>
<img src="/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/image-20230202101951030.png" alt="image-20230202101951030" style="zoom:67%;">

<p>然后启动 <code>sudo  python3 socket_http.py</code>，在浏览器页面中输入 <code>http://127.0.0.1/</code> 根路径，代码里要返回index.html这个文件，这个在网页中一般表示主页的意思，里面的内容也是自己定义的，这里”&#x2F;“就是指的根目录。如果在浏览器中输入 <code>http://127.0.0.1/123.HTML</code>，服务器端会返回给浏览器（客户端）123.html这个文件。</p>
<p>在浏览器（客户端）和服务器建立请求时，不用特定指定端口了，80就是服务器默认端口了，浏览器要建立就直接是80端口了。（每次发送连接请求，客户端的端口各不相同）</p>
<p>index.html内容：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>这是一个主页<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>浏览器呈现：</p>
<p><img src="/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/image-20230202102752447.png" alt="image-20230202102752447"></p>
<p>123.html内容：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>随便说点什么吧<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>浏览器呈现：</p>
<p><img src="/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/image-20230202102906931.png" alt="image-20230202102906931"></p>
<p>如果输入一个没有的链接：</p>
<p><img src="/2023/02/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/python%20socket/image-20230202103036882.png" alt="image-20230202103036882"></p>
<p>这样就实现了一个浏览器http和服务器的socket通信。</p>
<p>python的标准库里已经实现了一个简易的HTTP服务器，它主要被用在开发和测试中，调用起来很方便，命令是：<code>python -m http.server 8000</code> </p>
]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
      </tags>
  </entry>
  <entry>
    <title>socket入门</title>
    <url>/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/</url>
    <content><![CDATA[<h1 id="Socket通信"><a href="#Socket通信" class="headerlink" title="Socket通信"></a>Socket通信</h1><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV12A411X7gY/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">socket到底是什么？ </a>   对应公众号：<a href="https://mp.weixin.qq.com/s/VazobOgY9QVaADpEur81ng">socket到底是什么？</a></p>
</blockquote>
<h2 id="百度百科粗略的一个解释"><a href="#百度百科粗略的一个解释" class="headerlink" title="百度百科粗略的一个解释"></a>百度百科粗略的一个解释</h2><p>（百度百科粗略的一个解释，有浅显的一个理解，大概就是不同主机通信，收发数据的一个桥梁。）</p>
<p>socket（套接字）：对网络中不同主机上的应用进程之间进行双向通信的端点的抽象。一个套接字就是网络上进程通信的一端，提供了应用层进程利用网络协议交换数据的机制。 Socket是由IP地址和端口结合的，提供向应用层进程传送数据包的机制。</p>
<p>socket表示方法：套接字Socket&#x3D;（IP地址：端口号），套接字的表示方法是点分十进制的lP地址后面写上端口号，中间用冒号或逗号隔开。每一个传输层连接唯一地被通信两端的两个端点（即两个套接字）所确定。例如：如果IP地址是210.37.145.1，而端口号是23，那么得到套接字就是(210.37.145.1:23)   。</p>
<p>socket主要类型：</p>
<p><strong>1.流套接字(SOCK_STREAM)</strong></p>
<p>流套接字用于提供面向连接、可靠的数据传输服务。该服务将保证数据能够实现无差错、无重复送，并按顺序接收。流套接字之所以能够实现可靠的数据服务，原因在于其使用了传输控制协议，即TCP(The Transmission Control Protocol)协议。</p>
<p><strong>2.数据报套接字(SOCK_DGRAM)</strong></p>
<p>数据报套接字提供一种无连接的服务。该服务并不能保证数据传输的可靠性,数据有可能在传输过程中丢失或出现数据重复，且无法保证顺序地接收到数据。数据报套接字使用UDP( User DatagramProtocol)协议进行数据的传输。由于数据报套接字不能保证数据传输的可靠性，对于有可能出现的数据丢失情况，需要在程序中做相应的处理。</p>
<p><strong>3.原始套接字(SOCK_RAW)</strong></p>
<p>原始套接字与标准套接字(标准套接字指的是前面介绍的流套接字和数据报套接字)的区别在于：原始套接字可以读写内核没有处理的IP数据包，而流套接字只能读取TCP协议的数据，数据报套接字只能读取UDP协议的数据。因此，如果要访问其他协议发送的数据必须使用原始套接。</p>
<p>套接字之间的连接过程可以分为三个步骤：</p>
<ol>
<li>服务器监听：服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态。</li>
<li>客户端请求：由客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端接字提出连接请求。</li>
<li>连接确认：当服务器端套接字监听到或者说接收到客户端套接字的连接请求，就会响应客户端套接字的请求，建立一个新的线程，并把服务器端套接字的描述发送给客户端。一旦客户端确认了此描述，连接就建立好了。而服务器端套接字继续处于监听状态，接收其他客户端套接字的连接请求。</li>
</ol>
<h3 id="socket使用场景"><a href="#socket使用场景" class="headerlink" title="socket使用场景"></a>socket使用场景</h3><p>将数据从A电脑的某个进程发到B电脑的某个进程。</p>
<h3 id="socket白话理解"><a href="#socket白话理解" class="headerlink" title="socket白话理解"></a>socket白话理解</h3><p>为什么操作系统没有暴露tcp udp这些协议的使用给应用，说白了太底层了，用了一层socket封装，通过socket去操作底层协议的具体实现，应用程序只需要用socket暴露的API就好了。</p>
<p>一个内存里的抽象数据结构，用于管理硬件网卡对数据的收发。</p>
<h2 id="通信（网络传输）过程："><a href="#通信（网络传输）过程：" class="headerlink" title="通信（网络传输）过程："></a>通信（网络传输）过程：</h2><blockquote>
<p>b站：<a href="https://www.bilibili.com/video/BV12A411X7gY/?spm_id_from=333.337.search-card.all.click&vd_source=5e9891722f2b62adca440a5e92121b5b">socket到底是什么？ </a>   对应公众号：<a href="https://mp.weixin.qq.com/s/VazobOgY9QVaADpEur81ng">socket到底是什么？</a></p>
</blockquote>
<p>客户端、服务端各自执行socket方法，得到fd句柄之后，服务端依次执行bind、listen、accept方法，然后坐等客户端的连接请求 执行connect方法，向服务端发起建立连接的请求。连接建立完成后，客户端可以执行send方法发送消息，服务端可以执行recv()方法接收消息。反过来，服务器也可以执行send发送消息，客户端可以执行recv接收消息。</p>
<p>具体的：</p>
<p>第一步就是创建个关于TCP的<code>socket</code>。就像下面这样。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sock_fd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);</span><br></pre></td></tr></table></figure>

<p>这个方法会返回<code>socket_fd</code>，它是socket文件的句柄，是个数字，相当于socket的身份证号。</p>
<p>得到了<code>socket_fd</code>之后，对于服务端，就可以依次执行<code>bind()</code>, <code>listen()</code>, <code>accept()</code>方法，然后坐等客户端的连接请求。</p>
<p>对于客户端，得到<code>socket_fd</code>之后，你就可以执行<code>connect()</code>方法向服务端发起建立连接的请求，此时就会发生TCP三次握手。</p>
<p>连接建立完成后，<strong>客户端</strong>可以执行<code>send()</code> 方法发送消息，<strong>服务端</strong>可以执行<code>recv()</code>方法接收消息，反过来，<strong>服务器</strong>也可以执行<code>send()</code>，<strong>客户端</strong>执行<code>recv()</code>方法。</p>
<p><img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/640.gif" alt="640"></p>
<h2 id="socket的设计"><a href="#socket的设计" class="headerlink" title="socket的设计"></a>socket的设计</h2><p>网络传输，从操作上来看，就是两端之间<strong>互相</strong>收发数据，也就是对应<strong>读数据和写数据</strong>，也就是对文件的读、写（&#x3D;&#x3D;对远端服务器进程收发数据可以抽象为读和写&#x3D;&#x3D;）。</p>
<p>用一个数据结构（类），取名叫sock，表示互相收发读写功能。下面开始完善这个类，这个类定义过程中，需要解决两个问题：</p>
<ol>
<li>由于接收端和发送端不止一个，因此加入IP和端口做下区分，<strong>IP用来定位是哪台电脑，端口用来定位是这台电脑上的哪个进程。</strong></li>
<li>发送端和接收端的传输方式有很多区别，可以是可靠的<code>TCP协议</code>，也可以是不可靠的<code>UDP协议</code>，甚至还需要支持基于<code>icmp协议</code>的<code>ping命令</code>。</li>
</ol>
<p>解决第1个问题：可以在<code>sock</code>里加入<strong>IP和端口</strong>字段。</p>
<p>解决第2个问题：会发现这些协议虽然各不相同，但还是有一些功能相似的地方，比如收发数据时的一些逻辑完全可以复用。按面向对象编程的思想，我们可以将不同的协议当成是不同的<strong>对象类（或结构体）</strong>，将公共的部分提取出来，通过”<strong>继承</strong>“的方式，复用功能。（也就是说，不同协议是不同的类，用一个sock作为基类，不同协议类作为派生类，继承这个公共部分（基类））</p>
<h3 id="基于各种sock实现网络传输功能"><a href="#基于各种sock实现网络传输功能" class="headerlink" title="基于各种sock实现网络传输功能"></a>基于各种sock实现网络传输功能</h3><p>于是，我们将功能<strong>重新划分</strong>下，定义了一些数据结构。</p>
<p>继承sock的各类sock：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/642.png" alt="642" style="zoom:67%;">

<p><code>sock</code>是<strong>最基础</strong>的结构，维护一些任何协议都有可能会用到的收发数据缓冲区。</p>
<p><code>inet_sock</code>特指用了<strong>网络传输</strong>功能的<code>sock</code>，在<code>sock</code>的基础上还加入了<code>TTL</code>，<strong>端口，IP地址</strong>这些跟网络传输相关的字段信息。说到这里大家就懵了，难道还有不是用网络传输的？有，比如<code>Unix domain socket</code>，用于本机进程之间的通信，直接读写文件，不需要经过网络协议栈。</p>
<p><code>inet_connection_sock</code> 是指<strong>面向连接</strong>的<code>sock</code>，在<code>inet_sock</code>的基础上加入面向连接的协议里相关字段，比如<code>accept队列</code>，数据包分片大小，握手失败重试次数等。虽然我们现在提到面向连接的协议就是指TCP，但设计上linux需要支持扩展<strong>其他</strong>面向连接的<strong>新协议</strong>，比如SCTP协议。</p>
<p><code>tcp_sock</code> 就是正儿八经的<strong>tcp协议</strong>专用的<code>sock</code>结构了，在<code>inet_connection_sock</code>基础上还加入了tcp特有的<strong>滑动窗口</strong>、<strong>拥塞避免</strong>等功能。同样udp协议也会有一个专用的数据结构，叫<code>udp_sock</code>。</p>
<p>好了，现在有了这套数据结构，我们将它们跟<strong>硬件</strong>网卡对接一下，就实现了网络传输的功能。</p>
<h3 id="提供socket层"><a href="#提供socket层" class="headerlink" title="提供socket层"></a>提供socket层</h3><p>可以想象得到，这里面的代码肯定非常复杂，同时还操作了网卡硬件，需要比较高的<strong>操作系统权限</strong>，再考虑到性能和安全，于是决定将它放在<strong>操作系统内核</strong>里。</p>
<p>既然网络传输功能做在内核里，那用户空间的应用程序想要用这部分功能的话，该怎么办呢？</p>
<p>这个好办，本着不重复造轮子的原则，我们将这部分功能抽象成一个个<strong>简单的接口</strong>。以后别人只需要调用这些接口，就可以驱动我们写好的这一大堆复杂的数据结构去发送数据。</p>
<p>那么问题来了，<strong>怎么样将这部分功能暴露出去呢？让其他程序员更方便的使用呢？</strong></p>
<p>既然跟远端服务端进程收发数据可以抽象为“<strong>读和写</strong>”，操作文件也可以抽象为”<strong>读和写</strong>“，正好有句话叫，”<strong>linux里一切皆是文件</strong>“，那我们索性，&#x3D;&#x3D;<strong>将内核的sock封装成文件</strong>就好了。创建<code>sock</code>的同时也创建一个<strong>文件</strong>&#x3D;&#x3D;，<strong>文件有个句柄fd</strong>，说白了就是个<strong>文件系统</strong>里的<strong>身份证号码</strong>，通过它可以<strong>唯一确定</strong>是哪个<code>sock</code>。</p>
<blockquote>
<p>这个文件句柄fd其实就是 <code>sock_fd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP)</code> 里的<code>sock_fd</code>。</p>
</blockquote>
<p>将句柄暴露给用户，之后用户就可以像操作<strong>文件句柄</strong>那样去操作这个<strong>sock句柄</strong>。在用户空间里操作这个句柄，<strong>文件系统</strong>就会将操作<strong>指向</strong>内核<code>sock</code>结构。</p>
<p>是的，操作这个特殊的<strong>文件</strong>就相当于操作内核里对应的<code>sock</code>。</p>
<p>通过文件找到sock：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/641-16751508946574.png" alt="641" style="zoom:67%;">

<p>有了<code>sock_fd句柄</code>之后，我们就需要提供一些接口方法（API），让用户更方便的实现特定的网络编程功能。这些接口，我们列了一下，发现需要有<code>send()</code>，<code>recv()</code>，<code>bind()</code>, <code>listen()</code>，<code>connect()</code>这些。到这里，我们的内核网络传输功能就算设计完成了。</p>
<p>现在是不是眼熟了，<strong>上面这些接口方法其实就是&#x3D;&#x3D;socket&#x3D;&#x3D;提供出来的接口</strong>。</p>
<p>所以说，socket其实就是个<strong>代码库 or 接口层</strong>，它介于<strong>内核和应用程序之间</strong>，提供了一些<strong>高度封装过</strong>的接口，让我们去使用<strong>内核网络传输功能</strong>。</p>
<p>基于sock实现网络传输功能：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/643.png" alt="643" style="zoom:67%;">



<p>到这里，我们应该明白了。我们平时写的应用程序里代码里虽然用了socket实现了收发数据包的功能，但其实真正执行网络通信功能的，不是应用程序，而是<strong>linux内核</strong>。相当于&#x3D;&#x3D;应用程序通过socket提供的接口，将网络传输的这部分工作<strong>外包</strong>给了<strong>linux内核</strong>&#x3D;&#x3D;。</p>
<p>这听起来像不像我们最熟悉的<strong>前后端分离</strong>的服务架构，<strong>虽然这么说不太严谨</strong>，但看上去linux就像是被分成了<strong>应用程序和内核两个服务</strong>。内核就像是<strong>后端</strong>，暴露了好多个<strong>api接口</strong>，其中一类就是socket的<code>send()</code>和<code>recv()</code>这些方法。应用程序就像是<strong>前端</strong>，负责调用内核提供的接口来实现想要的功能。</p>
<p>进程通过socket调用内核功能：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/644.png" alt="644" style="zoom:67%;">



<p>看到这里，我担心大家会有点混乱，来做个小的<strong>总结</strong>。</p>
<p>&#x3D;&#x3D;<strong>在操作系统内核空间里，实现网络传输功能的结构是sock，基于不同的协议和应用场景，会被泛化为各种类型的xx_sock，它们结合硬件，共同实现了网络传输功能。为了将这部分功能暴露给用户空间的应用程序使用，于是引入了socket层，同时将sock嵌入到文件系统的框架里，sock就变成了一个特殊的文件，用户就可以在用户空间使用文件句柄，也就是socket_fd来操作内核sock的网络传输能力。</strong>&#x3D;&#x3D;</p>
<p>这个<code>socket_fd</code>是一个<strong>int类型的数字</strong>。现在回去看<code>socket</code>的中文翻译，<strong>套接字</strong>，<strong>我</strong>将它理解为一<strong>套</strong>用于连<strong>接</strong>的数<strong>字</strong>，是不是就觉得特别合理了。</p>
<p>网络分层与基于sock实现网络传输功能：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/645.png" alt="645" style="zoom:67%;">



<h2 id="socket如何实现网络通信"><a href="#socket如何实现网络通信" class="headerlink" title="socket如何实现网络通信"></a>socket如何实现网络通信</h2><p>以最常用的TCP协议为例，简单了解下它是怎么实现网络传输功能的。</p>
<p>将它分为两阶段，分别是<strong>建立连接</strong>和<strong>数据传输</strong>。</p>
<h3 id="建立连接"><a href="#建立连接" class="headerlink" title="建立连接"></a>建立连接</h3><p>对于TCP，要传数据，就得先在客户端和服务端中间<strong>建立连接</strong>。</p>
<p><strong>在客户端</strong>，代码执行socket提供的<code>connect(sockfd, &quot;ip:port&quot;)</code>方法时，会通过<strong>sockfd句柄</strong>找到对应的<strong>文件</strong>，再根据文件里的信息<strong>指向</strong>内核的<code>sock</code>结构。通过这个sock结构主动发起三次握手。</p>
<p>TCP三次握手：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/646.png" alt="646" style="zoom:67%;">



<p>在服务端握手次数还没达到”三次”的连接，叫<strong>半连接</strong>，完成好三次握手的连接，叫<strong>全连接</strong>。它们分别会用<strong>半连接队列</strong>和<strong>全连接队列</strong>来存放，这两个队列会在你执行<code>listen()</code>方法的时候创建好。当服务端执行<code>accept()</code>方法时，就会从全连接队列里拿出一条全连接。</p>
<p>半连接队列和全连接队列：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/647.png" alt="647" style="zoom:67%;">



<p>至此，连接就算准备好了，之后，就可以<strong>开始传输数据</strong>。</p>
<blockquote>
<p>虽然都叫队列，但半连接队列其实是个hash表，而全连接队列其实是个链表。</p>
<p>那么问题来了，为什么半连接队列要设计成哈希表而全连接队列是个链表？这个在我在我之前写的<a href="https://mp.weixin.qq.com/s?__biz=Mzg5NDY2MDk4Mw==&mid=2247487062&idx=1&sn=fa75a39e60f13e2275ff9ef7c96866de&scene=21#wechat_redirect">《没有accept，能建立TCP连接吗？》</a> 已经提到过，不再重复。</p>
</blockquote>
<h3 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h3><p>为了实现发送和接收数据的功能，sock结构体里带了<strong>一个发送缓冲区和一个接收缓冲区</strong>，&#x3D;&#x3D;说是<strong>缓冲区</strong>，但其实就是个<strong>链表</strong>&#x3D;&#x3D;，上面挂着一个个准备要发送或接收的数据。</p>
<p>当应用执行<code>send()</code>方法<strong>发送数据</strong>时，同样也会通过<code>sock_fd</code>句柄找到对应的文件，根据文件指向的<code>sock</code>结构，找到这个<code>sock</code>结构里带的<strong>发送缓冲区</strong>，将数据会放到发送缓冲区，然后结束流程，内核看心情决定什么时候将这份数据发送出去。</p>
<p><strong>接收数据</strong>流程也类似，当数据送到linux内核后，数据不是立马给到应用程序的，而是先放在接收缓冲区中，数据静静躺着，卑微的等待<strong>应用程序</strong>什么时候执行<code>recv()</code>方法来拿一下。</p>
<p>sock的发送和接收缓冲区：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/648.png" alt="648" style="zoom:67%;">

<p>IP和端口其实不在sock下，而在inet_sock下，上面这么画只是为了简化。</p>
<p>那么问题来了，发送数据是应用程序主动发起，这个大家都没问题。</p>
<p><strong>那接收数据呢？数据从远端发过来了，怎么通知并给到应用程序呢？</strong></p>
<p>这就需要用到<strong>等待队列</strong>。</p>
<p>sock内的等待队列：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/649.png" alt="649" style="zoom:67%;">

<p>当你的应用进程执行<code>recv()</code>方法尝试获取（阻塞场景下）接收缓冲区的数据时。</p>
<ul>
<li><p>如果有数据，那正好，取走就好了。这点没啥疑问。</p>
</li>
<li><p>但如果没数据，就会将自己的<strong>进程</strong>信息注册到这个sock用的<strong>等待队列</strong>里，然后进程<strong>休眠</strong>。如果这时候有数据从远端发过来了，数据进入到接收缓冲区时，内核就会取出sock的等待队列里的进程，<strong>唤醒</strong>进程来取数据。</p>
</li>
</ul>
<p>recv时无数据进程进入等待队列：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/650.png" alt="650" style="zoom: 50%;">



<p>有时候，你会看到<strong>多个进程</strong>通过<code>fork</code>的方式，<code>listen</code>了同一个<code>socket_fd</code>。在内核，它们都是<strong>同一个sock</strong>，多个进程执行listen()之后，都嗷嗷等待连接进来，所以都会将自身的进程信息注册到这个socket_fd对应的内核sock的<strong>等待队列</strong>中。如果这时真来了一个连接，是该唤醒等待队列里的哪个进程来接收连接呢？这个问题的答案比较有趣。</p>
<ul>
<li>在linux 2.6以前，会唤醒等待队列里的所有进程。但最后其实只有一个进程会处理这个连接请求，其他进程又重新进入休眠，这些被唤醒了又无事可做最后只能重新回去休眠的进程会消耗一定的资源。就好像你在广东的街头，想问路，叫一声靓仔，几十个人同时回头，但你其实只需要其中一个靓仔告诉你路该怎么走。你这种一不小心<strong>惊</strong>动这<strong>群</strong>靓仔的场景，在计算机领域中，就叫<strong>惊群效应</strong>。</li>
<li>在linux 2.6之后，只会唤醒等待队列里的其中一个进程。是的，socket监听的惊群效应问题被修复了。</li>
</ul>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/651.png" alt="651" style="zoom: 50%;">

<center><p>惊群效应</p></center>

<p>看到这里，问题又来了。</p>
<p><strong>服务端 listen 的时候，那么多数据到一个 socket 怎么区分多个客户端的？</strong></p>
<p>以TCP为例，服务端执行listen方法后，会等待客户端发送数据来。客户端发来的数据包上会有<strong>源IP地址和端口</strong>，以及<strong>目的IP地址和端口</strong>，这四个元素构成一个<strong>四元组</strong>，可以用于唯一标记一个客户端。</p>
<blockquote>
<p>其实说四元组并不严谨，因为过程中还有很多其他信息，也可以说是五元组。。。但大概理解就好，就这样吧。。。</p>
</blockquote>
<p>四元组：</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/652.png" alt="652" style="zoom: 50%;">



<p>服务端会创建一个新的内核sock，并用四元组生成一个<code>hash key</code>，将它放入到一个<code>hash表</code>中。</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/653.png" alt="653" style="zoom:50%;">

<center><p>四元组映射成hash键</p></center>



<p>下次再有消息进来的时候，通过消息自带的四元组生成<code>hash key</code>再到这个<code>hash表</code>里重新取出<strong>对应的sock</strong>就好了。所以说<strong>服务端是通过四元组来区分多个客户端的</strong>。</p>
<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/654.png" alt="654" style="zoom:50%;">

<center><p>多个hash_key对应多个客户端</p></center>



<h2 id="sock怎么实现”继承”"><a href="#sock怎么实现”继承”" class="headerlink" title="sock怎么实现”继承”"></a>sock怎么实现”继承”</h2><p>最后遗留一个问题。</p>
<p>大家都知道linux内核是C语言实现的，而<strong>C语言没有类也没有继承的特性，是怎么做到”继承”的效果的呢？</strong></p>
<p>在C语言里，结构体里的内存是<strong>连续</strong>的，将要继承的”父类”，放到结构体的<strong>第一位</strong>，就像下面这样。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> &#123;</span></span><br><span class="line">    <span class="comment">/* inet_connection_sock has to be the first member of tcp_sock */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">inet_connection_sock</span> <span class="title">inet_conn</span>;</span></span><br><span class="line">        <span class="comment">// 其他字段</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">inet_connection_sock</span> &#123;</span></span><br><span class="line">    <span class="comment">/* inet_sock has to be the first member! */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">inet_sock</span>   <span class="title">icsk_inet</span>;</span></span><br><span class="line">        <span class="comment">// 其他字段</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>然后我们就可以通过结构体名的长度来强行截取内存，这样就能转换结构体，从而实现类似”继承”的效果。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// sock 转为 tcp_sock</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="keyword">struct</span> tcp_sock *<span class="title function_">tcp_sk</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> sock *sk)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">struct</span> tcp_sock *)sk;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<img src="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/socket/655.png" alt="655" style="zoom:50%;">

<center>内存布局</center>



<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>socket中文套接字，我理解为一<strong>套</strong>用于连<strong>接</strong>的数<strong>字</strong>。</li>
<li>sock在内核，socket_fd在用户空间，socket层介于内核和用户空间之间。</li>
<li>在操作系统内核空间里，实现网络传输功能的结构是sock，基于不同的协议和应用场景，会被泛化为各种类型的xx_sock，它们结合硬件，共同实现了网络传输功能。为了将这部分功能暴露给用户空间的应用程序使用，于是引入了socket层，同时将sock嵌入到文件系统的框架里，sock就变成了一个特殊的文件，用户就可以在用户空间使用文件句柄，也就是socket_fd来操作内核sock的网络传输能力。</li>
<li>服务端可以通过四元组来区分多个客户端。</li>
<li>内核通过c语言”结构体里的内存是连续的”这一特点实现了类似继承的效果。</li>
</ul>
]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
      </tags>
  </entry>
  <entry>
    <title>简单的websocket_client.cc</title>
    <url>/2023/03/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E7%AE%80%E5%8D%95%E7%9A%84websocket_client.cc/</url>
    <content><![CDATA[<h1 id="简单的websocket-client-cc"><a href="#简单的websocket-client-cc" class="headerlink" title="简单的websocket_client.cc"></a>简单的websocket_client.cc</h1><p>参考的wenet&#x2F;runtime&#x2F;里websocker_client_main的写法，里面用了boost库进行websocket。进行语音识别，我这里把代码抠出来，只要websocket通信功能，后续开发什么功能（比如例子的语音识别）都可以。</p>
<p>参考前一篇《简单的websocket_server.cc》</p>
<p>yl_websocket_client.cc</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;yl_websocket_client.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/json/src.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line">namespace beast = boost::beast;          <span class="comment">// from &lt;boost/beast.hpp&gt;</span></span><br><span class="line">namespace http = beast::http;            <span class="comment">// from &lt;boost/beast/http.hpp&gt;</span></span><br><span class="line">namespace websocket = beast::websocket;  <span class="comment">// from &lt;boost/beast/websocket.hpp&gt;</span></span><br><span class="line">namespace asio = boost::asio;            <span class="comment">// from &lt;boost/asio.hpp&gt;</span></span><br><span class="line">using tcp = boost::asio::ip::tcp;        <span class="comment">// from &lt;boost/asio/ip/tcp.hpp&gt;</span></span><br><span class="line">namespace json = boost::json;</span><br><span class="line"></span><br><span class="line">WebSocketClient::WebSocketClient(<span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; hostname, <span class="type">int</span> port)</span><br><span class="line">    : hostname_(hostname), port_(port) &#123;</span><br><span class="line">  Connect();</span><br><span class="line"><span class="comment">//   t_.reset(new std::thread(&amp;WebSocketClient::ReadLoopFunc, this));</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">WebSocketClient::Connect</span><span class="params">()</span> &#123;</span><br><span class="line">  tcp::resolver resolver&#123;ioc_&#125;;</span><br><span class="line">  <span class="comment">// Look up the domain name</span></span><br><span class="line">  <span class="keyword">auto</span> <span class="type">const</span> results = resolver.resolve(hostname_, <span class="built_in">std</span>::to_string(port_));</span><br><span class="line">  <span class="comment">// Make the connection on the IP address we get from a lookup</span></span><br><span class="line">  <span class="keyword">auto</span> ep = asio::connect(ws_.next_layer(), results);</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> host = hostname_ + <span class="string">&quot;:&quot;</span> + <span class="built_in">std</span>::to_string(ep.port());</span><br><span class="line">  <span class="comment">// Perform the websocket handshake</span></span><br><span class="line">  ws_.handshake(host, <span class="string">&quot;/&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">WebSocketClient::SendStartSignal</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="comment">// json::value start_tag = &#123;&#123;&quot;signal&quot;, &quot;start&quot;&#125;&#125;;</span></span><br><span class="line">  <span class="comment">// std::string start_message = json::serialize(start_tag);</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> start_message = <span class="string">&quot;start&quot;</span>;</span><br><span class="line">  this-&gt;SendTextData(start_message);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">WebSocketClient::SendTextData</span><span class="params">(<span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; data)</span> &#123;</span><br><span class="line">  ws_.text(<span class="literal">true</span>);</span><br><span class="line">  ws_.write(asio::buffer(data));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">WebSocketClient::ReadSignal</span><span class="params">()</span> &#123;</span><br><span class="line">  try &#123;</span><br><span class="line">      <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        beast::flat_buffer buffer;</span><br><span class="line">        ws_.read(buffer);</span><br><span class="line">        <span class="keyword">if</span>(ws_.got_text())&#123;</span><br><span class="line">          <span class="built_in">std</span>::<span class="built_in">string</span> message = beast::buffers_to_string(buffer.data());</span><br><span class="line">          <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; message;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; catch (beast::system_error <span class="type">const</span>&amp; se) &#123;</span><br><span class="line">      <span class="comment">// This indicates that the session was closed</span></span><br><span class="line">      <span class="keyword">if</span> (se.code() != websocket::error::closed) &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; se.code().message();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; catch (<span class="built_in">std</span>::exception <span class="type">const</span>&amp; e) &#123;</span><br><span class="line">      <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; e.what();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  WebSocketClient <span class="title function_">client</span><span class="params">(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">10021</span>)</span>;</span><br><span class="line">  client.SendStartSignal();</span><br><span class="line">  client.ReadSignal();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>yl_websocket_client.h：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> WEBSOCKET_WEBSOCKET_CLIENT_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> WEBSOCKET_WEBSOCKET_CLIENT_H_</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/asio/connect.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/asio/ip/tcp.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/beast/core.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/beast/websocket.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line">namespace beast = boost::beast;          <span class="comment">// from &lt;boost/beast.hpp&gt;</span></span><br><span class="line">namespace http = beast::http;            <span class="comment">// from &lt;boost/beast/http.hpp&gt;</span></span><br><span class="line">namespace websocket = beast::websocket;  <span class="comment">// from &lt;boost/beast/websocket.hpp&gt;</span></span><br><span class="line">namespace asio = boost::asio;            <span class="comment">// from &lt;boost/asio.hpp&gt;</span></span><br><span class="line">using tcp = boost::asio::ip::tcp;        <span class="comment">// from &lt;boost/asio/ip/tcp.hpp&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WebSocketClient</span> &#123;</span></span><br><span class="line"> public:</span><br><span class="line">  WebSocketClient(<span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; host, <span class="type">int</span> port);</span><br><span class="line"></span><br><span class="line">  <span class="type">void</span> <span class="title function_">SendTextData</span><span class="params">(<span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; data)</span>;</span><br><span class="line"><span class="comment">//   void SendBinaryData(const void* data, size_t size);</span></span><br><span class="line"><span class="comment">//   void ReadLoopFunc();</span></span><br><span class="line"><span class="comment">//   void Close();</span></span><br><span class="line"><span class="comment">//   void Join();</span></span><br><span class="line">  <span class="type">void</span> <span class="title function_">SendStartSignal</span><span class="params">()</span>;</span><br><span class="line">  <span class="type">void</span> <span class="title function_">ReadSignal</span><span class="params">()</span>;</span><br><span class="line"><span class="comment">//   void SendEndSignal();</span></span><br><span class="line"><span class="comment">//   bool done() const &#123; return done_; &#125;</span></span><br><span class="line"></span><br><span class="line"> private:</span><br><span class="line">  <span class="type">void</span> <span class="title function_">Connect</span><span class="params">()</span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> hostname_;</span><br><span class="line">  <span class="type">int</span> port_;</span><br><span class="line">  <span class="type">bool</span> done_ = <span class="literal">false</span>;</span><br><span class="line">  asio::io_context ioc_;</span><br><span class="line">  websocket::stream&lt;tcp::socket&gt; ws_&#123;ioc_&#125;;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;<span class="built_in">std</span>::thread&gt; t_&#123;nullptr&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">// WEBSOCKET_WEBSOCKET_CLIENT_H_</span></span></span><br></pre></td></tr></table></figure>



<p>然后在命令行窗口执行 <code>./build/yl_websocket_server_main</code> 启动server端</p>
<p>在另一个命令行窗口执行 <code>./build/yl_websocket_client_main</code>  。</p>
<p>这里的功能是发送了一个start的消息给server，server接收到打印出来，server也发送一条success的消息给client，client接收到打印出来。</p>
<p>server是用多线程，client没有用，这是考虑到多个client向同一个server发起请求的情况。</p>
]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
        <tag>socket通信</tag>
      </tags>
  </entry>
  <entry>
    <title>websocketd</title>
    <url>/2023/03/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/websocketd/</url>
    <content><![CDATA[<h1 id="websocketd"><a href="#websocketd" class="headerlink" title="websocketd"></a>websocketd</h1><blockquote>
<p><a href="http://websocketd.com/">http://websocketd.com/</a></p>
</blockquote>
<p>举例：</p>
<h1 id="10-second-tutorial"><a href="#10-second-tutorial" class="headerlink" title="10 second tutorial"></a>10 second tutorial</h1><p>举例来说，下面是一个 Bash 脚本<code>counter.sh</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Count from 1 to 10 with a sleep</span></span><br><span class="line"><span class="keyword">for</span> ((COUNT = 1; COUNT &lt;= 10; COUNT++)); <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$COUNT</span></span><br><span class="line">  <span class="built_in">sleep</span> 0.5</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>



<p>或者python版本（也可以其它版本）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="keyword">from</span> sys <span class="keyword">import</span> stdout</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"><span class="comment"># Count from 1 to 10 with a sleep</span></span><br><span class="line"><span class="keyword">for</span> count <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>):</span><br><span class="line">  <span class="built_in">print</span>(count + <span class="number">1</span>)</span><br><span class="line">  stdout.flush()</span><br><span class="line">  sleep(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>



<p>或者C版本：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Disable output buffering.</span></span><br><span class="line">    setbuf(<span class="built_in">stdout</span>, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, i);</span><br><span class="line">        usleep(<span class="number">500000</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>命令行下运行这个脚本，会输出1、2、3、…，每个值之间间隔0.5秒。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ bash ./counter.sh</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td></tr></table></figure>



<p>现在，启动<code>websocketd</code>，指定这个脚本作为服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ websocketd --port=8080 bash ./counter.sh</span><br></pre></td></tr></table></figure>



<p>上面的命令会启动一个 WebSocket 服务器，端口是<code>8080</code>。每当客户端连接这个服务器，就会执行<code>counter.sh</code>脚本，并将它的输出推送给客户端。</p>
<p>然后启动客户端，连接客户端的程序到服务器端：</p>
<p>server.js：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title class_">WebSocket</span> = <span class="built_in">require</span>(<span class="string">&#x27;ws&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> ws = <span class="keyword">new</span> <span class="title class_">WebSocket</span>(<span class="string">&#x27;ws://localhost:8080/&#x27;</span>);</span><br><span class="line"></span><br><span class="line">ws.<span class="property">onmessage</span> = <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Count is: &#x27;</span> + event.<span class="property">data</span>);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<p>在命令行窗口执行 <code>node server.js</code></p>
<p>（比如报错 <a href="https://stackoverflow.com/questions/43311238/javascript-referenceerror-websocket-is-not-defined">JavaScript - ReferenceError: WebSocket is not defined</a> 则 在命令行窗口执行 <code>npm i ws</code>）</p>
<p>客户端返回 counter.sh的输出。</p>
<p>服务端显示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Mon, 06 Mar 2023 10:07:40 +0800 | INFO   | server     |  | Serving using application   : /usr/bin/bash ./counter.sh</span><br><span class="line">Mon, 06 Mar 2023 10:07:40 +0800 | INFO   | server     |  | Starting WebSocket server   : ws://LAPTOP-D2HCBJT4:8080/</span><br><span class="line"></span><br><span class="line">Mon, 06 Mar 2023 10:40:10 +0800 | ACCESS | session    | url:<span class="string">&#x27;http://localhost:8080/&#x27;</span> <span class="built_in">id</span>:<span class="string">&#x27;1678070410339596900&#x27;</span> remote:<span class="string">&#x27;127.0.0.1&#x27;</span> <span class="built_in">command</span>:<span class="string">&#x27;/usr/bin/bash&#x27;</span> origin:<span class="string">&#x27;file:&#x27;</span> | CONNECT</span><br><span class="line">Mon, 06 Mar 2023 10:40:12 +0800 | ACCESS | session    | url:<span class="string">&#x27;http://localhost:8080/&#x27;</span> <span class="built_in">id</span>:<span class="string">&#x27;1678070410339596900&#x27;</span> remote:<span class="string">&#x27;127.0.0.1&#x27;</span> <span class="built_in">command</span>:<span class="string">&#x27;/usr/bin/bash&#x27;</span> origin:<span class="string">&#x27;file:&#x27;</span> pid:<span class="string">&#x27;837&#x27;</span> | DISCONNECT</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
        <tag>socket通信</tag>
      </tags>
  </entry>
  <entry>
    <title>简单的websocket_server.cc</title>
    <url>/2023/03/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E7%AE%80%E5%8D%95%E7%9A%84websocket_server.cc/</url>
    <content><![CDATA[<h1 id="简单的websocket-server-cc"><a href="#简单的websocket-server-cc" class="headerlink" title="简单的websocket_server.cc"></a>简单的websocket_server.cc</h1><p>参考的wenet&#x2F;runtime&#x2F;里websocker_server_main的写法，里面用了boost库进行websocket。进行语音识别，我这里把代码抠出来，只要websocket通信功能，后续开发什么功能（比如例子的语音识别）都可以。</p>
<p>命令行敲 <code>tree -L 2 . </code> ， 查看二级目录</p>
<p>这里一开始只要新建yl_websocket_server.cc、yl_websocket_server.h、cmake里的boost.cmake、CMakeLists.txt就行，其它的（build&#x2F;和fc_base文件夹）都是后续生成的。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── CMakeLists.txt</span><br><span class="line">├── build</span><br><span class="line">│   ├── CMakeCache.txt</span><br><span class="line">│   ├── CMakeFiles</span><br><span class="line">│   ├── Makefile</span><br><span class="line">│   ├── cmake_install.cmake</span><br><span class="line">│   ├── yl_websocket_client_main</span><br><span class="line">│   └── yl_websocket_server_main</span><br><span class="line">├── cmake</span><br><span class="line">│   └── boost.cmake</span><br><span class="line">├── fc_base</span><br><span class="line">│   ├── boost-build</span><br><span class="line">│   ├── boost-src</span><br><span class="line">│   ├── boost-subbuild</span><br><span class="line">│   └── ex-boost-populate1234</span><br><span class="line">├── yl_websocket_client.cc</span><br><span class="line">├── yl_websocket_client.h</span><br><span class="line">├── yl_websocket_server.cc</span><br><span class="line">└── yl_websocket_server.h</span><br></pre></td></tr></table></figure>



<p>其中几个文件内容：</p>
<p>yl_websocket_server.cc：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;yl_websocket_server.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/json/src.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line">namespace beast = boost::beast;          <span class="comment">// from &lt;boost/beast.hpp&gt;</span></span><br><span class="line">namespace http = beast::http;            <span class="comment">// from &lt;boost/beast/http.hpp&gt;</span></span><br><span class="line">namespace websocket = beast::websocket;  <span class="comment">// from &lt;boost/beast/websocket.hpp&gt;</span></span><br><span class="line">namespace asio = boost::asio;            <span class="comment">// from &lt;boost/asio.hpp&gt;</span></span><br><span class="line">using tcp = boost::asio::ip::tcp;        <span class="comment">// from &lt;boost/asio/ip/tcp.hpp&gt;</span></span><br><span class="line">namespace json = boost::json;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ConnectionHandler::ConnectionHandler(tcp::socket&amp;&amp; socket): ws_(<span class="built_in">std</span>::move(socket)) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">ConnectionHandler::operator</span><span class="params">()</span><span class="params">()</span> &#123;</span><br><span class="line">  try &#123;</span><br><span class="line">    <span class="comment">// Accept the websocket handshake</span></span><br><span class="line">    ws_.accept();</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">      <span class="comment">// This buffer will hold the incoming message</span></span><br><span class="line">      beast::flat_buffer buffer;</span><br><span class="line">      <span class="comment">// Read a message</span></span><br><span class="line">      ws_.read(buffer); <span class="comment">//看ws_读数据，也就是先有client给ws_写了东西</span></span><br><span class="line">      <span class="keyword">if</span> (ws_.got_text()) &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">string</span> message = beast::buffers_to_string(buffer.data());</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; message &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">string</span> backmessage = <span class="string">&quot;success&quot;</span>; </span><br><span class="line">        ws_.text(<span class="literal">true</span>);</span><br><span class="line">        ws_.write(asio::buffer(backmessage)); <span class="comment">// 写给client</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125; </span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; catch (beast::system_error <span class="type">const</span>&amp; se) &#123;</span><br><span class="line">    <span class="comment">// LOG(INFO) &lt;&lt; se.code().message();</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; se.code().message();</span><br><span class="line">    <span class="comment">// This indicates that the session was closed</span></span><br><span class="line">    <span class="keyword">if</span> (se.code() == websocket::error::closed) &#123;</span><br><span class="line">    <span class="comment">//   OnSpeechEnd();</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// if (decode_thread_ != nullptr) &#123;</span></span><br><span class="line">    <span class="comment">//   decode_thread_-&gt;join();</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">  &#125; catch (<span class="built_in">std</span>::exception <span class="type">const</span>&amp; e) &#123;</span><br><span class="line">    <span class="comment">// LOG(ERROR) &lt;&lt; e.what();</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; e.what();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">WebSocketServer::Start</span><span class="params">()</span>&#123;</span><br><span class="line">    try&#123;</span><br><span class="line">        <span class="keyword">auto</span> <span class="type">const</span> address = asio::ip::make_address(<span class="string">&quot;0.0.0.0&quot;</span>);</span><br><span class="line">        tcp::acceptor acceptor&#123;ioc_, &#123;address, static_cast&lt;<span class="type">uint16_t</span>&gt;(port_)&#125;&#125;;</span><br><span class="line">        <span class="comment">// 一直在循环执行</span></span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            <span class="comment">// This will receive the new connection</span></span><br><span class="line">            tcp::socket socket&#123;ioc_&#125;;</span><br><span class="line">            <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;wait message&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">            <span class="comment">// Block until we get a connection</span></span><br><span class="line">            acceptor.accept(socket);  <span class="comment">// 接受客户端连接请求，在这里地方就停住了，直到客户端有请求，程序才接着往下走。</span></span><br><span class="line">            <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;receive&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">            <span class="comment">// Launch the session, transferring ownership of the socket</span></span><br><span class="line">            ConnectionHandler <span class="title function_">handler</span><span class="params">(<span class="built_in">std</span>::move(socket))</span>; </span><br><span class="line">            <span class="built_in">std</span>::thread <span class="title function_">t</span><span class="params">(<span class="built_in">std</span>::move(handler))</span>;  <span class="comment">// 在子线程中 进入operator函数</span></span><br><span class="line">            t.detach();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (<span class="type">const</span> <span class="built_in">std</span>::exception&amp; e) &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; e.what();</span><br><span class="line">        <span class="comment">// LOG(ERROR) &lt;&lt; e.what();</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    WebSocketServer <span class="title function_">server</span><span class="params">(<span class="number">10021</span>)</span>;</span><br><span class="line">    server.Start();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>yl_websocket_server.h：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> WEBSOCKET_WEBSOCKET_SERVER_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> WEBSOCKET_WEBSOCKET_SERVER_H_</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/asio/connect.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/asio/ip/tcp.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/beast/core.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;boost/beast/websocket.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line">namespace beast = boost::beast;          <span class="comment">// from &lt;boost/beast.hpp&gt;</span></span><br><span class="line"><span class="comment">// namespace http = beast::http;            // from &lt;boost/beast/http.hpp&gt;</span></span><br><span class="line">namespace websocket = beast::websocket;  <span class="comment">// from &lt;boost/beast/websocket.hpp&gt;</span></span><br><span class="line">namespace asio = boost::asio;            <span class="comment">// from &lt;boost/asio.hpp&gt;</span></span><br><span class="line">using tcp = boost::asio::ip::tcp;        <span class="comment">// from &lt;boost/asio/ip/tcp.hpp&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConnectionHandler</span> &#123;</span></span><br><span class="line"> public:</span><br><span class="line">  ConnectionHandler(tcp::socket&amp;&amp; socket);</span><br><span class="line">  <span class="type">void</span> <span class="title function_">operator</span><span class="params">()</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line"> private:</span><br><span class="line">  websocket::stream&lt;tcp::socket&gt; ws_;</span><br><span class="line"></span><br><span class="line">  <span class="type">bool</span> got_start_tag_ = <span class="literal">false</span>;</span><br><span class="line">  <span class="type">bool</span> got_end_tag_ = <span class="literal">false</span>;</span><br><span class="line">  <span class="comment">// When endpoint is detected, stop recognition, and stop receiving data.</span></span><br><span class="line">  <span class="type">bool</span> stop_recognition_ = <span class="literal">false</span>;</span><br><span class="line">  </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WebSocketServer</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">    WebSocketServer(<span class="type">int</span> port):port_(port)&#123;&#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">Start</span><span class="params">()</span>;</span><br><span class="line">private:</span><br><span class="line">    <span class="type">int</span> port_;</span><br><span class="line">    asio::io_context ioc_&#123;<span class="number">1</span>&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// WEBSOCKET_WEBSOCKET_SERVER_H_</span></span></span><br></pre></td></tr></table></figure>



<p><code>cmake/boost.cmake</code>：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">FetchContent_Declare(boost</span><br><span class="line">  URL      https://boostorg.jfrog.io/artifactory/main/release/<span class="number">1.75</span>.<span class="number">0</span>/source/boost_1_75_0.tar.gz</span><br><span class="line">  URL_HASH SHA256=aeb26f80e80945e82ee93e5939baebdca47b9dee80a07d3144be1e1a6a66dd6a</span><br><span class="line">)</span><br><span class="line">FetchContent_MakeAvailable(boost)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;boost_SOURCE_DIR&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(MSVC)</span><br><span class="line">  <span class="keyword">add_definitions</span>(-DBOOST_ALL_DYN_LINK -DBOOST_ALL_NO_LIB)</span><br></pre></td></tr></table></figure>

<p>这个会自动下载boost包</p>
<p><code>CMakeLists.txt</code>：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.14</span> FATAL_ERROR)</span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span> (websockettest)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) </span></span><br><span class="line"><span class="comment"># SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;)</span></span><br><span class="line"><span class="comment"># SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_VERBOSE_MAKEFILE <span class="keyword">OFF</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">include</span>(FetchContent)</span><br><span class="line"><span class="keyword">set</span>(FETCHCONTENT_QUIET <span class="keyword">OFF</span>)</span><br><span class="line"><span class="keyword">get_filename_component</span>(fc_base <span class="string">&quot;fc_base&quot;</span> REALPATH BASE_DIR <span class="string">&quot;$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;&quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(FETCHCONTENT_BASE_DIR <span class="variable">$&#123;fc_base&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">list</span>(APPEND CMAKE_MODULE_PATH <span class="variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/cmake)</span><br><span class="line"><span class="comment"># target_link_libraries(yl_websocket_server_main PUBLIC websocket)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">NOT</span> MSVC)</span><br><span class="line">  <span class="comment"># Keep the same with openfst, -fPIC or -fpic</span></span><br><span class="line">  <span class="keyword">set</span>(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++14 -pthread -fPIC&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>()</span><br><span class="line">  <span class="keyword">set</span>(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS <span class="keyword">ON</span>)</span><br><span class="line">  <span class="keyword">add_compile_options</span>(<span class="string">&quot;$&lt;$&lt;CXX_COMPILER_ID:MSVC&gt;:/utf-8&gt;&quot;</span>)</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">include</span>(boost)</span><br><span class="line"></span><br><span class="line"><span class="comment"># aux_source_directory(. DIR_LIB_SRCS)</span></span><br><span class="line"><span class="comment"># add_executable(yl_websocket_server_main $&#123;DIR_LIB_SRCS&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(yl_websocket_server_main yl_websocket_server.cc)</span><br><span class="line"><span class="keyword">add_executable</span>(yl_websocket_client_main yl_websocket_client.cc)</span><br></pre></td></tr></table></figure>



<p>然后在命令行里敲：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">cmake --build .</span><br></pre></td></tr></table></figure>



<p>就可以在build&#x2F;里看见名叫yl_websocket_server的可执行文件了。</p>
]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
        <tag>socket通信</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机科学速成课</title>
    <url>/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/</url>
    <content><![CDATA[<h1 id="计算机科学速成课"><a href="#计算机科学速成课" class="headerlink" title="计算机科学速成课"></a>计算机科学速成课</h1><blockquote>
<p>2022.12.27</p>
<p>b站 <a href="https://www.bilibili.com/video/BV1EW411u7th/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">【计算机科学速成课】[40集全&#x2F;精校] - Crash Course Computer Science</a></p>
<p>网友的笔记：<a href="https://shimo.im/docs/vkCKkj3YxGtygrVg/read">https://shimo.im/docs/vkCKkj3YxGtygrVg/read</a> 、 <a href="https://shimo.im/docs/PJAUY30F1uYksv0h/read">https://shimo.im/docs/PJAUY30F1uYksv0h/read</a> 、<a href="https://www.processon.com/view/link/61ef6e8f0e3e7439ae917672#map">https://www.processon.com/view/link/61ef6e8f0e3e7439ae917672#map</a></p>
</blockquote>
<h2 id="5-算术逻辑单元-ALU"><a href="#5-算术逻辑单元-ALU" class="headerlink" title="5.算术逻辑单元 ALU"></a>5.算术逻辑单元 ALU</h2><p><strong>8位行波进位加法器 8-bit ripple carry adder</strong></p>
<p>加法时，A和B的每一位分别相加，输出sum和carry进位数，进位数再后面的A和B的位相加（通过full adder），输出sum和carry进位数。</p>
<img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227164420738.png" alt="image-20221227164420738" style="zoom: 80%;">

<p>half adder、full adder都是由逻辑门构成（电流来控制不同的输出，电流作用类似开关）</p>
<p>现在计算机不用这个8位行波进位加法器，而是用“超前进位加法器” carry-look-ahead adder</p>
<h2 id="寄存器-amp-内存-Registers-and-RAM"><a href="#寄存器-amp-内存-Registers-and-RAM" class="headerlink" title="寄存器 &amp; 内存-Registers and RAM"></a>寄存器 &amp; 内存-Registers and RAM</h2><p>把输出接回输入，当输入A输入1时，输出为1，接回来B也是1，输出1。之后如果A输入0，输出还是1，变得不管A是0或1，输出都是1。</p>
<img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227173010474.png" alt="image-20221227173010474" style="zoom: 50%;">



<img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227173316947.png" alt="image-20221227173316947" style="zoom:80%;">



<p><img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227173342706.png" alt="image-20221227173342706"></p>
<p>存储memory ，and-or 锁存器，锁存，因为它“锁定”（latch）了一个值</p>
<img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227173826032.png" alt="image-20221227173826032" style="zoom: 50%;">



<p>一串锁存器组成寄存器register。</p>
<p>用矩阵（行、列）排列锁存器。对于256位的存储，只要35条线，即一条“数据线”，一条“允许写入线”，一条“允许读取线”，还有16行16列的线用于选择锁存器（16+16+3&#x3D;35）。<br>因此4位表示行地址，4位表示列地址，就能得到某个锁存器的地址了。</p>
<p>实现的方法是通过 多路复用器 multiplexer。</p>
<p>内存的一个重要特性是：可以随时访问任何位置，因此叫“随机存取存储器”，简称 RAM（random-access memory）</p>
<h2 id="7-中央处理器-CPU-The-Central-Processing-Unit"><a href="#7-中央处理器-CPU-The-Central-Processing-Unit" class="headerlink" title="7. 中央处理器(CPU)-The Central Processing Unit"></a>7. 中央处理器(CPU)-The Central Processing Unit</h2><p>指令地址寄存器：一个寄存器追踪程序运行到哪里了，存当前指令的内存地址。</p>
<p>指令寄存器：一个寄存器存当前指令。</p>
<img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227191530623.png" alt="image-20221227191530623" style="zoom:50%;">





<h2 id="8-指令和程序-Instructions-amp-Programs"><a href="#8-指令和程序-Instructions-amp-Programs" class="headerlink" title="8. 指令和程序-Instructions &amp; Programs"></a>8. 指令和程序-Instructions &amp; Programs</h2><p>指令，就是程序的一条条命令，从第一条开始执行，比如把第一条指令里面的地址内容放到寄存器A，或者add，或者jump到某个指令，停止halt。</p>
<p><img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227225041097.png" alt="image-20221227225041097"></p>
<h2 id="9-高级CPU设计-Advanced-CPU-Designs"><a href="#9-高级CPU设计-Advanced-CPU-Designs" class="headerlink" title="9. 高级CPU设计-Advanced CPU Designs"></a>9. 高级CPU设计-Advanced CPU Designs</h2><p>指令集，就是类似jump等指令的集合，是固定数量的，如果不同cpu都有一份指令集，不同cpu要兼容各个指令集，指令数量就会越来越多。</p>
<p>即使cpu时钟很高可以处理指令很快，但是ram存储器和cpu交互、传输的数据线（叫 总线 bus）可能传输得不够快，有延迟。因此用到了“缓存”cache。</p>
<p>先把ram内存的一批地址的数据复制到cpu的缓存里。</p>
<img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227225336293.png" alt="image-20221227225336293" style="zoom:50%;">



<p>当缓存里的数和ram的同一个地址的内容不一致时，要记录下来，以便于后续ram的同步。因此缓存里每块空间都有一个特殊标记，叫“脏位”dirty bit。</p>
<p>同步一般发生在缓存满了，cpu要新的地址内容（缓存里没有）时，在清理缓存腾出空间之前，会先检查脏位。如果是脏的，在加载新内容之前，会把数据写回ram。</p>
<p>指令流水线 instruction pipeline</p>
<img src="/2022/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/image-20221227230531536.png" alt="image-20221227230531536" style="zoom:50%;">





<p><strong>乱序执行 out-of-order execution</strong>：解决指令之间的依赖关系（举例子：你在读某个数据，正在执行的指令会改这个数据，变成拿的旧数据了）。因此要动态排序有依赖关系的指令，以达到最小化流水线的时间。</p>
<p><strong>分支预测 branch prediction</strong>：解决条件跳转（conditional jump instruction）（比如jump negative等指令）造成cpu空等的时间（cpu空等因为要等条件跳转的结果出来（结果是可能会跳转，也可能不会跳转））。jump想成“岔路口”branch，<strong>cpu会猜哪条路的可能性大一点</strong>，然后提前把指令放进流水线，这叫“推测执行”spectaculative execution。当jump的结果出了，cpu猜对的话，流水线已经塞满正确指令，可以马上执行（就没有延迟了），猜错了，就要清空流水线 pipeline flush，就像走错路掉头。这种猜测哪条分支更有可能的方法叫分支预测。</p>
<p>超标量处理器 superscalar 一个时钟周期完成多个指令。</p>
<p>超级计算机 supercomputer 很多个cpu组成。</p>
<h2 id="10-早期的编程方式-Early-Programming"><a href="#10-早期的编程方式-Early-Programming" class="headerlink" title="10. 早期的编程方式-Early Programming"></a>10. 早期的编程方式-Early Programming</h2>]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机科学速成课（三）</title>
    <url>/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="计算机科学速成课（三）"><a href="#计算机科学速成课（三）" class="headerlink" title="计算机科学速成课（三）"></a>计算机科学速成课（三）</h1><blockquote>
<p>2022.12.29</p>
<p>b站 <a href="https://www.bilibili.com/video/BV1EW411u7th/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">【计算机科学速成课】[40集全&#x2F;精校] - Crash Course Computer Science</a></p>
</blockquote>
<h2 id="20-文件系统-Files-amp-File-Systems"><a href="#20-文件系统-Files-amp-File-Systems" class="headerlink" title="20. 文件系统-Files &amp; File Systems"></a>20. 文件系统-Files &amp; File Systems</h2><p>文件（比如txt、wav、bmp）在底层全是一样的，一长串二进制，为了知道文件是什么，文件格式至关重要。</p>
<p>元数据 meta data，就是数据头header，写数据的一些信息、属性，比如文件有多长。</p>
<p>为了存多个文件（为了知道不同文件的开头和结尾在哪里，因为存储器只是存大量的bit，没有文件概念），需要一个特殊文件，记录其他文件的位置，这个特殊文件叫“目录文件”。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229155456876.png" alt="image-20221229155456876" style="zoom:50%;">



<p>目录文件会存每个文件的信息，比如创造时间、开始位置、结束位置。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229155716320.png" alt="image-20221229155716320" style="zoom:50%;">



<p>增加某文件内存可能会影响后面文件，因此现代文件系统会做两件事：1.把空间分成一块块，有一些“预留空间” slack space 可以方便改动、方便管理。因此目录文件还要记录文件在哪些块里；2.拆分文件，存在多个块里，因此只要分配块，文件可以轻松增大缩小。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229160055376.png" alt="image-20221229160055376" style="zoom:50%;">



<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229160311205.png" alt="image-20221229160311205" style="zoom:50%;">



<p>文件在不同块block里，叫做“碎片” framentation。碎片整理。</p>
<h2 id="21-压缩-Compression"><a href="#21-压缩-Compression" class="headerlink" title="21. 压缩-Compression"></a>21. 压缩-Compression</h2><p>压缩来减少文件的字节数。</p>
<p>无损压缩：没有丢失任何数据，解压缩后，数据和压缩前的完全一样。无损压缩的格式有：GIF，PNG，PDF，ZIP。游程编码、字典编码。</p>
<p>压缩方法：</p>
<ol>
<li>游程编码 run-length encoding 减少重复信息，适合经常出现相同值的文件。<strong>消除冗余</strong>。</li>
</ol>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229164251003.png" alt="image-20221229164251003" style="zoom: 67%;">

<ol start="2">
<li>字典编码 dictionary encoding 。霍夫曼树 huffman tree。选<strong>频率</strong>最低的两个，放在一起，记录总频率，再重复上述操作。<strong>用更紧凑的表示方法</strong>。</li>
</ol>
<p>按频率排列，频率高的在上面。这种<strong>编码不会冲突</strong>，因为树的每条路径唯一，也就是不会出现某个编码是另一个编码的前缀的情况，称为“无前缀” prefix-free。</p>
<p><img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229164901465.png" alt="image-20221229164901465"></p>
<p>压缩：</p>
<p><img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229164838329.png" alt="image-20221229164838329"></p>
<p>原本是：</p>
<p><img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229165943601.png" alt="image-20221229165943601"></p>
<p>变成：</p>
<p><img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229165916051.png" alt="image-20221229165916051"></p>
<p>有损压缩 lossy compression 丢掉那些人类区分不出的数据。</p>
<p>音频压缩，用不同精度编码不同频段。感知编码 perceptual coding。</p>
<p>图片压缩，人类对物体边缘、尖锐对比敏感，对颜色细微变化不敏感。JPEG</p>
<p>视频压缩，时间冗余 temporal redundancy 视频中不用每一帧都存这些像素，可以只存变化的部分。这是利用了帧和帧之间的相似性 inter-frame similarity。进一步地，可以找出帧和帧之间相似地补丁，通过比如移动和旋转、变亮和变暗，就也不需要保存像素，只需要对之前帧做操作。MPEG-4。</p>
<p>但视频中有时会出现补丁错了：这是因为压缩太严重，没有足够容量更新补丁内的像素。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229171941945.png" alt="image-20221229171941945" style="zoom:50%;">



<h2 id="22-命令行界面-Keyboards-amp-Command-Line-Interfaces"><a href="#22-命令行界面-Keyboards-amp-Command-Line-Interfaces" class="headerlink" title="22. 命令行界面-Keyboards &amp; Command Line Interfaces"></a>22. 命令行界面-Keyboards &amp; Command Line Interfaces</h2><p>人类和计算机交互，早期是电传打字机。命令行交互。后来屏幕代替电传打字机。</p>
<h2 id="23-屏幕-amp-2D-图形显示-Screens-amp-2D-Graphics"><a href="#23-屏幕-amp-2D-图形显示-Screens-amp-2D-Graphics" class="headerlink" title="23. 屏幕&amp;2D 图形显示-Screens&amp;2D Graphics"></a>23. 屏幕&amp;2D 图形显示-Screens&amp;2D Graphics</h2><p>CRT：阴极射线显像管，原理基于电子打到磷上会发光，然后磁可以控制电子走向，于是可以控制达到屏幕的图案，再通过光栅扫描（沿着行、列，一行行扫描，在某些地方有电子，有些地方没电子），持续重复扫描，图案就可以持续显示在屏幕上。</p>
<p>字符生成器。早期屏幕上不用像素来呈像，而是只显示字符，这样省内存。</p>
<p>后来出现 CRT上的“矢量模型”。认为所有图形都由线条组成。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221229181048214.png" alt="image-20221229181048214" style="zoom:50%;">



<p><strong>Sketchpad</strong> ，一个交互式图形界面，用途是计算机辅助设计 (CAD)。</p>
<p><strong>光笔</strong>，就是一个有线连着电脑的触控笔，有了它们，用户可以画出很完美的线条并进行缩放等操作。</p>
<p>像素：内存中的位（bit）对应屏幕中的像素，这叫“位图显示”。把图形想成一个巨大的像素值矩阵。计算机把像素数据会缓存起来，存在“帧缓存区”，在显卡上，因此访问速度快。</p>
<h2 id="24-冷战和消费主义-The-Cold-War-and-Consumerism"><a href="#24-冷战和消费主义-The-Cold-War-and-Consumerism" class="headerlink" title="24. 冷战和消费主义-The Cold War and Consumerism"></a>24. 冷战和消费主义-The Cold War and Consumerism</h2><h2 id="25-个人计算机革命-The-Personal-Computer-Revolution"><a href="#25-个人计算机革命-The-Personal-Computer-Revolution" class="headerlink" title="25. 个人计算机革命-The Personal Computer Revolution"></a>25. 个人计算机革命-The Personal Computer Revolution</h2><p>microcomputer。</p>
<p>personal computer 。个人计算机。</p>
<p>解释器 interpreter。解释器和编译器很像，区别是解释器运行时转换（把某种代码转换成可执行机器码），编译器提前转换。</p>
<h2 id="26-图形用户界面-Graphical-User-Interfaces"><a href="#26-图形用户界面-Graphical-User-Interfaces" class="headerlink" title="26. 图形用户界面-Graphical User Interfaces"></a>26. 图形用户界面-Graphical User Interfaces</h2><p>GUI是“事件驱动编程” event-driver programming ，代码可以在任意时间执行以响应事件。</p>
<h2 id="27-3D-图形-3D-Graphics"><a href="#27-3D-图形-3D-Graphics" class="headerlink" title="27. 3D 图形-3D Graphics"></a>27. 3D 图形-3D Graphics</h2><p>3D投影 projection：图形算法把3D坐标“拍平”显示到2D屏幕上，就是把所有点从3D转成2D，然后用画2D线段的函数来连接这些点，这叫“<strong>线框渲染</strong>” wireframe rendering。</p>
<p>3D投影有好多种：正交投影 orthographic projection，各个边在投影钟互相平行；透视投影 perspective projection 平行线段在远处收敛于一点。</p>
<p>在3D图形学中把三角形称为“多边形”polygons。由多边形组成的茶壶：</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230110828008.png" alt="image-20221230110828008" style="zoom:50%;">

<p>一堆多边形的集合叫“网格”mesh。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230110936985.png" alt="image-20221230110936985" style="zoom:50%;">

<p>用三角形的原因是空间中三个点定义一个平面，只要给3个3D坐标点，就可以画出一个平面。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230111153237.png" alt="image-20221230111153237" style="zoom: 33%;">



<p>3D图像需要填充，填充图形的经典算法叫“扫描线渲染”scanline rendering。填充就是要把多边形转成一块填满像素的区域。</p>
<p>扫描线渲染的原理：先铺一层像素网格，找到多边形的三个点的最大和最小的Y值，只在这两点间工作，算法从上往下，一次处理一行，计算每行和多边形相交的两个点（然后因为是三角形，如果相交一条边，必然相交另一条边），扫描线算法会填满2个相交点之间的像素。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230112129035.png" alt="image-20221230112129035" style="zoom:50%;">

<p>填充速率叫fillrate。</p>
<p>但是这样边缘会有锯齿，一种减轻锯齿的方法叫“抗锯齿”anti-aliasing。通过判断多边形切过像素的程度，来调整颜色。如果像素在多边形内部，就直接涂颜色；如果多边形划过像素，颜色就浅一些。这种边缘羽化的效果，看着更舒服。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230112407564.png" alt="image-20221230112407564" style="zoom:50%;">



<p>遮挡 occlusion：在3D场景中，由于距离远近不同，多边形往往只有一部分能看见，因为其它的被挡住了。</p>
<p>实现遮挡的方法：1. 画家算法 painter’s algorithm ，排序算法，从远到近排列，然后从远到近渲染。和画家画画一样，画家也是先画背景，然后再画更近的东西。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230115023741.png" alt="image-20221230115023741" style="zoom:50%;">

<ol start="2">
<li>深度缓冲 Z-buffering。事先生成一个“缓冲区”网格，里面距离都是无穷远，然后并不排序，依次把三角形填充，发现三角形的距离比缓冲区更小时，缓冲区变成该距离，如果某些地方没有比缓冲区里的值小，则不填充。</li>
</ol>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230115442227.png" alt="image-20221230115442227" style="zoom: 67%;">



<p>3D游戏中有个优化叫“背面剔除”back-face culling，因为平面是有两面的，正面和背面，有些物体只需要渲染一面，另一面不渲染，节省处理时间。</p>
<p>灯光，也叫“明暗处理” shading。3D场景中，物体表面应该有明暗变化。三角形面对的方向叫“表面法线”surface normal，这个方向是垂直于表面的。根据灯光和法线的关系，进行着色。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230121201963.png" alt="image-20221230121201963" style="zoom:50%;">



<p>纹理 texture 在图形学中指的是“外观”（而不是手感），各种花哨效果。纹理映射 texture mapping。就是把多边形坐标和纹理坐标对应起来，扫描线算法填充颜色时，纹理算法会查询纹理，从响应区域取平均颜色，并填充多边形。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230121116431.png" alt="image-20221230121116431" style="zoom:50%;">



<p>再大的场景，过程都是一遍又一遍地处理所有多边形。扫描线填充，抗锯齿，光照，纹理化。</p>
<p>加速渲染：1.用专门的硬件来加速运算；2.把3D场景分成多个小部分，并行渲染。GPU 图形处理单元，GPU在显卡上，周围有专用的RAM（保存网格和纹理），让GPU的多个核心可以高速访问。</p>
<h2 id="28-计算机网络-Computer-Networks"><a href="#28-计算机网络-Computer-Networks" class="headerlink" title="28. 计算机网络-Computer Networks"></a>28. 计算机网络-Computer Networks</h2><p>局域网 LAN ，以太网。以太网的原理：很多台电脑都用电缆连接（一条以太网电线能连接到彼此各个电脑），当一台电脑要传数据给另一台电脑时，以电信号形式将数据传入电缆，最早因为电缆是共享的，连在同一个网络里的其他计算机也能看见数据，后来以太网需要每台计算机都有唯一的媒体访问控制地址（MAC地址），这个唯一的地址放在头部，作为数据的前缀发送到网络中，所以计算机只需要监听以太网电缆，只有看见自己的MAC地址，才处理数据。</p>
<p>以太网、无线网络（WIFI）都用的这个机制。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230123145005.png" alt="image-20221230123145005" style="zoom:50%;">



<p>多台电脑共享一个传输媒介，很多计算机同时侦听载体，这种方法叫“载波侦听多路访问”，carrier sense multiple access，CSMA，载体（carrier）指运输数据的共享媒介，以太网的“载体”是铜线（电缆），WiFi的“载体”是传播无线电波的空气。载体传输数据的速度叫“带宽” bandwidth。</p>
<p>冲突 collision，多台计算机同时传输数据，会在载体里产生冲突，网络阻塞。解决的方法是遇到冲突，计算机会等待1秒+随机数，也就是1点多秒，然后再看看载体是不是空的，如果是空的就传输，如果不是空的，就等2s，再不是空的就等4s，…，8s，…，这种指数级增加等待时间的方法叫“指数退避” exponential backoff。</p>
<p>同一个载体连接的设备叫“冲突域”collision domain（可能发生冲突的范围）。为了减少冲突，可以通过“交换机”把一个冲突域拆成两个冲突域。交换机会记录一个列表，写着哪个mac地址在哪边网络（哪个域）。 </p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230144646123.png" alt="image-20221230144646123" style="zoom:50%;">



<p>计算机网络从一个地点到另一个地点之间通常有多条线路，叫“路由”routing。两个地点之间是专有线路。</p>
<p>传输数据的另一种方法叫“报文交换”message switching。消息会经过好几个站点。报文交换的好处是 可以用不同路由，使通信更可靠更能容错falut-tolerant。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230145234823.png" alt="image-20221230145234823" style="zoom:50%;">

<p>消息沿着路由跳转的次数，叫“跳数”hop count。通过检测跳数，可以看出报文传输正不正常。</p>
<p>很大的报文传输会阻塞网络，使得后面的报文传输很慢（因为要等前面的大报文传完，或者选择效率低的路由路线），解决方法是将大报文分成很多小块，叫“数据包”packet。</p>
<p>报文的具体格式由“互联网协议“（IP）定义。</p>
<p>同一个报文的数据包可能会经过不同线路，因此到达目的地的顺序不同。TCP&#x2F;IP可以解决乱序问题。</p>
<p>分组交换 packet switching：将数据包拆分成多个小数据包，然后通过灵活的路由传递。</p>
<h2 id="29-互联网-The-Internet"><a href="#29-互联网-The-Internet" class="headerlink" title="29. 互联网-The Internet"></a>29. 互联网-The Internet</h2><p>个人计算机和一个巨大的分布式网络连在一起（互联网）。网络传输的过程是这样的，比如手机或电脑要看一个视频，首先要连接到局域网（LAN）上，家庭路由器连着的所有设备，组成了局域网。局域网再连到广域网（WAN），WAN的路由器一般属于在互联网服务提供商（ISP），比如电信联通，广域网里，先连到一个区域路由器，比如覆盖一个街区的路由器，然后连到更大的路由器，比如覆盖一个城市，可能再<strong>跳</strong>几次，达到互联网主干，沿着主干到达视频文件的服务器，比如youtube的服务器。（可以用traceroute来看数据包传输过程中跳了几次）。</p>
<p>IP是底层协议，只记录了地址，数据传到某地址的计算机之后，不知道要传给哪个程序用，因此还有上层协议，比如”用户数据报协议“UDP。UDP的头header里有<strong>端口号</strong>信息。每个想访问网络的程序都要向操作系统申请一个端口号。</p>
<ul>
<li>IP负责把数据包送到正确的计算机；</li>
<li>UDP负责把数据包送到正确的程序；</li>
</ul>
<p>UDP的header里还有校验和。但是UDP也不会修复数据包，也不会让数据重发，接收方遇到数据损坏一般只是扔掉。UDP无法得知数据包是否到达目的地，<strong>发送方</strong>发了数据之后，无法得知数据包是否到达目的地。适用于比如视频通话，速度快，简单。</p>
<p>TCP，传输控制协议，所有数据必须到达，适合发邮件等不能缺失数据的场景。</p>
<p>TCP&#x2F;IP。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230162037668.png" alt="image-20221230162037668" style="zoom:50%;">



<p>TCP的数据包有序号，因此接收方即使收到的数据包的到达时间不同，也可以根据序号把数据包排成正确的顺序；</p>
<p>TCP要求接收方的电脑收到数据包，并且校验和检查无误后（数据没有损坏），给发送方发一个确认码 ACK，代表收到了。得知上一个数据包成功抵达后，发送方会发下一个数据包。</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230162438942.png" alt="image-20221230162438942" style="zoom:50%;">



<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230162609656.png" alt="image-20221230162609656" style="zoom:50%;">



<p>TCP可以处理乱序和丢失数据包，丢了就重发，还可以根据拥挤程度自动调整传输速率。</p>
<p>互联网有个服务，负责把域名和IP地址一一对应，就像互联网的电话簿，叫”<strong>域名系统</strong>“，<strong>DNS</strong>，比如输入某个IP+端口号能访问谷歌网址，输入google.com也能访问谷歌。</p>
<p>域名结构用树形表示：</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230163346522.png" alt="image-20221230163346522" style="zoom:50%;">



<p>物理层 physical layer：线路里的电信号，无线网络里的无线信号，这些叫”物理层“ physical layer。</p>
<p>数据链路层 data link layer：媒体访问控制地址（MAC)，冲突检测，指数退避，以及底层协议。 ”数据链路层“负责操控”物理层“。</p>
<p>网络层 network layer ：负责各种报文交换和路由。</p>
<p>传输层 transport layer：比如UDP和TCP协议，负责在计算机之间进行点到点的传输，还会检测和修复错误。</p>
<p>会话层 session layer：会话层会使用TCP和UDP来创建连接，传递信息，然后关掉连接。这一整套叫”会话“。</p>
<p>OSI：</p>
<img src="/2022/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%B8%89%EF%BC%89/image-20221230164318470.png" alt="image-20221230164318470" style="zoom:50%;">

<p>上面还有”表示层“ presentation layer和”应用程序层“ application layer。</p>
]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机科学速成课（二）</title>
    <url>/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="计算机科学速成课（二）"><a href="#计算机科学速成课（二）" class="headerlink" title="计算机科学速成课（二）"></a>计算机科学速成课（二）</h1><blockquote>
<p>2022.12.28</p>
<p>b站 <a href="https://www.bilibili.com/video/BV1EW411u7th/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">【计算机科学速成课】[40集全&#x2F;精校] - Crash Course Computer Science</a></p>
<p>网友的笔记：<a href="https://shimo.im/docs/vkCKkj3YxGtygrVg/read">https://shimo.im/docs/vkCKkj3YxGtygrVg/read</a> 、 <a href="https://shimo.im/docs/PJAUY30F1uYksv0h/read">https://shimo.im/docs/PJAUY30F1uYksv0h/read</a> 、<a href="https://www.processon.com/view/link/61ef6e8f0e3e7439ae917672#map">https://www.processon.com/view/link/61ef6e8f0e3e7439ae917672#map</a></p>
</blockquote>
<h2 id="11-编程语言发展史-The-First-Programming-Languages"><a href="#11-编程语言发展史-The-First-Programming-Languages" class="headerlink" title="11. 编程语言发展史-The First Programming Languages"></a>11. 编程语言发展史-The First Programming Languages</h2><p>汇编器 assembler ： 汇编器读取用“汇编语言”写的程序，然后转成“机器码”（比如jump、add等机器能知道的），最早是人手动写很多行指令（直接写机器码），喂给机器，然后为了实现某功能，会在写指令之前写伪代码帮助理解，然后人们想出了写汇编语言，然后通过汇编器把汇编语言转成指令，机器读指令。因此以后就不需要手动写指令，写汇编语言就行。</p>
<p>汇编码的作用其实是修饰了一下机器码，比如汇编码的 LOAD_A 14 ， 对应的机器码是 0011 0111这种，前四位是操作码，后四位是地址。使用汇编码时，依然要写清楚用什么寄存器和用哪块内存地址。</p>
<p>后来发展出了“编译器”compiler，将高级语言转成低级语言（低级语言是汇编码或机器码），因此只要写高级语言，不用管用哪个寄存器或哪块地址，编译器会处理。程序员只需要创建 代表内存地址的抽象 叫“变量”，给变量取名字。</p>
<h2 id="12-编程原理-语句和函数-Programming-Basics-Statements-amp-Functions"><a href="#12-编程原理-语句和函数-Programming-Basics-Statements-amp-Functions" class="headerlink" title="12. 编程原理-语句和函数-Programming Basics - Statements &amp; Functions"></a>12. 编程原理-语句和函数-Programming Basics - Statements &amp; Functions</h2><h2 id="13-算法入门-Intro-to-Algorithms"><a href="#13-算法入门-Intro-to-Algorithms" class="headerlink" title="13. 算法入门 - Intro to Algorithms"></a>13. 算法入门 - Intro to Algorithms</h2><h2 id="14-数据结构-Data-Structures"><a href="#14-数据结构-Data-Structures" class="headerlink" title="14. 数据结构-Data Structures"></a>14. 数据结构-Data Structures</h2><h2 id="15-阿兰·图灵-Alan-Turing"><a href="#15-阿兰·图灵-Alan-Turing" class="headerlink" title="15. 阿兰·图灵-Alan Turing"></a>15. 阿兰·图灵-Alan Turing</h2><p>可判定性问题 ：是否存在一种算法，输入正式逻辑语句，输出准确的“是”或“否”答案。</p>
<p>图灵机。只要有足够的规则，状态和纸带，可以创造任何东西，它是一台通用计算机。</p>
<img src="/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221228171641116.png" alt="image-20221228171641116" style="zoom:50%;">

<p>图灵完备 turing complete</p>
<p>停机问题 halting problem</p>
<h2 id="16-软件工程-Software-Engineering"><a href="#16-软件工程-Software-Engineering" class="headerlink" title="16. 软件工程-Software Engineering"></a>16. 软件工程-Software Engineering</h2><img src="/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221228181615787.png" alt="image-20221228181615787" style="zoom: 67%;">

<p>找某个函数要从最外层往里找，比如 Car.Engine.CruiseControl.setCruiseSpeed(55)</p>
<p><strong>面向对象编程 object oriented programing</strong>：把函数打包成对象。通过封装组件，隐藏复杂度，选择性公布功能（public、private）。</p>
<h2 id="17-集成电路-amp-摩尔定律-Integrated-Circuits-amp-Moore’s-Law"><a href="#17-集成电路-amp-摩尔定律-Integrated-Circuits-amp-Moore’s-Law" class="headerlink" title="17. 集成电路&amp;摩尔定律-Integrated Circuits &amp; Moore’s Law"></a>17. 集成电路&amp;摩尔定律-Integrated Circuits &amp; Moore’s Law</h2><img src="/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221228190315984.png" alt="image-20221228190315984" style="zoom:50%;">

<p> 通过光刻技术，把很多很多晶体管做到一块集成电路上。</p>
<p>摩尔定律：每两年左右，得益于材料和制造技术的发展 ，同样大小的空间，能塞进两倍数量的晶体管。</p>
<p>一直做小会遇到问题：</p>
<ol>
<li>用光掩模把图案弄到晶圆上，由于光的波长限制，精度已到极限。所以科学家在研制波长更短的光源，投射更小的形状。</li>
<li>量子隧穿效应：当晶体管非常小，电极之间可能只距离几个原子，电子会跳过间隙，会产生漏电问题（如果晶体管漏电，就不是好开关）。</li>
</ol>
<h2 id="18-操作系统-Operating-Systems"><a href="#18-操作系统-Operating-Systems" class="headerlink" title="18. 操作系统-Operating Systems"></a>18. 操作系统-Operating Systems</h2><blockquote>
<p>这集可以再重温，知识点比较多</p>
</blockquote>
<p>最早是在打孔纸卡上写程序，然后送程序进计算机计算，但是计算机计算越来越快，放程序时间比程序运行时间还长，因此需要一种方式让计算机自动运行，于是诞生了“操作系统”operating system，OS。</p>
<p>操作系统也是程序，但它有操作硬件的特殊权限，可以运行和管理其它程序。</p>
<p>批处理 batch processing 一个程序紧接着一个程序运行，自动加载程序。</p>
<p>最早的外部设备 peripheral 是独立的底层硬件程序，会有很多不同的外部设备，比如不同的打印机，都要单独写一个和计算机交互的程序。后来操作系统充当软件和硬件之间的媒介，操作系统提供 API 来抽象硬件，叫“设备驱动程序” device driver，程序员用标准化机制，和输入输出硬件 I&#x2F;O 交互。</p>
<p>多任务处理 multitasking 。一个cpu上运行多个程序。</p>
<p>每个程序会占用一些内存，一开始会给每个程序分配专属内存块，后面某个程序又想申请内存，新分配的内存地址和之前内存地址会不连续了，这样程序员就不好追踪了，因此出现了“虚拟内存” virtual memory ，操作系统会把内存地址进行“虚拟化”，程序员看见的是虚拟内存，而不是真实的物理内存地址。（虚拟内存假定内存都是从地址0开始）。操作系统去处理物理内存和虚拟内存之间的映射。</p>
<p>虚拟内存的出现使得程序的内存大小可以灵活增减，叫“动态内存分配” dynamic memory allocation。</p>
<img src="/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221229110515545.png" alt="image-20221229110515545" style="zoom:50%;">

<p>内存保护 memory protection，每个程序只能用一部分内存，不能去用别的程序的内存，不然就可以修改其他程序的内存地址的数据了（恶意修改，病毒）。</p>
<p>分时操作系统 time-sharing ：多个用户用同一个操作系统的情况（用户在不同终端登录），此时操作系统要处理多个用户，为了确保某个用户不会占满计算机资源，开发了分时操作系统，每个用户只能用一小部分处理器、内存等。</p>
<p>内核 kernel：如内存管理，多任务和输入&#x2F;输出处理。</p>
<p>unix是一个操作系统，由两部分组成，一部分是内核，一部分是一堆有用的工具（比如程序和运行库）</p>
<p><strong>内核恐慌 kernel panic</strong>：以前操作系统为了防止错误发生，会事先写很多很多的错误恢复代码。而unix没有很多的“恢复”代码，遇到内核崩溃，没办法恢复，所以调用一个叫“恐慌”的函数。这个恐慌函数可以是比如重启？。</p>
<h2 id="19-内存-amp-储存介质-Memory-amp-Storage"><a href="#19-内存-amp-储存介质-Memory-amp-Storage" class="headerlink" title="19. 内存&amp;储存介质-Memory &amp; Storage"></a>19. 内存&amp;储存介质-Memory &amp; Storage</h2><p>存储器 storage，非易失性 non-volatile，存储器比如是硬盘，写入的数据会一直存着，直到被覆盖或删除，断电也不会丢失。</p>
<p>最早是打孔纸卡、打孔纸带，但是读取慢，能存的很有限，只能写入一次（write-once），并且不方便存临时值，因此需要更大、更快、更灵活的存储方式，于是诞生了延迟线存储器 delay line memory。延迟线存储器是一个管子装满液体，比如水银，管子一端放扬声器，一端放麦克风。扬声器发出脉冲，产生压力波，经过一段时间传播到麦克风，麦克风将压力波转换回电信号。缺点是每个时刻只能读一位bit，想访问某bit，只能顺序访问，等待它从循环中出现，所以又叫“顺序存储器”或“循环存储器” sequential memory、cyclic-access memory。</p>
<img src="/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221229152109232.png" alt="image-20221229152109232" style="zoom:50%;">



<p>我们需要的是可以随机存取的存储器 random access memory，可以随时访问任何位置。</p>
<p>出现了“磁芯存储器” magnetic core memory。给磁芯绕上电线，施加电流，可以将磁化在一个方向，此时关掉电流，磁芯保持磁化，如果施加反方向电流，磁化方向（极性）会翻转。这样就可以用来存1和0。</p>
<img src="/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221229152841004.png" alt="image-20221229152841004" style="zoom:50%;">



<p>后来又发展出磁带、磁鼓存储器、磁盘。但是磁带是连续的，必须倒带或快进达到特定位置，访问速度慢，。</p>
<p>磁盘表面有磁性、有写入头和读取头，可以处理上面的1和0。要访问某个特定bit，磁头会移动。磁盘高速旋转，加快访问速度，称为寻道时间 seek time。</p>
<img src="/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221229153452820.png" alt="image-20221229153452820" style="zoom:50%;">



<p>后来发展出软盘、硬盘、光盘。</p>
<p>光盘表面有很多小坑，造成光的不同反射，光学传感器会捕捉到，并解码为1和0。</p>
<img src="/2022/12/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E4%BA%8C%EF%BC%89/image-20221229153736689.png" alt="image-20221229153736689" style="zoom:50%;">



<p>现在存储技术朝固态发展，没有机械活动部件（没有一个移动的磁头，磁头不用等磁盘转），比如机械硬盘、U盘、固态硬盘SSD，通过集成电路的技术，访问时间很短。</p>
]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ queue</title>
    <url>/2022/10/20/%E7%AE%97%E6%B3%95/C++%20queue/</url>
    <content><![CDATA[<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">queue&lt;pair&lt;<span class="type">char</span>, <span class="type">int</span>&gt;&gt; q;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机科学速成课（四）</title>
    <url>/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="计算机科学速成课（四）"><a href="#计算机科学速成课（四）" class="headerlink" title="计算机科学速成课（四）"></a>计算机科学速成课（四）</h1><blockquote>
<p>2022.12.30</p>
<p>b站 <a href="https://www.bilibili.com/video/BV1EW411u7th/?spm_id_from=333.999.0.0&vd_source=5e9891722f2b62adca440a5e92121b5b">【计算机科学速成课】[40集全&#x2F;精校] - Crash Course Computer Science</a></p>
</blockquote>
<h2 id="30-万维网-The-World-Wide-Web"><a href="#30-万维网-The-World-Wide-Web" class="headerlink" title="30. 万维网-The World Wide Web"></a>30. 万维网-The World Wide Web</h2><p>万维网是一个程序，互联网上传输最多数据的程序。（互联网是传递数据的管道，各种程序都会用），万维网的基本单位是”单个页面“。超链接，关联式索引。</p>
<p>为了使网页能相互链接，每个网页需要一个唯一的地址 ，叫统一资源定位器 uniform resource location，url。</p>
<p>一个网页URL，比如 thecrashcourse.com&#x2F;courses，网络会正常通过TCP&#x2F;IP访问到thecrashcourse.com的服务器，下一步是向服务器请求”courses“这个网页页面。这种网络连接用的超文本传输协议 HTTP，（超文本指的是某个文本字段有超链接功能），比如向服务器发送指令”GET:&#x2F;courses“。</p>
<p>超文本标记语言 HTML，不同的html指令，HTML的由来是因为指令也是以文本的形式传输，不好区分哪些是文本、哪些是超文本，因此开发了HTML，一种语言。</p>
<p>做一个网页：</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20221230171214598.png" alt="image-20221230171214598" style="zoom:50%;">





<h2 id="31-计算机安全-Cybersecurity"><a href="#31-计算机安全-Cybersecurity" class="headerlink" title="31. 计算机安全-Cybersecurity"></a>31. 计算机安全-Cybersecurity</h2><p>可以把计算机安全看成是保护系统和数据的”保密性“，”完整性“和”可用性“。</p>
<p>保密性：只有有权限的人，才能读取计算机系统和数据。黑客泄露别人的信用卡信息，就是攻击保密性。</p>
<p>完整性：只有有权限的人，才能使用和修改系统和数据。黑客知道你的邮箱密码，冒充你发邮件，就是攻击完整性。</p>
<p>可用性：有权限的人，可以随时访问计算机系统和数据。拒绝服务攻击（DDOS）就是黑客发大量的假请求，让网站很慢或者挂掉，这就是攻击可用性。</p>
<p>身份验证、访问控制（r、w、d）</p>
<h2 id="32-黑客-amp-攻击-Hackers-amp-Cyber-Attacks"><a href="#32-黑客-amp-攻击-Hackers-amp-Cyber-Attacks" class="headerlink" title="32. 黑客&amp;攻击-Hackers &amp; Cyber Attacks"></a>32. 黑客&amp;攻击-Hackers &amp; Cyber Attacks</h2><p>社会工程学 Social Engineering：欺骗别人让人泄露信息来获得信息，或让人电脑配置成易于攻击的系统。</p>
<p>钓鱼 Phishing，邮件链接，进入假网站。</p>
<p>假托 Pretexting，假装成it部分让人配置电脑。</p>
<p>木马 Trojan Horses。</p>
<p>NAND镜像 NAND Mirroring</p>
<p>漏洞利用 Exploit</p>
<p>缓冲区溢出 Buffer Overflow</p>
<p>边界检查 Bounds Checking和金丝雀</p>
<p>代码注入 Code Injection：攻击用数据库的网站</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20221230181742798.png" alt="image-20221230181742798" style="zoom: 50%;">



<p>零日漏洞 Zero Day Vulnerability：当软件制造者不知道软件有新漏洞被发现了，这个漏洞被称为“零日漏洞”</p>
<p>计算机蠕虫 Worms：如果有足够多的电脑有漏洞，让恶意程序可以在电脑间互相传播，这种恶意程序叫做蠕虫</p>
<p>僵尸网络 Botnet：如果黑客掌握足够多电脑，那他们可以组成“僵尸网络”，然后可以比如发大量的垃圾邮件、或者用别人的电脑的计算能力和电费挖比特币。</p>
<h2 id="33-加密-Cryptography"><a href="#33-加密-Cryptography" class="headerlink" title="33. 加密-Cryptography"></a>33. 加密-Cryptography</h2><p>计算机安全中最常见的防御形式，密码学Cryptography。</p>
<p>加密 - Encryption，解密 - Decryption</p>
<p>凯撒加密 Caesar cipher——一种替换加密  Substitution cipher，把字母替换成其他字母。但是没有改变字母频率，有些很高频出现的字母，替换后很容易看出来。</p>
<p>移位加密 Permutation cipher</p>
<p>enigma 英格玛</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230103154016960.png" alt="image-20230103154016960" style="zoom:50%;">



<p>AES密钥 128位&#x2F;192位&#x2F;256位 因此很难暴力破解</p>
<p>密码交换 key exchange ，是一种不用发送密钥，也能让两台计算机在密钥达成共识的算法。（密码由发送者发送，接收者需要解密）。举例，双方都有一个密钥，a和b，还有一个公共密钥p。a和p某种方式混合后发送给b，与b混合，得到a、p、b的混合，b和p某种方式混合后发送给a，与a混合，得到b、p、a的混合，于是双方混合后的结果相同，就得到了某个只有双方知道的密钥。而比如黑客可能可以看到a和p的混合结果，或者b和p的混合结果（在网络中传输），但是混合简单，解混合困难，a和p混合结果再拆分成a与p是困难的，因此很难知道密钥。</p>
<p> 建立共享密钥，双方用一样的密钥加密和解密消息，这叫”对称加密“，因为密钥一样。</p>
<p>迪菲-赫尔曼密钥交换 diffie-hellman 数学单向函数。函数比如用模幂函数，一个数字做底数，一个数字做指数，一个数字做要除的数（模数），最后得到的余数作为密码。$B^x\mod M$ ， 如果只给M和B、余数，很难猜出指数x是多少，比如3的某次方 模31，余数是7，很难猜出次方是多少。 </p>
<p>diffie-hellman 算法 流程如下：公开的值 public value 有 基数 B （base）和 模数 M （modulus），计算机双方都选一个指数数字，a选x，b选y，然后a计算 $B^x\mod M$ ，发送给b； b计算 $B^y\mod M$ 的结果，发送给a。为了算出双方共用的密钥，a把 $B^y\mod M$ 用a的指数x进行模幂运算 $(B^y\mod M)^x&#x3D;B^{yx} \mod M$ ，b把 $B^x\mod M$ 用b的指数y进行模幂运算 $(B^x\mod M)^y&#x3D;B^{yx} \mod M$  。因此双方有一样的密钥，即使从来没给对方发过各自的秘密指数（x和y）。</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230103152512820.png" alt="image-20230103152512820" style="zoom:50%;">



<p>非堆成密钥 一个是公开的，一个是私有的。用公钥加密消息，只有有私钥的人能解密。反过来也可以，私钥加密后，用公钥解密。服务器用私钥加密，任何人都可以用公钥解密，RSA</p>
<h2 id="34-机器学习-amp-人工智能-Machine-Learning-amp-Artificial-Intelligence"><a href="#34-机器学习-amp-人工智能-Machine-Learning-amp-Artificial-Intelligence" class="headerlink" title="34. 机器学习&amp;人工智能-Machine Learning &amp; Artificial Intelligence"></a>34. 机器学习&amp;人工智能-Machine Learning &amp; Artificial Intelligence</h2><p>从数据中学习。</p>
<p>SVM：用任意线段来切分”决策空间“，不一定是直线，可以是多项式或其他数学函数（决策边界）。 </p>
<h2 id="35-计算机视觉-Computer-Vision"><a href="#35-计算机视觉-Computer-Vision" class="headerlink" title="35. 计算机视觉-Computer Vision"></a>35. 计算机视觉-Computer Vision</h2><p>举例：找垂直边缘的算法：认为色差大的可能是边缘。用到了卷积convolution。</p>
<p>卷积过程这里是把一个 [[-1,0,1],[-1,0,1],[-1,0,1]]的核作用到像素上，对应点相乘再全相加。</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230103185328402.png" alt="image-20230103185328402" style="zoom:50%;">



<p>一张灰度图：</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230103185724524.png" alt="image-20230103185724524" style="zoom: 33%;">



<p>经过卷积后变为：</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230103185754284.png" alt="image-20230103185754284" style="zoom: 33%;">



<p>用 对水平边缘敏感的“核”，提取后：</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104095753733.png" alt="image-20230104095753733" style="zoom: 33%;">

<p>这两个边缘增强的核叫“prewitt”算子 opterators</p>
<p>【inspired！！】以前总看见一开始的卷积是提取边缘，一直没有理解是什么意思，直到看到这个视频，才知道卷积核的不同，真的可以提取边缘、变模糊 等一系列操作，随着层数往上，提取的是更大范围的“不同”，比如就能看到嘴巴、鼻子了。之前一直没理解，是因为卷积核参数是神经网络更新的，而“核”的提出，一开始是人为构造里面的参数的！如果要提取垂直边缘，核参数就是 $\begin{bmatrix} -1 &amp; 0 &amp; 1\ -1 &amp; 0 &amp; 1 \ -1 &amp; 0 &amp; 1 \end{bmatrix}$ 。 如果要提取（突出）水平边缘 核参数就是 $\begin{bmatrix} -1 &amp; -1 &amp; -1\ 0 &amp; 0 &amp; 0 \ 1 &amp; 1 &amp; 1 \end{bmatrix}$ 。</p>
<p>核能做很多种图像转换。</p>
<p>比如锐化图像的核 $\begin{bmatrix} -1 &amp; -1 &amp; -1\ 1 &amp; 9 &amp; -1 \ -1 &amp; -1 &amp; -1 \end{bmatrix}$ ：</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104100127972.png" alt="image-20230104100127972" style="zoom:33%;">



<p>模糊图像：</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104100147562.png" alt="image-20230104100147562" style="zoom: 50%;">



<p>核也可以像饼干模具一样，匹配特定形状。</p>
<p>比如做边缘检测的核  $\begin{bmatrix} - &amp; +\  \end{bmatrix}$ 和 $\begin{bmatrix} - \ +   \end{bmatrix}$ 。会检查左右和上下的差异。</p>
<p>比如做出擅长找线段的核  $\begin{bmatrix} -&amp;+&amp;-\  \end{bmatrix}$ 和 $\begin{bmatrix} - \ +  \ - \end{bmatrix}$ （比如找出鼻梁，因为鼻梁比鼻子两侧更亮）</p>
<p>比如包了一圈对比色的区域（比如找出眼睛）<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104100851352.png" alt="image-20230104100851352" style="zoom:33%;"></p>
<p>这类核可以描述简单的形状。</p>
<p>核“找出”某想要的形状 的意思是卷积后这个区域的值会更高。而其他区域值会低。</p>
<p>计算机扫描图像，最常见的是用一个窗口扫，多个核组合，能找出人脸，虽然单个核找出脸的能力很弱，但组合在一起会相当准确，因为 “不是脸 却有一堆脸的特征在正确的位置 这种情况不太可能” ，哈哈。这叫 viola-jones face detection 维奥拉-琼斯人脸检测算法。</p>
<h2 id="36-自然语言处理-Natural-Language-Processing"><a href="#36-自然语言处理-Natural-Language-Processing" class="headerlink" title="36. 自然语言处理-Natural Language Processing"></a>36. 自然语言处理-Natural Language Processing</h2><p>人类语言叫“自然语言”</p>
<p>分析树 parse tree</p>
<p>短语结构规则</p>
<p>知识图谱 knowledge graph 。包含大量实体，以及不同实体之间的关系。</p>
<p>语音识别</p>
<p>频谱图。可以看出不同音的共振峰 formant 是有区别的。因此可以通过共振峰来区分不同的音。</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104110445077.png" alt="image-20230104110445077" style="zoom: 33%;">



<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104110612894.png" alt="image-20230104110612894" style="zoom:33%;">



<h2 id="37-机器人-Robots"><a href="#37-机器人-Robots" class="headerlink" title="37. 机器人-Robots"></a>37. 机器人-Robots</h2><p>控制回路 control loop的目的是把机器人的属性（比如当前位置）变成期望值（比如想让机器人到达某个位置）。</p>
<p>PID控制器</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104113816049.png" alt="image-20230104113816049" style="zoom:50%;">



<p><strong>PID 原理</strong>：以速度为例，我们希望保持匀速，但是实际有外界影响，可能当前速度核理想速度不一致，PID会计算三个值，第一个值是“比例值”，就是实际值和理想值差多少，实际值和理想值的差距越大，就需要越用力，因此是“比例控制”的。第二个值是“积分值”，是一段时间内的误差总和，比如最近的几秒钟，帮助弥补误差，比如上坡（速度变慢）就会产生误差，如果这个积分值（误差值）很大，说明比例控制得不够，要继续用力前进来减少误差。第三个值是“导数值”，是理想值与实际值之间的变化率，有助于解决 未来可能出现的错误，也叫“预期控制”，比如前进得太快（导数值很大），就要放松一点，避免冲过头。这三个值会一起使用，有不同的权重，然后用来控制系统。</p>
<p>积分值：</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104114251778.png" alt="image-20230104114251778" style="zoom:33%;">

<p>导数值：</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104114548572.png" alt="image-20230104114548572" style="zoom: 33%;">



<h2 id="38-计算机心理学-Psychology-of-Computing"><a href="#38-计算机心理学-Psychology-of-Computing" class="headerlink" title="38. 计算机心理学 - Psychology of Computing"></a>38. 计算机心理学 - Psychology of Computing</h2><p>系统设计师在创造软件时，会运用社会心理学，认知心理学，行为心理学，感知心理学的原理。</p>
<p>增强凝视，在视频通话、会议、虚拟教室中，用计算机软件修正眼睛方向，看起来像是在凝视着对方的眼睛。</p>
<h2 id="39-教育科技-Educational-Technology"><a href="#39-教育科技-Educational-Technology" class="headerlink" title="39. 教育科技-Educational Technology"></a>39. 教育科技-Educational Technology</h2><p>主动学习的技巧可以提升学习效率。</p>
<p>主动学习的技巧：</p>
<ol>
<li>把视频速度调整到适合你的速度，让你能理解视频，有足够时间思考；</li>
<li>暂停！在困难的部分暂停。问自己一些问题，看能不能回答。或想想视频接下来可能讲什么，然后继续播放，看猜对没有；</li>
<li>做视频中提供的练习；</li>
</ol>
<p>智能辅导系统 intelligent tutoring system。判断规则 production rule。学生做完一个步骤后可能触发多个“判断规则”，系统虽然不能完全弄清是什么原因让学生选择了那个答案，但是可以通过“判断规则”和算法结合 判断可能原因，让学生得到有用反馈。</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104154257083.png" alt="image-20230104154257083" style="zoom:50%;">



<p>贝叶斯知识追踪 bayesian knowledge tracing 。记录4个概率，1.学生已经学会的概率；2.瞎猜的概率（答对但是是蒙的）；3.失误的概率（答错但是是不小心填错的）；4.做题过程中学会的概率（一开始不会，解决问题过程中学会了怎么做）。</p>
<p>mastery learning</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230104154849780.png" alt="image-20230104154849780" style="zoom:50%;">



<p>教育数据挖掘。</p>
<p>neal stephenson的“钻石时代”书。</p>
<h2 id="40-奇点-天网-计算机的未来-The-Singularity-Skynet-and-the-Future-of-Computing"><a href="#40-奇点-天网-计算机的未来-The-Singularity-Skynet-and-the-Future-of-Computing" class="headerlink" title="40. 奇点,天网,计算机的未来-The Singularity, Skynet, and the Future of Computing"></a>40. 奇点,天网,计算机的未来-The Singularity, Skynet, and the Future of Computing</h2><p>普适计算 ubiquitous computing，我理解就是各行各业、各个地方都用上计算机。</p>
<p>智能科技的失控性发展叫“奇点” singularity。</p>
<p>工作可以分成两个维度，分别是“从手工型到思维型”，“从重复性到非重复性”，（手工型 manual 比如组装玩具，思维型 cognitive 比如选股票）</p>
<p>重复性手工型工作，可以让机器自动化；</p>
<p>非重复性手工型工作，比如厨师、服务员、保安；</p>
<p>重复性思维型工作，比如客服、收银员、银行柜员和办公室助理；</p>
<p>非重复性思维型工作，比如教师、艺术家、小说家、律师、医生、科学家；</p>
<img src="/2022/12/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE%EF%BC%88%E5%9B%9B%EF%BC%89/image-20230105121526961.png" alt="image-20230105121526961" style="zoom:50%;">

]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>计算机组成</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ set</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/C++%20set/</url>
    <content><![CDATA[<h1 id="C-set"><a href="#C-set" class="headerlink" title="C++ set"></a>C++ set</h1><p><a href="https://cplusplus.com/reference/set/set/find/">https://cplusplus.com/reference/set/set/find/</a></p>
<h2 id="判断元素在不在set中"><a href="#判断元素在不在set中" class="headerlink" title="判断元素在不在set中"></a>判断元素在不在set中</h2><p>可以用count()函数，如果为0，则不在set中；大于0，在set中；</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">set&lt;<span class="type">int</span>&gt; ss;</span><br><span class="line">ss.<span class="built_in">insert</span>(<span class="number">1</span>);</span><br><span class="line">ss.<span class="built_in">insert</span>(<span class="number">2</span>);</span><br><span class="line">cout&lt;&lt;ss.<span class="built_in">count</span>(<span class="number">1</span>)&lt;&lt;<span class="string">&#x27; &#x27;</span>&lt;&lt;ss.<span class="built_in">count</span>(<span class="number">3</span>);</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ vector</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/C++%20vector/</url>
    <content><![CDATA[<p>C++ vector</p>
<h2 id="新建vector数组"><a href="#新建vector数组" class="headerlink" title="新建vector数组"></a>新建vector数组</h2><ol>
<li><p>已知内容：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">vector&lt;<span class="type">int</span>&gt; a = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line"><span class="comment">// 注意，不是[1,2,3,4,5]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> i[<span class="number">6</span>] = &#123;<span class="number">6</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">7</span>&#125;;</span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">a</span><span class="params">(i,i+<span class="number">6</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化固定长度，初值为0</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">vec</span><span class="params">(k, <span class="number">0</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化固定长度，无初值</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">vec</span><span class="params">(k)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>不知道长度，每次用push进去</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">vector&lt;<span class="type">int</span>&gt; a;</span><br><span class="line">a.<span class="built_in">push_back</span>(<span class="number">1</span>);</span><br><span class="line">a.<span class="built_in">push_back</span>(<span class="number">2</span>);</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="新建二维vector数组"><a href="#新建二维vector数组" class="headerlink" title="新建二维vector数组"></a>新建二维vector数组</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">visited</span>(h, <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(w));</span><br></pre></td></tr></table></figure>





<h2 id="得到vector最后一个元素"><a href="#得到vector最后一个元素" class="headerlink" title="得到vector最后一个元素"></a>得到vector最后一个元素</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">merged.<span class="built_in">back</span>()</span><br></pre></td></tr></table></figure>



<h2 id="计数"><a href="#计数" class="headerlink" title="计数"></a>计数</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// vector中0的个数</span></span><br><span class="line"><span class="type">int</span> s1 = <span class="built_in">accumulate</span>(students.<span class="built_in">begin</span>(), students.<span class="built_in">end</span>(), <span class="number">0</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​	</p>
<h2 id="新建一个"><a href="#新建一个" class="headerlink" title="新建一个"></a>新建一个</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ret.<span class="built_in">push_back</span>(vector &lt;<span class="type">int</span>&gt; ());</span><br></pre></td></tr></table></figure>



<h2 id="在末尾添加元素"><a href="#在末尾添加元素" class="headerlink" title="在末尾添加元素"></a>在末尾添加元素</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ret.<span class="built_in">back</span>().<span class="built_in">push_back</span>(node-&gt;val);</span><br></pre></td></tr></table></figure>



<h2 id="切片、截取部分"><a href="#切片、截取部分" class="headerlink" title="切片、截取部分"></a>切片、截取部分</h2><p>取vector区间的元素<br>取数组{1, 4, 3, 2, 5}在[1, 3]区间的元素为{4, 3, 2}</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;; </span><br><span class="line"><span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">result</span><span class="params">(v.begin() + <span class="number">1</span>,v.begin() + <span class="number">3</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//————————————————</span></span><br><span class="line"><span class="comment">//版权声明：本文为CSDN博主「thisiszdy」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。</span></span><br><span class="line"><span class="comment">//原文链接：https://blog.csdn.net/thisiszdy/article/details/120086664</span></span><br></pre></td></tr></table></figure>





<p>以下有点麻烦啊。。。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; Arrs &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>&#125;; </span><br><span class="line">    <span class="comment">// 假设有这么个数组,要截取第2个元素到第6个元素：2，3，4,5,6对应索引分别为 1，2，3,4,5</span></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt;::const_iterator First = Arrs.<span class="built_in">begin</span>() + <span class="number">1</span>;  <span class="comment">// 找到第  2 个迭代器 （idx=1）</span></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt;::const_iterator Second = Arrs.<span class="built_in">begin</span>() + <span class="number">6</span>; <span class="comment">// 找到第  6 个迭代器 （idx=5）的下一个位置 </span></span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; Arr2;</span><br><span class="line">    Arr2.<span class="built_in">assign</span>(First,Second);  <span class="comment">// [First,Second)  左闭右开区间</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i : Arr2)&#123;</span><br><span class="line">        cout &lt;&lt; i&lt;&lt;<span class="string">&quot;--&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ————————————————</span></span><br><span class="line"><span class="comment">// 版权声明：本文为CSDN博主「索隆啊」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。</span></span><br><span class="line"><span class="comment">// 原文链接：https://blog.csdn.net/qq_36758461/article/details/120059080</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 哈希表</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/C++%20%E5%93%88%E5%B8%8C%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="C-哈希表"><a href="#C-哈希表" class="headerlink" title="C++ 哈希表"></a>C++ 哈希表</h1><p>哈希表在 C++ 中用 unordered_set 数据结构表示</p>
<p>是<code>C++</code> 中的 <code>std::unordered_set</code>，<code>Java</code> 中的 <code>HashSet</code>，<code>Python</code> 中的 <code>set</code>, <code>JavaScript</code> 中的 <code>Set</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">unordered_set&lt;vector&lt;<span class="type">int</span>&gt;*&gt; a;</span><br></pre></td></tr></table></figure>



<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">unordered_map&lt;State, unordered_map&lt;CharType, State&gt;&gt; transfer&#123;&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 命令行窗口输入</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/C++%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E8%BE%93%E5%85%A5/</url>
    <content><![CDATA[<h1 id="C-命令行窗口输入"><a href="#C-命令行窗口输入" class="headerlink" title="C++ 命令行窗口输入"></a>C++ 命令行窗口输入</h1><blockquote>
<p>参考leetcode的playground <a href="https://leetcode.cn/playground/new/empty/">https://leetcode.cn/playground/new/empty/</a></p>
</blockquote>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">stringToInteger</span><span class="params">(string input)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">stoi</span>(input);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    string line;</span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">getline</span>(cin, line)) &#123;</span><br><span class="line">        <span class="type">int</span> a = <span class="built_in">stringToInteger</span>(line);</span><br><span class="line">        <span class="built_in">getline</span>(cin, line);</span><br><span class="line">        <span class="type">int</span> b = <span class="built_in">stringToInteger</span>(line);</span><br><span class="line">        </span><br><span class="line">        <span class="type">int</span> ret = <span class="built_in">Solution</span>().<span class="built_in">add</span>(a, b);</span><br><span class="line"></span><br><span class="line">        string out = <span class="built_in">to_string</span>(ret);</span><br><span class="line">        cout &lt;&lt; out &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>C++数据结构</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/C++%20%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h1 id="C-数据结构"><a href="#C-数据结构" class="headerlink" title="C++数据结构"></a>C++数据结构</h1><blockquote>
<p>中文版：	<a href="http://c.biancheng.net/view/7250.html">http://c.biancheng.net/view/7250.html</a>    、 <a href="http://c.biancheng.net/">http://c.biancheng.net/</a> 、 <a href="http://c.biancheng.net/algorithm">http://c.biancheng.net/algorithm</a></p>
<p>官方中文版：<a href="https://zh.cppreference.com/w/cpp/container/vector">https://zh.cppreference.com/w/cpp/container/vector</a></p>
<p>英文版：<a href="https://cplusplus.com/reference/unordered_set/unordered_set/">https://cplusplus.com/reference/unordered_set/unordered_set/</a>  、 <a href="https://en.cppreference.com/w/cpp/container/vector">https://en.cppreference.com/w/cpp/container/vector</a></p>
<p>教程：<a href="https://labuladong.gitee.io/algo/%E3%80%81https://labuladong.github.io/algo/">https://labuladong.gitee.io/algo/、https://labuladong.github.io/algo/</a></p>
<p><a href="https://zerotrac.github.io/leetcode_problem_rating/#/">https://zerotrac.github.io/leetcode_problem_rating/#/</a></p>
<p><a href="https://blog.csdn.net/fuxuemingzhu/article/details/105183554">https://blog.csdn.net/fuxuemingzhu/article/details/105183554</a></p>
</blockquote>
<p>要用一些STL容器：<a href="http://c.biancheng.net/stl/">http://c.biancheng.net/stl/</a></p>
<p>​                </p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>leetcode刷题</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/leetcode/</url>
    <content><![CDATA[<h1 id="leetcode刷题"><a href="#leetcode刷题" class="headerlink" title="leetcode刷题"></a>leetcode刷题</h1><ul>
<li><input disabled type="checkbox"> <a href="https://leetcode.cn/problems/counting-bits/">338. 比特位计数</a>  动态规划解法[TODO]</li>
<li><input disabled type="checkbox"> <a href="https://leetcode.cn/problems/majority-element/">169. 多数元素</a> 很多种解法 [TODO]</li>
<li><input disabled type="checkbox"> <a href="https://leetcode.cn/problems/next-permutation/">31. 下一个排列</a> 感觉还是比较难的，不保证完全掌握</li>
</ul>
<h2 id="题型汇总"><a href="#题型汇总" class="headerlink" title="题型汇总"></a>题型汇总</h2><ol>
<li><p>&#x3D;&#x3D;对于这类寻找所有可行解的题，我们都可以尝试用「搜索回溯」的方法来解决。&#x3D;&#x3D;</p>
<p>回溯法：一种通过探索所有可能的候选解来找出所有的解的算法。如果候选解被确认不是一个解（或者至少不是最后一个解），回溯算法会通过在上一步进行一些变化抛弃该解，即回溯并且再次尝试。</p>
</li>
</ol>
<p>要学会用递归</p>
<h3 id="相关题目有："><a href="#相关题目有：" class="headerlink" title="相关题目有："></a>相关题目有：</h3><h4 id="39-组合总和"><a href="#39-组合总和" class="headerlink" title="39. 组合总和"></a><a href="https://leetcode.cn/problems/combination-sum/">39. 组合总和</a></h4><p>难度中等2209收藏分享切换为英文接收动态反馈</p>
<p>给你一个 <strong>无重复元素</strong> 的整数数组 <code>candidates</code> 和一个目标整数 <code>target</code> ，找出 <code>candidates</code> 中可以使数字和为目标数 <code>target</code> 的 <em>所有</em> <strong>不同组合</strong> ，并以列表形式返回。你可以按 <strong>任意顺序</strong> 返回这些组合。</p>
<p><code>candidates</code> 中的 <strong>同一个</strong> 数字可以 <strong>无限制重复被选取</strong> 。如果至少一个数字的被选数量不同，则两种组合是不同的。 </p>
<p>对于给定的输入，保证和为 <code>target</code> 的不同组合数少于 <code>150</code> 个。</p>
<h4 id="46-全排列"><a href="#46-全排列" class="headerlink" title="46. 全排列"></a><a href="https://leetcode.cn/problems/permutations/">46. 全排列</a></h4><p>难度中等2262</p>
<p>给定一个不含重复数字的数组 <code>nums</code> ，返回其 <em>所有可能的全排列</em> 。你可以 <strong>按任意顺序</strong> 返回答案。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,2,3]</span><br><span class="line">输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]</span><br></pre></td></tr></table></figure>

<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [0,1]</span><br><span class="line">输出：[[0,1],[1,0]]</span><br></pre></td></tr></table></figure>

<p><strong>示例 3：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1]</span><br><span class="line">输出：[[1]]</span><br></pre></td></tr></table></figure>



<p>（dfs：深度优先遍历）</p>
<p><img src="/2022/11/14/%E7%AE%97%E6%B3%95/leetcode/image-20221018171006175.png" alt="image-20221018171006175"></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>时间复杂度和简单排序</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%92%8C%E7%AE%80%E5%8D%95%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h1 id="时间复杂度和简单排序"><a href="#时间复杂度和简单排序" class="headerlink" title="时间复杂度和简单排序"></a>时间复杂度和简单排序</h1><p>2022.8.26</p>
<blockquote>
<p>b站 算法大神左神（左程云）带你一周刷爆LeetCode，数据结构算法-leetcode真题解析 P2 </p>
</blockquote>
<h3 id="异或"><a href="#异或" class="headerlink" title="异或"></a>异或</h3><p>异或性质：</p>
<ul>
<li>0 ^ N &#x3D; N, N ^ N &#x3D; 0</li>
<li>满足交换律、结合律 a ^ b &#x3D; b ^ a ， a ^ b ^ c &#x3D; a ^ (b ^ c)</li>
<li>同一批数异或起来，无论顺序，结果相同</li>
</ul>
<h4 id="swap交换"><a href="#swap交换" class="headerlink" title="swap交换"></a>swap交换</h4><p>异或可以用来交换两个变量的值</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">a = a ^ b</span><br><span class="line">b = a ^ b</span><br><span class="line">a = a ^ b</span><br></pre></td></tr></table></figure>

<p>（前提是 两个变量在内存里是两个独立区域）</p>
<h1 id="快排"><a href="#快排" class="headerlink" title="快排"></a>快排</h1><blockquote>
<p><a href="https://www.cnblogs.com/MOBIN/p/4681369.html">图解快速排序</a></p>
<p>runoob <a href="https://www.runoob.com/w3cnote/quick-sort-2.html">快速排序</a></p>
<p><a href="https://www.geeksforgeeks.org/quick-sort/">https://www.geeksforgeeks.org/quick-sort/</a></p>
<p><a href="http://data.biancheng.net/view/117.html">http://data.biancheng.net/view/117.html</a></p>
<p><a href="https://www.cnblogs.com/MOBIN/p/4681369.html">https://www.cnblogs.com/MOBIN/p/4681369.html</a></p>
</blockquote>
<p>挖空，填空，</p>
<p>从右到左，遇到比基准小的就往靠左的空位放，然后自己空出来；</p>
<p>再从左到右，遇到比御准大的就往靠右的空位放，然后自己空出来；</p>
<p>再一直执行上述两个步骤，直到不满足左指针&lt;右指针；</p>
<p>感觉就是小的一直填在左边，大的也一直填在右边；</p>
<p><img src="/2022/11/14/%E7%AE%97%E6%B3%95/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%92%8C%E7%AE%80%E5%8D%95%E6%8E%92%E5%BA%8F/v2-39daebea8336b763eb087e6410ee576b_r.jpg" alt="img"></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>暴力递归 回溯</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/%E6%9A%B4%E5%8A%9B%E9%80%92%E5%BD%92%EF%BC%88%E5%9B%9E%E6%BA%AF%EF%BC%89/</url>
    <content><![CDATA[<h1 id="暴力递归-回溯"><a href="#暴力递归-回溯" class="headerlink" title="暴力递归 回溯"></a>暴力递归 回溯</h1><blockquote>
<p><a href="https://mp.weixin.qq.com/s/nMUHqvwzG2LmWA9jMIHwQQ">回溯算法详解（修订版）</a></p>
</blockquote>
<p><strong>解决一个回溯问题，实际上就是一个决策树的遍历过程</strong>。你只需要思考 3 个问题：</p>
<p><strong>1、</strong> <strong>路径</strong>：也就是已经做出的选择。</p>
<p><strong>2、选择列表</strong>：也就是你当前可以做的选择。</p>
<p><strong>3、结束条件</strong>：也就是到达决策树底层，无法再做选择的条件。</p>
<p>代码方面，回溯算法的框架：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">result = []</span><br><span class="line">def <span class="built_in">backtrack</span>(路径, 选择列表):</span><br><span class="line">    <span class="keyword">if</span> 满足结束条件:</span><br><span class="line">        result.<span class="built_in">add</span>(路径)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> 选择 in 选择列表:</span><br><span class="line">        做选择</span><br><span class="line">        <span class="built_in">backtrack</span>(路径, 选择列表)</span><br><span class="line">        撤销选择</span><br></pre></td></tr></table></figure>

<img src="/2022/11/14/%E7%AE%97%E6%B3%95/%E6%9A%B4%E5%8A%9B%E9%80%92%E5%BD%92%EF%BC%88%E5%9B%9E%E6%BA%AF%EF%BC%89/640.jpeg" alt="图片" style="zoom:50%;">

<p><strong>函数其实就像一个指针，在这棵树上游走</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> 选择 in 选择列表:</span><br><span class="line">    # 做选择</span><br><span class="line">    将该选择从选择列表移除</span><br><span class="line">    路径.<span class="built_in">add</span>(选择)</span><br><span class="line">    <span class="built_in">backtrack</span>(路径, 选择列表)</span><br><span class="line">    # 撤销选择</span><br><span class="line">    路径.<span class="built_in">remove</span>(选择)</span><br><span class="line">    将该选择再加入选择列表</span><br></pre></td></tr></table></figure>

<p><strong>在递归之前做出选择，在递归之后撤销刚才的选择</strong></p>
<p><strong>有的时候，我们并不想得到所有合法的答案，只想要一个答案，怎么办呢</strong>？ ：</p>
<p>解：<strong>函数找到一个答案后就返回 true</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 函数找到一个答案后就返回 true</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">backtrack</span><span class="params">(vector&lt;string&gt;&amp; board, <span class="type">int</span> row)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 触发结束条件</span></span><br><span class="line">    <span class="keyword">if</span> (row == board.<span class="built_in">size</span>()) &#123;</span><br><span class="line">        res.<span class="built_in">push_back</span>(board);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> col = <span class="number">0</span>; col &lt; n; col++) &#123;</span><br><span class="line">        ...</span><br><span class="line">        board[row][col] = <span class="string">&#x27;Q&#x27;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">backtrack</span>(board, row + <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">        board[row][col] = <span class="string">&#x27;.&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<p><strong>写<code>backtrack</code>函数时，需要维护走过的「路径」和当前可以做的「选择列表」，当触发「结束条件」时，将「路径」记入结果集</strong>。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>有限状态自动机</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E8%87%AA%E5%8A%A8%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="有限状态自动机"><a href="#有限状态自动机" class="headerlink" title="有限状态自动机"></a>有限状态自动机</h1><blockquote>
<p><a href="https://leetcode.cn/problems/biao-shi-shu-zhi-de-zi-fu-chuan-lcof/solutions/372095/biao-shi-shu-zhi-de-zi-fu-chuan-by-leetcode-soluti/">leetcode题目 表示数值的字符串</a> </p>
</blockquote>
<p>根据上面的描述，现在可以定义自动机的「状态集合」了。那么怎么挖掘出所有可能的状态呢？一个常用的技巧是，用「当前处理到字符串的哪个部分」当作状态的表述。</p>
<p><img src="/2022/11/14/%E7%AE%97%E6%B3%95/%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E8%87%AA%E5%8A%A8%E6%9C%BA/jianzhi_20_fig1.png" alt="fig1"></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unordered_set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unordered_map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">enum</span> <span class="title class_">State</span> &#123;</span><br><span class="line">        STATE_INITIAL,</span><br><span class="line">        STATE_INT_SIGN,</span><br><span class="line">        STATE_INTEGER,</span><br><span class="line">        STATE_POINT,</span><br><span class="line">        STATE_POINT_WITHOUT_INT,</span><br><span class="line">        STATE_FRACTION,</span><br><span class="line">        STATE_EXP,</span><br><span class="line">        STATE_EXP_SIGN,</span><br><span class="line">        STATE_EXP_NUMBER,</span><br><span class="line">        STATE_END</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">enum</span> <span class="title class_">CharType</span> &#123;</span><br><span class="line">        CHAR_NUMBER,</span><br><span class="line">        CHAR_EXP,</span><br><span class="line">        CHAR_POINT,</span><br><span class="line">        CHAR_SIGN,</span><br><span class="line">        CHAR_SPACE,</span><br><span class="line">        CHAR_ILLEGAL</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="function">CharType <span class="title">toCharType</span><span class="params">(<span class="type">char</span> ch)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (ch &gt;= <span class="string">&#x27;0&#x27;</span> &amp;&amp; ch &lt;= <span class="string">&#x27;9&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> CHAR_NUMBER;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ch == <span class="string">&#x27;e&#x27;</span> || ch == <span class="string">&#x27;E&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> CHAR_EXP;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ch == <span class="string">&#x27;.&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> CHAR_POINT;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ch == <span class="string">&#x27;+&#x27;</span> || ch == <span class="string">&#x27;-&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> CHAR_SIGN;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ch == <span class="string">&#x27; &#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> CHAR_SPACE;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> CHAR_ILLEGAL;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">isNumber</span><span class="params">(string s)</span> </span>&#123;</span><br><span class="line">        unordered_map&lt;State, unordered_map&lt;CharType, State&gt;&gt; transfer&#123;</span><br><span class="line">            <span class="comment">//value的 哈希表表示转移</span></span><br><span class="line">            &#123;</span><br><span class="line">                STATE_INITIAL, &#123;</span><br><span class="line">                    &#123;CHAR_SPACE, STATE_INITIAL&#125;,</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_INTEGER&#125;,</span><br><span class="line">                    &#123;CHAR_POINT, STATE_POINT_WITHOUT_INT&#125;,</span><br><span class="line">                    &#123;CHAR_SIGN, STATE_INT_SIGN&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_INT_SIGN, &#123;</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_INTEGER&#125;,</span><br><span class="line">                    &#123;CHAR_POINT, STATE_POINT_WITHOUT_INT&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_INTEGER, &#123;</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_INTEGER&#125;,</span><br><span class="line">                    &#123;CHAR_EXP, STATE_EXP&#125;,</span><br><span class="line">                    &#123;CHAR_POINT, STATE_POINT&#125;,</span><br><span class="line">                    &#123;CHAR_SPACE, STATE_END&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_POINT, &#123;</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_FRACTION&#125;,</span><br><span class="line">                    &#123;CHAR_EXP, STATE_EXP&#125;,</span><br><span class="line">                    &#123;CHAR_SPACE, STATE_END&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_POINT_WITHOUT_INT, &#123;</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_FRACTION&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_FRACTION,</span><br><span class="line">                &#123;</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_FRACTION&#125;,</span><br><span class="line">                    &#123;CHAR_EXP, STATE_EXP&#125;,</span><br><span class="line">                    &#123;CHAR_SPACE, STATE_END&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_EXP,</span><br><span class="line">                &#123;</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_EXP_NUMBER&#125;,</span><br><span class="line">                    &#123;CHAR_SIGN, STATE_EXP_SIGN&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_EXP_SIGN, &#123;</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_EXP_NUMBER&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_EXP_NUMBER, &#123;</span><br><span class="line">                    &#123;CHAR_NUMBER, STATE_EXP_NUMBER&#125;,</span><br><span class="line">                    &#123;CHAR_SPACE, STATE_END&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, &#123;</span><br><span class="line">                STATE_END, &#123;</span><br><span class="line">                    &#123;CHAR_SPACE, STATE_END&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> len = s.<span class="built_in">length</span>();</span><br><span class="line">        State st = STATE_INITIAL;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">            CharType typ = <span class="built_in">toCharType</span>(s[i]);</span><br><span class="line">            <span class="keyword">if</span> (transfer[st].<span class="built_in">find</span>(typ) == transfer[st].<span class="built_in">end</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                st = transfer[st][typ];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> st == STATE_INTEGER || st == STATE_POINT || st == STATE_FRACTION || st == STATE_EXP_NUMBER || st == STATE_END;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 作者：力扣官方题解</span></span><br><span class="line"><span class="comment">// 链接：https://leetcode.cn/problems/biao-shi-shu-zhi-de-zi-fu-chuan-lcof/solutions/372095/biao-shi-shu-zhi-de-zi-fu-chuan-by-leetcode-soluti/</span></span><br><span class="line"><span class="comment">// 来源：力扣（LeetCode）</span></span><br><span class="line"><span class="comment">// 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="built_in">Solution</span>().<span class="built_in">isNumber</span>(<span class="string">&quot;-.&quot;</span>) &lt;&lt; endl;</span><br><span class="line">    <span class="comment">// string line;</span></span><br><span class="line">    <span class="comment">// while(1)&#123;</span></span><br><span class="line">    <span class="comment">// getline(cin, line);</span></span><br><span class="line">    <span class="comment">// cout &lt;&lt; Solution().isNumber(line) &lt;&lt; endl;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>算法体系</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E4%BD%93%E7%B3%BB/</url>
    <content><![CDATA[<p><img src="/2022/11/14/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E4%BD%93%E7%B3%BB/1667376439-wxbxBv-%E8%AF%BE%E7%A8%8B%E4%BD%93%E7%B3%BB.png" alt="img"></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>矩阵连乘的快速实现</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/%E7%9F%A9%E9%98%B5%E8%BF%9E%E4%B9%98%E7%9A%84%E5%BF%AB%E9%80%9F%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="矩阵连乘的快速实现"><a href="#矩阵连乘的快速实现" class="headerlink" title="矩阵连乘的快速实现"></a>矩阵连乘的快速实现</h1><blockquote>
<p> 矩阵快速幂 例子 斐波那契数列 <a href="https://leetcode.cn/problems/fei-bo-na-qi-shu-lie-lcof/solutions/976888/fei-bo-na-qi-shu-lie-by-leetcode-solutio-hbss/">https://leetcode.cn/problems/fei-bo-na-qi-shu-lie-lcof/solutions/976888/fei-bo-na-qi-shu-lie-by-leetcode-solutio-hbss/</a></p>
</blockquote>
<p>矩阵幂次乘：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">vector&lt;vector&lt;<span class="type">long</span>&gt;&gt; q&#123;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;, &#123;<span class="number">1</span>, <span class="number">0</span>&#125;&#125;;</span><br><span class="line">vector&lt;vector&lt;<span class="type">long</span>&gt;&gt; res = <span class="built_in">pow</span>(q, n - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vector&lt;vector&lt;<span class="type">long</span>&gt;&gt; <span class="built_in">pow</span>(vector&lt;vector&lt;<span class="type">long</span>&gt;&gt;&amp; a, <span class="type">int</span> n) &#123;</span><br><span class="line">    vector&lt;vector&lt;<span class="type">long</span>&gt;&gt; ret&#123;&#123;<span class="number">1</span>, <span class="number">0</span>&#125;, &#123;<span class="number">0</span>, <span class="number">1</span>&#125;&#125;;</span><br><span class="line">    <span class="keyword">while</span> (n &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (n &amp; <span class="number">1</span>) &#123;</span><br><span class="line">            ret = <span class="built_in">multiply</span>(ret, a);</span><br><span class="line">        &#125;</span><br><span class="line">        n &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">        a = <span class="built_in">multiply</span>(a, a);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vector&lt;vector&lt;<span class="type">long</span>&gt;&gt; <span class="built_in">multiply</span>(vector&lt;vector&lt;<span class="type">long</span>&gt;&gt;&amp; a, vector&lt;vector&lt;<span class="type">long</span>&gt;&gt;&amp; b) &#123;</span><br><span class="line">    vector&lt;vector&lt;<span class="type">long</span>&gt;&gt; c&#123;&#123;<span class="number">0</span>, <span class="number">0</span>&#125;, &#123;<span class="number">0</span>, <span class="number">0</span>&#125;&#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; j++) &#123;</span><br><span class="line">            c[i][j] = (a[i][<span class="number">0</span>] * b[<span class="number">0</span>][j] + a[i][<span class="number">1</span>] * b[<span class="number">1</span>][j]) % MOD;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>贪心</title>
    <url>/2022/11/14/%E7%AE%97%E6%B3%95/%E8%B4%AA%E5%BF%83/</url>
    <content><![CDATA[<h1 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h1><p>leetcode</p>
<h4 id="55-跳跃游戏"><a href="#55-跳跃游戏" class="headerlink" title="55. 跳跃游戏"></a><a href="https://leetcode.cn/problems/jump-game/">55. 跳跃游戏</a></h4><p>难度中等2055收藏分享切换为英文接收动态反馈</p>
<p>给定一个非负整数数组 <code>nums</code> ，你最初位于数组的 <strong>第一个下标</strong> 。</p>
<p>数组中的每个元素代表你在该位置可以跳跃的最大长度。</p>
<p>判断你是否能够到达最后一个下标。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [2,3,1,1,4]</span><br><span class="line">输出：true</span><br><span class="line">解释：可以先跳 1 步，从下标 0 到达下标 1, 然后再从下标 1 跳 3 步到达最后一个下标。</span><br></pre></td></tr></table></figure>

<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [3,2,1,0,4]</span><br><span class="line">输出：false</span><br><span class="line">解释：无论怎样，总会到达下标为 3 的位置。但该下标的最大跳跃长度是 0 ， 所以永远不可能到达最后一个下标。</span><br></pre></td></tr></table></figure>

<h4 id="解："><a href="#解：" class="headerlink" title="解："></a>解：</h4><p>找最远能到达的距离。</p>
<hr>
<h4 id="56-合并区间"><a href="#56-合并区间" class="headerlink" title="56. 合并区间"></a><a href="https://leetcode.cn/problems/merge-intervals/">56. 合并区间</a></h4><p>难度中等1680</p>
<p>以数组 <code>intervals</code> 表示若干个区间的集合，其中单个区间为 <code>intervals[i] = [starti, endi]</code> 。请你合并所有重叠的区间，并返回 <em>一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间</em> 。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：intervals = [[1,3],[2,6],[8,10],[15,18]]</span><br><span class="line">输出：[[1,6],[8,10],[15,18]]</span><br><span class="line">解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6].</span><br></pre></td></tr></table></figure>

<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：intervals = [[1,4],[4,5]]</span><br><span class="line">输出：[[1,5]]</span><br><span class="line">解释：区间 [1,4] 和 [4,5] 可被视为重叠区间。</span><br></pre></td></tr></table></figure>



<h4 id="解"><a href="#解" class="headerlink" title="解"></a>解</h4><p>按照区间的左端点排序。</p>
<hr>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第10章 DNN-HMM TDNNF推导过程</title>
    <url>/2023/01/10/%E8%AF%86%E5%88%AB/TDNNF%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="TDNNF推导过程"><a href="#TDNNF推导过程" class="headerlink" title="TDNNF推导过程"></a>TDNNF推导过程</h1><blockquote>
<p>《语音识别原理与应用》洪青阳 P215</p>
</blockquote>
<p>2018 年，著名的语音学者 Daniel Povey对TDNN 网络做了进一步的改进提出了因子分解的 TDNN，即带有半正交矩阵的TDNN-F，TDNN-F建立在奇异值分解 ( Singular Value Decomposition, SVD)的基础上。作为最著名的矩阵分解方法，SVD 是减少已训练的模型大小的一种有效方法，因为通过SVD我们可以将每个权重矩阵分解为两个因子矩阵，通过丟弃相对更小的奇异值，优化网络参数。</p>
<p>TDNNF 特点：</p>
<ul>
<li>通过奇异值分解(SVD) ，把每个权重矩阵因子分解为两个更小的矩阵，减少神经网络参数。</li>
<li>TDNN-F限定其中一个矩阵为半正交的(semi-orthogonal)。</li>
<li>类似残差网络，TDNN-F采用跳层连接，减少梯度的消失。</li>
</ul>
<p>TDNN-F 的内部结构与经过SVD压缩的 TDNN 是相同的。虽然经过 SVD 压缩的 TDNN 在随机初始化后，直接训练带有瓶颈层的模型会更高效，但是训练不稳定的问题时有发生。为了避免这种情况，TDNN-F 会在进行完SVD 分解后，将两个分解因子矩阵中的一个约束为半正交矩阵。这种做法既符合 SVD 的要求和特点，也不会损失网络的建模能力。</p>
<p>我们来看具体的推导过程。TDNN-F 把一个权重矩阵M分解为两个矩阵A和B，并限定其中B为半正交的矩阵。<br>$$<br>M&#x3D;AB<br>$$<br>迭代优化M如下：<br>$$<br>M^{\prime} \leftarrow M-\varepsilon \Delta M<br>$$<br>定义<br>$$<br>P&#x3D;M M^{\top}<br>$$<br>TDNN-F的限制条件是使 $P&#x3D;I$，定义<br>$$<br>Q&#x3D;p-I<br>$$<br>TDNN-F 的优化目标等价于使用最小化函数<br>$$<br>f&#x3D;\operatorname{tr}\left(Q Q^{\top}\right)<br>$$<br>对Q、P、M求偏导，分别得到<br>$$<br>\begin{aligned}<br>&amp; \frac{\partial f}{\partial Q}&#x3D;2 Q \<br>&amp; \frac{\partial f}{\partial P}&#x3D;2 Q \<br>&amp; \frac{\partial f}{\partial M}&#x3D;4 Q M<br>\end{aligned}<br>$$<br>因此，可如下迭代优化权重矩阵M：<br>$$<br>\begin{gathered}<br>\Delta M&#x3D;\nabla_N f&#x3D;\frac{\partial f}{\partial M}&#x3D;4 Q M \<br>M^{\prime} \leftarrow M-4 \varepsilon Q M<br>\end{gathered}<br>$$<br>其中， $\varepsilon$ 是学习率。</p>
<p>假如原来 $M$ 是 $128 \times 128$ 矩阵, 通过因子分解，得到的 $A$ 为 $128 \times 32$ 矩阵, $B$ 为 $32 \times 128$ 矩阵, 其中 32 是中间瓶颈层的节点数。这样网络参数量从 $128 \times 128$ 个减 少到 $128 \times 32 \times 2$ 个, 即从 16384 个减到 8192 个, 权重运算量也会大为诚少。</p>
<p>随着网络的加深, 为了减少梯度消失的情况, 在 TDNN-F 网络中还增加了跳层连接, 即将之前层的输出加上当前层的输出作为下一层的输入。这种构造与残差结构类似, 目的都是为了减少梯度消失的情况。同时, 为了防止模型过拟合, 在每个 TDNN-F 的单元结构中还㴛加了 dropout 层。</p>
<h1 id="kaldi中的TDNN-F"><a href="#kaldi中的TDNN-F" class="headerlink" title="kaldi中的TDNN-F"></a>kaldi中的TDNN-F</h1><p>参考Kaldi 的配置文件，采用40 维FBank特征，则 TDNN-F 的结构如下表所示。我们解释一下tdnnf-layer的参数</p>
<ul>
<li>l2-regularize：设置L2 正则系数。</li>
<li>dropout-proportion：设置丢弃（dropout）的比例。</li>
<li>bypass-scale：设置跳连接时针对上一层输出节点的尺度，默认值为 0.66，不应该大于1。当设为0时，则不进行跳连接操作。</li>
<li>time-stride ：控制时间维度拼接，time-stride&#x3D;1表示在线性层使用Append(-1,0)，在仿射变换时使用 Append(0.1)。设置当time-stride 为负数时，如-1，则表示先使用右偏置，再使用左偏置。</li>
<li>bottleneck-dim：设置分解矩阵后的维度。</li>
</ul>
<p>TDNN-F 网络结构信息表：</p>
<p>tdnnf-layer	name&#x3D;tdnnf2	12-regularize&#x3D;0.01	dropout-proportion&#x3D;0.0	bypass-scale&#x3D;0.66	dim&#x3D;1536	bottleneck-dim&#x3D;160	time-stride&#x3D;1</p>
<p>第一个隐藏层的输出是1536 维的特征。第二个隐藏层接收上层的输人。先进行因子分解，因为 time-strde&#x3D;1，所以在线性变换时输入的特征是当前帧与左偏移一帧的拼接帧。通过线性变换将特征维度减少到瓶颈节点数，不同于普通的线性变换，这里限制B矩阵为半正交矩阵，同时使用了 L2 正则系统。接着经过 1536x160 （time-stride&#x3D;1，仿射变换时的输入是当前帧与右偏移一帧的拼接帧）权重矩阵计算，并进行仿射变换得到 1536 维的输出。上面两生完成了增加中间层、减少参数数量的操作。再使用 ReLU 两数作为激活函数，进行批处理规整（batchnorm）计算，然后再根据 dropout-proportion 的值进行dropout。 最后由于 bypass-scale&#x3D;0.66 不为0，所以要进行跳连接，将第一个隐藏层的output 和第二个隐藏层的 output 相加作为第三个隐藏层的输人。</p>
<p>TDNN-F与CNN结合：CNN提取局部频域特征，TDNN-F提取上下文时域特征。</p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>《语音识别原理与应用》</tag>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Wenet的语音识别</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/Wenet/</url>
    <content><![CDATA[<h1 id="基于Wenet的语音识别"><a href="#基于Wenet的语音识别" class="headerlink" title="基于Wenet的语音识别"></a>基于Wenet的语音识别</h1><p>​																																																																												2022.5.7</p>
<h4 id="带LM的方案："><a href="#带LM的方案：" class="headerlink" title="带LM的方案："></a>带LM的方案：</h4><p>现CTC&#x2F;AED方案：</p>
<p>只在推理用：预训练的LM参与CTC解码，CTC解码完将n-best送入attention decoder，作为attention decoder的解码空间，二遍解码；</p>
<p>还可以有的方案：</p>
<ol>
<li><p>cold fusion：预训练LM参数不更新，与CTC&#x2F;AED AM模型融合，只更新AM模型，然后推理解码CTC+LM，（不）送入attention decoder？？（这里的更新am，要有领域wav+text时，更新才有效）</p>
</li>
<li><p>shallow fusion：只在推理用：attention decoder解码时引入预训练LM分数，影响rescore路径；</p>
</li>
</ol>
<p>（参考las：$\large s(y|x)&#x3D;\frac{logP(y|x)}{|y|<em>c}+\lambda logP</em>{LM}(y)$）</p>
<ol start="3">
<li>rescore，但是ctc n-best是给decoder输出每个符号的限制范围，不是只在ctc的beam条路径中选一条，而是decoder也可以做beam search</li>
</ol>
<p>班博说：</p>
<ul>
<li><p>如果没有领域数据</p>
<ul>
<li><p>比如文言文出师表这种，即使am训练得再好，如果不依赖lm，那么ctc出来的n-best里就不会有文言文这条候选路径，那么即使后面怎么rescore都无效；</p>
</li>
<li><p>ctc解码过程中引入lm，出来的可能会有效，然后再可选加&#x2F;不加rescore；</p>
</li>
<li><p>ctc解码过程中纯纯声学模型过程，语言模型有起一点作用但是很弱，我们对通用语料训练得到的am的唯一要求就是发音准确，对它没有语言模型的要求，甚至希望它能减少语言模型的依赖，因为后期要加领域数据训练的语言模型</p>
<p>这里encoder+ctc之所以有一点语言模型作用（我一开始以为它是纯纯am，只是音到字的建模，没有字到字的建模），是因为不然发同音字，它出来的可以是任意字，而很不容易发出对的字，但是实际上大部分都是发对的字，说明有语言模型的作用在里头）</p>
</li>
<li><p>更好的结合方式是，ctc解码纯纯声学模型，再用领域数据的语言模型rescore，这时候按字建模就不合适了，不然n-best可能都没那条路径，最好的就是按音素&#x2F;音节建模，避开字建模，这样n-best好出来；</p>
</li>
<li><p>字、词、声韵母、音素不同建模+领域TLG+领域rescoring</p>
</li>
</ul>
</li>
<li><p>如果有领域数据</p>
<ul>
<li><p>领域数据是弱标注时：字+领域TLG+领域rescoring</p>
<p>（弱标注指的是有领域的音频但是没有标注，放到腾讯&#x2F;百度&#x2F;讯飞等开放平台上得到asr结果，如果多家都是一样的，则认为这个标注是对的，称为弱标注）</p>
</li>
<li><p>领域数据是人工标注时：字+领域TLG+领域rescoring</p>
</li>
</ul>
</li>
<li><p>中英混：查看CTC出来的n-best（这个n可以很大），与标注文本之间的WER，如果n&gt;1的第n条路径WER低于1-best，说明有提升的空间（说明候选路径里有通过rescore能校准的可能性，再去调研rescore方法），如果wer没有差别，说明此方法不可行，要探索其他方法</p>
</li>
</ul>
<p>班博说：</p>
<ol>
<li><p>跟业务确定现在的50小时数据是否为真实课堂场景数据</p>
<ul>
<li>如果业务反馈该数据可以代表真实环境，那么研究院没必要继续跟进</li>
<li>如果业务反馈该数据不能代表真实环境，那么需要提供接近真实的场景测试数据</li>
</ul>
</li>
<li><p>如果新的真实场景数据ASR结果较差，或者提高中英混效果，研究院可以研究的点</p>
<ul>
<li>字、词、声韵母、音素不同建模+领域TLG+领域rescoring</li>
<li>第三方弱标注领域音频，训练字+领域TLG+领域resocring</li>
<li>第三方人工标注领域音频，训练字+领域TLG+领域resocring</li>
</ul>
</li>
</ol>
<p>$\large y\in \mathbb R^{L\times e}$</p>
<hr>
<p>encoder、decoder的输入都要加位置编码，</p>
<p>decoder最下面（第一个）的attention是mask attention，mask就是下三角矩阵，只看见previous，输入不是逐符号输入的，而是整句文本都输入，整句话提取embedding，然后做attention，一次到位，并不是我想象得那种第一个符号输出作为第二个符号的输入那样，</p>
<p>第二个attention，Inter-attention</p>
<h2 id="训练耗时"><a href="#训练耗时" class="headerlink" title="训练耗时"></a>训练耗时</h2><p>4台8卡（32卡），1w小时，1个epoch 2.5小时，80个epoch大约8天</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/Wenet/v2-5169789bc1a176f10f950f9c7b79c7d9_r.jpg" alt="preview"></p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>编译Wenet runtime</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/Wenet%E7%BC%96%E8%AF%91/</url>
    <content><![CDATA[<h1 id="编译Wenet-runtime"><a href="#编译Wenet-runtime" class="headerlink" title="编译Wenet runtime"></a>编译Wenet runtime</h1><p>需要有cmake、g++</p>
<p>在wenet&#x2F;runtime&#x2F;server&#x2F;x86 进行：mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; cmake –build .</p>
<h1 id="调试wenet"><a href="#调试wenet" class="headerlink" title="调试wenet"></a>调试wenet</h1><p>需要有gdb（安装的gdb 9.2，.&#x2F;configure –prefix&#x3D;… &amp;&amp; make -j all &amp;&amp; make install）（安装gdb需要有texinfo（安装的texinfo 6.6，.&#x2F;configure –prefix&#x3D;… &amp;&amp; make -j all &amp;&amp; make install））</p>
<h1 id="编译、调试成功"><a href="#编译、调试成功" class="headerlink" title="编译、调试成功"></a>编译、调试成功</h1><p>10.22.24.2（yelong port&#x3D;51720  password&#x3D;123）</p>
<h1 id="调试decoder-main"><a href="#调试decoder-main" class="headerlink" title="调试decoder_main"></a>调试decoder_main</h1><p>用的cgdb调试</p>
<p>首先之前编译cmake时，没有加可选debug的选项，因此不可调试，在<strong>CMakeLists.txt</strong>加入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) </span><br><span class="line">SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;)</span><br><span class="line">SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</span><br></pre></td></tr></table></figure>

<p>重新编译：在build里：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">cmake clean ..</span></span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug ..</span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug --build .</span><br><span class="line">make	# 记得还要一步 make</span><br></pre></td></tr></table></figure>

<p>然后在Libtorch下调试：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cgdb build/bin/decoder_main</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后在界面中打断点：比如</span> </span><br><span class="line">b asr_decoder.cc:194</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">无tlg</span></span><br><span class="line">run  --chunk_size -1 --wav_scp /home/yelong/data/wenet/examples/aishell/s0/data/xueyuan/wav.scp.1 --model_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/final.zip --unit_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang.char.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">不调试运行就是：</span></span><br><span class="line">./build/bin/decoder_main --chunk_size -1 --wav_scp /home/yelong/data/wenet/examples/aishell/s0/data/xueyuan/wav.scp.1 --model_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/final.zip --unit_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang.char.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">要打印n_best：加 --output_nbest <span class="literal">true</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tlg</span></span><br><span class="line">run --acoustic_scale 5 --beam 5.0 --lattice_beam 7.5 --max_active 7000 --ctc_weight 1 --rescoring_weight 0 --chunk_size -1  --fst_path /data_local/yelong/wenet/examples/aishell/s0/exp/aban-c009/lang_test_aban-c009_lin/TLG.fst  --wav_scp home/yelong/data/wenet/examples/aishell/s0/data/xueyuan/wav.scp.1 --model_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/final.zip  --dict_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang_test_aban-c009_lin/words.txt --unit_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang.char.txt</span><br></pre></td></tr></table></figure>



<h2 id="gdb调试报错warning-Error-disabling-address-space-randomization-Operation-not-permitted"><a href="#gdb调试报错warning-Error-disabling-address-space-randomization-Operation-not-permitted" class="headerlink" title="gdb调试报错warning: Error disabling address space randomization: Operation not permitted"></a>gdb调试报错warning: Error disabling address space randomization: Operation not permitted</h2><blockquote>
<p><a href="https://gitee.com/openeuler/community/issues/I1KPAQ">https://gitee.com/openeuler/community/issues/I1KPAQ</a></p>
</blockquote>
<p>启动docker时加参数</p>
<p>启动容器时加上–cap-add&#x3D;SYS_PTRACE –security-opt seccomp&#x3D;unconfined选项可以解决该问题</p>
<p>docker run -it –cap-add&#x3D;SYS_PTRACE –security-opt seccomp&#x3D;unconfined mobvoiwenet&#x2F;wenet:latest bash</p>
<p>在172.17.84.128的docker里编译，不加debug，是可以编译成功的，</p>
<p>但是加debug后</p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>Wenet脚本 LM</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/Wenet%E8%84%9A%E6%9C%AC%20LM/</url>
    <content><![CDATA[<h1 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h1><blockquote>
<p><a href="https://wenet.org.cn/wenet/lm.html">LM for WeNet</a></p>
</blockquote>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/Wenet%E8%84%9A%E6%9C%AC%20LM/lm_system.png" alt="img" style="zoom:80%;">

<ol>
<li>没有LM，用CTC prefix beam search来产生N-best</li>
<li>有LM，用CTC WFST search来产生N-best，其中CTC WFST search是传统的基于WFST的decoder</li>
</ol>
<p>第一步是构建解码图，用建模单元T，词典L，语言模型G组合compose到统一一个解码图TLG里，其中T是端到端训练的建模单元，中文里是char，英文是char或BPE；L是词典，就是把词组分开成建模单元，比如把word“我们”分开成两个chars“我 们”，word“APPLE”分开成五个字母letters“A P P L E”，没有音素，词典不用特殊设计；G是语言模型，就是将n-gram编译成标准的WFST表示；</p>
<p>第二步是解码，和传统方法一样，用Viterbi搜索算法；</p>
<p>WeNet利用Kaldi中的解码器和相关工具来支持基于LM和WFST的解码。为了便于使用和保持独立性，我们在WeNet运行时直接将Kaldi中与解码相关的代码迁移到<a href="https://github.com/wenet-e2e/wenet/tree/main/runtime/core/kaldi">此目录</a>。并按以下原则进行修改和组织:</p>
<ol>
<li>为了最小化更改，迁移后的代码保持与原始代码相同的目录结构。</li>
<li>我们使用GLOG代替Kaldi的日志系统。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_WARN \</span></span><br><span class="line"><span class="meta">  google::LogMessage(__FILE__, __LINE__, google::GLOG_WARNING).stream()</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_ERR \</span></span><br><span class="line"><span class="meta">  google::LogMessage(__FILE__, __LINE__, google::GLOG_ERROR).stream()</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_INFO \</span></span><br><span class="line"><span class="meta">  google::LogMessage(__FILE__, __LINE__, google::GLOG_INFO).stream()</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_VLOG(v) VLOG(v)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> KALDI_ASSERT(condition) CHECK(condition)</span></span><br></pre></td></tr></table></figure>

<ol>
<li>我们修改了代码格式，以满足WeNet代码风格的lint要求。</li>
</ol>
<p>核心代码是 <a href="https://github.com/wenet-e2e/wenet/blob/main/runtime/core/decoder/ctc_wfst_beam_search.cc">https://github.com/wenet-e2e/wenet/blob/main/runtime/core/decoder/ctc_wfst_beam_search.cc</a>  ,   它在Kaldi中包装wrap了LatticeFasterDecoder。我们使用空白帧跳转来加速解码。</p>
<p>此外，WeNet还迁移了构建解码图的相关工具，如arpa2fst、fstdeterminizestar、fsttablecompose、fstminimizeencoded等工具。因此，所有与LM相关的工具都是内置工具，可以开箱即用。</p>
<p>我们在不同的数据集上获得了一致的增益(3%~10%)，包括aishell、aishell2和librispeech</p>
<h3 id="词典的构造："><a href="#词典的构造：" class="headerlink" title="词典的构造："></a>词典的构造：</h3><p>tools&#x2F;fst&#x2F;prepare_dict.py</p>
<p>之前训练时，按字建模，没有词组，因此字一共有4232个字（训练集）（data&#x2F;dict&#x2F;lexicon.txt），加eos&#x2F;sos是4233个</p>
<p>现在：把aishell里的一个自带的词典corpus&#x2F;aishell&#x2F;resource_aishell&#x2F;lexicon.txt（13万个词组），通过data&#x2F;dict&#x2F;lexicon.txt进行过滤，只保留训练集有的字的词组，</p>
<p>得到的词典用字建模，组成词组，12万词的词典（data&#x2F;local&#x2F;dict&#x2F;lexicon.txt）；</p>
<h3 id="训练LM："><a href="#训练LM：" class="headerlink" title="训练LM："></a>训练LM：</h3><p>local&#x2F;aishell_train_lms.sh</p>
<p>用训练集训练LM：</p>
<p>从corpus&#x2F;data_aishell&#x2F;transcript&#x2F;aishell_transcript_v0.8.txt（所有train&#x2F;dev&#x2F;test音频对应的文本，进行了分词）过滤出训练集对应的12万条分词文本（data&#x2F;local&#x2F;lm&#x2F;text）</p>
<p>用分词过的12万条训练集文本、12万词的词典 训练语言模型，得到 16M的 3-gram的lm.arpa</p>
<p>file data&#x2F;local&#x2F;lm&#x2F;heldout: 10000 sentences, 89496 words, 0 OOVs<br>0 zeroprobs, logprob&#x3D; -272791.2 ppl&#x3D; 551.7352 ppl1&#x3D; 1117.077</p>
<p>可以看出，ppl&#x3D;500多，还不是特别好（300以内才好）</p>
<h3 id="构建解码中使用的TLG"><a href="#构建解码中使用的TLG" class="headerlink" title="构建解码中使用的TLG"></a>构建解码中使用的TLG</h3><p>tools&#x2F;fst&#x2F;compile_lexicon_token_fst.sh</p>
<p>tools&#x2F;fst&#x2F;make_tlg.sh </p>
<p>TLG.fst &#x3D;  T compose（determini（L compose G））</p>
<h3 id="TLG参与推理解码"><a href="#TLG参与推理解码" class="headerlink" title="TLG参与推理解码"></a>TLG参与推理解码</h3><p>.&#x2F;tools&#x2F;decode.sh</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./tools/decode.sh --nj 16 \</span><br><span class="line">    --beam 15.0 --lattice_beam 7.5 --max_active 7000 \</span><br><span class="line">    --blank_skip_thresh 0.98 --ctc_weight 0.5 --rescoring_weight 1.0 \</span><br><span class="line">    --fst_path data/lang_test/TLG.fst \</span><br><span class="line">    data/test/wav.scp data/test/text <span class="variable">$dir</span>/final.zip \</span><br><span class="line">    data/lang_test/words.txt <span class="variable">$dir</span>/lm_with_runtime</span><br></pre></td></tr></table></figure>

<p>.&#x2F;tools&#x2F;decode.sh 具体为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">decoder_main \</span><br><span class="line">   --rescoring_weight <span class="variable">$rescoring_weight</span> \</span><br><span class="line">   --ctc_weight <span class="variable">$ctc_weight</span> \</span><br><span class="line">   --reverse_weight <span class="variable">$reverse_weight</span> \</span><br><span class="line">   --chunk_size <span class="variable">$chunk_size</span> \</span><br><span class="line">   --wav_scp <span class="variable">$&#123;dir&#125;</span>/split<span class="variable">$&#123;nj&#125;</span>/wav.<span class="variable">$&#123;n&#125;</span>.scp \</span><br><span class="line">   --model_path <span class="variable">$model_file</span> \</span><br><span class="line">   --dict_path <span class="variable">$dict_file</span> \</span><br><span class="line">   <span class="variable">$wfst_decode_opts</span> \</span><br><span class="line">   --result <span class="variable">$&#123;dir&#125;</span>/split<span class="variable">$&#123;nj&#125;</span>/<span class="variable">$&#123;n&#125;</span>.text &amp;&gt; <span class="variable">$&#123;dir&#125;</span>/split<span class="variable">$&#123;nj&#125;</span>/<span class="variable">$&#123;n&#125;</span>.<span class="built_in">log</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>要到runtime&#x2F;server&#x2F;x86 进行编译：<code>mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; cmake --build .	</code>		[用docker的话，这步就不需要]</p>
<p>cmake版本要3.14 ，我没有编译成功（3.12），错误报告见：&#x2F;home&#x2F;data&#x2F;yelong&#x2F;newest_wenet&#x2F;wenet&#x2F;runtime&#x2F;server&#x2F;x86&#x2F;build&#x2F;CMakeFiles&#x2F;CMakeOutput.log</p>
<p>因此决定直接用 docker</p>
<p>进入到container中：docker exec -it 5627fbb7b503 bash</p>
<p>进入到&#x2F;home&#x2F;wenet&#x2F;runtime&#x2F;server&#x2F;x86</p>
<p>用c进行解码</p>
<h2 id="使用docker启动语音识别服务"><a href="#使用docker启动语音识别服务" class="headerlink" title="使用docker启动语音识别服务"></a>使用docker启动语音识别服务</h2><p>先要拉去最新的image</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> docker</span><br><span class="line">docker build --no-cache -t wenet:latest .</span><br><span class="line"><span class="comment"># 或者：</span></span><br><span class="line">docker run -it -p 10086:10086 -v <span class="variable">$model_dir</span>:/home/wenet/model wenetorg/wenet-mini:latest bash /home/run.sh</span><br><span class="line"><span class="comment"># 这里10086:10086是服务器端口，映射到容器的端口，内部端口:外部端口</span></span><br></pre></td></tr></table></figure>

<p>最简单的使用 Wenet 的方式是通过官方提供的 docker 镜像 <code>wenetorg/wenet:mini</code> 来启动服务。</p>
<p>（镜像默认都是放在<a href="https://hub.docker.com/%E9%87%8C%EF%BC%8C%E7%84%B6%E5%90%8E%E8%99%BD%E7%84%B6%E6%B2%A1%E6%9C%89%E8%BF%99%E4%B8%AA%E5%89%8D%E7%BC%80%EF%BC%8C%E4%BD%86%E6%98%AF%E4%BC%9A%E5%8E%BB%E8%BF%99%E4%B8%8A%E9%9D%A2%E6%89%BE%E9%95%9C%E5%83%8F%EF%BC%8C%E9%95%9C%E5%83%8F%E5%90%8D%E5%8F%ABwenetorg/wenet-mini%EF%BC%89">https://hub.docker.com/里，然后虽然没有这个前缀，但是会去这上面找镜像，镜像名叫wenetorg/wenet-mini）</a></p>
<p>下面的命令先下载官方提供的预训练模型，并启动 docker 服务，加载模型，提供 websocket 协议的语音识别服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> wenet/runtime/server/x86</span><br><span class="line">wget https://wenet-1256283475.cos.ap-shanghai.myqcloud.com/models/aishell/20210601_u2%2B%2B_conformer_libtorch.tar.gz</span><br><span class="line">tar -xf 20210602_u2++_conformer_libtorch.tar.gz</span><br><span class="line">model_dir=<span class="variable">$PWD</span>/20210602_u2++_conformer_libtorch</span><br><span class="line">docker run --<span class="built_in">rm</span> -it -p 10086:10086 -v <span class="variable">$model_dir</span>:/home/wenet/model wenetorg/wenet-mini:latest bash /home/run.sh</span><br><span class="line"><span class="comment"># 这里起一次就生成一个容器了，之后只要用：</span></span><br><span class="line">docker <span class="built_in">exec</span> -it .... bash <span class="comment"># 再次进入就好</span></span><br></pre></td></tr></table></figure>

<p><code>$model_dir</code> 是模型在本机的目录，将被映射到容器的 <code>/home/wenet/model</code> 目录，然后启动 web 服务。</p>
<h3 id="用网页的实时识别"><a href="#用网页的实时识别" class="headerlink" title="用网页的实时识别"></a>用网页的实时识别</h3><p>上面的docker容器中运行 <code>bash /home/run.sh</code></p>
<p>&#x2F;home&#x2F;run.sh内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/home/wenet/lib</span><br><span class="line"><span class="built_in">export</span> GLOG_logtostderr=1</span><br><span class="line"><span class="built_in">export</span> GLOG_v=2</span><br><span class="line"></span><br><span class="line">model=/home/wenet/model</span><br><span class="line">/home/wenet/websocket_server_main   --port 10086   --chunk_size 16   --model_path <span class="variable">$model</span>/final.zip   --dict_path <span class="variable">$model</span>/words.txt 2&gt;&amp;1 | <span class="built_in">tee</span> server.log</span><br></pre></td></tr></table></figure>



<p>然后下载github的wenet整个项目到windows本地，使用浏览器打开文件<code>runtime/server/x86/web/templates/index.html</code>，在 <code>WebSocket URL：</code>填入 服务器的地址，端口号，比如<code>ws://10.22.23.14:10086</code></p>
<p>就可以了！</p>
<p>经我测试，识别非常慢，识别不准确。。？？</p>
<h2 id="在-Docker-环境中使用"><a href="#在-Docker-环境中使用" class="headerlink" title="在 Docker 环境中使用"></a>在 Docker 环境中使用</h2><p>如果遇到问题比如无法编译，我们提供了 docker 镜像用于直接执行示例。需要先安装好 docker，运行如下命令，进入 docker 容器环境。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -it mobvoiwenet/wenet:latest bash</span><br></pre></td></tr></table></figure>

<p>该镜像包含了编译过程中所依赖的所有第三方库、编译好的文件和预训练模型。</p>
<p>预训练模型在 <code>/home/model</code> 目录, 可执行程序在 <code>/home/wenet/runtime/server/x86/build</code> 目录。</p>
<p>有了这个镜像后，平时需要的话，可以新建容器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -it mobvoiwenet/wenet:latest bash</span><br></pre></td></tr></table></figure>



<p>如果修改了cc文件，要执行 <code>mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; cmake --build .</code>进行编译</p>
<h2 id="自行编译运行时程序"><a href="#自行编译运行时程序" class="headerlink" title="自行编译运行时程序"></a>自行编译运行时程序</h2><p>&#x3D;&#x3D;该方式不推荐，因为本地编译麻烦，cmake升级版本还和gcc版本有关&#x3D;&#x3D;</p>
<p>如果想使用非 docker 方式，需要自行编译。Wenet 支持 linux&#x2F;macos&#x2F;windows 三种平台上的编译。需要安装 cmake 3.14 或者更高版本。</p>
<p>运行如下命令，完成编译。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 当前目录为 wenet/runtime/server/x86</span></span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build &amp;&amp; cmake .. &amp;&amp; cmake --build .</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>或者使用命令编译以支持 gRPC。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir build &amp;&amp; cd build &amp;&amp; cmake -DGRPC=ON .. &amp;&amp; cmake --build .</span><br></pre></td></tr></table></figure>

<p>编译好的可执行程序在 <code>wenet/runtime/server/x86/build/</code> 下：</p>
<ul>
<li>decoder_main 本地文件识别工具</li>
<li>websocket_server_main 基于websocket协议的识别服务端</li>
<li>websocket_client_main 基于websocket协议的识别客户端</li>
</ul>
<p>下载预训练模型</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 当前目录为 wenet/runtime/server/x86</span><br><span class="line">wget https://wenet-1256283475.cos.ap-shanghai.myqcloud.com/models/aishell/20210601_u2%2B%2B_conformer_libtorch.tar.gz</span><br><span class="line">tar -xf 20210602_u2++_conformer_libtorch.tar.gz</span><br></pre></td></tr></table></figure>

<p>以上不推荐，因为本地编译麻烦，cmake升级版本还和gcc版本有关</p>
<hr>
<h2 id="本地wav文件识别"><a href="#本地wav文件识别" class="headerlink" title="本地wav文件识别"></a>本地wav文件识别</h2><p>本地文件识别，即程序每次运行时，给定一个语音文件或者一组语音文件列表，输出识别结果，然后结束程序。</p>
<p>下载好模型后，执行如下的命令进行本地wav文件识别，将 <code>wav_path</code> 设为你想测试的 wav 文件地址，将 <code>model_dir</code> 设为你的模型目录地址。</p>
<p>进入到镜像为mobvoiwenet&#x2F;wenet:latest的容器里</p>
<p>cd &#x2F;home&#x2F;wenet&#x2F;runtime&#x2F;server&#x2F;x86</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 当前目录为 wenet/runtime/server/x86</span></span><br><span class="line"><span class="comment"># 已经下载并解压20210602_unified_transformer_server.tar.gz到当前目录</span></span><br><span class="line"><span class="comment"># 准备好一个16k采样率，单通道，16bits的音频文件test.wav</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> GLOG_logtostderr=1</span><br><span class="line"><span class="built_in">export</span> GLOG_v=2</span><br><span class="line"><span class="comment"># 如果要显示多一点LOG，比如RTF信息，要设置为：</span></span><br><span class="line"><span class="built_in">export</span> GLOG_logtostderr=</span><br><span class="line"><span class="built_in">export</span> GLOG_v=</span><br><span class="line"></span><br><span class="line">wav_path=test.wav</span><br><span class="line">model_dir=./20210602_unified_transformer_server</span><br><span class="line">./build/decoder_main \</span><br><span class="line">    --chunk_size -1 \</span><br><span class="line">    --wav_path <span class="variable">$wav_path</span> \</span><br><span class="line">    --model_path <span class="variable">$model_dir</span>/final.zip \</span><br><span class="line">    --dict_path <span class="variable">$model_dir</span>/words.txt 2&gt;&amp;1 | <span class="built_in">tee</span> log.txt</span><br><span class="line">    </span><br><span class="line">./build/decoder_main --chunk_size -1 --wav_path <span class="variable">$wav_path</span> --model_path <span class="variable">$model_dir</span>/final.zip --dict_path <span class="variable">$model_dir</span>/words.txt 2&gt;&amp;1 | <span class="built_in">tee</span> log.txt</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">./build/decoder_main --chunk_size -1 --wav_scp ./wav_scp --model_path <span class="variable">$model_dir</span>/final.zip --dict_path <span class="variable">$model_dir</span>/words.txt</span><br></pre></td></tr></table></figure>

<p><code>decoder_main</code>工具支持两种wav文件模式：</p>
<ul>
<li>使用<code>--wav_path</code>指定单个文件，一次识别单个wav文件。</li>
<li>使用<code>--wav_scp</code>指定一个.scp格式的wav列表，一次识别多个wav文件。</li>
</ul>
<p>执行 <code>./build/decoder_main --help</code> 可以了解更多的参数意义。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d -v /home/data/yelong/newest_wenet/wenet/runtime/server/x86/docker/docker_resource:/home/data/yelong/newest_wenet/wenet/runtime/server/x86/docker_resource -it wenet bash</span><br><span class="line"></span><br><span class="line">docker  exec -it 276e2d438bf6 bash</span><br></pre></td></tr></table></figure>



<h2 id="测试不同解码方法的rtf"><a href="#测试不同解码方法的rtf" class="headerlink" title="测试不同解码方法的rtf"></a>测试不同解码方法的rtf</h2><p>测试集、模型在：10.22.24.3:&#x2F;home&#x2F;data&#x2F;to_yelong&#x2F;rtf-test</p>
<p>在空机器10.22.23.14，cpu，单线程测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grep Decoded exp/hua/xueyuan_0.0_1.0/split1/1.log | awk &#x27;&#123;print$6&#125;&#x27; | sed s&#x27;/ms//g&#x27; | awk &#x27;&#123;sum+=$1&#125; END &#123;print sum&#125;&#x27;</span><br><span class="line">grep Decoded exp/hua/xueyuan_0.0_1.0/split1/1.log | awk &#x27;&#123;print$9&#125;&#x27; | sed s&#x27;/ms.//g&#x27; | awk &#x27;&#123;sum+=$1&#125; END &#123;print sum&#125;&#x27;</span><br><span class="line"></span><br><span class="line">grep Decoded exp/140-models/xueyuan_0.0_1.0/split1/1.log | awk &#x27;&#123;print$6&#125;&#x27; | sed s&#x27;/ms//g&#x27; | awk &#x27;&#123;sum+=$1&#125; END &#123;print sum&#125;&#x27;</span><br><span class="line">grep Decoded exp/140-models/xueyuan_0.0_1.0/split1/1.log | awk &#x27;&#123;print$9&#125;&#x27; | sed s&#x27;/ms.//g&#x27; | awk &#x27;&#123;sum+=$1&#125; END &#123;print sum&#125;&#x27;</span><br><span class="line"></span><br><span class="line">grep Decoded exp/140-models/xueyuan_0.0_0.0/split1/1.log | awk &#x27;&#123;print$6&#125;&#x27; | sed s&#x27;/ms//g&#x27; | awk &#x27;&#123;sum+=$1&#125; END &#123;print sum&#125;&#x27;</span><br><span class="line">grep Decoded exp/140-models/xueyuan_0.0_0.0/split1/1.log | awk &#x27;&#123;print$9&#125;&#x27; | sed s&#x27;/ms.//g&#x27; | awk &#x27;&#123;sum+=$1&#125; END &#123;print sum&#125;&#x27;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>decoder_main 单线程测试，n-best&#x3D;10，无LM，解码方式CTC prefix beam search （+rescore）：</p>
<ul>
<li><p>37.pt（195M模型，大概50M参数）：rtf&#x3D;0.08475（有rescore）</p>
</li>
<li><p>4.pt（500M模型，140M参数）：rtf&#x3D;0.2759（有rescore）；rtf&#x3D;0.1377（无rescore）</p>
</li>
</ul>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>Wenet脚本 BPE</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/Wenet%E8%84%9A%E6%9C%AC%20BPE/</url>
    <content><![CDATA[<h1 id="Wenet脚本-BPE"><a href="#Wenet脚本-BPE" class="headerlink" title="Wenet脚本 BPE"></a>Wenet脚本 BPE</h1><ul>
<li>multi_cn构建dict：把英文词用▁连起，得到▁英文词串，▁英文词串过一遍（不带▁英文文本训练的）bpe.model得子词，去重得dict</li>
<li>librispeech构建dict：用不带▁的英文词串过一遍（不带▁英文文本训练的）bpe.model得子词，去重得dict</li>
</ul>
<p>二者的区别在于，一个bpe.model encode的对象是单词，一个是▁连起的单词串，然后再分开再encode，应该都可以？</p>
<p>先训练好一个bpe model，英文的，然后把这些词放进中文字典中，扩充字典（字典里的英文是bpe格式的词）</p>
<p>然后使用时，把正常英文encoder编码成bpe格式，然后训练；推理的时候bpe decoder解码成原来的英文单词；</p>
<p>中英混时，用的5000词的bpe model，但是对训练集编码，发现没有用到整个5000词，可能只用了500个子词，因此只把500个英文子词，联合着中文一起，添加到词典中，因此词典可能是6、7千字的样子（最后softmax输出的大小）</p>
<p>统计每个英文词出现的次数，估摸着够不够样本训练；</p>
<h3 id="统计："><a href="#统计：" class="headerlink" title="统计："></a>统计：</h3><h4 id="法一：统计英文单词的样本数【没采用，因为我们时bpe建模，没有用真正的英文单词，因此该统计无意义】"><a href="#法一：统计英文单词的样本数【没采用，因为我们时bpe建模，没有用真正的英文单词，因此该统计无意义】" class="headerlink" title="法一：统计英文单词的样本数【没采用，因为我们时bpe建模，没有用真正的英文单词，因此该统计无意义】"></a>法一：统计英文单词的样本数【没采用，因为我们时bpe建模，没有用真正的英文单词，因此该统计无意义】</h4><ol>
<li>一共有多少个词</li>
<li>每个词的数量</li>
<li>每个词在不在bpe_model中，若不在，则添加进bpe.model中；（至少bpe.model要能够表示它）</li>
</ol>
<h4 id="法二：统计英文子词的样本数【采用】"><a href="#法二：统计英文子词的样本数【采用】" class="headerlink" title="法二：统计英文子词的样本数【采用】"></a>法二：统计英文子词的样本数【采用】</h4><ol>
<li>确保每个词在bpe.model中；</li>
<li>看用了哪些子词，一共有多少个子词；</li>
<li>统计每个子词的样本数量；</li>
</ol>
<p>将有空格的词分成没空格的字（汉字），将英文转成bpe格式的词：</p>
<ul>
<li>text2token.py：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copyright 2017 Johns Hopkins University (Shinji Watanabe)</span></span><br><span class="line"><span class="comment"># Copyright 2021 JD AI Lab. All Rights Reserved. (authors: Lu Fan)</span></span><br><span class="line"><span class="comment"># Copyright 2021 Mobvoi Inc. All Rights Reserved. (Di Wu)</span></span><br><span class="line"><span class="comment">#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">is_python2 = sys.version_info[<span class="number">0</span>] == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exist_or_not</span>(<span class="params">i, match_pos</span>):</span><br><span class="line">    start_pos = <span class="literal">None</span></span><br><span class="line">    end_pos = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> match_pos:</span><br><span class="line">        <span class="keyword">if</span> pos[<span class="number">0</span>] &lt;= i &lt; pos[<span class="number">1</span>]:</span><br><span class="line">            start_pos = pos[<span class="number">0</span>]</span><br><span class="line">            end_pos = pos[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> start_pos, end_pos</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seg_char</span>(<span class="params">sent</span>):</span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fa5])&#x27;</span>)</span><br><span class="line">    chars = pattern.split(sent)</span><br><span class="line">    chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> chars</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_parser</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(</span><br><span class="line">        description=<span class="string">&#x27;convert raw text to tokenized text&#x27;</span>,</span><br><span class="line">        formatter_class=argparse.ArgumentDefaultsHelpFormatter)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nchar&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-n&#x27;</span>,</span><br><span class="line">                        default=<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of characters to split, i.e., \</span></span><br><span class="line"><span class="string">                        aabb -&gt; a a b b with -n 1 and aa bb with -n 2&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--skip-ncols&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-s&#x27;</span>,</span><br><span class="line">                        default=<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;skip first n columns&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--space&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;&lt;space&gt;&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;space symbol&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--bpe-model&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-m&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;conf/train_960_unigram5000.model&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;bpe model for english part&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--non-lang-syms&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-l&#x27;</span>,</span><br><span class="line">                        default=<span class="literal">None</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;list of non-linguistic symobles,&#x27;</span></span><br><span class="line">                        <span class="string">&#x27; e.g., &lt;NOISE&gt; etc.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;text&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&#x27;data_bpe/train/text&#x27;</span>,</span><br><span class="line">                        nargs=<span class="string">&#x27;?&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;input text&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--trans_type&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-t&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;cn_char_en_bpe&quot;</span>,</span><br><span class="line">                        choices=[<span class="string">&quot;char&quot;</span>, <span class="string">&quot;phn&quot;</span>, <span class="string">&quot;cn_char_en_bpe&quot;</span>],</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&quot;&quot;&quot;Transcript type. char/phn. e.g., for TIMIT</span></span><br><span class="line"><span class="string">                             FADG0_SI1279 -</span></span><br><span class="line"><span class="string">                             If trans_type is char, read from</span></span><br><span class="line"><span class="string">                             SI1279.WRD file -&gt; &quot;bricks are an alternative&quot;</span></span><br><span class="line"><span class="string">                             Else if trans_type is phn,</span></span><br><span class="line"><span class="string">                             read from SI1279.PHN file -&gt;</span></span><br><span class="line"><span class="string">                             &quot;sil b r ih sil k s aa r er n aa l</span></span><br><span class="line"><span class="string">                             sil t er n ih sil t ih v sil&quot; &quot;&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> parser</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = get_parser()</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    rs = []</span><br><span class="line">    <span class="keyword">if</span> args.non_lang_syms <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">with</span> codecs.<span class="built_in">open</span>(args.non_lang_syms, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            nls = [x.rstrip() <span class="keyword">for</span> x <span class="keyword">in</span> f.readlines()]</span><br><span class="line">            rs = [re.<span class="built_in">compile</span>(re.escape(x)) <span class="keyword">for</span> x <span class="keyword">in</span> nls]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.bpe_model <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line">        sp = spm.SentencePieceProcessor()</span><br><span class="line">        sp.load(args.bpe_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.text:</span><br><span class="line">        f = codecs.<span class="built_in">open</span>(args.text, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        f = codecs.getreader(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">            sys.stdin <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdin.buffer)</span><br><span class="line"></span><br><span class="line">    sys.stdout = codecs.getwriter(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">        sys.stdout <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdout.buffer)</span><br><span class="line">    line = f.readline()</span><br><span class="line">    n = args.nchar</span><br><span class="line">    <span class="keyword">while</span> line:</span><br><span class="line">        x = line.split()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>.join(x[:args.skip_ncols]), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">        a = <span class="string">&#x27; &#x27;</span>.join(x[args.skip_ncols:])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get all matched positions</span></span><br><span class="line">        match_pos = []</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> rs:</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &gt;= <span class="number">0</span>:</span><br><span class="line">                m = r.search(a, i)</span><br><span class="line">                <span class="keyword">if</span> m:</span><br><span class="line">                    match_pos.append([m.start(), m.end()])</span><br><span class="line">                    i = m.end()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(match_pos) &gt; <span class="number">0</span>:</span><br><span class="line">            chars = []</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(a):</span><br><span class="line">                start_pos, end_pos = exist_or_not(i, match_pos)</span><br><span class="line">                <span class="keyword">if</span> start_pos <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    chars.append(a[start_pos:end_pos])</span><br><span class="line">                    i = end_pos</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    chars.append(a[i])</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            a = chars</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (args.trans_type == <span class="string">&quot;phn&quot;</span>):</span><br><span class="line">            a = a.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">        <span class="keyword">elif</span> args.trans_type == <span class="string">&quot;cn_char_en_bpe&quot;</span>:</span><br><span class="line">            b = seg_char(a)</span><br><span class="line">            a = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> b:</span><br><span class="line">                <span class="comment"># we use &quot;▁&quot; to instead of blanks among english words</span></span><br><span class="line">                <span class="comment"># warning: here is &quot;▁&quot;, not &quot;_&quot;</span></span><br><span class="line">                <span class="keyword">for</span> l <span class="keyword">in</span> j.strip().split(<span class="string">&quot;▁&quot;</span>):</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> l.encode(<span class="string">&#x27;UTF-8&#x27;</span>).isalpha(): <span class="comment">#是不是英文字母</span></span><br><span class="line">                        a.append(l)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">for</span> k <span class="keyword">in</span> sp.encode_as_pieces(l):</span><br><span class="line">                            <span class="keyword">if</span> k == <span class="string">&quot;▁&quot;</span>:</span><br><span class="line">                                <span class="built_in">print</span>(<span class="string">&quot;yelong&quot;</span>,end=<span class="string">&#x27; &#x27;</span>) <span class="comment"># 如果不在bpe.model里，这里报错来的</span></span><br><span class="line">                            a.append(k)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            a = [a[j:j + n] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a), n)]</span><br><span class="line"></span><br><span class="line">        a_flat = []</span><br><span class="line">        <span class="keyword">for</span> z <span class="keyword">in</span> a:</span><br><span class="line">            a_flat.append(<span class="string">&quot;&quot;</span>.join(z))</span><br><span class="line"></span><br><span class="line">        a_chars = [z.replace(<span class="string">&#x27; &#x27;</span>, args.space) <span class="keyword">for</span> z <span class="keyword">in</span> a_flat]</span><br><span class="line">        <span class="keyword">if</span> (args.trans_type == <span class="string">&quot;phn&quot;</span>):</span><br><span class="line">            a_chars = [z.replace(<span class="string">&quot;sil&quot;</span>, args.space) <span class="keyword">for</span> z <span class="keyword">in</span> a_chars]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>.join(a_chars))</span><br><span class="line">        line = f.readline()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>发现很多单词不在bpe中【用原来的bpe.model后，词典的英文词有 4719 个词】，因此要做<strong>清洗</strong>，具体操作：</p>
<h3 id="清洗"><a href="#清洗" class="headerlink" title="清洗"></a>清洗</h3><h4 id="重新训练bpe-model"><a href="#重新训练bpe-model" class="headerlink" title="重新训练bpe.model"></a>重新训练bpe.model</h4><ol start="0">
<li><p>删除text的标点符号</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i &#x27;s/MOTHER`/MOTHER&#x27;\&#x27;&#x27;/g&#x27; text.org</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">等等 将，。、！：替换成空格</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>只挑选训练集中英文部分；[英文中间夹着中文，去掉中文后，其实并没有语序关系，这里就不管这种情况了]： </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cut -d &#x27; &#x27; -f 2- text | grep &quot;[a-zA-Z]&quot; &gt; text_chi_eng</span><br></pre></td></tr></table></figure>


</li>
<li><p>将英文文本token化，变成带有▁符号</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat text_chi_eng | tr &#x27;a-z&#x27; &#x27;A-Z&#x27; | sed &#x27;s/\([A-Z]\) \([A-Z]\)/\1▁\2/g&#x27; | sed &#x27;s/\([A-Z]\) \([A-Z]\)/\1▁\2/g&#x27; | tr -d &quot; &quot; &gt;  text_token_chi_eng</span><br></pre></td></tr></table></figure>



<p>自己写了一个去掉中文的脚本：delete_chi.py【旧】，这里的输入是带有“▁”的英文，因为后面查看有没有英文unk时，是用的带▁的英文文本，因此这里先处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># python delete_chi.py &gt; text_token_eng</span></span><br><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copyright 2017 Johns Hopkins University (Shinji Watanabe)</span></span><br><span class="line"><span class="comment"># Copyright 2021 JD AI Lab. All Rights Reserved. (authors: Lu Fan)</span></span><br><span class="line"><span class="comment"># Copyright 2021 Mobvoi Inc. All Rights Reserved. (Di Wu)</span></span><br><span class="line"><span class="comment">#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">is_python2 = sys.version_info[<span class="number">0</span>] == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exist_or_not</span>(<span class="params">i, match_pos</span>):</span><br><span class="line">    start_pos = <span class="literal">None</span></span><br><span class="line">    end_pos = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> match_pos:</span><br><span class="line">        <span class="keyword">if</span> pos[<span class="number">0</span>] &lt;= i &lt; pos[<span class="number">1</span>]:</span><br><span class="line">            start_pos = pos[<span class="number">0</span>]</span><br><span class="line">            end_pos = pos[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> start_pos, end_pos</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seg_char</span>(<span class="params">sent</span>):</span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fa5])&#x27;</span>)</span><br><span class="line">    chars = pattern.split(sent)</span><br><span class="line">    chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> chars</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_parser</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(</span><br><span class="line">        description=<span class="string">&#x27;convert raw text to tokenized text&#x27;</span>,</span><br><span class="line">        formatter_class=argparse.ArgumentDefaultsHelpFormatter)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nchar&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-n&#x27;</span>,</span><br><span class="line">                        default=<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of characters to split, i.e., \</span></span><br><span class="line"><span class="string">                        aabb -&gt; a a b b with -n 1 and aa bb with -n 2&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--skip-ncols&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-s&#x27;</span>,</span><br><span class="line">                        default=<span class="number">0</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;skip first n columns&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--space&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;&lt;space&gt;&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;space symbol&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--bpe-model&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-m&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;data/lang_char/train_unigram5000.model&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;bpe model for english part&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--non-lang-syms&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-l&#x27;</span>,</span><br><span class="line">                        default=<span class="literal">None</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;list of non-linguistic symobles,&#x27;</span></span><br><span class="line">                        <span class="string">&#x27; e.g., &lt;NOISE&gt; etc.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;text&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&#x27;/home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/train/text_token_chi_eng&#x27;</span>,</span><br><span class="line">                        <span class="comment"># default=&#x27;/home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/test_1.4w/text_token_chi_eng&#x27;,</span></span><br><span class="line">                        <span class="comment"># default=&#x27;/home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/lang_char/2&#x27;,</span></span><br><span class="line">                        nargs=<span class="string">&#x27;?&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;input text&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--trans_type&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-t&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;cn_char_en_bpe&quot;</span>,</span><br><span class="line">                        choices=[<span class="string">&quot;char&quot;</span>, <span class="string">&quot;phn&quot;</span>, <span class="string">&quot;cn_char_en_bpe&quot;</span>],</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&quot;&quot;&quot;Transcript type. char/phn. e.g., for TIMIT</span></span><br><span class="line"><span class="string">                             FADG0_SI1279 -</span></span><br><span class="line"><span class="string">                             If trans_type is char, read from</span></span><br><span class="line"><span class="string">                             SI1279.WRD file -&gt; &quot;bricks are an alternative&quot;</span></span><br><span class="line"><span class="string">                             Else if trans_type is phn,</span></span><br><span class="line"><span class="string">                             read from SI1279.PHN file -&gt;</span></span><br><span class="line"><span class="string">                             &quot;sil b r ih sil k s aa r er n aa l</span></span><br><span class="line"><span class="string">                             sil t er n ih sil t ih v sil&quot; &quot;&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> parser</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = get_parser()</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    rs = []</span><br><span class="line">    <span class="keyword">if</span> args.non_lang_syms <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">with</span> codecs.<span class="built_in">open</span>(args.non_lang_syms, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            nls = [x.rstrip() <span class="keyword">for</span> x <span class="keyword">in</span> f.readlines()]</span><br><span class="line">            rs = [re.<span class="built_in">compile</span>(re.escape(x)) <span class="keyword">for</span> x <span class="keyword">in</span> nls]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.bpe_model <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line">        sp = spm.SentencePieceProcessor()</span><br><span class="line">        sp.load(args.bpe_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.text:</span><br><span class="line">        f = codecs.<span class="built_in">open</span>(args.text, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        f = codecs.getreader(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">            sys.stdin <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdin.buffer)</span><br><span class="line"></span><br><span class="line">    sys.stdout = codecs.getwriter(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">        sys.stdout <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdout.buffer)</span><br><span class="line">    line = f.readline()</span><br><span class="line">    n = args.nchar</span><br><span class="line">    <span class="keyword">while</span> line:</span><br><span class="line">        x = line.split()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>.join(x[:args.skip_ncols]), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">        a = <span class="string">&#x27; &#x27;</span>.join(x[args.skip_ncols:])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get all matched positions</span></span><br><span class="line">        match_pos = []</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> rs:</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &gt;= <span class="number">0</span>:</span><br><span class="line">                m = r.search(a, i)</span><br><span class="line">                <span class="keyword">if</span> m:</span><br><span class="line">                    match_pos.append([m.start(), m.end()])</span><br><span class="line">                    i = m.end()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(match_pos) &gt; <span class="number">0</span>:</span><br><span class="line">            chars = []</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(a):</span><br><span class="line">                start_pos, end_pos = exist_or_not(i, match_pos)</span><br><span class="line">                <span class="keyword">if</span> start_pos <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    chars.append(a[start_pos:end_pos])</span><br><span class="line">                    i = end_pos</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    chars.append(a[i])</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            a = chars</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (args.trans_type == <span class="string">&quot;phn&quot;</span>):</span><br><span class="line">            a = a.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">        <span class="keyword">elif</span> args.trans_type == <span class="string">&quot;cn_char_en_bpe&quot;</span>:</span><br><span class="line">            b = seg_char(a)</span><br><span class="line">            a = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> b:</span><br><span class="line">                <span class="comment"># we use &quot;▁&quot; to instead of blanks among english words</span></span><br><span class="line">                <span class="comment"># warning: here is &quot;▁&quot;, not &quot;_&quot;</span></span><br><span class="line">                <span class="comment"># for l in j.strip().split(&quot; &quot;):</span></span><br><span class="line">                <span class="comment"># count = len(j.strip().split(&quot;▁&quot;)) -1 </span></span><br><span class="line">                <span class="keyword">for</span> l <span class="keyword">in</span> j.strip().split(<span class="string">&#x27;▁&#x27;</span>):</span><br><span class="line">                    <span class="keyword">if</span> l.encode(<span class="string">&#x27;UTF-8&#x27;</span>).isalpha(): <span class="comment">#是不是英文字母 #T-shirt这种就会没有掉  TODO MACY&#x27;S</span></span><br><span class="line">                        a.append(l)</span><br><span class="line">                        a.append(<span class="string">&#x27;▁&#x27;</span>)</span><br><span class="line">                        <span class="comment"># if count:</span></span><br><span class="line">                        <span class="comment">#     a.append(&#x27;▁&#x27;)</span></span><br><span class="line">                        <span class="comment">#     count = count - 1</span></span><br><span class="line"></span><br><span class="line">                        </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            a = [a[j:j + n] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a), n)]</span><br><span class="line"></span><br><span class="line">        a_flat = []</span><br><span class="line">        <span class="keyword">for</span> z <span class="keyword">in</span> a:</span><br><span class="line">            a_flat.append(<span class="string">&quot;&quot;</span>.join(z))</span><br><span class="line"></span><br><span class="line">        a_chars = [z.replace(<span class="string">&#x27; &#x27;</span>, args.space) <span class="keyword">for</span> z <span class="keyword">in</span> a_flat]</span><br><span class="line">        <span class="keyword">if</span> (args.trans_type == <span class="string">&quot;phn&quot;</span>):</span><br><span class="line">            a_chars = [z.replace(<span class="string">&quot;sil&quot;</span>, args.space) <span class="keyword">for</span> z <span class="keyword">in</span> a_chars]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(a_chars) &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> a_chars[-<span class="number">1</span>] == <span class="string">&#x27;▁&#x27;</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(a_chars[:-<span class="number">1</span>]))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(a_chars))</span><br><span class="line">        line = f.readline()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>上面的delete_chi.py比较慢，新删除一些行，新写了delete_chi.py：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copyright 2017 Johns Hopkins University (Shinji Watanabe)</span></span><br><span class="line"><span class="comment"># Copyright 2021 JD AI Lab. All Rights Reserved. (authors: Lu Fan)</span></span><br><span class="line"><span class="comment"># Copyright 2021 Mobvoi Inc. All Rights Reserved. (Di Wu)</span></span><br><span class="line"><span class="comment">#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">is_python2 = sys.version_info[<span class="number">0</span>] == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exist_or_not</span>(<span class="params">i, match_pos</span>):</span><br><span class="line">    start_pos = <span class="literal">None</span></span><br><span class="line">    end_pos = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> pos <span class="keyword">in</span> match_pos:</span><br><span class="line">        <span class="keyword">if</span> pos[<span class="number">0</span>] &lt;= i &lt; pos[<span class="number">1</span>]:</span><br><span class="line">            start_pos = pos[<span class="number">0</span>]</span><br><span class="line">            end_pos = pos[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> start_pos, end_pos</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seg_char</span>(<span class="params">sent</span>):</span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fa5])&#x27;</span>)</span><br><span class="line">    chars = pattern.split(sent)</span><br><span class="line">    chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> chars</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_parser</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(</span><br><span class="line">        description=<span class="string">&#x27;convert raw text to tokenized text&#x27;</span>,</span><br><span class="line">        formatter_class=argparse.ArgumentDefaultsHelpFormatter)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nchar&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-n&#x27;</span>,</span><br><span class="line">                        default=<span class="number">1</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of characters to split, i.e., \</span></span><br><span class="line"><span class="string">                        aabb -&gt; a a b b with -n 1 and aa bb with -n 2&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--skip-ncols&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-s&#x27;</span>,</span><br><span class="line">                        default=<span class="number">0</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;skip first n columns&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--space&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;&lt;space&gt;&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;space symbol&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--bpe-model&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-m&#x27;</span>,</span><br><span class="line">                        default=<span class="string">&#x27;data/lang_char/train_unigram5000.model&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;bpe model for english part&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--non-lang-syms&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-l&#x27;</span>,</span><br><span class="line">                        default=<span class="literal">None</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;list of non-linguistic symobles,&#x27;</span></span><br><span class="line">                        <span class="string">&#x27; e.g., &lt;NOISE&gt; etc.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;text&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&#x27;/home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/test/text_token_chi_eng&#x27;</span>,</span><br><span class="line">                        <span class="comment"># default=&#x27;/home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/test_1.4w/text_token_chi_eng&#x27;,</span></span><br><span class="line">                        <span class="comment"># default=&#x27;/home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/lang_char/2&#x27;,</span></span><br><span class="line">                        nargs=<span class="string">&#x27;?&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;input text&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--trans_type&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;-t&#x27;</span>,</span><br><span class="line">                        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&quot;cn_char_en_bpe&quot;</span>,</span><br><span class="line">                        choices=[<span class="string">&quot;char&quot;</span>, <span class="string">&quot;phn&quot;</span>, <span class="string">&quot;cn_char_en_bpe&quot;</span>],</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&quot;&quot;&quot;Transcript type. char/phn. e.g., for TIMIT</span></span><br><span class="line"><span class="string">                             FADG0_SI1279 -</span></span><br><span class="line"><span class="string">                             If trans_type is char, read from</span></span><br><span class="line"><span class="string">                             SI1279.WRD file -&gt; &quot;bricks are an alternative&quot;</span></span><br><span class="line"><span class="string">                             Else if trans_type is phn,</span></span><br><span class="line"><span class="string">                             read from SI1279.PHN file -&gt;</span></span><br><span class="line"><span class="string">                             &quot;sil b r ih sil k s aa r er n aa l</span></span><br><span class="line"><span class="string">                             sil t er n ih sil t ih v sil&quot; &quot;&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> parser</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = get_parser()</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    rs = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.bpe_model <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line">        sp = spm.SentencePieceProcessor()</span><br><span class="line">        sp.load(args.bpe_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.text:</span><br><span class="line">        f = codecs.<span class="built_in">open</span>(args.text, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        f = codecs.getreader(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">            sys.stdin <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdin.buffer)</span><br><span class="line"></span><br><span class="line">    sys.stdout = codecs.getwriter(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">        sys.stdout <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdout.buffer)</span><br><span class="line">    line = f.readline()</span><br><span class="line">    n = args.nchar</span><br><span class="line">    <span class="keyword">while</span> line:</span><br><span class="line">        <span class="comment"># x = line.split()</span></span><br><span class="line">        <span class="comment"># print(&#x27; &#x27;.join(x[:args.skip_ncols]), end=&quot; &quot;)</span></span><br><span class="line">        <span class="comment"># a = &#x27; &#x27;.join(x[args.skip_ncols:])</span></span><br><span class="line">        a = line.strip()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get all matched positions</span></span><br><span class="line">        b = seg_char(a)</span><br><span class="line">        a = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> b:</span><br><span class="line">            <span class="comment"># we use &quot;▁&quot; to instead of blanks among english words</span></span><br><span class="line">            <span class="comment"># warning: here is &quot;▁&quot;, not &quot;_&quot;</span></span><br><span class="line">            <span class="comment"># for l in j.strip().split(&quot; &quot;):</span></span><br><span class="line">            <span class="comment"># count = len(j.strip().split(&quot;▁&quot;)) -1 </span></span><br><span class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> j.strip().split(<span class="string">&#x27;▁&#x27;</span>):</span><br><span class="line">                <span class="keyword">if</span> l.encode(<span class="string">&#x27;UTF-8&#x27;</span>).isalpha() <span class="keyword">or</span> <span class="string">&quot;&#x27;&quot;</span> <span class="keyword">in</span> l: <span class="comment">#是不是英文字母 #T-shirt这种就会没有掉  TODO MACY&#x27;S</span></span><br><span class="line">                    a.append(l)</span><br><span class="line">                    a.append(<span class="string">&#x27;▁&#x27;</span>)</span><br><span class="line">                    <span class="comment"># if count:</span></span><br><span class="line">                    <span class="comment">#     a.append(&#x27;▁&#x27;)</span></span><br><span class="line">                    <span class="comment">#     count = count - 1</span></span><br><span class="line"></span><br><span class="line">        a_flat = []</span><br><span class="line">        <span class="keyword">for</span> z <span class="keyword">in</span> a:</span><br><span class="line">            a_flat.append(<span class="string">&quot;&quot;</span>.join(z))</span><br><span class="line"></span><br><span class="line">        a_chars = [z.replace(<span class="string">&#x27; &#x27;</span>, args.space) <span class="keyword">for</span> z <span class="keyword">in</span> a_flat]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(a_chars) &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> a_chars[-<span class="number">1</span>] == <span class="string">&#x27;▁&#x27;</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(a_chars[:-<span class="number">1</span>]))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(a_chars))</span><br><span class="line">        line = f.readline()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>







<p>对text_token_eng过一遍英文的token_fast_eng.py，看看有没有<unk>或 ▁ ，注意，这里的text_token_eng不是data_4000_add_we_bpe&#x2F;train里的text_token_eng；</unk></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i &#x27;s/ *$//&#x27; text_token_eng</span><br><span class="line">sed -i &#x27;s/^ *//&#x27; text_token_eng</span><br><span class="line">python token_fast_eng.py &gt; i</span><br><span class="line">grep &quot;&lt;unk&gt;&quot; i</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">grep <span class="string">&quot;▁ &quot;</span> i</span></span><br></pre></td></tr></table></figure>



<p>其中，token_fast_eng.py：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">is_python2 = sys.version_info[<span class="number">0</span>] == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__tokenize_by_bpe_model</span>(<span class="params">sp, txt</span>):</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="comment"># CJK(China Japan Korea) unicode range is [U+4E00, U+9FFF], ref:</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fff])&#x27;</span>)</span><br><span class="line">    <span class="comment"># Example:</span></span><br><span class="line">    <span class="comment">#   txt   = &quot;你好 ITS&#x27;S OKAY 的&quot;</span></span><br><span class="line">    <span class="comment">#   chars = [&quot;你&quot;, &quot;好&quot;, &quot; ITS&#x27;S OKAY &quot;, &quot;的&quot;]</span></span><br><span class="line">    chars = pattern.split(txt.upper())</span><br><span class="line">    mix_chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ch_or_w <span class="keyword">in</span> mix_chars:</span><br><span class="line">        <span class="comment"># ch_or_w is a single CJK charater(i.e., &quot;你&quot;), do nothing.</span></span><br><span class="line">        <span class="keyword">if</span> pattern.fullmatch(ch_or_w) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            tokens.append(ch_or_w)</span><br><span class="line">        <span class="comment"># ch_or_w contains non-CJK charaters(i.e., &quot; IT&#x27;S OKAY &quot;),</span></span><br><span class="line">        <span class="comment"># encode ch_or_w using bpe_model.</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> sp.encode_as_pieces(ch_or_w):</span><br><span class="line">                tokens.append(p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">sample,sp,</span></span><br><span class="line"><span class="params">             symbol_table</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Decode text to chars or BPE</span></span><br><span class="line"><span class="string">        Inplace operation</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data: Iterable[&#123;key, wav, txt, sample_rate&#125;]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Iterable[&#123;key, wav, txt, tokens, label, sample_rate&#125;]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    txt = sample[<span class="string">&#x27;txt&#x27;</span>].strip()</span><br><span class="line">    parts = [txt]</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="keyword">for</span> part <span class="keyword">in</span> parts:</span><br><span class="line">        tokens.extend(__tokenize_by_bpe_model(sp, part))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tokens)):</span><br><span class="line">        ch = tokens[i]</span><br><span class="line">        <span class="keyword">if</span> ch <span class="keyword">not</span> <span class="keyword">in</span> symbol_table:</span><br><span class="line">            tokens[i]  = <span class="string">&#x27;&lt;unk&gt;&#x27;</span></span><br><span class="line">        <span class="comment"># elif &#x27;&lt;unk&gt;&#x27; in symbol_table:</span></span><br><span class="line">            <span class="comment"># label.append(symbol_table[&#x27;&lt;unk&gt;&#x27;])</span></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">    sample[<span class="string">&#x27;tokens&#x27;</span>] = tokens</span><br><span class="line">    <span class="comment"># sample[&#x27;label&#x27;] = label</span></span><br><span class="line">    <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_symbol_table</span>(<span class="params">symbol_table_file</span>):</span><br><span class="line">    symbol_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(symbol_table_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> fin:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">            arr = line.strip().split()</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(arr) == <span class="number">2</span></span><br><span class="line">            symbol_table[arr[<span class="number">0</span>]] = <span class="built_in">int</span>(arr[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> symbol_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line">    sp = spm.SentencePieceProcessor()</span><br><span class="line">    sp.load(<span class="string">&#x27;data_4000_add_we/lang_char/train_unigram100.model&#x27;</span>)</span><br><span class="line">    <span class="comment"># sp.load(&#x27;data_4000_add_we/lang_char/train_unigram500.model&#x27;)</span></span><br><span class="line">    <span class="comment"># sp.load(&#x27;data_4000_add_we/lang_char/train_unigram1000.model&#x27;)</span></span><br><span class="line">    symbol_table = read_symbol_table(<span class="string">&#x27;data_4000_add_we/dict_bpe/lang_char.txt.bpe_100_eng600_chi4700_all5300&#x27;</span>)</span><br><span class="line">    <span class="comment"># symbol_table = read_symbol_table(&#x27;data_4000_add_we/dict_bpe/lang_char.txt.bpe_500_eng1000_chi4700_all5700&#x27;)</span></span><br><span class="line">    <span class="comment"># symbol_table = read_symbol_table(&#x27;data_4000_add_we/dict_bpe/lang_char.txt.bpe_1000_eng1400_chi4700_all6000&#x27;)</span></span><br><span class="line">    f = codecs.<span class="built_in">open</span>(<span class="string">&#x27;data_4000_add_we/test/text_token_eng1&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="comment"># f = codecs.open(&#x27;data_4000_add_we/train/text_token_eng&#x27;, encoding=&quot;utf-8&quot;)</span></span><br><span class="line">    <span class="comment"># f = codecs.open(&#x27;data_4000_add_we/test_1.4w/text_token_eng&#x27;, encoding=&quot;utf-8&quot;)</span></span><br><span class="line">    sys.stdout = codecs.getwriter(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">            sys.stdout <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdout.buffer)</span><br><span class="line">    line = f.readline()</span><br><span class="line">    <span class="keyword">while</span> line:</span><br><span class="line">        <span class="comment"># if len(line.strip().split()) &gt; 1:</span></span><br><span class="line">        data=&#123;&#125;</span><br><span class="line">        <span class="comment"># data[&#x27;key&#x27;]=line.strip().split()[0]</span></span><br><span class="line">        data[<span class="string">&#x27;txt&#x27;</span>]=<span class="string">&#x27;&#x27;</span>.join(line.strip().split())</span><br><span class="line">        sample = tokenize(data,sp,</span><br><span class="line">                symbol_table)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(sample[<span class="string">&#x27;tokens&#x27;</span>]))</span><br><span class="line">        <span class="comment"># print(&#x27; &#x27;.join(sample[&#x27;tokens&#x27;]))</span></span><br><span class="line">        <span class="comment"># print(sample[&#x27;key&#x27;], sample[&#x27;tokens&#x27;])</span></span><br><span class="line">        line = f.readline()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>







<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cut -d &#x27; &#x27; -f 2- data/train/text | grep &quot;[a-zA-Z]&quot;  &gt; input.txt</span><br><span class="line">/home/yelong/data/wenet/examples/multi_cn/s0/delete_chi.py input.txt &gt; text_for_bpe_model</span><br><span class="line">sed -i &#x27;s/SIL//g&#x27; text_for_bpe_model	# 不要SIL符号（bpe模型训练里不需要）</span><br><span class="line">sed -i &#x27;/^\s*$/d&#x27; text_for_bpe_model	#删除空行</span><br><span class="line">sed -i &#x27;s/ \+/ /g&#x27; text_for_bpe_model 	# 删除连续空格</span><br><span class="line">sed -i &#x27;s/ *$//&#x27; text_for_bpe_model		# 删除行尾空格</span><br><span class="line">sed -i &#x27;s/^ *//&#x27; text_for_bpe_model		# 删除行首空格</span><br><span class="line">sed -i &#x27;/^\s*$/d&#x27; text_for_bpe_model	#删除空行</span><br></pre></td></tr></table></figure>
</li>
<li><p>训练集中把SIL换成blank；不参与bpe.model的训练；（先暂时删掉）</p>
</li>
<li><p>看看有多少个词：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat text_for_bpe_model | tr &#x27;\t&#x27; &#x27; &#x27; | awk &#x27;&#123;if(NF&gt;1)print$0&#125;&#x27; | cut -d &#x27; &#x27; -f 2- | tr &#x27; &#x27; &#x27;\n&#x27;  | sort -u | wc -l</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">24062 (2万个词)</span></span><br></pre></td></tr></table></figure>

<p>其实这里可以简单统计一下词频，（带英文的文本共204万条（2041819）），但是没啥意义，因为最后也没用词频来放进词典；</p>
</li>
<li><p>把一些词拆开，像合在一起的QQ啊，这种，这种词来源于train_960_unigram5000.model里不存在的词（上面text2token输出yelong）【未做】</p>
</li>
</ol>
<p><code>sed -i &#39;s/▁/ /g&#39; qq </code></p>
<ol start="5">
<li>新训练bpe.model</li>
</ol>
<h3 id="生成dict"><a href="#生成dict" class="headerlink" title="生成dict"></a>生成dict</h3><p>数据集用的101、100（4000h）</p>
<ol>
<li><p>用新训练的bpe.model过一遍训练集，得到训练集对应的子词格式，注意，这里的训练集，英文单词时间用▁连接；text2token.py；</p>
</li>
<li><ol>
<li>去重得到dict，注意，用新的bpe.model（5000子词）发现最后字典里，英文有5300个字，这比用不匹配的librispeech训练（4700个）出来的还要多；</li>
<li>去重得到dict，用新的bpe.model（1000子词）发现最后字典里，英文有1300个字；</li>
<li>去重得到dict，用新的bpe.model（100子词）发现最后字典里，英文有500个字；</li>
</ol>
</li>
</ol>
<h3 id="添加wenetspeech文本数据（也有中英混合）"><a href="#添加wenetspeech文本数据（也有中英混合）" class="headerlink" title="添加wenetspeech文本数据（也有中英混合）"></a>添加wenetspeech文本数据（也有中英混合）</h3><p>上述都用的雷博的4000小时中英混合数据的文本，现添加wenetspeech文本数据；</p>
<p>bpe.model（1000个子词），字典里有1480 个字；</p>
<h3 id="统计每个子词的样本数"><a href="#统计每个子词的样本数" class="headerlink" title="统计每个子词的样本数"></a>统计每个子词的样本数</h3><p>这里text_token是变成子词模式的文本（这里只认为一个词在一条文本只出现一次）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tools/text2token.py -s 0 -n 1 -m $&#123;bpecode&#125; \</span><br><span class="line">    data_4000_add_we_$&#123;en_modeling_unit&#125;/$&#123;train_set&#125;/text_chi_eng $&#123;trans_type_ops&#125;  &gt; data_4000_add_we_bpe/train/text_token</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">法一：</span></span><br><span class="line">awk &#x27;&#123;print&quot;grep -w \&quot;&quot;$1&quot;\&quot; text_token | wc -l &quot;&#125;&#x27; ../../data_4000_add_we/dict_bpe/lang_char.txt &gt; 1</span><br><span class="line">. ./1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">后来觉得 这样遍历的次数是 文本集行数*查询词数，很慢，全摆在一块儿，再遍历文本，会快一点；</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">法二：[后来发现这样不行]</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> <span class="built_in">cut</span> -d <span class="string">&#x27; &#x27;</span> -f 1 ../../data_4000_add_we/dict_bpe/lang_char.txt | <span class="built_in">tr</span> <span class="string">&#x27;\n&#x27;</span> <span class="string">&#x27;|&#x27;</span> | awk <span class="string">&#x27;&#123;print&quot;grep -E \&quot;&quot;$1&quot;\&quot; text_token &quot;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure>

<p>bpe.model（1000子词）字典里，</p>
<ul>
<li>英文有1480 个字：</li>
</ul>
<p>字典中，词频小于500的有468个词，这种感觉样本数太少，就应该训练不好，应该把这些样本扩充或者把这些词看怎么分解一下</p>
<p>在500-2000个词，样本数尚可，该类型在字典中有476，不清楚该样本数能否训练好建模单元；</p>
<p>在大于2000个词，样本数认为足够建模型，该类型在字典中有533；</p>
<p>后两者占70%左右；前者占30%，说明词频小于500的也是非常多了，多达英文的30%；</p>
<ul>
<li>中文有7200个字：</li>
</ul>
<p>字典中，词频小于500的有3363个词，这种感觉样本数太少，就应该训练不好，应该把这些样本扩充或者把这些词删掉，因为现在中文字典字数偏多，保持在5000个左右会比较合适，而且很多生僻字可以去掉；</p>
<p>在500-2000个词，样本数尚可，该类型在字典中有987，不清楚该样本数能否训练好建模单元；</p>
<p>在大于2000个词，样本数认为足够建模型，该类型在字典中有2859；</p>
<p>后两者占54%左右；前者占46%，说明词频小于500的也是非常多了，多达中文的46%！！</p>
<p>（平均训练集总字数为2.7亿，7200个字，平均每个字分到3.7w次）</p>
<ul>
<li>超过100万次的字：44个</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一 上 下 不 个 为 么 也 了 人 什 他 以 们 会 你 到 去 可 后 吗 啊 在 大 天 好 子 就 得 我 时 是 有 来 没 的 看 能 要 说 还 这 那 都</span><br></pre></td></tr></table></figure>

<ul>
<li>小于100次的字：2512个（若除去，则中文字典剩下4700个字）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">○ 㖏 丌 丟 両 丨 丶 乂 乗 乜 乩 亊 亍 亓 亶 亹 仂 仝 仞 仟 仡 仮 仵 伃 伉 伋 伛 伝 伥 伧 伱 伲 伷 佉 佚 佢 佥 佧 佶 佺 佻 佾 侂 來 侉 侑 侔 侩 侪 俅 俎 俚 俛 俜 俟 俣 俤 俦 俳 俵 俶 俾 倅 個 倌 們 倢 倥 倧 倨 倬 倮 偁 偈 偓 偪 偲 偾 傈 傧 傩 傺 僆 僕 僖 僢 僬 僭 僮 僳 僶 儋 儍 兒 兕 內 円 冇 冏 冔 冨 冫 凃 凇 凕 凖 凪 凫 凼 刈 刖 別 刭 刳 刼 刿 剀 剋 剌 剛 剜 剞 剡 剣 劂 劢 劬 劭 効 劻 劼 勍 勐 動 勖 勣 勧 勰 勷 匄 匏 匦 匼 卅 単 卟 卣 卬 卮 卲 卺 卻 厍 厓 厔 厖 厙 厝 厣 厩 厶 叁 叄 叆 収 叻 吋 吔 吡 吲 吶 吿 呋 呎 呒 呓 呔 呖 呙 呣 呤 咁 咘 咝 咲 咴 咵 咾 哂 哌 哓 哕 哚 哜 哞 唑 唗 唛 唪 唳 唷 唻 唿 啁 啉 啐 啖 啫 啭 啮 啲 啶 啻 喁 喈 喑 喒 喙 喟 喭 喯 喰 営 喹 喾 嗄 嗉 嗌 嗍 嗎 嗐 嗙 嗞 嗥 嗪 嗬 嗮 嗳 嗵 嗾 嘁 嘅 嘌 嘏 嘢 嘤 嘧 嘬 嘭 噃 噏 噘 噙 噤 噫 嚅 嚆 嚒 嚟 嚭 嚯 嚲 囍 囗 囝 囟 団 囫 図 囵 囹 囿 圄 圉 圜 圧 圪 圬 圮 圯 圴 圹 圻 坌 坒 坜 坩 坫 坭 坶 坻 坼 垆 垉 垌 垍 垓 垕 垚 垟 垡 垤 垧 垩 垭 垱 垲 垴 垸 垿 埇 埈 埏 埒 埕 埗 埘 埙 埚 埜 埝 埤 埭 埴 埵 埸 埼 埽 堀 堃 堇 堋 堌 堍 堙 堞 堠 堨 堺 塄 塍 塡 塩 塬 塱 塽 墀 墁 墉 墋 墎 墒 墘 墡 墪 壅 壥 売 壴 壵 壸 壻 夌 夔 夤 夼 奁 奝 奫 奭 妁 妗 妣 妤 妧 妪 妫 妯 妱 妳 姌 姍 姒 姘 姞 姹 娈 娉 娌 娵 婄 婖 媖 媞 媪 媵 媾 嫒 嫘 嫚 嫝 嫠 嫫 嫯 嫱 嫲 嬅 嬖 嬗 嬜 嬲 孀 孑 孓 孛 孥 孱 孳 學 宍 実 寔 寘 寛 寤 實 尅 對 尓 尜 尟 尥 屃 屄 屐 屙 屣 屮 屺 岀 岈 岍 岘 岙 岜 岢 岣 岫 岬 岵 岽 岿 峁 峄 峇 峋 峤 峯 崀 崃 崆 崐 崒 崞 崤 崦 崧 崮 嵂 嵊 嵎 嵒 嵖 嵛 嵝 嵨 嵫 嵬 嵯 嵴 嶂 嶃 嶋 嶓 嶙 嶝 嶷 巯 巳 巻 巽 巿 帀 帏 帑 帔 帙 帱 帶 帻 幛 幞 幹 庋 庑 庠 庥 庹 廑 廕 廛 廨 廪 廻 廼 廾 廿 弁 弇 弐 弭 弶 彀 彊 彖 彘 彟 彧 彳 彿 徂 徉 後 徕 徜 徭 徳 徵 徼 忄 忖 忝 忪 忭 忸 忾 忿 怃 怊 怍 怏 怙 怛 怩 怿 恂 恚 恧 恫 恵 恸 恹 恽 悃 悆 悌 悒 悕 悛 悝 悫 悭 悱 悳 惇 惎 惡 惢 惲 惴 愀 愆 愍 愎 愔 愘 愛 愠 慉 慊 慒 慜 慝 慥 憀 憍 憙 憷 懑 懔 懶 戆 戋 戕 戗 戡 戢 戥 戦 戸 戽 扃 扞 扥 扦 扽 抔 抟 拊 拶 挈 挢 挲 挹 捌 捘 捜 捭 捯 捱 捴 掊 掎 掞 掭 掮 掴 掼 掾 揄 揆 揠 揩 揶 揸 揺 揾 揿 搠 搢 搦 搧 搴 搵 搽 摅 摈 摛 摭 摺 摽 撃 撄 撘 撙 撷 撺 擗 擘 擢 擤 攉 攫 攮 攴 敕 斫 斱 旃 旄 旆 旎 旒 旖 旰 旴 旸 旻 旼 昃 昇 昉 昝 昫 昶 昺 時 晊 晙 晞 晡 晳 晷 晻 暌 暕 暝 暦 暹 暾 曈 曛 曩 曷 朊 朐 杈 杓 杝 杪 杬 杲 杼 枋 枘 枞 枥 枧 枨 枰 枱 枲 枳 枹 柁 柃 柈 柊 柒 柘 柙 柝 柞 柟 柢 柤 柰 柷 柸 柽 栄 栊 栌 栎 栝 栱 栲 栳 栻 桁 桄 桅 桉 桎 桕 桜 桠 桡 桤 桫 桯 桴 桷 桼 梃 梏 梶 棂 棨 棰 棹 棻 棼 椁 椋 椐 椟 椤 椪 椴 椵 椹 椽 楀 楗 楙 楝 楢 楦 楫 楮 楯 楱 楸 楹 楽 榇 榉 榑 榖 榘 榧 榫 榼 槁 槊 槎 槔 様 槩 槭 槲 槻 樉 樋 樓 樗 樘 樨 権 樯 樽 樾 橐 橛 橥 橹 橼 檄 檎 檗 檦 檩 檫 檵 櫾 權 欤 欷 欸 欹 欻 歃 歐 歔 歘 歙 歩 歯 歳 歴 殁 殂 殄 殍 殚 殛 殪 殭 毐 毖 毘 毳 毹 氅 氆 氇 氍 氐 氕 氖 気 氘 氙 氚 氡 氣 氤 氩 氲 氽 氾 汆 汊 汎 汏 汔 汜 汨 汩 沄 沆 沇 沒 沔 沢 沤 沩 況 泅 泆 泐 泖 泘 泚 泠 泫 泬 泮 泺 洄 洇 洌 洎 洑 洣 洧 洨 洮 洳 洸 洹 洺 浃 浈 浉 浍 浐 浗 浞 浠 浥 浯 浼 涑 涔 涖 涘 涙 涠 涫 涬 涼 淖 淙 淛 淝 淠 淯 渀 済 渌 渑 渫 湉 湎 湓 湔 湜 湝 湟 湣 湫 満 溆 溍 溏 溘 溦 溱 溻 溽 滂 滏 滓 滗 滘 滠 滢 滹 滺 漭 漼 潆 潋 潟 潩 潲 潴 澉 澌 澍 澚 澧 澪 澴 澶 澹 濉 濛 濞 濩 濬 濯 瀍 瀣 瀬 灣 炁 炆 炔 炘 炝 炟 炴 烀 烃 烔 烜 焐 焓 焗 焘 無 煅 煊 煨 煳 煺 熘 熳 熵 燊 燚 燠 燧 燮 燹 爝 爨 爰 爿 牁 牂 牍 牖 牝 牤 牯 牾 犍 犰 犲 犴 犸 狃 狍 狎 狒 狝 狨 狯 狲 狳 狴 狷 狺 狻 猁 猇 猊 猗 猞 猡 猢 猱 猲 猷 猸 猹 獐 獠 獣 獬 玎 玑 玘 玚 玢 玦 玳 玹 珙 珜 珣 珥 珧 珪 珮 珰 珽 現 琇 琌 琍 琎 琚 琠 琬 琮 琯 琲 瑀 瑊 瑗 瑨 瑭 瑮 瑱 瑴 瑷 璁 璈 璘 璟 璠 璩 瓠 瓤 瓴 瓿 甑 甙 甯 甾 畀 畈 畊 畋 畎 畑 畚 畦 畯 畲 當 畹 畿 疃 疋 疎 疔 疖 疠 疥 疬 疰 疳 疴 疸 疽 痂 痈 痍 痖 痦 痩 痼 瘅 瘆 瘊 瘌 瘐 瘕 瘗 瘘 瘢 瘥 瘰 瘳 瘼 瘿 癀 癃 癍 癔 癯 癸 発 皁 皌 皕 皝 皤 皲 皴 盁 盂 盍 盤 盥 盩 眀 眄 眇 県 眍 眚 眛 眢 眦 眬 眭 睃 睇 睖 睚 睟 睥 睨 瞀 瞋 瞢 瞫 瞵 瞽 矅 矍 矐 矱 矸 矽 砀 砗 砜 砟 砢 砣 砦 砧 砩 砫 砬 砭 砲 砻 砼 硇 硎 硐 硖 硗 硚 硪 硭 硷 硼 碁 碇 碓 碚 碛 碥 碲 碶 磉 磔 磙 磡 磬 磲 磴 磻 磾 礅 礌 礓 礤 礻 礽 祆 祇 祊 祏 祐 祓 祕 祗 祚 祜 祢 祧 禊 禚 禛 禨 禩 禫 禳 秕 秣 秫 秭 稂 稔 稗 稙 稹 穀 穂 穑 穣 穰 穸 窀 窠 窣 窨 窭 窸 窾 竑 竚 竦 竲 竽 笄 笏 笕 笞 笪 笫 笮 笳 笸 笹 笺 筆 筇 筌 筘 筚 筭 筮 筲 箅 箐 箓 箜 箝 箦 箧 箪 箬 箸 箾 篁 篌 篙 篚 篥 篦 篪 篼 篾 簃 簋 簌 簏 簖 簟 簦 籀 籓 籴 籼 粜 粝 粞 粢 粲 粳 粼 粿 糁 糅 糇 糌 糍 糨 糬 糸 紘 紙 紡 経 結 絜 給 絺 継 綦 綮 綽 緊 総 緑 縠 縡 縯 縻 績 繇 纁 纔 纛 纡 纩 纮 纻 纾 绀 绂 绉 绋 绌 绐 绗 绠 绦 绨 绲 绶 绺 绻 缁 缂 缃 缑 缒 缗 缛 缟 缣 缦 缧 缫 缬 缯 缱 缲 缳 缵 缶 缾 罃 罅 罍 罘 罟 罨 罴 罾 羝 羟 羣 羧 羰 羱 羸 羼 翕 翙 翚 翥 翦 翮 耄 耆 耋 耒 耔 耖 耜 耧 耨 耪 耵 聃 聍 聒 聡 聩 聱 聴 聿 肄 肟 肣 肫 肭 肸 肼 胂 胄 胍 胗 胙 胛 胝 胨 胪 胬 胲 胴 胼 脁 脒 脔 脘 脞 脩 脰 脲 腈 腓 腘 腙 腠 腧 腭 腴 腽 膦 臁 臕 臜 臬 臺 臾 舁 舂 舄 舐 舛 舢 舣 舨 舯 舸 舾 艄 艉 艋 艏 艨 艮 艹 艿 芄 芎 芑 芔 芗 芘 芟 芤 芨 芩 芫 芰 芴 芵 芾 苁 苄 苈 苋 苌 苎 苒 苕 苜 苡 苤 苪 苫 苴 苻 苾 茀 茆 茇 茈 茌 茏 茑 茔 茕 茛 茝 茭 茺 茼 荅 荇 荏 荑 荛 荜 荠 荦 荩 荪 荭 荸 荽 莒 莙 莛 莜 莠 莦 莨 莩 莪 莳 莶 莸 莼 菀 菈 菔 菖 菘 菝 菟 菡 菪 菰 菽 萁 萆 萋 萏 萘 萜 萩 萬 萸 萼 葑 葙 葚 葜 葭 葳 葶 葺 蒌 蒑 蒗 蒡 蒨 蒯 蒴 蒹 蒺 蒽 蓁 蓊 蓍 蓖 蓠 蓣 蓥 蓼 蓿 蔟 蔣 蔸 蕈 蕐 蕖 蕞 蕤 蕲 蕹 蕺 蕻 薁 薜 薤 薨 薬 薮 薳 薷 薹 藁 藜 蘅 蘇 蘖 蘡 蘧 蘩 蘼 虓 虛 虢 虬 虮 虺 虻 虼 虿 蚋 蚍 蚜 蚡 蚧 蚨 蚬 蚰 蚴 蚵 蚶 蚺 蚿 蛄 蛉 蛏 蛞 蛩 蛭 蛱 蛲 蛸 蜃 蜇 蜉 蜊 蜍 蜛 蜞 蜢 蜩 蜮 蜱 蝓 蝣 蝤 蝥 蝮 蝰 蝲 蝻 蝽 蝾 螅 螈 螟 螫 螬 螭 螯 螵 螽 蟊 蟛 蟥 蟪 蟮 蟲 蠃 蠊 蠓 蠖 蠛 蠨 蠲 蠳 蠹 衄 衝 衮 衽 衾 衿 袆 袝 袢 裉 裒 裛 裡 裢 裥 裨 裼 裾 褊 褓 褔 褙 褡 褦 褫 褭 襀 襁 襃 襞 襦 襶 見 視 覩 親 観 觇 觌 觏 觚 觜 觥 觧 觯 觱 訇 訏 訚 許 訾 詃 詧 誊 說 調 謇 謦 謩 讃 變 讐 讠 讣 讦 讫 讵 诂 诌 诐 诒 诔 诖 诘 诜 诤 诨 诮 诰 诳 诹 诼 谂 谄 谆 谌 谔 谖 谘 谝 谠 谡 谫 谮 谯 谰 谲 谳 谵 谶 豇 豉 豊 豕 豝 豢 豨 豳 豷 豸 貅 貉 貊 貓 貔 貕 貘 負 買 貿 贲 贳 贶 贽 赀 赉 赍 赑 赓 赙 赜 赟 赧 赭 赳 趄 趔 趵 趸 趺 趼 趿 跏 跖 跗 跣 跩 跫 跬 跱 跶 跸 跹 跼 跽 踅 踔 踟 踬 踯 踺 踽 蹀 蹁 蹇 蹍 蹑 蹙 蹚 蹩 蹰 蹼 躅 躐 躞 車 転 輀 轫 轭 轳 轸 轹 轾 辂 辇 辊 辋 辎 辏 辔 辚 辺 込 迓 迤 迨 迩 迮 迳 逄 逋 逓 逖 這 逡 逦 逯 逶 遄 過 遑 遘 遠 適 遰 遽 還 邅 邕 邗 邘 邙 邛 邠 邨 邰 邳 邴 邶 邽 邾 郃 郄 郇 郈 郍 郏 郓 郕 郗 郛 郜 郢 郤 郧 郫 郯 郾 鄄 鄅 鄋 鄕 鄜 鄣 鄩 鄫 鄮 鄯 鄹 酃 酆 酇 酎 酐 酞 酡 酢 酤 酩 酹 酺 酽 醅 醌 醍 醐 醚 醢 醣 醥 醪 醮 醯 醲 醴 醵 釆 鉄 鉏 銀 銷 鋈 鋐 鋒 鋳 錒 録 錾 鍉 鍊 鍒 鎉 鎏 鎛 鏊 鏐 鏖 钆 钇 钋 钌 钍 钎 钒 钕 钚 钜 钡 钣 钤 钪 钫 钭 钯 钲 钴 钶 钸 钹 钺 钼 钽 钿 铄 铈 铊 铋 铌 铍 铑 铒 铕 铖 铗 铙 铚 铞 铟 铥 铨 铩 铪 铫 铯 铱 铳 铷 铼 锃 锆 锇 锉 锊 锑 锒 锓 锔 锕 锗 锘 锛 锜 锝 锟 锨 锫 锳 锴 锶 锷 锸 锺 镆 镊 镋 镌 镏 镒 镓 镔 镗 镘 镙 镚 镛 镝 镞 镠 镡 镢 镦 镧 镨 镩 镪 镫 镬 镮 镱 镲 長 開 閑 閟 関 閤 闇 闘 闩 闱 闳 闼 闿 阃 阆 阇 阈 阊 阋 阌 阍 阏 阒 阕 阗 阝 阬 阼 阽 陉 陔 陖 陟 陧 陬 陲 陳 陴 険 陽 隈 隗 隰 隳 隹 隻 雉 雒 雔 雠 離 雩 雫 雱 霈 霊 霑 霪 霰 靑 靛 靰 靺 靼 鞆 鞑 鞒 鞣 鞥 鞨 鞯 鞲 鞴 鞶 韪 韫 頔 頠 頫 顗 顸 顼 颀 颃 颉 颎 颏 颔 颙 颛 颞 颟 颡 颢 颧 飑 飗 飨 飮 飯 餮 饔 饧 饬 饯 饴 饸 饹 馐 馑 馓 馔 馕 馲 駃 駆 験 騕 騜 騠 騪 騴 驩 驵 驺 驽 骈 骎 骒 骓 骕 骖 骘 骝 骟 骠 骢 骧 骶 骹 骺 髀 髁 髂 髌 髑 髗 髙 髡 髪 髫 髭 髯 髹 髽 鬃 鬄 鬈 鬏 鬐 鬣 鬲 鬶 鬻 魃 魆 魉 魋 魍 魑 鮑 鲀 鲂 鲃 鲆 鲇 鲋 鲌 鲎 鲐 鲑 鲔 鲖 鲚 鲛 鲠 鲡 鲢 鲣 鲥 鲧 鲩 鲭 鲮 鲯 鲰 鲱 鲳 鲵 鲷 鲺 鲽 鳃 鳇 鳊 鳋 鳎 鳏 鳐 鳓 鳔 鳙 鳜 鳟 鳢 鳣 鳯 鳳 鴐 鴶 鵴 鶒 鶲 鷏 鷩 鷲 鸂 鸨 鸩 鸪 鸫 鸬 鸮 鸰 鸱 鸲 鸶 鸷 鸸 鸹 鸻 鹀 鹁 鹄 鹇 鹈 鹎 鹔 鹕 鹗 鹘 鹚 鹛 鹞 鹟 鹣 鹧 鹩 鹪 鹫 鹬 鹮 鹯 鹳 鹾 麂 麇 麈 麴 麸 麹 麼 麾 麿 黃 黉 黍 黒 點 黟 黠 黡 黢 黥 黧 黩 黻 鼋 鼐 鼙 鼩 鼯 鼱 鼷 鼽 齁 齉 齑 齮 龃 龅 龆 龇 龉 龠 龢 ！</span><br></pre></td></tr></table></figure>

<p>低频次中文都去除，剩下高频4700个字，路径为：10.22.24.2：~&#x2F;data&#x2F;wenet&#x2F;examples&#x2F;multi_cn&#x2F;s0&#x2F;data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt</p>
<p>去除：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat 2 | tr &#x27; &#x27; &#x27;\n&#x27; | awk &#x27;&#123;print&quot;sed -i -e &#x27;\&#x27;&#x27;/&quot;$0&quot;&#x27;\&#x27;&#x27;/d 1&quot;&#125;&#x27; &gt; 3</span><br></pre></td></tr></table></figure>



<h4 id="4700个字可能还是有点少，还要再添加一点进去："><a href="#4700个字可能还是有点少，还要再添加一点进去：" class="headerlink" title="4700个字可能还是有点少，还要再添加一点进去："></a>4700个字可能还是有点少，还要再添加一点进去：</h4><p>把测试集有的，词典里没有，并且原来8000个字的字典有的，找出来</p>
<p>findout.py：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">is_python2 = sys.version_info[<span class="number">0</span>] == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># i_unk_ii</span></span><br><span class="line"><span class="comment"># 6792 草书千字文是宋徽宗赵1传世 6792 草书千字文是宋徽宗赵诘传世</span></span><br><span class="line"><span class="comment"># 10700 不用须1接上次 10700 不用须臾接上次</span></span><br><span class="line"><span class="comment"># 10813 是我国古代王室在龟甲或兽骨上1刻的文字 10813 是我国古代王室在龟甲或兽骨上镌刻的文字</span></span><br><span class="line"><span class="comment"># 21925 在澳大利亚的国徽上也有这样的动物左边的是袋鼠右边的是11 21925 在澳大利亚的国徽上也有这样的动物左边的是袋鼠右边的是鸸鹋</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_symbol_table</span>(<span class="params">symbol_table_file</span>):</span><br><span class="line">    symbol_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(symbol_table_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> fin:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">            arr = line.strip().split()</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(arr) == <span class="number">2</span></span><br><span class="line">            symbol_table[arr[<span class="number">0</span>]] = <span class="built_in">int</span>(arr[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> symbol_table</span><br><span class="line"></span><br><span class="line">symbol_table = read_symbol_table(<span class="string">&#x27;data_4000_add_we/dict_bpe/lang_char.txt.8000&#x27;</span>)</span><br><span class="line">f = codecs.<span class="built_in">open</span>(<span class="string">&#x27;i_unk_ii&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">sys.stdout = codecs.getwriter(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">        sys.stdout <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdout.buffer)</span><br><span class="line">line = f.readline()</span><br><span class="line"><span class="keyword">while</span> line:</span><br><span class="line">    unk = line.strip().split()[<span class="number">1</span>]</span><br><span class="line">    label = line.strip().split()[<span class="number">3</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(unk)):</span><br><span class="line">        <span class="keyword">if</span> unk[i] != label[i] <span class="keyword">and</span> label[i] <span class="keyword">in</span> symbol_table:</span><br><span class="line">            <span class="built_in">print</span>(label[i])</span><br><span class="line">    line = f.readline()</span><br></pre></td></tr></table></figure>

<p>一共有517个词，这里就先都添加进去，一共有5200个汉字，因此暂定词典大小为&#x3D;&#x3D;6691&#x3D;&#x3D;个字（1475个英文，6214个中文）</p>
<h3 id="统计与测试集的覆盖程度"><a href="#统计与测试集的覆盖程度" class="headerlink" title="统计与测试集的覆盖程度"></a>统计与测试集的覆盖程度</h3><ol start="0">
<li><p>先清洗测试集文本【训练时加上清洗脚本就行了，不需要把处理完的训练集文本给花哥】：</p>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i -e &#x27;/�/d&#x27; text</span><br><span class="line">sed -i &#x27;s/:/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/%/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/+/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/-/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/,/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/，/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/。/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/、/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/·/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/~/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/？/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/…/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/“/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/”/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/@/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/！/ /g&#x27; text</span><br><span class="line">sed -i &#x27;s/\./ /g&#x27; text</span><br><span class="line">cut -d &#x27; &#x27; -f 2- text | sed &#x27;s/[0-9]/ /g&#x27; &gt; 1</span><br><span class="line">cut -d &#x27; &#x27; -f 1 text  | paste -d &#x27; &#x27; - 1 &gt; 2</span><br><span class="line">mv 2 text</span><br><span class="line">rm 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sed -i <span class="string">&#x27;s/[0-9]/ /g&#x27;</span> text</span></span><br></pre></td></tr></table></figure>

</li>
<li><p>文本先转为token子词，然后查看是否在字典中（不在，就是unk），把wenet&#x2F;dataset&#x2F;processor.py的tokenize函数抠出；</p>
</li>
</ol>
<p>自己写的token.py：当有unk时，说明测试集里有字典里没有的字；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">is_python2 = sys.version_info[<span class="number">0</span>] == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__tokenize_by_bpe_model</span>(<span class="params">sp, txt</span>):</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="comment"># CJK(China Japan Korea) unicode range is [U+4E00, U+9FFF], ref:</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fff])&#x27;</span>)</span><br><span class="line">    <span class="comment"># Example:</span></span><br><span class="line">    <span class="comment">#   txt   = &quot;你好 ITS&#x27;S OKAY 的&quot;</span></span><br><span class="line">    <span class="comment">#   chars = [&quot;你&quot;, &quot;好&quot;, &quot; ITS&#x27;S OKAY &quot;, &quot;的&quot;]</span></span><br><span class="line">    chars = pattern.split(txt.upper())</span><br><span class="line">    mix_chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ch_or_w <span class="keyword">in</span> mix_chars:</span><br><span class="line">        <span class="comment"># ch_or_w is a single CJK charater(i.e., &quot;你&quot;), do nothing.</span></span><br><span class="line">        <span class="keyword">if</span> pattern.fullmatch(ch_or_w) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            tokens.append(ch_or_w)</span><br><span class="line">        <span class="comment"># ch_or_w contains non-CJK charaters(i.e., &quot; IT&#x27;S OKAY &quot;),</span></span><br><span class="line">        <span class="comment"># encode ch_or_w using bpe_model.</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> sp.encode_as_pieces(ch_or_w):</span><br><span class="line">                tokens.append(p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">sample,sp,</span></span><br><span class="line"><span class="params">             symbol_table,</span></span><br><span class="line"><span class="params">             bpe_model=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             non_lang_syms=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             split_with_space=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Decode text to chars or BPE</span></span><br><span class="line"><span class="string">        Inplace operation</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data: Iterable[&#123;key, wav, txt, sample_rate&#125;]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Iterable[&#123;key, wav, txt, tokens, label, sample_rate&#125;]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> non_lang_syms <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        non_lang_syms_pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;(\[[^\[\]]+\]|&lt;[^&lt;&gt;]+&gt;|&#123;[^&#123;&#125;]+&#125;)&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        non_lang_syms = &#123;&#125;</span><br><span class="line">        non_lang_syms_pattern = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> bpe_model <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        sp.load(bpe_model)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sp = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> <span class="string">&#x27;txt&#x27;</span> <span class="keyword">in</span> sample</span><br><span class="line">    txt = sample[<span class="string">&#x27;txt&#x27;</span>].strip()</span><br><span class="line">    <span class="keyword">if</span> non_lang_syms_pattern <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        parts = non_lang_syms_pattern.split(txt.upper())</span><br><span class="line">        parts = [w <span class="keyword">for</span> w <span class="keyword">in</span> parts <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        parts = [txt]</span><br><span class="line"></span><br><span class="line">    label = []</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="keyword">for</span> part <span class="keyword">in</span> parts:</span><br><span class="line">        <span class="keyword">if</span> part <span class="keyword">in</span> non_lang_syms:</span><br><span class="line">            tokens.append(part)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> bpe_model <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                tokens.extend(__tokenize_by_bpe_model(sp, part))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> split_with_space:</span><br><span class="line">                    part = part.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">                <span class="keyword">for</span> ch <span class="keyword">in</span> part:</span><br><span class="line">                    <span class="keyword">if</span> ch == <span class="string">&#x27; &#x27;</span>:</span><br><span class="line">                        ch = <span class="string">&quot;▁&quot;</span></span><br><span class="line">                    tokens.append(ch)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tokens)):</span><br><span class="line">        ch = tokens[i]</span><br><span class="line">        <span class="keyword">if</span> ch <span class="keyword">not</span> <span class="keyword">in</span> symbol_table:</span><br><span class="line">            tokens[i]  = <span class="string">&#x27;&lt;unk&gt;&#x27;</span></span><br><span class="line">        <span class="comment"># elif &#x27;&lt;unk&gt;&#x27; in symbol_table:</span></span><br><span class="line">            <span class="comment"># label.append(symbol_table[&#x27;&lt;unk&gt;&#x27;])</span></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">    sample[<span class="string">&#x27;tokens&#x27;</span>] = tokens</span><br><span class="line">    <span class="comment"># sample[&#x27;label&#x27;] = label</span></span><br><span class="line">    <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_symbol_table</span>(<span class="params">symbol_table_file</span>):</span><br><span class="line">    symbol_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(symbol_table_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> fin:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">            arr = line.strip().split()</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(arr) == <span class="number">2</span></span><br><span class="line">            symbol_table[arr[<span class="number">0</span>]] = <span class="built_in">int</span>(arr[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> symbol_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    symbol_table = read_symbol_table(<span class="string">&#x27;data_4000_add_we/dict_bpe/lang_char.txt&#x27;</span>)</span><br><span class="line">    <span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line">    sp = spm.SentencePieceProcessor()</span><br><span class="line">    f = codecs.<span class="built_in">open</span>(<span class="string">&#x27;data_4000_add_we/test/text1&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    sys.stdout = codecs.getwriter(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">            sys.stdout <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdout.buffer)</span><br><span class="line">    line = f.readline()</span><br><span class="line">    <span class="keyword">while</span> line:</span><br><span class="line">        data=&#123;&#125;</span><br><span class="line">        data[<span class="string">&#x27;key&#x27;</span>]=line.strip().split()[<span class="number">0</span>]</span><br><span class="line">        data[<span class="string">&#x27;txt&#x27;</span>]=<span class="string">&#x27;&#x27;</span>.join(line.strip().split()[<span class="number">1</span>:])</span><br><span class="line">        sample = tokenize(data,sp,</span><br><span class="line">                symbol_table,</span><br><span class="line">                bpe_model=<span class="string">&#x27;data_4000_add_we/lang_char/train_unigram1000.model&#x27;</span>,</span><br><span class="line">                non_lang_syms=<span class="literal">None</span>,</span><br><span class="line">                split_with_space=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(sample[<span class="string">&#x27;key&#x27;</span>], <span class="string">&#x27;&#x27;</span>.join(sample[<span class="string">&#x27;tokens&#x27;</span>]))</span><br><span class="line">        line = f.readline()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>



<p>后来又改写了一版token_fast.py：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">is_python2 = sys.version_info[<span class="number">0</span>] == <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__tokenize_by_bpe_model</span>(<span class="params">sp, txt</span>):</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="comment"># CJK(China Japan Korea) unicode range is [U+4E00, U+9FFF], ref:</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fff])&#x27;</span>)</span><br><span class="line">    <span class="comment"># Example:</span></span><br><span class="line">    <span class="comment">#   txt   = &quot;你好 ITS&#x27;S OKAY 的&quot;</span></span><br><span class="line">    <span class="comment">#   chars = [&quot;你&quot;, &quot;好&quot;, &quot; ITS&#x27;S OKAY &quot;, &quot;的&quot;]</span></span><br><span class="line">    chars = pattern.split(txt.upper())</span><br><span class="line">    mix_chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ch_or_w <span class="keyword">in</span> mix_chars:</span><br><span class="line">        <span class="comment"># ch_or_w is a single CJK charater(i.e., &quot;你&quot;), do nothing.</span></span><br><span class="line">        <span class="keyword">if</span> pattern.fullmatch(ch_or_w) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            tokens.append(ch_or_w)</span><br><span class="line">        <span class="comment"># ch_or_w contains non-CJK charaters(i.e., &quot; IT&#x27;S OKAY &quot;),</span></span><br><span class="line">        <span class="comment"># encode ch_or_w using bpe_model.</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> sp.encode_as_pieces(ch_or_w):</span><br><span class="line">                tokens.append(p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">sample,sp,</span></span><br><span class="line"><span class="params">             symbol_table</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Decode text to chars or BPE</span></span><br><span class="line"><span class="string">        Inplace operation</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data: Iterable[&#123;key, wav, txt, sample_rate&#125;]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Iterable[&#123;key, wav, txt, tokens, label, sample_rate&#125;]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    txt = sample[<span class="string">&#x27;txt&#x27;</span>].strip()</span><br><span class="line">    parts = [txt]</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="keyword">for</span> part <span class="keyword">in</span> parts:</span><br><span class="line">        tokens.extend(__tokenize_by_bpe_model(sp, part))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tokens)):</span><br><span class="line">        ch = tokens[i]</span><br><span class="line">        <span class="keyword">if</span> ch <span class="keyword">not</span> <span class="keyword">in</span> symbol_table:</span><br><span class="line">            tokens[i]  = <span class="string">&#x27;&lt;unk&gt;&#x27;</span></span><br><span class="line">        <span class="comment"># elif &#x27;&lt;unk&gt;&#x27; in symbol_table:</span></span><br><span class="line">            <span class="comment"># label.append(symbol_table[&#x27;&lt;unk&gt;&#x27;])</span></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">    sample[<span class="string">&#x27;tokens&#x27;</span>] = tokens</span><br><span class="line">    <span class="comment"># sample[&#x27;label&#x27;] = label</span></span><br><span class="line">    <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_symbol_table</span>(<span class="params">symbol_table_file</span>):</span><br><span class="line">    symbol_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(symbol_table_file, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> fin:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">            arr = line.strip().split()</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(arr) == <span class="number">2</span></span><br><span class="line">            symbol_table[arr[<span class="number">0</span>]] = <span class="built_in">int</span>(arr[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> symbol_table</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    symbol_table = read_symbol_table(<span class="string">&#x27;data_4000_add_we/dict_bpe/lang_char.txt&#x27;</span>)</span><br><span class="line">    <span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line">    sp = spm.SentencePieceProcessor()</span><br><span class="line">    sp.load(<span class="string">&#x27;data_4000_add_we/lang_char/train_unigram1000.model&#x27;</span>)</span><br><span class="line">    f = codecs.<span class="built_in">open</span>(<span class="string">&#x27;data_4000_add_we/test/text1&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    sys.stdout = codecs.getwriter(<span class="string">&quot;utf-8&quot;</span>)(</span><br><span class="line">            sys.stdout <span class="keyword">if</span> is_python2 <span class="keyword">else</span> sys.stdout.buffer)</span><br><span class="line">    line = f.readline()</span><br><span class="line">    <span class="keyword">while</span> line:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(line.strip().split()) &gt; <span class="number">1</span>:</span><br><span class="line">            data=&#123;&#125;</span><br><span class="line">            data[<span class="string">&#x27;key&#x27;</span>]=line.strip().split()[<span class="number">0</span>]</span><br><span class="line">            data[<span class="string">&#x27;txt&#x27;</span>]=<span class="string">&#x27;&#x27;</span>.join(line.strip().split()[<span class="number">1</span>:])</span><br><span class="line">            sample = tokenize(data,sp,</span><br><span class="line">                    symbol_table)</span><br><span class="line">            <span class="built_in">print</span>(sample[<span class="string">&#x27;key&#x27;</span>], <span class="string">&#x27;&#x27;</span>.join(sample[<span class="string">&#x27;tokens&#x27;</span>]))</span><br><span class="line">        <span class="comment"># print(sample[&#x27;key&#x27;], sample[&#x27;tokens&#x27;])</span></span><br><span class="line">        line = f.readline()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>



<h3 id="汉字覆盖率"><a href="#汉字覆盖率" class="headerlink" title="汉字覆盖率"></a>汉字覆盖率</h3><p>要满足：覆盖99.9%以上，至少识别率上限是99.9%，不至于太低</p>
<ul>
<li><p>希望覆盖训练集99.9%（data_4000_add_we&#x2F;train&#x2F;text）：</p>
<ul>
<li>7200汉字能够覆盖为 99.99993%（203没覆盖&#x2F;290200677个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi7200_all8600）</li>
<li>6000字汉字能够覆盖为；99.9976%（6873&#x2F;290200677个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi6000_all7500）</li>
<li>5200字汉字能够覆盖为；99.9919%：（23469&#x2F;290200677个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi5200_all6700）</li>
<li>4700字汉字能够覆盖为 99.984%：（45290 &#x2F;290200677个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi4700_all6000）</li>
</ul>
</li>
<li><p>希望覆盖测试集99.9%（data_4000_add_we&#x2F;text_1.4w）：</p>
<ul>
<li>7200字汉字能够覆盖为：100%（0 unk&#x2F;587421个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi7200_all8600）</li>
<li>6000字汉字能够覆盖为；100%（0 unk&#x2F;587421个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi6000_all7500）</li>
<li>5200字汉字能够覆盖为；100%（0 unk&#x2F;587421个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi5200_all6700）</li>
<li>4700字汉字能够覆盖为：99.9938%（36 unk&#x2F;587421个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi4700_all6000）</li>
</ul>
</li>
<li><p>希望覆盖测试集99.9%（data_4000_add_we&#x2F;text_chushibiao）：</p>
<ul>
<li>7200字汉字能够覆盖为：100%（0 unk &#x2F;624个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi7200_all8600）</li>
<li>6000字汉字能够覆盖为：100%（0 unk &#x2F;624个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi6000_all7500）</li>
<li>5200字汉字能够覆盖为：100%（0 unk &#x2F;624个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi5200_all6700）</li>
<li>4700字汉字能够覆盖为：100%（0 unk &#x2F;624个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi4700_all6000）</li>
</ul>
</li>
<li><p>希望覆盖测试集99.9%（data_4000_add_we&#x2F;text）：7G数据</p>
<ul>
<li>7200字汉字能够覆盖为：99.9999%（1741 unk&#x2F;2117514045个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi7200_all8600）</li>
<li>6000字汉字能够覆盖为；99.9999%（1741 unk&#x2F;2117514045个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi6000_all7500）（6000是又从7G测试集里加了一些）</li>
<li>5200字汉字能够覆盖为；99.9975%（52398 unk&#x2F;2117514045个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi5200_all6700）</li>
<li>4700字汉字能够覆盖为：99.9834%（350902 unk&#x2F;2117514045个字）（data_4000_add_we&#x2F;dict_bpe&#x2F;lang_char.txt.bpe_1000_eng1400_chi4700_all6000）</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>Wenet脚本 解码</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/Wenet%E8%84%9A%E6%9C%AC%20%E8%A7%A3%E7%A0%81/</url>
    <content><![CDATA[<h1 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h1><h2 id="decode-main"><a href="#decode-main" class="headerlink" title="decode_main"></a>decode_main</h2><p>decode_main参数：</p>
<ul>
<li>rescoring_weight：如果为0，不需要rescore；不为0的任意值，要做rescore</li>
<li>ctc_weight：rescore中，最终某条n-best分数 &#x3D; score_aed + ctc_weight * score_ctc</li>
</ul>
<h2 id="binding"><a href="#binding" class="headerlink" title="binding"></a>binding</h2><p>prefix beam search</p>
<p>参考 <a href="https://github.com/awni/speech">https://github.com/awni/speech</a></p>
<p>之前的笔记中解码代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Author: Awni Hannun</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This is an example CTC decoder written in Python. The code is</span></span><br><span class="line"><span class="string">intended to be a simple example and is not designed to be</span></span><br><span class="line"><span class="string">especially efficient.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">The algorithm is a prefix beam search for a model trained</span></span><br><span class="line"><span class="string">with the CTC loss function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">For more details checkout either of these references:</span></span><br><span class="line"><span class="string">  https://distill.pub/2017/ctc/#inference</span></span><br><span class="line"><span class="string">  https://arxiv.org/abs/1408.2873</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NEG_INF = -<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_new_beam</span>():</span><br><span class="line">    fn = <span class="keyword">lambda</span> : (NEG_INF, NEG_INF)</span><br><span class="line">    <span class="keyword">return</span> collections.defaultdict(fn)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logsumexp</span>(<span class="params">*args</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Stable log sum exp.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">all</span>(a == NEG_INF <span class="keyword">for</span> a <span class="keyword">in</span> args):</span><br><span class="line">        <span class="keyword">return</span> NEG_INF</span><br><span class="line">    a_max = <span class="built_in">max</span>(args)</span><br><span class="line">    lsp = math.log(<span class="built_in">sum</span>(math.exp(a - a_max)</span><br><span class="line">                       <span class="keyword">for</span> a <span class="keyword">in</span> args))</span><br><span class="line">    <span class="keyword">return</span> a_max + lsp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">probs, beam_size=<span class="number">3</span>, blank=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Performs inference for the given output probabilities.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">      probs: The output probabilities (e.g. post-softmax) for each</span></span><br><span class="line"><span class="string">        time step. Should be an array of shape (time x output dim).</span></span><br><span class="line"><span class="string">      beam_size (int): Size of the beam to use during inference.</span></span><br><span class="line"><span class="string">      blank (int): Index of the CTC blank label.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns the output label sequence and the corresponding negative</span></span><br><span class="line"><span class="string">    log-likelihood estimated by the decoder.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    T, S = probs.shape</span><br><span class="line">    probs = np.log(probs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Elements in the beam are (prefix, (p_blank, p_no_blank))</span></span><br><span class="line">    <span class="comment"># Initialize the beam with the empty sequence, a probability of</span></span><br><span class="line">    <span class="comment"># 1 for ending in blank and zero for ending in non-blank</span></span><br><span class="line">    <span class="comment"># (in log space).</span></span><br><span class="line">    beam = [(<span class="built_in">tuple</span>(), (<span class="number">0.0</span>, NEG_INF))]  <span class="comment"># 一开始走blank, p_b = 1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T): <span class="comment"># Loop over time</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># A default dictionary to store the next step candidates.</span></span><br><span class="line">        next_beam = make_new_beam() <span class="comment"># 新建一个dict，dict里的每个元素初始都是(-INF，-INF)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> <span class="built_in">range</span>(S): <span class="comment"># Loop over vocab</span></span><br><span class="line">            p = probs[t, s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># The variables p_b and p_nb are respectively the</span></span><br><span class="line">            <span class="comment"># probabilities for the prefix given that it ends in a</span></span><br><span class="line">            <span class="comment"># blank and does not end in a blank at this time step.</span></span><br><span class="line">            <span class="keyword">for</span> prefix, (p_b, p_nb) <span class="keyword">in</span> beam: <span class="comment"># Loop over beam</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                <span class="comment"># If we propose a blank the prefix doesn&#x27;t change.</span></span><br><span class="line">                <span class="comment"># Only the probability of ending in blank gets updated.</span></span><br><span class="line">                <span class="comment"># n_p_b、n_p_nb：路径总概率，累加.  n_p_b: new_p_b, new一条新创建的路径</span></span><br><span class="line">                <span class="keyword">if</span> s == blank:</span><br><span class="line">                  <span class="comment"># 只更新n_p_b的概率，论文里remove blank，指的是没有连续的blank blank，也就是说不考虑n_prefix = prefix + (s,)当s为blank的情况</span></span><br><span class="line">                  n_p_b, n_p_nb = next_beam[prefix]</span><br><span class="line">                  n_p_b = logsumexp(n_p_b, p_b + p, p_nb + p) <span class="comment"># 合并前缀/规整前缀</span></span><br><span class="line">                  next_beam[prefix] = (n_p_b, n_p_nb)</span><br><span class="line">                  <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Extend the prefix by the new character s and add it to</span></span><br><span class="line">                <span class="comment"># the beam. Only the probability of not ending in blank</span></span><br><span class="line">                <span class="comment"># gets updated.</span></span><br><span class="line">                <span class="comment"># 是否是aa还是ac，和前一个符号是否相等</span></span><br><span class="line">                end_t = prefix[-<span class="number">1</span>] <span class="keyword">if</span> prefix <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                n_prefix = prefix + (s,)</span><br><span class="line">                n_p_b, n_p_nb = next_beam[n_prefix] <span class="comment"># 先提出来，更新后，再赋回去</span></span><br><span class="line">                <span class="keyword">if</span> s != end_t:</span><br><span class="line">                  <span class="comment"># ac的情况</span></span><br><span class="line">                  n_p_nb = logsumexp(n_p_nb, p_b + p, p_nb + p)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                  <span class="comment"># aa的情况 a_a 输出 aa</span></span><br><span class="line">                  <span class="comment"># We don&#x27;t include the previous probability of not ending</span></span><br><span class="line">                  <span class="comment"># in blank (p_nb) if s is repeated at the end. The CTC</span></span><br><span class="line">                  <span class="comment"># algorithm merges characters not separated by a blank.</span></span><br><span class="line">                  n_p_nb = logsumexp(n_p_nb, p_b + p)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                <span class="comment"># *NB* this would be a good place to include an LM score.</span></span><br><span class="line">                next_beam[n_prefix] = (n_p_b, n_p_nb)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                <span class="comment"># If s is repeated at the end we also update the unchanged</span></span><br><span class="line">                <span class="comment"># prefix. This is the merging case.</span></span><br><span class="line">                <span class="keyword">if</span> s == end_t:</span><br><span class="line">                  <span class="comment"># aa的情况 aaa 输出a，这里把aaa情况合并到a情况（prefix=a）</span></span><br><span class="line">                  n_p_b, n_p_nb = next_beam[prefix]</span><br><span class="line">                  n_p_nb = logsumexp(n_p_nb, p_nb + p)</span><br><span class="line">                  next_beam[prefix] = (n_p_b, n_p_nb) <span class="comment"># next_beam[prefix]要更新</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sort and trim the beam before moving on to the</span></span><br><span class="line">        <span class="comment"># next time-step.</span></span><br><span class="line">        beam = <span class="built_in">sorted</span>(next_beam.items(),</span><br><span class="line">                key=<span class="keyword">lambda</span> x : logsumexp(*x[<span class="number">1</span>]),</span><br><span class="line">                reverse=<span class="literal">True</span>)</span><br><span class="line">        beam = beam[:beam_size]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    best = beam[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> best[<span class="number">0</span>], -logsumexp(*best[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># np.random.seed(3)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># time = 50</span></span><br><span class="line">    <span class="comment"># output_dim = 20</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># probs = np.random.rand(time, output_dim)</span></span><br><span class="line">    <span class="comment"># probs = probs / np.sum(probs, axis=1, keepdims=True)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 0 3 3 0 3 4 =&gt; 3 3 4</span></span><br><span class="line">    probs=[[<span class="number">0.8</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>],[<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.8</span>,<span class="number">0.05</span>],[<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.8</span>,<span class="number">0.05</span>],[<span class="number">0.8</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>],[<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.8</span>,<span class="number">0.05</span>],[<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.05</span>,<span class="number">0.8</span>]]</span><br><span class="line">    probs = np.array(probs)</span><br><span class="line">    probs = probs / np.<span class="built_in">sum</span>(probs, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    labels, score = decode(probs)</span><br><span class="line">    <span class="built_in">print</span>(labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Score &#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(score))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>BPE编码 Byte Pair Encoding 字节对编码</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/bpe/</url>
    <content><![CDATA[<h1 id="BPE编码-Byte-Pair-Encoding-字节对编码"><a href="#BPE编码-Byte-Pair-Encoding-字节对编码" class="headerlink" title="BPE编码 Byte Pair Encoding 字节对编码"></a>BPE编码 Byte Pair Encoding 字节对编码</h1><blockquote>
<p>Neural Machine Translation of Rare Words with Subword Units</p>
<p>github: <a href="https://github.com/sebastien-j/LV_groundhog">https://github.com/sebastien-j/LV_groundhog</a>  </p>
<p>github：<a href="https://github.com/rsennrich/subword-nmt">https://github.com/rsennrich/subword-nmt</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/86965595">https://zhuanlan.zhihu.com/p/86965595</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/164520154">https://zhuanlan.zhihu.com/p/164520154</a></p>
</blockquote>
<h5 id="解决了什么问题"><a href="#解决了什么问题" class="headerlink" title="解决了什么问题"></a>解决了什么问题</h5><ul>
<li>神经机器翻译（neural machine translation (NMT)  ）里存在OOV的问题，就是没见过的词没法翻译，本文提出了对罕见和没见过的词进行编码成子词序列，从而解决了OOV问题；该模型成为子词模型subword model</li>
<li></li>
</ul>
<h5 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><ul>
<li><p>将分词算法用于机器翻译任务中，这是来源于称职的译者可以根据已知的子词单位(如语素或音素)进行翻译，即使这些词对他或她来说是新颖的。因此分词算法用于翻译任务是有道理的；</p>
<p>即不同的词类可以通过比单词更小的单位进行翻译，例如名称(通过字符复制或音译)，化合物(通过组合翻译)，以及同源词和外来词(通过语音和形态的转换)。</p>
</li>
<li><p>分词算法包括n-gram和BPE；</p>
</li>
</ul>
<h5 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h5><ul>
<li>在WMT 15 translation tasks English→German and English→Russian  任务上，比back-off dictionary baseline  好1.1和1.3 BLEU</li>
</ul>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>将BPE(byte pair encoding (BPE) (Gage, 1994))算法用到机器翻译任务上，用作分词算法，以解决OOV问题；</p>
</li>
<li><p>BPE允许通过固定大小的词汇表（词汇表里构成词的字符序列不一样长的）来表示开放词汇表open vocabulary ；</p>
</li>
<li><p>NMT模型：encoder-decoder结构，encoder：biGRU</p>
</li>
<li><p>提出假设：将罕见词切分为适当的子词单元足以让神经翻译网络学习透明翻译，并将这一知识推广到翻译和产生不可见的词</p>
</li>
<li><p>BPE编码：迭代地用一个未使用的字节替换序列中最频繁的一对字节；本文合并字符或字符序列，而不是合并频繁的字节对。</p>
<p>首先，我们用字符词汇表初始化符号词汇表，并将每个单词表示为一个字符序列，加上一个特殊的词尾符号’·’，这使我们能够在翻译后恢复原来的标记化。我们迭代计算所有符号对，并将出现频率最高的符号对(‘ A ‘， ‘ B ‘)替换为新的符号’ AB ‘。每个合并操作产生一个表示字符n-gram的新符号。频繁的字符n-grams(或整个单词)最终会合并成一个符号，因此BPE不需要候选列表。最后的符号词汇表大小等于初始词汇表的大小加上合并操作的次数（超参）；</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/bpe/image-20220604163527055.png" alt="image-20220604163527055" style="zoom:80%;">

<h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><ol>
<li>确定subword词表大小</li>
<li>统计每一个<strong>连续字节对</strong>的出现频率，并保存为code_file。这个是git中learn-bpe完成</li>
<li>将单词拆分为字符序列并在末尾添加后缀“ ”，而后按照code_file合并新的subword，首先合并频率出现最高的字节对。例如单词birthday，分割为[‘b’, ‘i’, ‘r’, ‘t’, ‘h’, ‘d’, ‘a’, ‘y‘]，查code_file，发现’th’出现的最多，那么合并为[‘b’, ‘i’, ‘r’, ‘th’, ‘d’, ‘a’, ‘y‘]，最后，字符序列合并为[‘birth’, ‘day‘]。然后去除’‘,变为[‘birth’, ‘day’]，将这两个词添加到词表。这个是apply-bpe完成。</li>
<li>重复第3步直到达到<strong>第2步设定的subword词表大小</strong>或<strong>下一个最高频的字节对出现频率为1</strong></li>
</ol>
<p>或者：</p>
<ol>
<li>准备足够大的训练语料</li>
<li>确定期望的subword词表大小</li>
<li>将单词拆分为字符序列并在末尾添加后缀“ &lt;&#x2F; w&gt;”，统计单词频率。 本阶段的subword的粒度是字符。 例如，“ low”的频率为5，那么我们将其改写为“ l o w &lt;&#x2F; w&gt;”：5</li>
<li>统计每一个连续字节对的出现频率，选择最高频者合并成新的subword</li>
<li>重复第4步直到达到第2步设定的subword词表大小或下一个最高频的字节对出现频率为1</li>
</ol>
<p><strong>例子</strong></p>
<p>输入：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;l o w &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span> &#x27;l o w e r &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span> &#x27;n e w e s t &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span> &#x27;w i d e s t &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>Iter 1, 最高频连续字节对”e”和”s”出现了6+3&#x3D;9次，合并成”es”。输出：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;l o w &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span> &#x27;l o w e r &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span> &#x27;n e w es t &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span> &#x27;w i d es t &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>Iter 2, 最高频连续字节对”es”和”t”出现了6+3&#x3D;9次, 合并成”est”。输出：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;l o w &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span> &#x27;l o w e r &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span> &#x27;n e w est &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span> &#x27;w i d est &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>Iter 3, 以此类推，最高频连续字节对为”est”和”“ 输出：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;l o w &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span> &#x27;l o w e r &lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span> &#x27;n e w est&lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span> &#x27;w i d est&lt;/w&gt;&#x27;<span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>……</p>
<p>Iter n, 继续迭代直到达到预设的subword词表大小或下一个最高频的字节对出现频率为1。</p>
<h3 id="BPE包"><a href="#BPE包" class="headerlink" title="BPE包"></a>BPE包</h3><blockquote>
<p><a href="https://github.com/google/sentencepiece">https://github.com/google/sentencepiece</a></p>
</blockquote>
<p>▁表示空格，也表示文本开头，detoken时，▁换成空格，把空格连起来；</p>
<p>把比如token后的文本“▁A L V IN ▁AND ▁THE ▁C H AP TER”其实是“Alvin and the chapter”</p>
<p>grep “只能在线不能离线” text_token_eng</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br></pre></td></tr></table></figure>



<h3 id="BPE实现"><a href="#BPE实现" class="headerlink" title="BPE实现"></a>BPE实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re, collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_stats</span>(<span class="params">vocab</span>):</span><br><span class="line">    pairs = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">for</span> word, freq <span class="keyword">in</span> vocab.items():</span><br><span class="line">        symbols = word.split()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(symbols)-<span class="number">1</span>):</span><br><span class="line">            pairs[symbols[i],symbols[i+<span class="number">1</span>]] += freq</span><br><span class="line">    <span class="keyword">return</span> pairs</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_vocab</span>(<span class="params">pair, v_in</span>):</span><br><span class="line">    v_out = &#123;&#125;</span><br><span class="line">    bigram = re.escape(<span class="string">&#x27; &#x27;</span>.join(pair))</span><br><span class="line">    p = re.<span class="built_in">compile</span>(<span class="string">r&#x27;(?&lt;!\S)&#x27;</span> + bigram + <span class="string">r&#x27;(?!\S)&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> v_in:</span><br><span class="line">        w_out = p.sub(<span class="string">&#x27;&#x27;</span>.join(pair), word)</span><br><span class="line">        v_out[w_out] = v_in[word]</span><br><span class="line">    <span class="keyword">return</span> v_out</span><br><span class="line"></span><br><span class="line">vocab = &#123;<span class="string">&#x27;l o w &lt;/w&gt;&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;l o w e r &lt;/w&gt;&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;n e w e s t &lt;/w&gt;&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;w i d e s t &lt;/w&gt;&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line">num_merges = <span class="number">1000</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_merges):</span><br><span class="line">    pairs = get_stats(vocab)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pairs:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    best = <span class="built_in">max</span>(pairs, key=pairs.get)</span><br><span class="line">    vocab = merge_vocab(best, vocab)</span><br><span class="line">    <span class="built_in">print</span>(best)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print output</span></span><br><span class="line"><span class="comment"># (&#x27;e&#x27;, &#x27;s&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;es&#x27;, &#x27;t&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;est&#x27;, &#x27;&lt;/w&gt;&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;l&#x27;, &#x27;o&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;lo&#x27;, &#x27;w&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;n&#x27;, &#x27;e&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;ne&#x27;, &#x27;w&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;new&#x27;, &#x27;est&lt;/w&gt;&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;low&#x27;, &#x27;&lt;/w&gt;&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;w&#x27;, &#x27;i&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;wi&#x27;, &#x27;d&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;wid&#x27;, &#x27;est&lt;/w&gt;&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;low&#x27;, &#x27;e&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;lowe&#x27;, &#x27;r&#x27;)</span></span><br><span class="line"><span class="comment"># (&#x27;lower&#x27;, &#x27;&lt;/w&gt;&#x27;)</span></span><br></pre></td></tr></table></figure>



<h3 id="编码和解码"><a href="#编码和解码" class="headerlink" title="编码和解码"></a>编码和解码</h3><ul>
<li>编码</li>
</ul>
<p>在之前的算法中，我们已经得到了subword的词表，对该词表<strong>按照子词长度由大到小排序</strong>。编码时，对于每个单词，遍历排好序的子词词表寻找是否有token是当前单词的子字符串，如果有，则该token是表示单词的tokens之一。</p>
<p>我们从最长的token迭代到最短的token，尝试将每个单词中的子字符串替换为token。 最终，我们将迭代所有tokens，并将所有子字符串替换为tokens。 如果仍然有子字符串没被替换但所有token都已迭代完毕，则将剩余的子词替换为特殊token，如<unk>。</unk></p>
<p>例子</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line"># 给定单词序列</span><br><span class="line">[“the&lt;/w&gt;”, “highest&lt;/w&gt;”, “mountain&lt;/w&gt;”]</span><br><span class="line"></span><br><span class="line"># 假设已有排好序的subword词表</span><br><span class="line">[“errrr&lt;/w&gt;”, “tain&lt;/w&gt;”, “moun”, “est&lt;/w&gt;”, “high”, “the&lt;/w&gt;”, “a&lt;/w&gt;”]</span><br><span class="line"></span><br><span class="line"># 迭代结果</span><br><span class="line">&quot;the&lt;/w&gt;&quot; -&gt; [&quot;the&lt;/w&gt;&quot;]</span><br><span class="line">&quot;highest&lt;/w&gt;&quot; -&gt; [&quot;high&quot;, &quot;est&lt;/w&gt;&quot;]</span><br><span class="line">&quot;mountain&lt;/w&gt;&quot; -&gt; [&quot;moun&quot;, &quot;tain&lt;/w&gt;&quot;]</span><br></pre></td></tr></table></figure>

<p>编码的计算量很大。 在实践中，我们可以pre-tokenize所有单词，并在词典中保存单词tokenize的结果。 如果我们看到字典中不存在的未知单词。 我们应用上述编码方法对单词进行tokenize，然后将新单词的tokenization添加到字典中备用。</p>
<ul>
<li>解码</li>
</ul>
<p>将所有的tokens拼在一起。</p>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编码序列</span></span><br><span class="line">[“the&lt;/w&gt;”, “high”, “est&lt;/w&gt;”, “moun”, “tain&lt;/w&gt;”]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码序列</span></span><br><span class="line">“the&lt;/w&gt; highest&lt;/w&gt; mountain&lt;/w&gt;”</span><br></pre></td></tr></table></figure>



<p>tr ‘▁’ ‘ ‘  </p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>chain model</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/chain%20model/</url>
    <content><![CDATA[<h1 id="chain-model"><a href="#chain-model" class="headerlink" title="chain model"></a>chain model</h1><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/65557682">kaldi中的chain model(LFMMI)详解</a></p>
</blockquote>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/chain%20model/v2-df4fab74a246b6935e20ecf7e1ccff8b_720w.jpg" alt="img"></p>
<p>对应kaldi中的结构定义为：</p>
<blockquote>
<Topology>
<TopologyEntry>
<ForPhones>
1 2 3 4 5 6 7 8 …
</ForPhones>
<State> 0 <**ForwardPdfClass**> 0 <**SelfLoopPdfClass**> 1 <Transition> 0 0.5 <Transition> 1 0.5 </Transition></Transition></**SelfLoopPdfClass**></**ForwardPdfClass**></State>
<State> 1 </State>
</TopologyEntry>
</Topology>
</blockquote>
<p>在kaldi中，把Sp和Sb看做同一个状态(都对应state 0)，只是pdfclass不同。ForwardPdfClass表示Sp，SelfLoopPdfClass表示Sb。</p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>调试decoder_main</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/decoder_main/</url>
    <content><![CDATA[<h1 id="调试decoder-main"><a href="#调试decoder-main" class="headerlink" title="调试decoder_main"></a>调试decoder_main</h1><p>用的cgdb调试</p>
<p>首先之前编译cmake时，没有加可选debug的选项，因此不可调试，在<strong>CMakeLists.txt</strong>加入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) </span><br><span class="line"></span><br><span class="line">SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;)</span><br><span class="line">SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</span><br></pre></td></tr></table></figure>

<p>重新编译：在build里：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cmake clean ..</span></span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug ..</span><br><span class="line">cmake  -DCMAKE_BUILD_TYPE=Debug --build .</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>然后在Libtorch下调试：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cgdb build/bin/decoder_main</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后在界面中打断点：比如</span> </span><br><span class="line">b asr_decoder.cc:194</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">无tlg</span></span><br><span class="line">run  --chunk_size -1 --wav_scp /home/yelong/data/wenet/examples/aishell/s0/data/xueyuan/wav.scp.1 --model_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/final.zip --unit_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang.char.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">不调试运行就是：</span></span><br><span class="line">./build/bin/decoder_main --chunk_size -1 --wav_scp /home/yelong/data/wenet/examples/aishell/s0/data/xueyuan/wav.scp.1 --model_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/final.zip --unit_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang.char.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">要打印n_best：加 --output_nbest <span class="literal">true</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tlg</span></span><br><span class="line">run --acoustic_scale 5 --beam 15.0 --lattice_beam 7.5 --max_active 7000 --ctc_weight 1 --rescoring_weight 0 --chunk_size -1  --fst_path /data_local/yelong/wenet/examples/aishell/s0/exp/aban-c009/lang_test_aban-c009_lin/TLG.fst  --wav_scp /home/yelong/data/wenet/examples/aishell/s0/data/xueyuan/wav.scp.1 --model_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/final.zip  --dict_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang_test_aban-c009_lin/words.txt --unit_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang_test_aban-c009_lin/units.txt</span><br><span class="line"></span><br><span class="line">run --acoustic_scale 5 --beam 15.0 --lattice_beam 7.5 --max_active 7000 --ctc_weight 1 --rescoring_weight 0 --chunk_size -1  --fst_path /data_local/yelong/wenet/examples/aishell/s0/exp/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/TLG.fst  --wav_scp /home/yelong/data/wenet/examples/aishell/s0/data/xueyuan/wav.scp.1 --model_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/final.zip  --dict_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/words.txt --unit_path /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/units.txt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><p>172.17.84.128:root@067224ac4999:&#x2F;home&#x2F;newest_wenet&#x2F;wenet&#x2F;</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /home/newest_wenet/wenet/runtime/LibTorch/</span><br><span class="line">gdb build/bin/decoder_main</span><br><span class="line">run --acoustic_scale 5 --beam 20.0 --lattice_beam 7.5 --max_active 7000 --ctc_weight 1 --rescoring_weight 0 --chunk_size -1 --blank_skip_thresh 0.98 --fst_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/TLG.fst --wav_scp /home/data/yelong/docker_seewo/corpus/seewo/wav.scp --model_path /home/aban-c009/final.zip --dict_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/words.txt --unit_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/units.txt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">run --acoustic_scale 5 --beam 20.0 --lattice_beam 7.5 --max_active 7000 --ctc_weight 1 --rescoring_weight 0 --chunk_size -1 --blank_skip_thresh 0.98 --fst_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/TLG.fst --wav_scp /home/data/yelong/docker_seewo/corpus/200/wav.scp.1 --model_path /home/aban-c009/final.zip --dict_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/words.txt --unit_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_hua_lexicon_eng/units.txt</span><br><span class="line"></span><br><span class="line">./build/bin/decoder_main --acoustic_scale 5 --beam 20.0 --lattice_beam 7.5 --max_active 7000 --ctc_weight 1 --rescoring_weight 0 --chunk_size -1 --blank_skip_thresh 0.98 --fst_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_30w_2017_seewo_eng_word_new/TLG.fst --wav_scp /home/data/yelong/docker_seewo/corpus/200/wav.scp.1 --model_path /home/aban-c009/final.zip --dict_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_30w_2017_seewo_eng_word_new/words.txt --unit_path /home/aban-c009/lang_test_aban-c009_ngram_7g_train_30w_2017_seewo_eng_word_new/units.txt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">no tlg</span></span><br><span class="line">./build/bin/decoder_main --chunk_size -1 --wav_scp /home/data/yelong/docker_seewo/corpus/200/wav.scp.1  --model_path /home/aban-c009/final.zip --unit_path /home/aban-c009/lang.char.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="core-x2F-decoder-x2F-params-h"><a href="#core-x2F-decoder-x2F-params-h" class="headerlink" title="core&#x2F;decoder&#x2F;params.h"></a>core&#x2F;decoder&#x2F;params.h</h2><h3 id="参数解释："><a href="#参数解释：" class="headerlink" title="参数解释："></a>参数解释：</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">DEFINE_double(beam, 16.0, &quot;beam in ctc wfst search&quot;);</span><br><span class="line">DEFINE_double(lattice_beam, 10.0, &quot;lattice beam in ctc wfst search&quot;);</span><br><span class="line">DEFINE_double(acoustic_scale, 1.0, &quot;acoustic scale for ctc wfst search&quot;);	# 这个是乘在am分数上的， graph_cost是语言模型分数，acoustic_cost是am*acoustic_scale得到的缩放声学分数，因此如果这个很大，总体分数会很高，但是声学模型作用会比语言模型大，这个是合理的，和kaldi的希望缩放因子是作用在lm上的不同，这里是作用在am上的</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">比如acoustic_scale = 1：graph_cost = 15.0703125, acoustic_cost = 32.8631744</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">比如acoustic_scale = 20：graph_cost = 15.0703125, acoustic_cost = 657.263489</span></span><br><span class="line">DEFINE_int32(nbest, 10, &quot;nbest for ctc wfst or prefix search&quot;);</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">读模型 model-&gt;Read(FLAGS_model_path); 进入core/decoder/torch_asr_model.cc的void TorchAsrModel::Read(const std::string&amp; model_path) &#123;</span><br><span class="line"></span><br><span class="line">decoder/asr_decoder.cc的void AsrDecoder::Rescoring() &#123;</span><br><span class="line"></span><br><span class="line">模型前向过程（输入声学特征，出来ctc的分类概率）这里用到的是libtorch，就是把特征转成torch格式，送给模型，模型得到输出</span><br><span class="line"></span><br><span class="line">core/bin/decoder_main.cc ： wenet::DecodeState state = decoder.Decode();跳到core/decoder/asr_decoder.cc的DecodeState AsrDecoder::Decode(bool block) &#123;跳到DecodeState AsrDecoder::AdvanceDecoding(bool block) &#123; </span><br><span class="line"></span><br><span class="line">跳到core/decoder/asr_model.cc的 void AsrModel::ForwardEncoder( 跳到 core/decoder/torch_asr_model.cc的void TorchAsrModel::ForwardEncoderFunc(</span><br><span class="line"></span><br><span class="line">得到encoder输出：</span><br><span class="line"></span><br><span class="line">auto outputs =</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   model_-&gt;</span><span class="language-bash">get_method(<span class="string">&quot;forward_encoder_chunk&quot;</span>)(inputs).toTuple()-&gt;elements();</span></span><br><span class="line"></span><br><span class="line">得到ctc_log_probs：</span><br><span class="line"></span><br><span class="line">torch::Tensor ctc_log_probs =</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">   model_-&gt;</span><span class="language-bash">run_method(<span class="string">&quot;ctc_activation&quot;</span>, chunk_out).toTensor()[0];</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">返回core/decoder/asr_model.cc的model_-&gt;ForwardEncoder(chunk_feats, &amp;ctc_log_probs);得到ctc_log_probs的维度是362（T/4），11755（V）</span><br><span class="line"></span><br><span class="line">进入解码模块：searcher_-&gt;Search(ctc_log_probs); 跳到core/decoder/ctc_wfst_beam_search.cc的void CtcWfstBeamSearch::Search(const std::vector&lt;std::vector&lt;float&gt;&gt;&amp; logp) &#123;</span><br><span class="line"></span><br><span class="line">      // Get the best symbol</span><br><span class="line">      int cur_best =</span><br><span class="line">          std::max_element(logp[i].begin(), logp[i].end()) - logp[i].begin();？</span><br><span class="line"></span><br><span class="line">跳到decoder/lattice-faster-decoder.cc的void LatticeFasterDecoderTpl&lt;FST, Token&gt;::AdvanceDecoding(</span><br><span class="line">runeActiveTokens(config_.lattice_beam * config_.prune_scale);跳到core/kaldi/decoder/lattice-faster-decoder.cc的void LatticeFasterDecoderTpl&lt;FST, Token&gt;::PruneActiveTokens(BaseFloat delta) &#123;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">best path：</span></span><br><span class="line">core/decoder/ctc_wfst_beam_search.cc 的 decoder_.GetBestPath(&amp;lat, false);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">core/decoder/asr_decoder.ccd searcher_-&gt;Likelihood()</span><br><span class="line">/core/bin/decoder_main.cc：decoder.Rescoring();//做attention rescore</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>kaldi&#x2F;decoder&#x2F;lattice-faster-decoder.cc</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$\large c\in \mathbb R^&#123;F\times n&#125;$</span><br><span class="line"></span><br><span class="line">$\large x_i\in \mathbb R^&#123;F\times 1&#125;$</span><br><span class="line"></span><br><span class="line">设置输出log多还是少</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">export GLOG_logtostderr=1</span><br><span class="line">export GLOG_v=2	# 这里数值越大，当代码里的值小于该值，就输出log</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>decoder_main修改blank概率</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/decoder_main%E4%BF%AE%E6%94%B9blank%E6%A6%82%E7%8E%87/</url>
    <content><![CDATA[<h1 id="修改blank概率"><a href="#修改blank概率" class="headerlink" title="修改blank概率"></a>修改blank概率</h1><blockquote>
<p>孙思宁 知乎 <a href="https://zhuanlan.zhihu.com/p/531934889">Tiny-Transducer（1） 设备端轻量级ASR模型</a></p>
</blockquote>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><ol>
<li><strong>只对最大概率为非blank的帧进行解码</strong></li>
</ol>
<blockquote>
<p>不过由于Transducer模型的特性，大多数帧的输出都是blank概率占绝对优势的，因此在解码的时候，完全可以跳过这些帧，只把最大概率为nonblank的帧的后验送给解码器即可，这样，解码器从时间同步变成了音素同步了，极大的减少了解码的步数而不带来任何损失，但解码效率能提高很多！</p>
</blockquote>
<ol start="2">
<li><strong>送进去解码的后验概率向量中，把blank概率减去一个值，对blank进行抑制来减少删除错误（识别为blank空，删除错误）</strong></li>
</ol>
<blockquote>
<p>每一步都需要对blank的概率进行抑制，实验中我们发现，如果不对blank的概率进行抑制，模型会过度倾向blank的输出，这样就会导致非常高的删除错误。我们的做法很简单，在对数域上，每一步都需要给blank的概率剪掉一个常数,这里，我们实验发现在我们数据集合上，$β$取1.5或者2.0的时候效果最好。$\log p(blank)&#x3D;\log p(blank)-\beta$</p>
</blockquote>
<ol start="3">
<li><strong>不考虑blank类别，只在非blank类别做beam search</strong></li>
</ol>
<p>实现过程类似方法2，给blank概率一个极小值，比如1000，不好，插入错误很高</p>
<ol start="4">
<li>方法2基础上，<strong>如果blank是最大概率的时候，人为调小，blank不是最大概率，不用调</strong></li>
</ol>
<p>适当减少送入解码器的帧数（通过blank阈值，blank概率很高就不送，blank概率中等偏高还是要送的，因为包含了可能其他类别的可能性，只有很有把握，才不送），送进去时，已知可能是某一个概率较小的类别，因此把blank概率人为调小（如果blank是最大概率的时候，人为调小，blank不是最大概率，不用调）</p>
<ol start="5">
<li>[TODO]</li>
</ol>
<blockquote>
<p>在Transducer的Greedy search时，使用了ILME，无论是在大模型还是小模型，都能带来收益，</p>
</blockquote>
<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><ol>
<li>只单独用方法1，效果不好，因为有些帧最大概率就是blank，该帧其他概率包含识别文本，不把这一帧送入解码器的话，那帧结果永远别想出来；因此方法1有问题</li>
<li>删除错误变少，有提升</li>
<li>方法3和方法2类似，插入替换错误很高，强行在不是blank的地方让它去搜索，结果就是容易有插入错误；</li>
<li>比方法2提升多一点</li>
</ol>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><h4 id="解码测试集"><a href="#解码测试集" class="headerlink" title="解码测试集"></a>解码测试集</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解码</span></span><br><span class="line">export GLOG_logtostderr=1</span><br><span class="line">export GLOG_v=3</span><br><span class="line"></span><br><span class="line">langname=ngram_7g_train_en_zh_hua_lexicon</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker：067：</span></span><br><span class="line">./tools/decode.sh --nj 40 --acoustic_scale 10 --lattice_beam 30 --max_active 7000 --ctc_weight 0.05 --rescoring_weight 1 --chunk_size -1  --blank_skip_thresh 0.98 --dict_path /home/aban-c009/lang_aban-c009_$langname/words.txt --fst_path /home/aban-c009/lang_aban-c009_$langname/TLG.fst  /home/data/yelong/docker_seewo/corpus/200/doc/wav.scp /home/data/yelong/docker_seewo/corpus/200/doc/text /home/aban-c009/final.zip  /home/aban-c009/lang_aban-c009_$langname/units.txt exp/aban-c009/200.8/lm_10_attention_rescore</span><br></pre></td></tr></table></figure>



<p>5gram的RTF更快（结点的出边更少）但是加载TLG特别耗时，5gram的TLG是3gram的10多倍</p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>kaldi实现迁移学习</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="kaldi实现迁移学习"><a href="#kaldi实现迁移学习" class="headerlink" title="kaldi实现迁移学习"></a>kaldi实现迁移学习</h1><blockquote>
<p>speechhome 课程 Kaldi语音识别理论与实践 石颖 第9节 <a href="https://edu.speechhome.com/p/t_pc/course_pc_detail/video/v_632490ece4b050af23b7c9e2">https://edu.speechhome.com/p/t_pc/course_pc_detail/video/v_632490ece4b050af23b7c9e2</a></p>
</blockquote>
<p>两种方式的迁移学习：</p>
<ol>
<li>较多训练数据训练好的模型的参数作为初始模型参数，更新 其他领域数据&#x2F;新模型结构（只有一些层不一样）的模型参数。</li>
<li>固定训练好的模型的大部分参数，只更新部分层（新领域数据特别特别少时，用该方法）</li>
</ol>
<h2 id="方法1实现："><a href="#方法1实现：" class="headerlink" title="方法1实现："></a>方法1实现：</h2><p>以最后一层不一样举例，要调整最后一层结构，变成想要的输出维度。</p>
<h3 id="步骤1-把初始模型的输出维度更换成想要的维度："><a href="#步骤1-把初始模型的输出维度更换成想要的维度：" class="headerlink" title="步骤1. 把初始模型的输出维度更换成想要的维度："></a>步骤1. 把初始模型的输出维度更换成想要的维度：</h3><p><strong>思路：</strong>准备一个config文件，只保留输出维度相关的component（其他component都不要），然后用该config文件重新初始化模型，这时候旧模型的输出component会被新config里的component覆盖，旧模型其余会保留；</p>
<p><strong>做法：</strong>打开config文件，手动删除其他component，只保留输出维度相关的component</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20221009181943628.png" alt="image-20221009181943628"></p>
<p>然后在vim中输入 <code>:%s/旧维度/新维度/g</code>进行替换，就是把config里的比如输出维度4368换成2000。</p>
<p>然后在命令行输入：<code>nnet3-init final.mdl final.config final.change.output_dim.mdl</code></p>
<p>就可以了。</p>
<h3 id="步骤2-用新模型作为初始模型，在新数据集上进行训练："><a href="#步骤2-用新模型作为初始模型，在新数据集上进行训练：" class="headerlink" title="步骤2. 用新模型作为初始模型，在新数据集上进行训练："></a>步骤2. 用新模型作为初始模型，在新数据集上进行训练：</h3><p>在 run.sh中的 <code>steps/nnet3/chain/train.py --trainer.input-model final.change.output_dim.mdl</code></p>
<h2 id="方法2实现："><a href="#方法2实现：" class="headerlink" title="方法2实现："></a>方法2实现：</h2><p>固定某些层参数名</p>
<p>第一种粗暴的方法：打开mdl.txt，将component的名称手动更改为Fixed的component</p>
<p>比如把<AffineComponent>改为<FixedAffineComponent></FixedAffineComponent></AffineComponent></p>
<p>但是这样要改的地方很多。</p>
<p>第二种方法 【推荐】：</p>
<p>新建一个config文件（文件的第一个字段是要进行哪种操作，第二个字段是这个操作要应用在哪个component上）</p>
<p>该图的意思是对tdnn1-5层的仿射变换层更改为参数不可变的仿射变换层。</p>
<p>（比如保存在fix_config&#x2F;edit_config）</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20221009182908327.png" alt="image-20221009182908327"></p>
<p>然后在命令行输入：<code>nnet3-copy --edits-config=fix_config/edit_config --binary=false final.raw final.fix.tdnn1-5.raw</code></p>
<p>然后在 run.sh中的 <code>steps/nnet3/chain/train.py --trainer.input-model final.fix.tdnn1-5.raw</code></p>
<hr>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20221009183631092.png" alt="image-20221009183631092" style="zoom:80%;">

]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>kaldi chain</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/</url>
    <content><![CDATA[<h1 id="kaldi-chain"><a href="#kaldi-chain" class="headerlink" title="kaldi chain"></a>kaldi chain</h1><h3 id="生成phone的语言模型lm，为了分母hclg-lattice服务："><a href="#生成phone的语言模型lm，为了分母hclg-lattice服务：" class="headerlink" title="生成phone的语言模型lm，为了分母hclg lattice服务："></a>生成phone的语言模型lm，为了分母hclg lattice服务：</h3><p>chain_lib.create_phone_lm(args.dir, args.tree_dir, run_opts, lm_opts&#x3D;args.lm_opts)</p>
<p>exp7&#x2F;chain&#x2F;tdnn&#x2F;log&#x2F;make_phone_lm.log：</p>
<p>gunzip -c exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.1.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.2.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.3.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.4.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.5.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.6.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.7.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.8.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.9.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.10.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.11.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.12.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.13.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.14.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.15.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.16.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.17.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.18.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.19.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.20.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.21.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.22.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.23.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.24.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.25.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.26.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.27.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.28.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.29.gz exp7&#x2F;chain&#x2F;tri5_tree&#x2F;ali.30.gz | ali-to-phones exp7&#x2F;chain&#x2F;tri5_tree&#x2F;final.mdl ark:- ark:- | chain-est-phone-lm –num-extra-lm-states&#x3D;2000 ark:- exp7&#x2F;chain&#x2F;tdnn&#x2F;phone_lm.fst</p>
<h3 id="生成分母lattice"><a href="#生成分母lattice" class="headerlink" title="生成分母lattice"></a>生成分母lattice</h3><p>exp7&#x2F;chain&#x2F;tdnn&#x2F;log&#x2F;make_den_fst.log：</p>
<p>chain-make-den-fst exp7&#x2F;chain&#x2F;tdnn&#x2F;tree exp7&#x2F;chain&#x2F;tdnn&#x2F;0.trans_mdl exp7&#x2F;chain&#x2F;tdnn&#x2F;phone_lm.fst exp7&#x2F;chain&#x2F;tdnn&#x2F;den.fst exp7&#x2F;chain&#x2F;tdnn&#x2F;normalization.fst</p>
<p>den.fst ：</p>
<ul>
<li>第一列 ：输入结点（结点，也叫fst的状态数），G 3gram phone 状态（0-3475，一共3476个）；</li>
<li>第二列 ：输出结点，G 3gram phone 状态（0-3474，一共3475个）；（hmm_state？？？？chain&#x2F;chain-den-graph.cc）</li>
<li>第三列：in label：H pdf 状态（1-2392，一共2392个，原本pdf是0-2391的（pdf包含forward-pdf 和self-loop-pdf））（下面的例子用的tdnn_3、tdnn_4的模型，pdf 1976个）</li>
<li>第四列：out label：H pdf 状态</li>
<li>in label和out label相同</li>
<li>den.fst的结点是G空间，上面的分数是声学分数？语言分数？</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3475    1516    1       1       8.70407677</span><br><span class="line">3475    3011    1       1       15.0414305</span><br><span class="line">3475    198     1       1       9.42041969</span><br><span class="line">3475    318     1       1       9.59932804</span><br><span class="line">3475    271     1       1       10.1355295</span><br><span class="line">3475    99      1       1       8.69728088</span><br><span class="line">3475    689     1       1       10.1195202</span><br><span class="line">3475    3368    1       1       16.4325008</span><br><span class="line">3475    2406    1       1       13.7536497</span><br><span class="line">3475    914     1       1       10.7855644</span><br></pre></td></tr></table></figure>



<h3 id="计算loss脚本："><a href="#计算loss脚本：" class="headerlink" title="计算loss脚本："></a>计算loss脚本：</h3><p>exp7&#x2F;chain&#x2F;tdnn&#x2F;log&#x2F;compute_prob_valid.1.log：</p>
<p>nnet3-chain-compute-prob –l2-regularize&#x3D;0.0 –leaky-hmm-coefficient&#x3D;0.1 –xent-regularize&#x3D;0.1 exp7&#x2F;chain&#x2F;tdnn_3&#x2F;final.mdl exp7&#x2F;chain&#x2F;tdnn_3&#x2F;den.fst ‘ark,bg:nnet3-chain-copy-egs  ark:exp7&#x2F;chain&#x2F;tdnn_4&#x2F;egs&#x2F;train_diagnostic.cegs ark:- | nnet3-chain-merge-egs –minibatch-size&#x3D;1:64 ark:- ark:- |’</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nnet3-chain-merge-egs --minibatch-size=1:64 ark:- ark:-</span><br><span class="line">nnet3-chain-copy-egs ark:exp7/chain/tdnn/egs/valid_diagnostic.cegs ark:-</span><br><span class="line">LOG (nnet3-chain-copy-egs[5.5.591~43-fa0934]:main():nnet3-chain-copy-egs.cc:395) Read 400 neural-network training examples, wrote 400</span><br><span class="line">LOG (nnet3-chain-merge-egs[5.5.591~43-fa0934]:PrintSpecificStats():nnet-example-utils.cc:1143) Merged specific eg types as follows [format: &lt;eg-size1&gt;=&#123;&lt;mb-size1&gt;-&gt;&lt;num-minibatches1&gt;,&lt;mbsize2&gt;-&gt;&lt;num-minibatches2&gt;.../d=&lt;num-discarded&gt;&#125;,&lt;egs-size2&gt;=&#123;...&#125;,... (note,egs-size == number of input frames including context).</span><br><span class="line">LOG (nnet3-chain-merge-egs[5.5.591~43-fa0934]:PrintSpecificStats():nnet-example-utils.cc:1173) 152=&#123;44-&gt;1,d=0&#125;,173=&#123;40-&gt;1,d=0&#125;,212=&#123;60-&gt;1,64-&gt;4,d=0&#125;</span><br><span class="line">LOG (nnet3-chain-merge-egs[5.5.591~43-fa0934]:PrintAggregateStats():nnet-example-utils.cc:1139) Processed 400 egs of avg. size 201.5 into 7 minibatches, discarding 0% of egs.  Avg minibatch size was 57.14, #distinct types of egs/minibatches was 3/4</span><br><span class="line">LOG (nnet3-chain-compute-prob[5.5.591~43-fa0934]:PrintTotalStats():nnet-chain-diagnostics.cc:194) Overall log-probability for &#x27;output-xent&#x27; is -3.05123 per frame, over 18600 frames.</span><br><span class="line">LOG (nnet3-chain-compute-prob[5.5.591~43-fa0934]:PrintTotalStats():nnet-chain-diagnostics.cc:194) Overall log-probability for &#x27;output&#x27; is -0.328318 per frame, over 18600 frames.</span><br><span class="line">LOG (nnet3-chain-compute-prob[5.5.591~43-fa0934]:~CachingOptimizingCompiler():nnet-optimize.cc:710) 0.323 seconds taken in nnet3 compilation total (breakdown: 0.139 compilation, 0.00658 optimization, 0.17 shortcut expansion, 0.00139 checking, 3.81e-05 computing indexes, 0.00598 misc.) + 0 I/O.</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<blockquote>
<p><a href="https://bbs.huaweicloud.com/blogs/detail/180841">kaldi语音识别 chain模型的数据准备</a></p>
</blockquote>
<p>normalization.fst在分母有限状态机den.fst的基础上，修改了初始概率和终止概率得到的。</p>
<h3 id="查看-cegs内容："><a href="#查看-cegs内容：" class="headerlink" title="查看 cegs内容："></a>查看 cegs内容：</h3><p>nnet3-chain-copy-egs ark:exp7&#x2F;chain&#x2F;tdnn_4&#x2F;egs&#x2F;train_diagnostic.cegs ark,t:1</p>
<ul>
<li>由于chain模型采用跳帧策略，所以egs中存储的是三倍下采样后输出索引</li>
<li>分子lattice。WFSA结构。用于计算MMI，第三列、第四列是pdf的id（1-1975）</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211012143307127.png" alt="image-20211012143307127"></p>
<ul>
<li>强制对齐结果，用于计算交叉熵？？实际用上了吗？代码中交叉熵也是用的前后向计算的，没有用这个</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211012143412126.png" alt="image-20211012143412126"></p>
<h3 id="计算loss代码："><a href="#计算loss代码：" class="headerlink" title="计算loss代码："></a>计算loss代码：</h3><p><code>nnet3-chain-compute-prob --l2-regularize=0.0 --leaky-hmm-coefficient=0.1 --xent-regularize=0.1 exp7/chain/tdnn_3/final.mdl exp7/chain/tdnn_3/den.fst ark:1</code></p>
<blockquote>
<p><a href="https://www.cnblogs.com/JarvanWang/p/10281089.html">kaldi chain模型的序列鉴别性训练代码分析</a> jarvanWang博客园</p>
<p><a href="https://www.cnblogs.com/JarvanWang/p/10145889.html">Chain训练准则的计算</a> jarvanWang博客园</p>
</blockquote>
<p>跳转路线：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">chainbin/nnet3-chain-compute-prob.cc 的 chain_prob_computer.<span class="built_in">Compute</span>(example_reader.<span class="built_in">Value</span>());</span><br><span class="line"></span><br><span class="line">nnet3/nnet-chain-diagnostics.cc 的 <span class="keyword">this</span>-&gt;<span class="built_in">ProcessOutputs</span>(chain_eg, &amp;computer);  </span><br><span class="line"></span><br><span class="line">nnet3/nnet-chain-diagnostics.cc 的    <span class="built_in">ComputeChainObjfAndDeriv</span>(chain_config_, den_graph_,</span><br><span class="line">                             sup.supervision, nnet_output,</span><br><span class="line">                             &amp;tot_like, &amp;tot_l2_term, &amp;tot_weight,</span><br><span class="line">                             (nnet_config_.compute_deriv ? &amp;nnet_output_deriv :</span><br><span class="line">                              <span class="literal">NULL</span>), (use_xent ? &amp;xent_deriv : <span class="literal">NULL</span>));</span><br><span class="line">chain/chain-training.cc 的 <span class="function">ComputeChainObjfAndDerivE2e</span></span><br><span class="line"><span class="function">    DenominatorComputation <span class="title">denominator</span><span class="params">(opts, den_graph,supervision.num_sequences,nnet_output)</span></span>;<span class="comment">//得到objf（loss）</span></span><br><span class="line"><span class="comment">//分母计算：</span></span><br><span class="line">den_logprob_weighted = supervision.weight * denominator.<span class="built_in">Forward</span>();</span><br><span class="line">chain/chain-denominator.cc的<span class="function">BaseFloat <span class="title">DenominatorComputation::Forward</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">//分子计算：</span></span><br><span class="line">    numerator_ok = numerator.<span class="built_in">ForwardBackward</span>(&amp;num_logprob_weighted,</span><br><span class="line">                                               xent_output_deriv);</span><br></pre></td></tr></table></figure>

<p>nnet_output：dnn输出</p>
<p>chain&#x2F;chain-training.cc</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Supervision &amp;supervision</span><br><span class="line">DenominatorGraph &amp;den_graph</span><br></pre></td></tr></table></figure>

<h3 id="初始化："><a href="#初始化：" class="headerlink" title="初始化："></a>初始化：</h3><p>NnetChainComputeProb chain_prob_computer(nnet_opts, chain_opts, den_fst,nnet);</p>
<p>chain&#x2F;chain-supervision.h：可以看见类Supervision的详细定义与Supervision的成员解释</p>
<ul>
<li>Supervision类：<ul>
<li>label_dim：pdf数量</li>
<li>fst：按帧index排序</li>
</ul>
</li>
</ul>
<p>chain&#x2F;chain-den-graph.h：可以看见类DenominatorGraph的成员定义</p>
<ul>
<li>DenominatorGraph类：<ul>
<li>ForwardTransitions </li>
<li>BackwardTransitions </li>
<li>Transitions</li>
</ul>
</li>
</ul>
<p>chain&#x2F;chain-den-graph.cc：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">DenominatorGraph::SetTransitions</span><span class="params">(<span class="type">const</span> fst::StdVectorFst &amp;fst,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      int32 num_pdfs)</span> </span>&#123;</span><br><span class="line">  int32 num_states = fst.<span class="built_in">NumStates</span>();</span><br><span class="line"></span><br><span class="line">  std::vector&lt;std::vector&lt;DenominatorGraphTransition&gt; &gt;</span><br><span class="line">      <span class="built_in">transitions_out</span>(num_states),</span><br><span class="line">      <span class="built_in">transitions_in</span>(num_states);</span><br><span class="line">  <span class="keyword">for</span> (int32 s = <span class="number">0</span>; s &lt; num_states; s++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (fst::ArcIterator&lt;fst::StdVectorFst&gt; <span class="built_in">aiter</span>(fst, s); !aiter.<span class="built_in">Done</span>();</span><br><span class="line">         aiter.<span class="built_in">Next</span>()) &#123;</span><br><span class="line">      <span class="type">const</span> fst::StdArc &amp;arc = aiter.<span class="built_in">Value</span>();</span><br><span class="line">      DenominatorGraphTransition transition;</span><br><span class="line">      transition.transition_prob = <span class="built_in">exp</span>(-arc.weight.<span class="built_in">Value</span>());</span><br><span class="line">      transition.pdf_id = arc.ilabel - <span class="number">1</span>;</span><br><span class="line">      transition.hmm_state = arc.nextstate;</span><br><span class="line">      <span class="built_in">KALDI_ASSERT</span>(transition.pdf_id &gt;= <span class="number">0</span> &amp;&amp; transition.pdf_id &lt; num_pdfs);</span><br><span class="line">      transitions_out[s].<span class="built_in">push_back</span>(transition);</span><br><span class="line">      <span class="comment">// now the reverse transition.</span></span><br><span class="line">      transition.hmm_state = s;</span><br><span class="line">      transitions_in[arc.nextstate].<span class="built_in">push_back</span>(transition);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">std::vector&lt;Int32Pair&gt; <span class="title">forward_transitions</span><span class="params">(num_states)</span></span>;</span><br><span class="line">  <span class="function">std::vector&lt;Int32Pair&gt; <span class="title">backward_transitions</span><span class="params">(num_states)</span></span>;</span><br><span class="line">  std::vector&lt;DenominatorGraphTransition&gt; transitions;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (int32 s = <span class="number">0</span>; s &lt; num_states; s++) &#123;</span><br><span class="line">    forward_transitions[s].first = <span class="built_in">static_cast</span>&lt;int32&gt;(transitions.<span class="built_in">size</span>());</span><br><span class="line">    transitions.<span class="built_in">insert</span>(transitions.<span class="built_in">end</span>(), transitions_out[s].<span class="built_in">begin</span>(),</span><br><span class="line">                       transitions_out[s].<span class="built_in">end</span>());</span><br><span class="line">    forward_transitions[s].second = <span class="built_in">static_cast</span>&lt;int32&gt;(transitions.<span class="built_in">size</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (int32 s = <span class="number">0</span>; s &lt; num_states; s++) &#123;</span><br><span class="line">    backward_transitions[s].first = <span class="built_in">static_cast</span>&lt;int32&gt;(transitions.<span class="built_in">size</span>());</span><br><span class="line">    transitions.<span class="built_in">insert</span>(transitions.<span class="built_in">end</span>(), transitions_in[s].<span class="built_in">begin</span>(),</span><br><span class="line">                       transitions_in[s].<span class="built_in">end</span>());</span><br><span class="line">    backward_transitions[s].second = <span class="built_in">static_cast</span>&lt;int32&gt;(transitions.<span class="built_in">size</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  forward_transitions_ = forward_transitions;</span><br><span class="line">  backward_transitions_ = backward_transitions;</span><br><span class="line">  transitions_ = transitions;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>den.fst：（这里把fst权重转换为exp-）<code>fstprint den.fst | awk -F&#39;\t&#39; &#39;&#123;$NF=exp(-$NF);print$0&#125;&#39; | tr &#39; &#39; &#39;\t&#39; </code></li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211013153727170.png" alt="image-20211013153727170"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211013153656637.png" alt="image-20211013153656637"></p>
<ul>
<li>transitions_out ：transitions_out索引是den.fst的第一列，因此表示这个结点状态辐射出多少条路径的意思</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211013153537767.png" alt="image-20211013153537767"></p>
<p>​	</p>
<ul>
<li>transitions_in ：transitions_in索引是den.fst的第二列，因此表示多少条路径到这个结点状态的意思</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211013143601942.png" alt="image-20211013143601942"></p>
<p>​		</p>
<ul>
<li>transitions ：按顺序把transitions_out内容和transitions_in 全放到transitions里</li>
<li>forward_transitions ：transitions_out每个结点状态的初始数量和辐射出边的数量</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211013160335326.png" alt="image-20211013160335326"></p>
<ul>
<li>backward_transitions 内容：接完transitions_out全部后，transitions_in每个结点状态的初始数量和到这个结点边的数量</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211013160653298.png" alt="image-20211013160653298"></p>
<p>只求loss时，也会用到前后向算法（chain&#x2F;chain-training.cc:denominator.Forward()）</p>
<p>$\alpha$ 的概率，依赖声学分数（nnet_output（pdf数*帧数））和语言分数，因为里面的状态是G空间的状态</p>
<p>chain&#x2F;chain-denominator.cc：赋予$\alpha$ 值</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">BaseFloat <span class="title">DenominatorComputation::Forward</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">NVTX_RANGE</span>(__func__);</span><br><span class="line">  <span class="built_in">AlphaFirstFrame</span>(); <span class="comment">//初始权重</span></span><br><span class="line">  <span class="built_in">AlphaDash</span>(<span class="number">0</span>);</span><br><span class="line">  <span class="keyword">for</span> (int32 t = <span class="number">1</span>; t &lt;= frames_per_sequence_; t++) &#123;</span><br><span class="line">    <span class="built_in">AlphaGeneralFrame</span>(t);</span><br><span class="line">    <span class="built_in">AlphaDash</span>(t);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">ComputeTotLogLike</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">frames_per_sequence_ = 30</span><br><span class="line">den_graph_.NumStates() = 3221</span><br><span class="line">alpha_(frames_per_sequence_ + 1,den_graph_.NumStates() * num_sequences_ + num_sequences_,kUndefined),</span><br><span class="line"></span><br><span class="line">alpha_： num_cols_ = 3222, num_rows_ = 31, stride_ = 3224</span><br></pre></td></tr></table></figure>

<p>alpha(t, i)对应前后向算法中的$\alpha$（$\alpha_t(i)$定义：到时刻t，部分观测序列为$o_1,o_2….,o_t$且状态为i的概率为前向概率）</p>
<p>beta(t, i)对应前后向算法中的$\beta$（$\beta_t(i)$定义：到时刻t，状态i，部分观测序列为$o_{t+1},o_{t+2},…,o_T$的概率为后向概率）</p>
<p>gamma(t, n) （$\gamma_t(i)$定义：给定模型和观测序列，在时刻t处于状态i的概率$\large{\gamma_t(i)&#x3D;\frac{\alpha_t(i)\beta_t(i)}{\sum\limits_{j&#x3D;1}^N\alpha_t(j)\beta_t(j)}}$）</p>
<p>chain&#x2F;chain-datastruct.h：</p>
<p>后面计算alpha就是用到这个三元组，hmm_state知道哪个状态结点（要遍历的），pdf就知道对应哪个发射概率，transition_prob对应语言模型概率</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">DenominatorGraphTransition</span> &#123;</span><br><span class="line">  BaseFloat transition_prob;  <span class="comment">// language-model part of the probability (not</span></span><br><span class="line">                              <span class="comment">// in log)</span></span><br><span class="line">  int32_cuda pdf_id;   <span class="comment">// pdf-id on the transition.</span></span><br><span class="line">  int32_cuda hmm_state;  <span class="comment">// source, or destination, HMM state.</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>前后向算法里面的转移概率是语言模型概率</p>
<ul>
<li>loss，用前后向算法得到loss值</li>
</ul>
<p>分母前向alpha计算：chain&#x2F;chain-denominator.cc</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">int32 prob_stride = probs.<span class="built_in">Stride</span>(); <span class="comment">//yl:probs.Stride()是帧数</span></span><br><span class="line"><span class="keyword">for</span> (int32 h = <span class="number">0</span>; h &lt; num_hmm_states; h++)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (int32 s = <span class="number">0</span>; s &lt; num_sequences; s++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">double</span> this_tot_alpha = <span class="number">0.0</span>;</span><br><span class="line">    <span class="type">const</span> DenominatorGraphTransition</span><br><span class="line">        *trans_iter = transitions + backward_transitions[h].first,</span><br><span class="line">        *trans_end = transitions + backward_transitions[h].second;</span><br><span class="line">    <span class="keyword">for</span> (; trans_iter != trans_end; ++trans_iter)</span><br><span class="line">    &#123;</span><br><span class="line">      BaseFloat transition_prob = trans_iter-&gt;transition_prob;</span><br><span class="line">      int32 pdf_id = trans_iter-&gt;pdf_id,</span><br><span class="line">            prev_hmm_state = trans_iter-&gt;hmm_state;</span><br><span class="line">        <span class="comment">// prob_data 维度是pdf数，之前保存的矩阵是帧数行*pdf列，因此每次取当前帧的pdf值时，stride是帧数，每次跳这么多步，到达同一个时间的下一个pdf数值，取得该同一个时刻的发射概率</span></span><br><span class="line">      BaseFloat prob = prob_data[pdf_id * prob_stride + s],</span><br><span class="line">                this_prev_alpha = prev_alpha_dash[prev_hmm_state * num_sequences + s];</span><br><span class="line">      this_tot_alpha += this_prev_alpha * transition_prob * prob;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Let arbitrary_scale be the inverse of the alpha-sum value that we</span></span><br><span class="line">    <span class="comment">// store in the same place we&#x27;d store the alpha for the state numbered</span></span><br><span class="line">    <span class="comment">// &#x27;num_hmm_states&#x27;. We multiply this into all the</span></span><br><span class="line">    <span class="comment">// transition-probabilities from the previous frame to this frame, in</span></span><br><span class="line">    <span class="comment">// both the forward and backward passes, in order to keep the alphas in</span></span><br><span class="line">    <span class="comment">// a good numeric range.  This won&#x27;t affect the posteriors, but when</span></span><br><span class="line">    <span class="comment">// computing the total likelihood we&#x27;ll need to compensate for it later</span></span><br><span class="line">    <span class="comment">// on.</span></span><br><span class="line">    BaseFloat arbitrary_scale =</span><br><span class="line">        <span class="number">1.0</span> / prev_alpha_dash[num_hmm_states * num_sequences + s];</span><br><span class="line">    <span class="built_in">KALDI_ASSERT</span>(this_tot_alpha - this_tot_alpha == <span class="number">0</span>);</span><br><span class="line">    this_alpha[h * num_sequences + s] = this_tot_alpha * arbitrary_scale;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="分子"><a href="#分子" class="headerlink" title="分子"></a>分子</h2><p>分子loss计算：chain&#x2F;chain-generic-numerator.cc</p>
<p>知道了确定的pdf，三元组的时候就不用遍历所有pdf了，但也要遍历所有G空间状态。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//chain/chain-training.cc：</span></span><br><span class="line"><span class="function">GenericNumeratorComputation <span class="title">numerator</span><span class="params">(opts.numerator_opts,</span></span></span><br><span class="line"><span class="params"><span class="function">                                          supervision, nnet_output)</span></span>;</span><br><span class="line"><span class="comment">//跳到 chain/chain-generic-numerator.cc</span></span><br><span class="line">GenericNumeratorComputation::<span class="built_in">GenericNumeratorComputation</span>(</span><br><span class="line">    supervision_.e2e_fsts[i].<span class="built_in">NumStates</span>() <span class="comment">//fst就是分子lattice的结点数（状态数），对当前这条句子sequence能展开的图 有多少个状态</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//跳回chain/chain-training.cc：   </span></span><br><span class="line">          numerator_ok = numerator.<span class="built_in">ForwardBackward</span>(&amp;num_logprob_weighted,</span><br><span class="line">                                                   xent_output_deriv);    </span><br><span class="line"><span class="comment">//跳到chain/chain-generic-numerator.cc    </span></span><br><span class="line">    <span class="type">bool</span> GenericNumeratorComputation::<span class="built_in">ForwardBackward</span>( <span class="comment">// 计算out_transitions_、in_transitions_</span></span><br><span class="line"><span class="comment">//跳回chain/chain-generic-numerator.cc</span></span><br><span class="line">        <span class="comment">// Forward part</span></span><br><span class="line">        <span class="built_in">AlphaFirstFrame</span>(seq, &amp;alpha[thread]);</span><br><span class="line">        partial_loglike_mt[thread] += <span class="built_in">AlphaRemainingFrames</span>(seq, probs, &amp;alpha[thread]);</span><br><span class="line">        <span class="comment">// Backward part</span></span><br><span class="line">        <span class="built_in">BetaLastFrame</span>(seq, alpha[thread], &amp;beta[thread]);</span><br><span class="line">        <span class="built_in">BetaRemainingFrames</span>(seq, probs, alpha[thread], &amp;beta[thread], &amp;derivs);</span><br></pre></td></tr></table></figure>

<p>chain&#x2F;chain-generic-numerator.cc：</p>
<ul>
<li>out_transitions_：GenericNumeratorComputation的类成员，transition_prob是当前lattice里的权重减去该句子权重最大值，再取负号</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211020161517294.png" alt="image-20211020161517294"></p>
<ul>
<li>in_transitions_：GenericNumeratorComputation的类成员</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%20chain/image-20211020162405339.png" alt="image-20211020162405339"></p>
<ul>
<li>计算$\alpha$，所有lattice上这个状态结点的概率 累加 （概率还包含状态转移和pdf发射）</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> t = <span class="number">1</span>; t &lt;= num_frames; ++t)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">const</span> BaseFloat *probs_tm1 = probs.<span class="built_in">RowData</span>(t - <span class="number">1</span>);</span><br><span class="line">  BaseFloat *<span class="type">alpha_t</span> = alpha-&gt;<span class="built_in">RowData</span>(t);</span><br><span class="line">  <span class="type">const</span> BaseFloat *alpha_tm1 = alpha-&gt;<span class="built_in">RowData</span>(t - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (int32 h = <span class="number">0</span>; h &lt; supervision_.e2e_fsts[seq].<span class="built_in">NumStates</span>(); h++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> tr = in_transitions_[seq][h].<span class="built_in">begin</span>();</span><br><span class="line">         tr != in_transitions_[seq][h].<span class="built_in">end</span>(); ++tr)</span><br><span class="line">    &#123;</span><br><span class="line">      BaseFloat transition_prob = tr-&gt;transition_prob;</span><br><span class="line">      int32 pdf_id = tr-&gt;pdf_id,</span><br><span class="line">            prev_hmm_state = tr-&gt;hmm_state;</span><br><span class="line">      BaseFloat prob = probs_tm1[pdf_id];</span><br><span class="line">      <span class="type">alpha_t</span>[h] = <span class="built_in">LogAdd</span>(<span class="type">alpha_t</span>[h],</span><br><span class="line">                          alpha_tm1[prev_hmm_state] + transition_prob + prob);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">double</span> sum = alpha_tm1[alpha-&gt;<span class="built_in">NumCols</span>() - <span class="number">1</span>];</span><br><span class="line">  <span class="function">SubMatrix&lt;BaseFloat&gt; <span class="title">alpha_t_mat</span><span class="params">(*alpha, t, <span class="number">1</span>, <span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   alpha-&gt;NumCols() - <span class="number">1</span>)</span></span>;</span><br><span class="line">  alpha_t_mat.<span class="built_in">Add</span>(-sum);</span><br><span class="line">  sum = alpha_t_mat.<span class="built_in">LogSumExp</span>();</span><br><span class="line"></span><br><span class="line">  <span class="type">alpha_t</span>[alpha-&gt;<span class="built_in">NumCols</span>() - <span class="number">1</span>] = sum;</span><br><span class="line">  log_scale_product += sum;</span><br><span class="line">&#125;          </span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>kaldi的词典L.fst、L_disambig.fst</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%E7%9A%84%E8%AF%8D%E5%85%B8L.fst/</url>
    <content><![CDATA[<h1 id="kaldi的词典L-fst、L-disambig-fst"><a href="#kaldi的词典L-fst、L-disambig-fst" class="headerlink" title="kaldi的词典L.fst、L_disambig.fst"></a>kaldi的词典L.fst、L_disambig.fst</h1><p>权重：0.693147182</p>
<p>这是概率&#x3D;0.5，这里取-log表示在FST中</p>
<p>$0.693147182&#x3D;-log_e(0.5)$</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/kaldi%E7%9A%84%E8%AF%8D%E5%85%B8L.fst/image-20211230105520591.png" alt="image-20211230105520591" style="zoom:80%;">
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>lattice</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/lattice/</url>
    <content><![CDATA[<h1 id="lattice"><a href="#lattice" class="headerlink" title="lattice"></a>lattice</h1><h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p>词格，用topN中的路径重新生成一个图，这个图就叫lattice，就是在hclg进行解码，然后根据topN的解码结果，取出在hclg具体走的路径，构成的图，可以理解成从hclg只保留所需要的值，大部分无用的信息舍弃，最后是topN的word序列构成的fst；</p>
<blockquote>
<p><a href="https://blog.csdn.net/yutianzuijin/article/details/77621511">语音识别中的lattice与confusion network</a></p>
<p><a href="https://blog.csdn.net/qq_36782366/article/details/102847110">kaldi理解WFST，HCLG，lattice</a></p>
</blockquote>
<h3 id="生成lattice"><a href="#生成lattice" class="headerlink" title="生成lattice"></a>生成lattice</h3><p>在生成one best结果时，只需要从最优结果处回溯，但是为了生成lattice，我们需要保留更多信息。具体就是在生成每一个hist的时候保留多个候选alt，这样在回溯best hist的时候也访问alt来生成lattice。</p>
<p>在lattice上从左向右的任何一条路径，就构成一个识别结果，路径上每条边的声学得分相加，再加上路径对应的语言得分，就是整条路径的得分，通常取得分最大的前 N 条路径对应的词串作为识别的 N-Best 结果输出。上面lattice的生成用的语言模型往往不够精确，通常还需要在lattice上用更大的语言模型进rescore。</p>
<h3 id="lattice含义"><a href="#lattice含义" class="headerlink" title="lattice含义"></a>lattice含义</h3><p>在实际的语音识别系统中，最优路径不一定与实际字序列匹配，我们一般希望能够得到得分最靠前的多条候选路径，即N-best。为了紧凑地保存候选路径，防止占用过多内存空间，我们一般采用lattice（又叫词图）来保存识别的候选序列。lattice本质上是一个有向无环（directed acyclic graph）图。图上的每个节点代表一个词的结束时间点，每条边代表一个可能的词，以及该词发生的声学得分和语言模型得分。<br><img src="/2022/01/04/%E8%AF%86%E5%88%AB/lattice/SouthEast.png" alt="img"></p>
<h3 id="Lattice结构"><a href="#Lattice结构" class="headerlink" title="Lattice结构"></a>Lattice结构</h3><p>FST的形式，weight包括两部分（graph cost和acoustic cost），输入是transition-ids，输出是words。<br>其中weight的graph cost包含LM+transition+pronunciation三部分。</p>
<h3 id="CompactLattice结构"><a href="#CompactLattice结构" class="headerlink" title="CompactLattice结构"></a>CompactLattice结构</h3><p>和lattice相似，区别在于它是接收机FSA，输入和输出一样（都是words），weight包含两部分（权重和transition-ids），相比于Lattice，CompactLattice把输入的transition-ids转移到weight上面。</p>
<p>lattice保证每一个word-sequence只对应lattice中的一条路径。</p>
<h3 id="lattice剪枝"><a href="#lattice剪枝" class="headerlink" title="lattice剪枝"></a>lattice剪枝</h3><p>原始lattice可能会非常庞大，这时我们可以对lattice进行剪枝但是不影响最终的准确率。一种剪枝方法是对lattice进行前后向打分，计算每条边的后验概率，然后删除后验概率很低的边。</p>
<h2 id="confusion-network"><a href="#confusion-network" class="headerlink" title="confusion network"></a>confusion network</h2><p>混淆网络是一种特殊的lattice，由原始lattice经过变换生成。它要求lattice中的每条路径都必须经过所有的节点。如下图所示：</p>
<p><img src="https://img-blog.csdn.net/20170827170427344?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveXV0aWFuenVpamlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img"></p>
<p>简单描述一个近似于srilm中采用的混淆网络生成算法：首先进行前后向概率打分计算每条边的后验概率；其次根据后验概率对lattice进行剪枝；再次从原始lattice中选择一条得分最高的路径当作初始混淆网络（路径中的节点即为混淆网络中的节点）；最后就开始逐步将其他的边对齐添加到上述初始混淆网络中。特别地，如果在添加某条边到某节点中时发现已经有边指向该边并且也添加到该节点之后，则创建一个新的节点，让之前的边都指向新节点，要添加的边则从新节点指向之前的老节点。<br>相比于lattice，我们可以很容易从混淆网络中获取one best结果，只需要从每一段中选择后验概率最大的边即可。混淆网络作为lattice的简化版，会引入原始lattice中不存在的路径。但是通常情况下，用混淆网络获取的one best结果要好于原始的one best。混淆网络还有一个好处，我们可以很容易获取每个时刻相互竞争的词有哪些，怀疑苹果自带的输入法即采用了混淆网络来修改候选词。</p>
<h2 id="kaldi"><a href="#kaldi" class="headerlink" title="kaldi"></a>kaldi</h2><p>生成 lattice 的唯一解码器是定义在 decoder&#x2F;lattice-simple-decoder.h 中的类 LatticeSimpleDecoder，它被 gmm-latgen-simple.cc中调用。</p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>mmi</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/mmi/</url>
    <content><![CDATA[<h1 id="mmi"><a href="#mmi" class="headerlink" title="mmi"></a>mmi</h1><p>Maximum  mutual information </p>
<blockquote>
<p>Bahl L, Brown P, De Souza P, et al. Maximum mutual information estimation of hidden Markov model parameters for speech recognition[C]&#x2F;&#x2F;ICASSP’86. IEEE International Conference on Acoustics, Speech, and Signal Processing. IEEE, 1986, 11: 49-52. citation:1212</p>
<p>csdn blog <a href="https://blog.csdn.net/qq_35742630/article/details/89004890">区分性训练和mmi（一）</a></p>
<p>blog <a href="https://liuyanfeier.github.io/2018/12/16/%E5%8C%BA%E5%88%86%E6%80%A7%E8%AE%AD%E7%BB%83%EF%BC%88Discriminative-Training%EF%BC%89%E5%8F%8A%E5%85%B6%E5%9C%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%EF%BC%88ASR%EF%BC%89%E4%B8%8A%E7%9A%84%E8%BF%90%E7%94%A8/">区分性训练（Discriminative Training）及其在语音识别（ASR）上的运用</a></p>
<p>Chen, Zhehuai, Yanmin Qian, and Kai Yu. “Sequence discriminative training for deep learning based acoustic keyword spotting.” <em>Speech Communication</em> 102 (2018): 100-111.</p>
</blockquote>
<h3 id="GMM与DT"><a href="#GMM与DT" class="headerlink" title="GMM与DT"></a>GMM与DT</h3><ul>
<li><p>GMM-HMM，回顾最大似然准则（Maximum likelihood estimation ）：$F_{ML}&#x3D;\sum_{u&#x3D;1}^UlogP(X_u|W_u;\theta)$</p>
</li>
<li><p>其中，$W_u$是标注序列，$X_u$是语音信号，$\theta$是声学模型参数。</p>
<p>$p(x)&#x3D;\sum_yp(x,y)$</p>
<p>$p(x)&#x3D;\sum_yp(x)p(y)$</p>
</li>
</ul>
<h4 id="最大互信息准则"><a href="#最大互信息准则" class="headerlink" title="最大互信息准则"></a>最大互信息准则</h4><ul>
<li><p>熵：$H(X)\triangleq-\sum_xPr(X&#x3D;x)logPr(X&#x3D;x)$  （ps.$\triangleq$是定义为def的意思）（$P(X&#x3D;x)$也可以直接写成$P(x)$）</p>
</li>
<li><p>互信息 ：$I(X,Y)&#x3D;H(Y)-H(Y|X)$，熵-条件熵，互信息是描述两个随机变量的关联程度，于是在这里就是描述<strong>观测序列和文本的关联程度</strong></p>
</li>
<li><p>条件熵 $H(Y|X)&#x3D;\sum_{x\in{X}}p(x)H(Y|X&#x3D;x)&#x3D;-\sum_{x\in{X}}p(x)\sum_{y\in{Y}}p(y|x)logp(y|x)]&#x3D;-\sum_{x\in{X}}\sum_{y\in{Y}}p(x,y)logp(y|x)$</p>
</li>
<li><p>X,Y是变量，x,y是变量的取值，条件熵是指在给定某个数（某个变量为某个值）的情况下，另一个变量的熵是多少，变量的不确定性是多少？条件熵中X也是一个变量，意思是在一个变量X的条件下（变量X的每个值都会取），另一个变量Y熵对X的期望</p>
</li>
<li><p>我的理解是条件熵越小，相关性越大；或者说互信息越大，相关性越大。</p>
<p>H(Y|X)相当于告诉Y一些已知信息X后Y的熵，对Y加了一些限制条件。所以$H(Y)\geq{H(Y|X)}$，H(Y)就是Y的熵，描述Y的混乱程度，他们的互信息实际上也就是去求X和Y到底什么关系，X对Y到底产生了多大的影响。</p>
</li>
<li><p>互信息$I(X;Y)\triangleq{H(X)-H(X|Y)}$，或者写成$I(X;Y)\triangleq{H(Y)-H(Y|X)}$，</p>
</li>
<li><p>互信息$\large{I(X;Y)&#x3D;\sum_{x,y}Pr(X&#x3D;x,Y&#x3D;y)log\frac{Pr(X&#x3D;x,Y&#x3D;y)}{Pr(X&#x3D;x)Pr(Y&#x3D;y)}}$</p>
<p>（∵$I(X;Y)&#x3D;-\sum_xp(x)log(x)+\sum_{xy}p(x,y)logp(x|y)&#x3D;-\sum_{xy}p(x,y)log(x)+\sum_{xy}p(xy)log\frac{p(x,y)}{p(y)}$）</p>
<p>可以看出，互信息会更关注因为引入的某个“文本”，对于观测序列的影响、变化。</p>
</li>
<li><p>MMI准则公式：$\large{F_{MMIE}(\lambda)&#x3D;\sum_{u&#x3D;1}^{U}logP(W_u|x_u;\theta)&#x3D;\sum_{u&#x3D;1}^Ulog\frac{P(X_u|W_u;\theta)P(W_u)}{\sum_{w’}P(X_u|w’;\theta)P(w’)}}$</p>
</li>
<li><p>其中$P(W_u)$是固定的语言模型</p>
<p>分子上的$P(X_u|Wu;θ)$，正是ML的目标函数；而分母则是所有文本（包括训练文本和它的所有竞争者）产生训练语音的概率（按语言模型加权）和。</p>
<p>分子Numerator表示的是正确单词序列的可能性，分母Denominator是所有可能单词序列的可能性之和。</p>
<p>两者之间的区别在于条件概率不同。ML中只要训练文本产生训练语音的概率大就行，而MMI要求的是训练语音对应训练文本的概率大，就是要训练文本产生语音信号的概率与其它文本产生语音信号的概率之差大。</p>
</li>
</ul>
<h3 id="DNN与DT"><a href="#DNN与DT" class="headerlink" title="DNN与DT"></a>DNN与DT</h3><h4 id="MMI损失函数"><a href="#MMI损失函数" class="headerlink" title="MMI损失函数"></a>MMI损失函数</h4><p>在DNN神经网络中，DT准则可以替换CE准则作为损失函数。</p>
<ul>
<li><p>MMI准则过程为：</p>
<ul>
<li>$\large{P(\textbf{W}_u|\textbf{O}_u)&#x3D;\frac{p(\textbf{O}_u|\textbf{W}_u)P(\textbf{W}_u)}{p(\textbf{O}_u)}}$</li>
</ul>
<p>其中，$P(\textbf{W}_u)$是语言模型概率（一整句话有一个语言模型概率），在kws中，是keyword序列和非keyword的先验概率。</p>
<ul>
<li>分子  $p(\textbf{O}_u|\textbf{W}<em>u)&#x3D;\sum</em>{L\in{\mathcal{L}(W)}}p(\textbf{O}|\textbf{L})P(\textbf{L}|\textbf{W})$</li>
</ul>
<p>其中，$p(\textbf{O}|\textbf{L})$由HMM给出，$L$是状态（或者说标签）序列；$\mathcal{L}$是词序列W到它的标签序列$L$的映射函数，也就是词典lexicon；$P(\textbf{L}|\textbf{W})$是发音概率，由词典和语言模型决定；</p>
<p>所以，是在分子lattice上可能的L序列路径求和的过程（用前后向）</p>
<ul>
<li>分母 $p(\textbf{O}<em>u)&#x3D;\sum</em>{W}p(\textbf{O}_u,W)&#x3D;\sum_WP(\textbf{W})p(\textbf{O}_u|\textbf{W})$</li>
</ul>
<p>其中，$\textbf{W}$denotes one of the competing hypotheses, which are usually represented as a path in the decoding lattice  </p>
<ul>
<li>MMI准则公式为：$\large{\mathcal{F}_{MMI}&#x3D;\sum_ulog\frac{P(\textbf{O}_u|\textbf{W}_u)^kP(\textbf{W}<em>u)}{\sum</em>{\textbf{W}}P(\textbf{O}<em>u|\textbf{W})^kP(\textbf{W})}&#x3D;\sum_ulog\frac{\sum</em>{L\in{\mathcal{L}(W)}}p(\textbf{O}|\textbf{L})^kP(\textbf{L}|\textbf{W})^kP(\textbf{W}_u)}{\sum_Wp(\textbf{O}_u|\textbf{W})^kP(\textbf{W})}}$</li>
</ul>
<p>（$logp(w|o)&#x3D;logp(o,w)-log(o)&#x3D;log\sum_sp(o,s,w)-log(o)&#x3D;log\sum_sp(o|s,w)p(s|w)p(w)-logp(o)$）</p>
</li>
<li><p>u是某一条样本，就是w的状态序列s的引入，对音频观测序列o产生多大的影响，loss越大，条件熵越小，互信息越大，越相关。因此要最大化互信息。</p>
</li>
<li><p>MMI准则最大化单词序列分布和观察序列分布之间的互信息,，减小句子错误率。最大化分子， 最小化分母。 </p>
</li>
<li><p>DT训练之前需要使用CE准则生成alignments和lattices，DT的初始化模型为使用CE准则训练出的最好模型。</p>
</li>
<li><p>理论上说,，DT训练分母应该取遍所有可能的单词序列。不过在实际中，这个求和运算是限制在解码得到的lattice上做的，这样可以减少运算量。</p>
</li>
<li><p>DNN训练算法一般是用来最小化一个目标方程, 所以我们可以对MMI准则取反进行最小化，而不是最大化互信息。</p>
</li>
<li><p>最大互信息量估计准则（Maximum Mutual Information Estimation，MMIE）、最小分类错误准则（Minimum Classification Error，MCE），以及最小词&#x2F;音素错误准则(Minimum Word&#x2F;Phone Error)。而常用的参数优化准则算法则包括广义概率下降(Generalized Pmbability Descent，GPD)，以及扩展Baum-Welch(Extened Baum—Welch，EB)算法。</p>
</li>
</ul>
<h4 id="MMI求导"><a href="#MMI求导" class="headerlink" title="MMI求导"></a>MMI求导</h4><p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/mmi/image-20211006170322880.png" alt="image-20211006170322880"></p>
<h2 id="MMI详细求导过程"><a href="#MMI详细求导过程" class="headerlink" title="MMI详细求导过程"></a>MMI详细求导过程</h2><blockquote>
<p>Veselý K, Ghoshal A, Burget L, et al. Sequence-discriminative training of deep neural networks[C]&#x2F;&#x2F;Interspeech. 2013, 2013: 2345-2349. citation：802 Daniel Povey</p>
<p>[mmi推导]Note_on_MMI （Sequence-discriminative training of deep neural networks）.pdf</p>
</blockquote>
<ul>
<li>得到反向传播的可导性（求偏导）</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/mmi/image-20211012153400589.png" alt="image-20211012153400589"></p>
<ul>
<li>分母用前后向求得</li>
</ul>
<h2 id="lattice"><a href="#lattice" class="headerlink" title="lattice"></a>lattice</h2><p>前向后向算法都是在lattice上进行的，下图是一个word级别的lattice：</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/mmi/1.png" alt="img"></p>
<h4 id="kaldi中的DT实现"><a href="#kaldi中的DT实现" class="headerlink" title="kaldi中的DT实现"></a>kaldi中的DT实现</h4><p>kaldi nnet3中的DT计算过程</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/mmi/2.png" alt="img"></p>
<ul>
<li>lattice rescore是DNN前向计算出$P(s|o)$，除以先验概率$P(s)$，得到似然概率$P(o|s)$，替换lattice边上对应的$P(o|s)$</li>
<li>其中<code>vector&lt;BaseFloat&gt; answers</code>是前面计算出来的DNN的输出对应参考pdf的概率。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// nnet3/discriminative-training.cc</span></span><br><span class="line"><span class="comment">// 对lattice进行声学校正, 将负（缩放）声学对数似然置于lattice的弧中</span></span><br><span class="line"><span class="function"><span class="type">size_t</span> <span class="title">DiscriminativeComputation::LatticeAcousticRescore</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;BaseFloat&gt; &amp;answers,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">size_t</span> index, Lattice *lat)</span> </span>&#123;</span><br><span class="line">  int32 num_states = lat-&gt;<span class="built_in">NumStates</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (StateId s = <span class="number">0</span>; s &lt; num_states; s++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (fst::MutableArcIterator&lt;Lattice&gt; <span class="built_in">aiter</span>(lat, s);</span><br><span class="line">         !aiter.<span class="built_in">Done</span>(); aiter.<span class="built_in">Next</span>()) &#123;</span><br><span class="line">      Arc arc = aiter.<span class="built_in">Value</span>();</span><br><span class="line">      <span class="keyword">if</span> (arc.ilabel != <span class="number">0</span>) &#123; <span class="comment">// input-side has transition-ids, output-side empty</span></span><br><span class="line">        arc.weight.<span class="built_in">SetValue2</span>(-answers[index]);</span><br><span class="line">        <span class="comment">// graph cost: lm + transition + pronunciation</span></span><br><span class="line">        <span class="comment">// acoustic cost: -P(o|s)</span></span><br><span class="line">        index++;</span><br><span class="line">        aiter.<span class="built_in">SetValue</span>(arc);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    LatticeWeight <span class="keyword">final</span> = lat-&gt;<span class="built_in">Final</span>(s);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">final</span> != LatticeWeight::<span class="built_in">Zero</span>()) &#123;</span><br><span class="line">      <span class="keyword">final</span>.<span class="built_in">SetValue2</span>(<span class="number">0.0</span>); <span class="comment">// 确保在最终概率中没有声学项</span></span><br><span class="line">      lat-&gt;<span class="built_in">SetFinal</span>(s, <span class="keyword">final</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 用于rescore lattice的对数似然的索引个数</span></span><br><span class="line">  <span class="keyword">return</span> index;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>在分母lattice上进行前向后向的计算函数为LatticeForwardBackward；在分子lattice的前向后向计算函数为AlignmentToPosterior。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// lat/lattice-functions.cc</span></span><br><span class="line"><span class="comment">// 在lattice上执行前向后向算法并计算弧的后验概率</span></span><br><span class="line"><span class="function">BaseFloat <span class="title">LatticeForwardBackward</span><span class="params">(<span class="type">const</span> Lattice &amp;lat, Posterior *post,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">double</span> *acoustic_like_sum)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 注意Posterior定义如下:  </span></span><br><span class="line">  <span class="comment">// Indexed [frame], then a list of (transition-id, posterior-probability) pairs.</span></span><br><span class="line">  <span class="comment">// typedef std::vector&lt;std::vector&lt;std::pair&lt;int32, BaseFloat&gt; &gt; &gt; Posterior;</span></span><br><span class="line">  <span class="keyword">using</span> <span class="keyword">namespace</span> fst;</span><br><span class="line">  <span class="keyword">typedef</span> Lattice::Arc Arc;</span><br><span class="line">  <span class="keyword">typedef</span> Arc::Weight Weight;</span><br><span class="line">  <span class="keyword">typedef</span> Arc::StateId StateId;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (acoustic_like_sum) *acoustic_like_sum = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 确保lattices在拓扑上排序</span></span><br><span class="line">  <span class="keyword">if</span> (lat.<span class="built_in">Properties</span>(fst::kTopSorted, <span class="literal">true</span>) == <span class="number">0</span>)</span><br><span class="line">    KALDI_ERR &lt;&lt; <span class="string">&quot;Input lattice must be topologically sorted.&quot;</span>;</span><br><span class="line">  <span class="built_in">KALDI_ASSERT</span>(lat.<span class="built_in">Start</span>() == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  int32 num_states = lat.<span class="built_in">NumStates</span>();</span><br><span class="line">  vector&lt;int32&gt; state_times;</span><br><span class="line">  <span class="comment">// 拓扑迭代den_lats中的每个state，并按顺序对每个state进行计数，结果</span></span><br><span class="line">  <span class="comment">// 保存在vector state_times中，最后一个state对应的计数时间应该为帧的数量值</span></span><br><span class="line">  int32 max_time = <span class="built_in">LatticeStateTimes</span>(lat, &amp;state_times);</span><br><span class="line">  <span class="function">std::vector&lt;<span class="type">double</span>&gt; <span class="title">alpha</span><span class="params">(num_states, kLogZeroDouble)</span></span>;</span><br><span class="line">  <span class="function">std::vector&lt;<span class="type">double</span>&gt; &amp;<span class="title">beta</span><span class="params">(alpha)</span></span>; </span><br><span class="line">  <span class="comment">// 重用相同的内存，beta是alpha的引用</span></span><br><span class="line">  <span class="type">double</span> tot_forward_prob = kLogZeroDouble;</span><br><span class="line"></span><br><span class="line">  post-&gt;<span class="built_in">clear</span>();</span><br><span class="line">  post-&gt;<span class="built_in">resize</span>(max_time);</span><br><span class="line"></span><br><span class="line">  alpha[<span class="number">0</span>] = <span class="number">0.0</span>;</span><br><span class="line">  <span class="comment">// Propagate alphas forward.</span></span><br><span class="line">  <span class="keyword">for</span> (StateId s = <span class="number">0</span>; s &lt; num_states; s++) &#123;</span><br><span class="line">    <span class="type">double</span> this_alpha = alpha[s];</span><br><span class="line">    <span class="comment">// alpha[]里面存储着从init state走到该state的所有路径中cost value加和最大值</span></span><br><span class="line">    <span class="keyword">for</span> (ArcIterator&lt;Lattice&gt; <span class="built_in">aiter</span>(lat, s); !aiter.<span class="built_in">Done</span>(); aiter.<span class="built_in">Next</span>()) &#123;</span><br><span class="line">      <span class="type">const</span> Arc &amp;arc = aiter.<span class="built_in">Value</span>();</span><br><span class="line">      <span class="comment">// arc_like = arc.weight.value1 + arc.weight.value2</span></span><br><span class="line">      <span class="type">double</span> arc_like = -<span class="built_in">ConvertToCost</span>(arc.weight);    </span><br><span class="line">      <span class="comment">// LogAdd返回两者之间较大的一个... + something else</span></span><br><span class="line">      alpha[arc.nextstate] = <span class="built_in">LogAdd</span>(alpha[arc.nextstate], this_alpha + arc_like);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// get状态s的final weight; if == Weight::Zero() =&gt; non-final</span></span><br><span class="line">    <span class="comment">// final state上面有单独的语言和声学分 </span></span><br><span class="line">    Weight f = lat.<span class="built_in">Final</span>(s);</span><br><span class="line">    <span class="keyword">if</span> (f != Weight::<span class="built_in">Zero</span>()) &#123;     </span><br><span class="line">      <span class="type">double</span> final_like = this_alpha - (f.<span class="built_in">Value1</span>() + f.<span class="built_in">Value2</span>());</span><br><span class="line">      tot_forward_prob = <span class="built_in">LogAdd</span>(tot_forward_prob, final_like);</span><br><span class="line">      <span class="built_in">KALDI_ASSERT</span>(state_times[s] == max_time &amp;&amp;</span><br><span class="line">                   <span class="string">&quot;Lattice is inconsistent (final-prob not at max_time)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (StateId s = num_states<span class="number">-1</span>; s &gt;= <span class="number">0</span>; s--) &#123;</span><br><span class="line">    Weight f = lat.<span class="built_in">Final</span>(s);</span><br><span class="line">    <span class="comment">// 如果s不是final state, this_beta = 0</span></span><br><span class="line">    <span class="type">double</span> this_beta = -(f.<span class="built_in">Value1</span>() + f.<span class="built_in">Value2</span>());</span><br><span class="line">    <span class="comment">// beta[]里面存储的是从该state走到final state的所有路径中cost value加和最大值（加上final state的权值）</span></span><br><span class="line">    <span class="keyword">for</span> (ArcIterator&lt;Lattice&gt; <span class="built_in">aiter</span>(lat, s); !aiter.<span class="built_in">Done</span>(); aiter.<span class="built_in">Next</span>()) &#123;</span><br><span class="line">      <span class="type">const</span> Arc &amp;arc = aiter.<span class="built_in">Value</span>();</span><br><span class="line">      <span class="type">double</span> arc_like = -<span class="built_in">ConvertToCost</span>(arc.weight),</span><br><span class="line">          arc_beta = beta[arc.nextstate] + arc_like;</span><br><span class="line">      this_beta = <span class="built_in">LogAdd</span>(this_beta, arc_beta);</span><br><span class="line">      int32 transition_id = arc.ilabel;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 该if判断是一个优化，以避免不需要的exp()函数</span></span><br><span class="line">      <span class="keyword">if</span> (transition_id != <span class="number">0</span> || acoustic_like_sum != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="type">double</span> posterior = <span class="built_in">Exp</span>(alpha[s] + arc_beta - tot_forward_prob);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (transition_id != <span class="number">0</span>) <span class="comment">// 该弧上有tid，不是epsilon</span></span><br><span class="line">          <span class="comment">// (*post)[state_times[s]]是以时间帧为编号的vector</span></span><br><span class="line">          (*post)[state_times[s]].<span class="built_in">push_back</span>(std::<span class="built_in">make_pair</span>(transition_id,</span><br><span class="line">                                                           <span class="built_in">static_cast</span>&lt;kaldi::BaseFloat&gt;(posterior)));</span><br><span class="line">        <span class="keyword">if</span> (acoustic_like_sum != <span class="literal">NULL</span>)</span><br><span class="line">          *acoustic_like_sum -= posterior * arc.weight.<span class="built_in">Value2</span>();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (acoustic_like_sum != <span class="literal">NULL</span> &amp;&amp; f != Weight::<span class="built_in">Zero</span>()) &#123;</span><br><span class="line">      <span class="type">double</span> final_logprob = - <span class="built_in">ConvertToCost</span>(f),</span><br><span class="line">          posterior = <span class="built_in">Exp</span>(alpha[s] + final_logprob - tot_forward_prob);</span><br><span class="line">      *acoustic_like_sum -= posterior * f.<span class="built_in">Value2</span>();     <span class="comment">// value2声学分数 </span></span><br><span class="line">    &#125;</span><br><span class="line">    beta[s] = this_beta;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">double</span> tot_backward_prob = beta[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">ApproxEqual</span>(tot_forward_prob, tot_backward_prob, <span class="number">1e-8</span>)) &#123;</span><br><span class="line">    KALDI_WARN &lt;&lt; <span class="string">&quot;Total forward probability over lattice = &quot;</span> &lt;&lt; tot_forward_prob</span><br><span class="line">              &lt;&lt; <span class="string">&quot;, while total backward probability = &quot;</span> &lt;&lt; tot_backward_prob;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 按照第一个元素排序，把tid(pdfid)相同的后验combine起来(posterior值加起来)</span></span><br><span class="line">  <span class="keyword">for</span> (int32 t = <span class="number">0</span>; t &lt; max_time; t++)</span><br><span class="line">    <span class="built_in">MergePairVectorSumming</span>(&amp;((*post)[t]));</span><br><span class="line">  <span class="keyword">return</span> tot_backward_prob;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="trick"><a href="#trick" class="headerlink" title="trick"></a>trick</h4><ul>
<li>frame rejection<br>当分子alignment的状态没有在分母lattice中出现的时候，会导致梯度过大，舍弃该帧的梯度。这种情况对于silence帧尤其常见，因为silence经常出现在分子的lattice，但是很容易被分母的lattice忽略。<br>如果新的对齐和lattice在每轮训练后被重新生成，那么运算结果将得到进一步改进。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 如果两个post[i]的第一个元素(tid)没有交集，返回true</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">PosteriorEntriesAreDisjoint</span>(post1[i], post2[i])) &#123;</span><br><span class="line">      num_disjoint++;</span><br><span class="line">      <span class="keyword">if</span> (drop_frames)</span><br><span class="line">        (*post)[i].<span class="built_in">clear</span>();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>帧平滑  $J_{FS-SEQ}(\theta;S)&#x3D;(1-H)J_{CE}(\theta;S)+HJ_{SEQ}(\theta;S)$</p>
<p>当训练dt准则函数持续改进时，只用DNN计算出的帧准确率却显著变差。帧&#x2F;序列的比从 1:4 (H &#x3D; 4&#x2F;s )到 1:10 (H &#x3D; 10&#x2F;11 )常常是有效的。</p>
</li>
<li><p>更小的lr，大数据集上smbr效果最好</p>
</li>
</ul>
<hr>
<blockquote>
<p>七月在线的视频 07.第四课 序列判别式训练（视频），PPT:《asr_lecture4.pdf》</p>
</blockquote>
<ul>
<li>之前是nbest求和，现在是用lattice，lattice上路径会有重合，也是求和</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/mmi/image-20211008150208238.png" alt="image-20211008150208238"></p>
<ul>
<li>用lattice估计全量量的W </li>
<li>用最初的模型⽣生成lattice</li>
<li>使用弱的语言模型，通常用1-gram的语言模型</li>
<li>但是控制lattice⼤小，通过beam控制，以减小计算的复杂度</li>
<li>继承解码后的边对应的phone</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/mmi/image-20211008160228044.png" alt="image-20211008160228044"></p>
<p>生成分母FST代码： kaldi&#x2F;src&#x2F;chainbin&#x2F;chainmake-den-fst.cc  </p>
<p>2016 paper仍需要用gmm进行预训练，进行对齐，对phone出现的帧进行限制，同分母的fst进行连接，那样就是带上语言模型概念</p>
<hr>
<p>区分性训练，其实应该说鉴别性训练，相对于生成式模型？<del>意思就是不是把所有样本一视同仁地训练，而是赋予不同权重训练</del></p>
<ul>
<li><p>LFMMI之前的MMI分母用的解码得到的lattice作为词空间</p>
</li>
<li><p>LFMMI分子用的对齐lattice，分母用的是phoneWFST构成的lattice，所有句子的分母lattice都相同，就一个，之前没用这个HCLG是因为用word得到的HCLG特别大</p>
</li>
</ul>
<hr>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzU4MTA0NDE5NQ==&mid=2247485166&idx=1&sn=8b16bf29ed1a40e5b6cb2ba7104a1f1d&chksm=fd4cd462ca3b5d7446b4893cee3a03015d2b91dd0013f61ed0586be79bc514ebdb85a14ee31c&mpshare=1&scene=1&srcid=&sharer_sharetime=1584408100044&sharer_shareid=2c567b07b642647cb9daac1b143684f9#rd">语音识别系列之区分性训练和LF-MMI</a></p>
</blockquote>
<ul>
<li><p>普通MMI：MMI的训练依赖Lattice，Lattice又依赖已经训练好的声学模型，所以在DNN的声学模型中，我们要先基于ML准则先训练好DNN模型，然后做MMI的训练。并且，<strong>Lattice是一个解码过程，其生成代价很高</strong>，并且只能在CPU上进行解码生成。一般我们只生成一次Lattice，区分性训练的过程中我们并不根据当前更新后的声学模型实时生成Lattice，也就是不使用实时的Lattice做MMI训练。所以在这种方式中，<strong>Lattice是滞后的，和当前的声学模型并不同步</strong>。</p>
<p>每句话生成一个lattice，这个lattice之后都不更新，并且这个lattice也许不能代表这句话的全部词空间</p>
</li>
<li><p>LFMMI的分母改进：提到W一定要是有限的，可枚举的，当MMI分母和语音识别解码图是一样时，即以词Word作为语言模型的单元，一般的语音识别系统词级别在数十万到百万之间，即使做个简单的bi-gram，其复杂度也非常非常高（HCLG的大小），训练代价非常高。为了降低复杂度，考虑以：</p>
<ul>
<li>Phone作为语言模型单元。识别系统中Phone的一般在几十个到一百多个，考虑到数据稀疏性，即使做tri-gram或者4-gram复杂度也在合理区间内。以Phone作为建模单元时，MMI的分母图为HCG(没有词典L了，并且G的单元是Phone）。</li>
<li>State作为语言模型建模单元。识别系统中的State一般在几千个左右，考虑到数据稀疏性，做tri-gram复杂度也在合理区间内。以State作为建模单元时，MMI的分母图为G（G以State作为建模单元，这里State是指上下文相关的CD-State&#x2F;senone）。</li>
</ul>
</li>
</ul>
<p>其中，Phone和State的训练语料都可以由语音识别的训练数据通过对齐生成。<strong>合理的控制Phone和State的MMI分母的大小，可以将其前向后向计算塞进GPU进行计算，也就是将MMI训练迁移到GPU，从而大大提高了MMI的训练速度</strong>。在业界中，Phone和State的两者都有实际应用。Kaldi的chain model中，使用Phone作为MMI分母建模单元。在一些其他工作或文章中，如”Achieving Human Parity in Conversational Speech Recognition”这篇文章中，以State作为MMI分母的建模单元，该论文中的结果如下表所示，可以看到，LF-MMI也拿到了合理的收益，其收益和Lattice based的MMI收益相近。</p>
<p>当使用语言模型的思想表示MMI的分母时，我们无需再对训练语料进行解码，无需生成Lattice，所以称之为Lattice Free MMI(LF-MMI)。对于所有训练语料来讲，MMI的分母图是以一样的，并且，因为我们限制了MMI分母图的空间，该前向后向算法是on-the-fly的，在训练过程中直接计算，其与声学模型是同步更新（声学模型更新后，lattice也更新（lattice更新里面的声学分数）（hclg不变，因为hclg里的信息就涉及声学模型只有转移））。</p>
<h2 id="chain-model"><a href="#chain-model" class="headerlink" title="chain model"></a>chain model</h2><blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzU4MTA0NDE5NQ==&mid=2247485166&idx=1&sn=8b16bf29ed1a40e5b6cb2ba7104a1f1d&chksm=fd4cd462ca3b5d7446b4893cee3a03015d2b91dd0013f61ed0586be79bc514ebdb85a14ee31c&mpshare=1&scene=1&srcid=&sharer_sharetime=1584408100044&sharer_shareid=2c567b07b642647cb9daac1b143684f9#rd">语音识别系列之区分性训练和LF-MMI</a></p>
<p>2016 - Povey et al. - Purely sequence-trained neural networks for ASR based on lattice-free MMI </p>
</blockquote>
<p>chain model本质是LFMMI，用了一些trick</p>
<p>chain model中比较重要的tirck有：</p>
<ol>
<li>HMM拓扑结构改变，从标准的三状态改为单状态的HMM。</li>
<li>帧率从10ms降低到30ms。</li>
<li>MMI分母使用Phone作为语言模型建模单元，最终表示为HCG，且为简化，C为bi-phone。</li>
<li>训练数据均做等长(1.5s)切分，分子使用该句话的Lattice表示。且在分子Lattice上引入一定时间扰动。</li>
<li>CE正则化。训练时同时引入CE作为第二个任务进行multi task learning。所以，最终chain model的网络结构如下图所示：</li>
<li>L2正则化&#x2F;Leaky HMM等</li>
</ol>
<h2 id="区分性训练trick"><a href="#区分性训练trick" class="headerlink" title="区分性训练trick"></a>区分性训练trick</h2><blockquote>
<p><a href="https://blog.csdn.net/xmdxcsj/article/details/52760111">声学模型学习笔记（五） SDT(MMI&#x2F;BMMI&#x2F;MPE&#x2F;sMBR)</a> xmdxcsj csdn blog</p>
</blockquote>
<h3 id="lattice-generation"><a href="#lattice-generation" class="headerlink" title="lattice generation"></a>lattice generation</h3><p>区分性训练时生成高质量的lattice很重要，需要使用最好的模型来生成对应的lattice，并且作为seed model。</p>
<h3 id="lattice-compensation"><a href="#lattice-compensation" class="headerlink" title="lattice compensation"></a>lattice compensation</h3><p> 如果lattice产生的不合理的话，会导致计算出来的梯度异常，比如分子的标注路径没有在分母中的lattice出现，这种情况对于silience帧尤其常见，因为silience经常出现在分子的lattice，但是很容易被分母的lattice忽略。有一些方法可以解决这种问题：</p>
<ul>
<li>fame rejection，直接删除这些帧</li>
<li>根据reference hypothesis修正lattice，比如在lattice中人为地添加一下silience边</li>
</ul>
<h3 id="frame-smoothing"><a href="#frame-smoothing" class="headerlink" title="frame smoothing"></a>frame smoothing</h3><p>SDT很容易出现overfitting，两方面原因</p>
<ul>
<li><p>sparse lattice</p>
</li>
<li><p>sdt的squence相比于frame增加了建模的维度，导致训练集的后验概率分布更容易跟测试集出现差异</p>
</li>
</ul>
<p>可以修改训练准则来减弱overfitting，通过结合squence criteria和frame criteria来实现：<br>$$<br>J_{FS-SEQ}(\theta;S)&#x3D;(1-H)J_{CE}(\theta;S)+HJ_{SEQ}(\theta;S)<br>$$<br>其中，$H$成为smoothing factor，经验值设为4&#x2F;5或10&#x2F;11</p>
<h3 id="learning-rate"><a href="#learning-rate" class="headerlink" title="learning rate"></a>learning rate</h3><p>SDT的学习率相比于CE要小，因为</p>
<ul>
<li>SDT的起点一般基于CE训练出来的model</li>
<li>SDT训练容易出现overfitting</li>
</ul>
<h3 id="criterion-selection"><a href="#criterion-selection" class="headerlink" title="criterion selection"></a>criterion selection</h3><p>sMBR效果相比其他会好一点，MMI比较容易理解和实现。</p>
<h3 id="noise-contrastIve-estimation"><a href="#noise-contrastIve-estimation" class="headerlink" title="noise contrastIve estimation"></a>noise contrastIve estimation</h3><p>NCE可以用于加速训练</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>[1]《automatic speech recognition a deep learning approach》 chapter8<br>[2]Sequence-discriminative training of deep neural networks<br>[3]Boosted MMI for model and feature-space discriminative training<br>[4]discriminative training for large vocabulary speech recognition {daniel povey的博士论文chapter6}</p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第11章 序列区分性训练————Lattice-based和Lattice-free MMI</title>
    <url>/2023/01/10/%E8%AF%86%E5%88%AB/mmi%E4%B9%A6%20%E6%B4%AA%E9%9D%92%E9%98%B3/</url>
    <content><![CDATA[<h1 id="序列区分性训练"><a href="#序列区分性训练" class="headerlink" title="序列区分性训练"></a>序列区分性训练</h1><blockquote>
<p>《语音识别原理与应用》洪青阳 第11章</p>
<p>《11. 序列区分性训练.pptx》</p>
</blockquote>
<p>原理公式 直接看PPT或者书就行。</p>
<h2 id="MMI-求导"><a href="#MMI-求导" class="headerlink" title="MMI 求导"></a>MMI 求导</h2><p><img src="/2023/01/10/%E8%AF%86%E5%88%AB/mmi%E4%B9%A6%20%E6%B4%AA%E9%9D%92%E9%98%B3/image-20230116234330915.png" alt="image-20230116234330915"></p>
<p>其中，$\alpha_t^u(j)$ 为第 $u$ 条句子 $t$ 时刻的观察值$ o_t^u$ 的在DNN输出节点（状态） $j$ 的激活输出。</p>
<p><img src="/2023/01/10/%E8%AF%86%E5%88%AB/mmi%E4%B9%A6%20%E6%B4%AA%E9%9D%92%E9%98%B3/image-20230116234504909.png" alt="image-20230116234504909"></p>
<p>$\gamma_u^{NUM}(s_t^u&#x3D;j)$ 是针对训练标注，$t$ 时刻为状态 $j$ 的后验概率，其计算采用标准的<strong>前向-后向算法</strong>，复杂度相对较低。而 $\gamma_u^{DEN}(s_t^u&#x3D;j)$ 虽然也是 $t$ 时刻为状态 $j$ 的后验概率，但要穷举所有可能的词序列对应的状态序列，计算量巨大无比。</p>
<p>我自己的理解：</p>
<ul>
<li>分子网是要计算到某个标注（对齐）状态的所有可能路径（到某个状态的所有可能路径求和通过前后向算法），然后整个对齐标注状态序列，就是对所有时刻 t的状态 j 连乘 就得到分子网（偏导对象是某个时刻t，某个时刻j，这里其实没有算连乘）。</li>
<li>分母网也是到某个时刻t的状态j的可能路径概率求和，但是很多不同词序列都有可能在某个时刻t能够处在状态j，因此要对这些所有的不同词序列求和。而分子网考虑的文本序列就是标注序列。</li>
</ul>
<h2 id="Lattice-based-MMI"><a href="#Lattice-based-MMI" class="headerlink" title="Lattice-based MMI"></a>Lattice-based MMI</h2><p>分母网用n-best代替所有路径的方案比较粗糙，更好的方案是为每个训练句子生成一个词图lattice，来近似mmi的分母部分。</p>
<p>这样, $\gamma_u^{\mathrm{DEN}}\left(s_t^u&#x3D;j\right)$ 就可通过汇总 Lattice 所有可能的词序列的概率得到。由 于 Lattice 的路径有限, 故需要的计算量将大为降低。</p>
<p>事实上, $\gamma_u^{\mathrm{NUM}}\left(s_t^u&#x3D;j\right)$ 的前向和后向概率也可通过 Lattice 计算。因此, <strong>每条训练句子均需要生成正确标注和竞争路径对应的 Lattice，包含采用音素 (不需词典) 的简化版语言模型。</strong></p>
<h4 id="基于DNN-HMM的Lattice-based-MMI训练流程如下："><a href="#基于DNN-HMM的Lattice-based-MMI训练流程如下：" class="headerlink" title="基于DNN-HMM的Lattice-based MMI训练流程如下："></a>基于DNN-HMM的Lattice-based MMI训练流程如下：</h4><ul>
<li>Step1：基于CE准则，训练一个DNN-HMM做为种子模型，并用该模型做状态级别的强制对齐，并生成正确标注对应的Lattice，即MMI分子部分对应的Numerator Lattice；</li>
<li>Step2：基于一元语言模型构建HCLG，然后对每条训练句子做识别，得到各种竞争路径，保存为MMI分母部分对应的Denominator Lattice。</li>
<li>Step3：进行Lattice-based MMI训练。</li>
</ul>
<p><img src="/2023/01/10/%E8%AF%86%E5%88%AB/mmi%E4%B9%A6%20%E6%B4%AA%E9%9D%92%E9%98%B3/image-20230117001637221.png" alt="image-20230117001637221"></p>
<p>分母网也是用DNN-HMM生成的。分母网是固定的状态序列，无法根据新训练的声学模型动态更新。</p>
<h2 id="Lattice-free-MMI"><a href="#Lattice-free-MMI" class="headerlink" title="Lattice-free MMI"></a>Lattice-free MMI</h2><p>2016年，D. Povey等人提出Lattice-free MMI方案，把分母部分用音素级别的有限状态转换器（FST）图表示，这样可以不用Lattice，做到纯序列区分性训练（Sequence Discriminative Training）。</p>
<p><img src="/2023/01/10/%E8%AF%86%E5%88%AB/mmi%E4%B9%A6%20%E6%B4%AA%E9%9D%92%E9%98%B3/image-20230117001830073.png" alt="image-20230117001830073"></p>
<p>Lattice-free MMI（LF-MMI）采用音素语言模型（Phone LM）替代词语言模型（Word LM），这样就不需要词典，因此HCLG精简为<strong>HCP</strong>，其中C由决策树生成，P代表Phone LM，Kaldi设为4-gram，基于训练数据的对齐音素序列训练而成，并且低于3元不采用回退和插值，即3元组合本身不存在的话，不考虑更低元的语言模型，以免引起更多混淆。</p>
<p>由于音素个数比词个数少很多，因此Phone LM产生的FST图很小，最后得到的HCP（即针对MMI分母的FST图）也会小很多，可以直接放到GPU训练。事实上，这个HCP可认为是串接HMM的FST形式，MMI训练的前后-后向计算将基于该FST图进行，HMM 状态之间的转移概率也可根据 FST 找到对应值。</p>
<p>Lattice-free MMI 对应 $\gamma_u^{N U M}\left(s_t^u&#x3D;j\right)$ 的 FST 的前向-后向计算量较少, 可在 CPU 中运行。而对应 $\gamma_u^{\mathrm{DEN}}\left(s_t^u&#x3D;j\right)$ 的 FST 的前向-后向计算量较大, 一般要在 GPU 中 运行, 并且有两处特殊处理:</p>
<ul>
<li>不采用对数和指数运算, 为了避免目标函数值突变, 同时需对前向和后向 计算结果做规整。</li>
<li>先做 $\gamma_u^{\mathrm{DEN}}\left(s_t^u&#x3D;j\right)$ 计算, 再做 $\gamma_u^{\mathrm{NUM}}\left(s_t^u&#x3D;j\right)$ 计算，以减少内存占用。</li>
</ul>
<h4 id="Lattice-free-MMI-的训练流程"><a href="#Lattice-free-MMI-的训练流程" class="headerlink" title="Lattice-free MMI 的训练流程"></a>Lattice-free MMI 的训练流程</h4><ul>
<li>Step1：MMI分母部分 $\gamma_u^{\mathrm{DEN}}\left(s_t^u&#x3D;j\right)$ 的FST<strong>前向-后向计算</strong>直接使用音素级别的FST图，不需要每个句子分别解码得到的Lattice；</li>
<li>Step2：基于GMM-HMM或DNN-HMM对齐得到句子的Lattice（以FST形式保存），进行MMI分子部分 $\gamma_u^{\mathrm{NUM}}\left(s_t^u&#x3D;j\right)$ 的<strong>前向-后向计算</strong>。</li>
<li>Step3：进行Lattice-free MMI训练。</li>
</ul>
<p><img src="/2023/01/10/%E8%AF%86%E5%88%AB/mmi%E4%B9%A6%20%E6%B4%AA%E9%9D%92%E9%98%B3/image-20230118001853394.png" alt="image-20230118001853394"></p>
<p><img src="/2023/01/10/%E8%AF%86%E5%88%AB/mmi%E4%B9%A6%20%E6%B4%AA%E9%9D%92%E9%98%B3/image-20230118001913981.png" alt="image-20230118001913981"></p>
<p><img src="/2023/01/10/%E8%AF%86%E5%88%AB/mmi%E4%B9%A6%20%E6%B4%AA%E9%9D%92%E9%98%B3/image-20230118001934327.png" alt="image-20230118001934327"></p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>《语音识别原理与应用》</tag>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>kaldi nnet3</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/nnet3/</url>
    <content><![CDATA[<h1 id="kaldi-nnet3"><a href="#kaldi-nnet3" class="headerlink" title="kaldi nnet3"></a>kaldi nnet3</h1><h2 id="nnet3-component"><a href="#nnet3-component" class="headerlink" title="nnet3 component"></a>nnet3 component</h2><blockquote>
<p>参考 ：《Kaldi语音识别实战》P209</p>
</blockquote>
<p>基于计算图构建网络结构</p>
<p>以component为标识的行定义了每个节点的类型和输入输出维度，以Component-node为标识的行定义了每个节点的输入。定义节点输入的方法被称为描述符（Descriptors），用于表示节点之间如何连接，默认情况下，直接取输入节点的输出作为输入。常用的描述符包括：</p>
<ul>
<li>节点名，这是最基本的描述符，即不做任何操作；</li>
<li>拼接（Append），将给定描述符拼接在一起，维度相当于各描述符维度之和；</li>
<li>求和（Sum），对给定描述符求和，要求各个描述符维度一致；</li>
<li>常量（Const），不要求指定描述符，而是根据参数生成一个描述符，如Const(1.0,512)生成一个512维的单位矢量；</li>
<li>缩放（Scale），对给定描述符的每一维进行缩放；</li>
<li>偏移（Offset），对给定描述符在t轴或x轴上进行偏移；</li>
<li>替换（Replace），用于将给定描述符的某个轴设为指定常量，例如，当有拼接时变（声学特征）和时不变（说话人特征）两组特征时，可以指定时不变特征的t轴为0（也就是不管什么时刻，说话人特征都是那100维固定向量）</li>
<li>判断（IfDefined和Failover），用于根据不同的情况改变描述符的行为。</li>
</ul>
<p>src&#x2F;nnet3&#x2F;nnet-descriptor.h ：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;descriptor&gt;  ::=   &lt;node-name&gt;      ;; node name of kInput or kComponent node.</span><br><span class="line">&lt;descriptor&gt;  ::=   Append(&lt;descriptor&gt;, &lt;descriptor&gt; [, &lt;descriptor&gt; ... ] )</span><br><span class="line">&lt;descriptor&gt;  ::=   Sum(&lt;descriptor&gt;, &lt;descriptor&gt;)</span><br><span class="line">&lt;descriptor&gt;  ::=   Const(&lt;value&gt;, &lt;dimension&gt;)    ;; e.g. Const(1.0, 512)</span><br><span class="line">&lt;descriptor&gt;  ::=   Scale(&lt;scale&gt;, &lt;descriptor&gt;)   ;; e.g. Scale(-1.0, tdnn2)</span><br><span class="line">;; Failover or IfDefined might be useful for time t=-1 in a RNN, for instance.</span><br><span class="line">&lt;descriptor&gt;  ::=   Failover(&lt;descriptor&gt;, &lt;descriptor&gt;)   ;; 1st arg if computable, else 2nd</span><br><span class="line">&lt;descriptor&gt;  ::=   IfDefined(&lt;descriptor&gt;)     ;; the arg if defined, else zero.</span><br><span class="line">&lt;descriptor&gt;  ::=   Offset(&lt;descriptor&gt;, &lt;t-offset&gt; [, &lt;x-offset&gt; ] ) ;; offsets are integers</span><br><span class="line">;; Switch(...) is intended to be used in clockwork RNNs or similar schemes.  It chooses</span><br><span class="line">;; one argument based on the value of t (in the requested Index) modulo the number of</span><br><span class="line">;; arguments</span><br><span class="line">&lt;descriptor&gt;  ::=   Switch(&lt;descriptor&gt;, &lt;descriptor&gt; [, &lt;descriptor&gt; ...])</span><br><span class="line">;; For use in clockwork RNNs or similar, Round() rounds the time-index t of the</span><br><span class="line">;; requested Index to the next-lowest multiple of the integer &lt;t-modulus&gt;,</span><br><span class="line">;; and evaluates the input argument for the resulting Index.</span><br><span class="line">&lt;descriptor&gt;  ::=   Round(&lt;descriptor&gt;, &lt;t-modulus&gt;)  ;; &lt;t-modulus&gt; is an integer</span><br><span class="line">;; ReplaceIndex replaces some &lt;variable-name&gt; (t or x) in the requested Index</span><br><span class="line">;; with a fixed integer &lt;value&gt;.  E.g. might be useful when incorporating</span><br><span class="line">;; iVectors; iVector would always have time-index t=0.</span><br><span class="line">&lt;descriptor&gt;  ::=   ReplaceIndex(&lt;descriptor&gt;, &lt;variable-name&gt;, &lt;value&gt;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="component和component-node："><a href="#component和component-node：" class="headerlink" title="component和component-node："></a>component和component-node：</h2><p>component 是类；</p>
<p>component-node 是类的实例</p>
<h2 id="kaldi-nnet3-写一个cnn："><a href="#kaldi-nnet3-写一个cnn：" class="headerlink" title="kaldi nnet3 写一个cnn："></a>kaldi nnet3 写一个cnn：</h2><p>kernel是用time-offsets和height-offsets设置得到的卷积核大小；</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/nnet3/image-20221009190513492.png" alt="image-20221009190513492"></p>
<h2 id="kaldi-nnet3写一个lstm"><a href="#kaldi-nnet3写一个lstm" class="headerlink" title="kaldi nnet3写一个lstm"></a>kaldi nnet3写一个lstm</h2><p>delay指的是进行几次循环</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/nnet3/image-20221009190903142.png" alt="image-20221009190903142"> </p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/nnet3/image-20221009191218981.png" alt="image-20221009191218981"></p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>wav2vec 2.0 A framework for self-supervised learning of speech representations</title>
    <url>/2023/04/17/%E8%AF%86%E5%88%AB/wav2vec%202.0%20A%20framework%20for%20self-supervised%20learning%20of%20speech%20representations/</url>
    <content><![CDATA[<h1 id="wav2vec-2-0-A-framework-for-self-supervised-learning-of-speech-representations"><a href="#wav2vec-2-0-A-framework-for-self-supervised-learning-of-speech-representations" class="headerlink" title="wav2vec 2.0: A framework for self-supervised learning of speech representations"></a>wav2vec 2.0: A framework for self-supervised learning of speech representations</h1><blockquote>
<p>&#x3D;&#x3D;Baevski, Alexei, et al. “wav2vec 2.0: A framework for self-supervised learning of speech representations.” <em>Advances in Neural Information Processing Systems</em> 33 (2020): 12449-12460.&#x3D;&#x3D; citations：2004</p>
<p>github：<a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a>  </p>
</blockquote>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><p>提供自监督学习里一个好的语音表示。</p>
<h3 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h3><p>mask一部分特征，量化表示，改进loss。</p>
<h3 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h3><ol>
<li>在Librispeech数据集训练，在clean&#x2F;other测试集上的WER为1.8&#x2F;3.3；</li>
<li>如果只用1小时训练，效果优于之前方法用100小时训练的结果；</li>
<li><strong>只用10分钟有标签训练</strong>，53K无标签预训练，WER为4.8&#x2F;8.2。</li>
</ol>
<h3 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h3><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><img src="/2023/04/17/%E8%AF%86%E5%88%AB/wav2vec%202.0%20A%20framework%20for%20self-supervised%20learning%20of%20speech%20representations/image-20230417160834856.png" alt="image-20230417160834856" style="zoom:80%;">



<h3 id="Feature-encoder："><a href="#Feature-encoder：" class="headerlink" title="Feature encoder："></a>Feature encoder：</h3><p>$f: \mathcal{X} \mapsto \mathcal{Z}$  。 结构是多层TCN卷积接LN，接GELU激活。输入encoder的原始波形归一化为零均值和单位方差</p>
<h3 id="Contextualized-representations-with-Transformers-（context-network）："><a href="#Contextualized-representations-with-Transformers-（context-network）：" class="headerlink" title="Contextualized representations with Transformers （context network）："></a>Contextualized representations with Transformers （context network）：</h3><p>$g: \mathcal{Z} \mapsto \mathcal{C}$ 。结构是用了卷积做<strong>相对位置编码</strong>。用了残差，把input接GELU激活加上卷积层输出的和，再接LN。</p>
<h3 id="Quantization-module："><a href="#Quantization-module：" class="headerlink" title="Quantization module："></a>Quantization module：</h3><p> $ \mathcal{Z} \mapsto \mathcal{Q}$ 量化encoder的输出，量化后的q来表示自监督目标里的target。用的product quantization：先学discrete units离散单元，再学上下文表示，具体做法相当于从多个码本中选择量化表示，再拼接起来。</p>
<p>给定$G$个码本、$V$个entries  $e \in$ $\mathbb{R}^{V \times d &#x2F; G}$ ，从每个码本里选择一个entry（条目），将得到的向量连接起来 $e_1, \ldots, e_G$ ；</p>
<p>再经过一个linear变换 $\mathbb{R}^d \mapsto \mathbb{R}^f$ ，得到量化表示 $\mathbf{q} \in \mathbb{R}^f$ 。</p>
<p>Gumbel softmax能够以可导的方式选择离散的码本条目。使用straight-through estimator ，设置 $G$ 硬Gumbel softmax操作，则feature encoder的输出  $\mathbf{z}$ 映射到  $\mathbf{l} \in \mathbb{R}^{G \times V}$ logits ，选第 $v$ 个码本entry，对于 group $g$ 的表达式：<br>$$<br>p_{g, v}&#x3D;\frac{\exp \left(l_{g, v}+n_v\right) &#x2F; \tau}{\sum_{k&#x3D;1}^V \exp \left(l_{g, k}+n_k\right) &#x2F; \tau},<br>$$<br>其中， $\tau$ is a 非负 temperature； $n&#x3D;-\log (-\log (u))$ ， $u$ 是从均匀分布 $\mathcal{U}(0,1)$ 中采样的的样本；</p>
<p>前向传播中， codeword $i$ 是由 $i&#x3D;\operatorname{argmax}<em>j p</em>{g, j}$ ；反向传播中，使用Gumbel softmax输出的真实梯度。</p>
<p>。。。。量化这块不懂，TODO</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>类似BERT的做法，在 latent feature encoder space  中mask一部分time steps。训练目标要求为每个mask时间步，在一组带有干扰项（噪声）中分类出真实的quantized latent audio representation。</p>
<h3 id="Masking"><a href="#Masking" class="headerlink" title="Masking"></a>Masking</h3><p>mask一部分feature encoder outputs  ，替换为所有mask时间步之间共享的训练过的特征向量。quantization module 的输入<strong>不</strong>mask。</p>
<p>具体mask操作为：在所有时间步长中随机抽取一定比例p作为起始indces，然后从每个采样index中mask后面的M个连续时间步长，跨度可能重叠。</p>
<h3 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h3><p>用了wav2vec1.0论文里的contrastive task $L_m$，还有增加了一个codebook diversity loss  码本多样性loss $L_d$，鼓励模型<strong>多多使用</strong>码本entry。</p>
<p>$$<br>\mathcal{L}&#x3D;\mathcal{L}_m+\alpha\mathcal{L}_d<br>$$<br>其中，$\alpha$是一个超参。</p>
<h4 id="Contrastive-Loss"><a href="#Contrastive-Loss" class="headerlink" title="Contrastive Loss"></a>Contrastive Loss</h4><p>模型要从K个干扰项、1个真实量化latent speech表示$q_t$ 中分类出这个真实的$q_t$。干扰项来自每句话mask的时间步里进行均匀分布采样得到。</p>
<p>Contrastive  loss表示为：<br>$$<br>\mathcal{L}_m&#x3D;-\log \frac{\exp \left(\operatorname{sim}\left(\mathbf{c}_t, \mathbf{q}<em>t\right) &#x2F; \kappa\right)}{\sum</em>{\tilde{\mathbf{q}} \sim \mathbf{Q}_t} \exp \left(\operatorname{sim}\left(\mathbf{c}_t, \tilde{\mathbf{q}}\right) &#x2F; \kappa\right)}<br>$$<br>其中，计算了quantized latent speech representations和context representations之间的余弦相似度 $\operatorname{sim}(\mathbf{a}, \mathbf{b})&#x3D;\mathbf{a}^T \mathbf{b} &#x2F;|\mathbf{a}||\mathbf{b}|$ 。</p>
<h4 id="Diversity-Loss"><a href="#Diversity-Loss" class="headerlink" title="Diversity Loss"></a>Diversity Loss</h4><p>为了鼓励每个G码本中equal地使用 V entry，对每个码本$\bar{p}<em>g$最大化averaged softmax distribution $\mathbf{l}$   ，表达式为：<br>$$<br>\mathcal{L}<em>d&#x3D;\frac{1}{G V} \sum</em>{g&#x3D;1}^G-H\left(\bar{p}<em>g\right)&#x3D;\frac{1}{G V} \sum</em>{g&#x3D;1}^G \sum</em>{v&#x3D;1}^V \bar{p}<em>{g, v} \log \bar{p}</em>{g, v}<br>$$<br>公式里不包括temperature 和gumbel noise。</p>
<p>实现上，是最大化 perplexity：<br>$$<br>\frac{GV-\sum_{g&#x3D;1}^G \exp(-\sum_{v&#x3D;1}^Vp_{gv}\log p_{gv})}{GV}<br>$$</p>
<p>和上式等价。</p>
<h3 id="Fine-tuning"><a href="#Fine-tuning" class="headerlink" title="Fine-tuning"></a>Fine-tuning</h3><p>在context network 后接一个linear层，输出vocabulary大小的分类。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2>]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
        <tag>预训练</tag>
      </tags>
  </entry>
  <entry>
    <title>wav2vec Unsupervised pre-training for speech recognition</title>
    <url>/2023/04/17/%E8%AF%86%E5%88%AB/wav2vec%20Unsupervised%20pre-training%20for%20speech%20recognition/</url>
    <content><![CDATA[<h1 id="wav2vec-Unsupervised-pre-training-for-speech-recognition"><a href="#wav2vec-Unsupervised-pre-training-for-speech-recognition" class="headerlink" title="wav2vec: Unsupervised pre-training for speech recognition"></a>wav2vec: Unsupervised pre-training for speech recognition</h1><blockquote>
<p>&#x3D;&#x3D;Schneider, Steffen, et al. “wav2vec: Unsupervised pre-training for speech recognition.” <em>arXiv preprint arXiv:1904.05862</em> (2019).&#x3D;&#x3D;Facebook citations：883</p>
<p>github：<a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></p>
</blockquote>
<h3 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h3><p>打破了语音识别声学模型要大量标注数据才能训练好的常规认知。通过学习原始音频表征来探索语音识别的无监督预训练。</p>
<h3 id="提出什么方法"><a href="#提出什么方法" class="headerlink" title="提出什么方法"></a>提出什么方法</h3><p>用一批无标签的训练数据，通过contrastive  loss，训练一个分类真实音频的无监督模型。（正样本来自无标签数据，负样本来自从噪声中采样）</p>
<h3 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h3><p>用1000个小时的无标签数据预训练，在WSJ 数据集达到sota。比Deep Speech2论文里在character-based system的效果更好，WER从3.1%下降到2.43%，并且训练数据比其少两个数量级。</p>
<p>超越了frame-wise phoneme classification。</p>
<h3 id="还有什么问题"><a href="#还有什么问题" class="headerlink" title="还有什么问题"></a>还有什么问题</h3><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><ul>
<li>提出一种用无监督预训练来改善有监督语音识别的方法；训练一个无监督预训练模型，用来给下游的语音识别任务作为输入；</li>
<li>该无监督预训练模型叫做wav2vec；该模型输入是原始音频，输出是embedding，这个embedding是用大量无标签音频训练得到的，能表示一定的输入音频信息，模型结构用的CNN；loss function是contrastive loss，从negative中鉴别出哪个是真实的 future audio sample；</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>模型结构全由卷积构成。</p>
<ul>
<li><p>输入原始音频x通过encoder network  $f:X -&gt;   Z$ ，得到具有上下文表示的输出z；</p>
<p>The encoder layers have kernel sizes (10; 8; 4; 4; 4) and strides (5; 4; 2; 2; 2).   </p>
<p>causal convolution with 512 channels, a group normalization layer and a ReLU nonlinearity.   </p>
<p>输入30ms窗长，10ms窗移，16kHz音频，输出<strong>低频</strong>特征表示；</p>
</li>
<li><p>然后经过一个context network $g:Z -&gt;   C$ ，把encoder的输出z，多个z concat起来经过g得到c：$\large c_i&#x3D;g(z_i…z_{i-v})$，其中v是感受野，是一个超参；</p>
<p>The context network has nine layers with kernel size three and stride one  ，感受野210ms；</p>
</li>
<li><p>encoder network和context network的结构：causal convolution with 512 channels, a group normalization layer and a ReLU nonlinearity.</p>
</li>
</ul>
<p>group norm：在特征和时间维度上对每个样本进行归一化，这相当于用一个单个的归一化组进行group normalization。</p>
<p>发现选择一种对输入的缩放和偏移量无关的归一化方案是很重要的，该归一化方法对于<strong>跨数据集</strong>泛化性更好；</p>
<p>为了在更大的数据集上训练，还做了一个更大点的模型(“wav2vec large”)，在encoder中使用两个额外的linear层和一个相当大的context network（由12个层组成，kernel size不断增加（2,3,…,13））。</p>
<p>在这种情况下，发现在aggregator中引入skip connections来帮助收敛是很重要的。因此，总receptive field增加到 810 ms。</p>
<img src="/2023/04/17/%E8%AF%86%E5%88%AB/wav2vec%20Unsupervised%20pre-training%20for%20speech%20recognition/image-20220626160341868.png" alt="image-20220626160341868" style="zoom: 40%;">

<h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>loss function：预测未来样本。不是对 $p(x)$ 建模，而是在时间轴建模 $\large p(z_{i+k}|z_i…z_{i-r})&#x2F;p(z_{i+k})$</p>
<p>作者利用了负采样技术，作者从一个概率分布 $p_n$ 中采样出负样本 $\tilde z$，，最终模型的loss为区分正例和反例的contrastive loss：</p>
<p>训练一个模型，从带有干扰噪声 $\tilde{\mathbf{z}}$（服从$p_n$分布）中区分出、预测出真实样本的未来样本 $\mathbf{z}_{i+k}$，这里 $\mathrm{k}$ 是未来的$\mathrm{k}$步。</p>
<p>最小化 contrastive loss for each step $k&#x3D;$ $1, \ldots, K$ :<br>$$<br>\mathcal{L}<em>k&#x3D;-\sum</em>{i&#x3D;1}^{T-k}\left(\log \sigma\left(\mathbf{z}_{i+k}^{\top} h_k\left(\mathbf{c}_i\right)\right)+\underset{\tilde{\mathbf{z}} \sim p_n}{\lambda \mathbb{E}}\left[\log \sigma\left(-\tilde{\mathbf{z}}^{\top} h_k\left(\mathbf{c}<em>i\right)\right)\right]\right)<br>$$<br>其中，$c$ 是context network的输出（仿射变换前）；sigmoid $\sigma(x)&#x3D;1 &#x2F;(1+\exp (-x))$， 因此 $\sigma\left(\mathbf{z}</em>{i+k}^{\top} h_k\left(\mathbf{c}<em>i\right)\right)$ 表示 $\mathbf{z}</em>{i+k}$ 是真实样本的概率。</p>
<p>放射变换每一步的参数都不同？ step-specific affine transformation $h_k\left(\mathbf{c}_i\right)&#x3D;W_k \mathbf{c}_i+\mathbf{b}_k$ for each step $k$, that is applied to $\mathbf{c}_i$ (van den Oord et al., 2018). </p>
<p>把所有步累加起来，最优化loss $\mathcal{L}&#x3D;\sum_{k&#x3D;1}^K \mathcal{L}_k$ 。</p>
<p>公式的意思就是希望 真实未来样本和第k步网络输出（anchor）作用后的概率尽可能大，干扰样本和第k步网络输出（anchor）作用后的概率尽可能小。</p>
<p>比如 k&#x3D;2，未来第2步，T&#x3D;100，则 $L_2$ 是要累加i&#x3D;1到i&#x3D;98那么多帧。这里的 $c_i$ 就是anchor。</p>
<p>i&#x3D;1时，$\mathbf{z}&#x3D;\mathbf{z}_3$（在第3帧），$c&#x3D;c_1$（在第1帧），负样本$\tilde{\mathbf{z}}$ 是除$\mathbf{z}_3$之外的序列其他帧的采样$\lambda$个的均值；</p>
<p>i&#x3D;2时，$\mathbf{z}&#x3D;\mathbf{z}_4$（在第4帧），$c&#x3D;c_2$（在第2帧），负样本$\tilde{\mathbf{z}}$ 是除$\mathbf{z}_4$之外的序列其他帧的采样$\lambda$个的均值；</p>
<p>（还挺神奇？？？希望当前输入下能输出未来时刻的可能性越高越好，而不是当前输入下输出当前时刻的可能性越高越好，也就是和当前时刻连接最紧密的居然是未来时刻？？？）</p>
<p>负样本来源：每个音频序列中均匀选择10个干扰样本作为负样本（这样能接近期望，更能混淆），服从的分布表达式为 $p_n(\mathbf{z})&#x3D;\frac{1}{T}$ （均匀分布）。其中 $T$ 是序列长度，  $\lambda$ 是负样本数。</p>
<p><strong>如果负样本是从不同音频、不同说话人里采样的，效果会差。</strong></p>
<h3 id="下游任务"><a href="#下游任务" class="headerlink" title="下游任务"></a>下游任务</h3><p>把encoder-context network输出的$c$ 作为embedding，声学特征，作为下游任务的输入，也就是语音识别声学模型的输入（替换掉 FBank 特征）。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2>]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
        <tag>预训练</tag>
      </tags>
  </entry>
  <entry>
    <title>声学模型论文笔记</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E5%A3%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="声学模型论文笔记"><a href="#声学模型论文笔记" class="headerlink" title="声学模型论文笔记"></a>声学模型论文笔记</h1><blockquote>
<p>[FSMN] &#x3D;&#x3D;Shiliang Zhang et al. “Feedforward Sequential Memory Networks: A New Structure to Learn Long-term Dependency” arXiv: Neural and Evolutionary Computing (2015): n. pag.&#x3D;&#x3D; citations：62</p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>提出前馈序列记忆网络 FSMN（Feedforward Sequential Memory Networks）</p>
</li>
<li><p>将上下文编码成一个向量（与隐层输出结点维度相同），其实就是不同时间帧特征加权求和  $\large{\tilde{h}<em>t^l&#x3D;\sum\limits</em>{i&#x3D;0}^{N_1}a_i^l\cdot{h_{t-i}^l}+\sum\limits_{j&#x3D;1}^{N_2}c_j^l\cdot{h_{t+j}^l}}$</p>
<p>其中，$a_i$和$c_i$是常数系数或常数向量，在任意t时刻，都是不变的（时不变系数）（可通过梯度更新来更新该值）</p>
<p>这和只用h，只梯度更新h就够了不一样（一开始想的是这个a都不需要，h能自动更新到那个值，其实不是的），可以认为是一个scale因子</p>
<p>这个结构叫 tapped-delay  structure（抽头延时）</p>
<p>在下标索引超出范围时使用零填充向量</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E5%A3%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/b93c627a679b04982e51b0c95743e475_2_Figure_1.png" alt="img" style="zoom:80%;">
</li>
<li><p>前向传播：$\large{h_t^{l+1}&#x3D;f(W^lh_t^l+\tilde{W}\tilde{h}_t^l+b^l)}$</p>
</li>
<li><p>FSMN与RNN比较，RNN：$\large{h_t&#x3D;f(Wx_t+\tilde{W}h_{t-1}+b)}$</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E5%A3%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/b93c627a679b04982e51b0c95743e475_3_Figure_2.png" alt="img" style="zoom:80%;">

<p>​	同一层下，当前时刻h来自前一时刻h和x。这和FSMN不同，FSMN当前时刻h不会来自同一层的不同时刻h。</p>
<p>​	RNN类似无限脉冲响应IIR；FSMN类似高阶有限脉冲响应；</p>
<ul>
<li>时不变系数a可以换成attention系数（时变了）（context-dependent系数）</li>
</ul>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>识别方向</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E6%96%B9%E5%90%91/</url>
    <content><![CDATA[<p>方向：</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E6%96%B9%E5%90%91/image-20220512174709926.png" alt="image-20220512174709926" style="zoom:80%;">

<p>会议：</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E6%96%B9%E5%90%91/image-20220512175109288.png" alt="image-20220512175109288"></p>
<p>数据：<a href="http://yqli.tech/page/data.html#row-5">http://yqli.tech/page/data.html#row-5</a></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E6%96%B9%E5%90%91/image-20220512175309644.png" alt="image-20220512175309644"></p>
<p>论文列表：<a href="http://yqli.tech/page/asr_paper.html">http://yqli.tech/page/asr_paper.html</a></p>
<p>C++：<a href="http://yqli.tech/page/pro.html">http://yqli.tech/page/pro.html</a></p>
<p>python：<a href="http://www.pythondoc.com/">http://www.pythondoc.com/</a></p>
<p>课程：<a href="https://nndl.github.io/">https://nndl.github.io/</a> 、 <a href="https://atcold.github.io/pytorch-Deep-Learning/zh/">https://atcold.github.io/pytorch-Deep-Learning/zh/</a>  、 <a href="http://jalammar.github.io/illustrated-transformer/">http://jalammar.github.io/illustrated-transformer/</a></p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>识别工具包</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E5%B7%A5%E5%85%B7%E5%8C%85/</url>
    <content><![CDATA[<h1 id="Vosk-Speech-Recognition-Toolkit"><a href="#Vosk-Speech-Recognition-Toolkit" class="headerlink" title="Vosk Speech Recognition Toolkit"></a>Vosk Speech Recognition Toolkit</h1><blockquote>
<p>github：<a href="https://github.com/alphacep/vosk-api">https://github.com/alphacep/vosk-api</a></p>
</blockquote>
<h1 id="Wenet"><a href="#Wenet" class="headerlink" title="Wenet"></a>Wenet</h1><blockquote>
<p><a href="https://github.com/wenet-e2e/wenet">https://github.com/wenet-e2e/wenet</a></p>
</blockquote>
<h1 id="emoASR"><a href="#emoASR" class="headerlink" title="emoASR"></a>emoASR</h1><blockquote>
<p><a href="https://github.com/emonosuke/emoASR">https://github.com/emonosuke/emoASR</a></p>
</blockquote>
<p>专注推理过程</p>
<ul>
<li>Encoder <ul>
<li>RNN </li>
<li>Transformer(Trf.)[Vaswani 2017] </li>
<li>Conformer(Cf.)[Gulati 2020]</li>
</ul>
</li>
<li>Decoder <ul>
<li>CTC[Graves 2006] </li>
<li>RNN-Transducer(RNN-T)[Graves2012] </li>
<li>LAS [chan 2015] </li>
<li>Transformer(Trf.)</li>
</ul>
</li>
<li>LM <ul>
<li>RNNLM </li>
<li>Transformer LM </li>
<li>BERT [Devlin 2018]</li>
<li>ELECTRA[Clark2020] </li>
<li>Phone-attentive ELECTRA(P-ELECTRA [Futami 2021]</li>
</ul>
</li>
<li>Method <ul>
<li>Rescoring </li>
<li>Shallow Fusion </li>
<li>KnowledgeDistillation</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>识别论文笔记（一）端到端识别方案</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="端到端识别方案"><a href="#端到端识别方案" class="headerlink" title="端到端识别方案"></a>端到端识别方案</h1><blockquote>
<p>&#x3D;&#x3D;Yao, Zhuoyuan, et al. “Wenet: Production oriented streaming and non-streaming end-to-end speech recognition toolkit.” <em>arXiv preprint arXiv:2102.01547</em> (2021).&#x3D;&#x3D;</p>
<p>github：<a href="https://github.com/mobvoi/wenet">https://github.com/mobvoi/wenet</a>  </p>
<p>chao yang ：<a href="http://placebokkk.github.io/wenet/2021/06/04/asr-wenet-nn-1.html">Wenet网络设计与实现</a></p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>提出识别框架Wenet</p>
</li>
<li><p>解决流式非流式问题方法：用dynamic chunk-based attention策略，提出two-pass方法框架（U2，a unified two-pass joint CTC&#x2F;AED model ）解决流式非流式的统一 （unifying streaming and non-streaming modes）</p>
</li>
<li><p>U2：</p>
<ul>
<li>Shared Encoder ：多个Transformer和Conformer（只看右context），只看部分输入音频特征长度，因此可以流式；</li>
<li>CTC Decoder：线性层，CTC loss；</li>
<li>Attention Decoder：多个Transformer decoder层；</li>
<li>rescore解码过程：CTC Decoder流式进行一遍解码，Attention Decoder进行第二遍解码；attention rescoring ：CTC prefix beam search输出n-best候选路径，n-best和encoder通过AED decoder得到output，这里n-best（没有blank了）是作为decoder的输入序列（类似于训练时的label序列，可以并行，一次到位，不需要输出作用到下一个输入）；</li>
<li>rescore：<ul>
<li>aed的输出并没有用什么beam search，而是直接取和ctc n-best对应位置相同的路径分数</li>
<li>aed输出的第n条序列分数为：&#x3D;&#x3D;对应ctc 第n条路径分数 * ctc_weight + 在ctc第n条作为输入的前提下 aed的输出的路径分数&#x3D;&#x3D;（recore 分数）</li>
<li>可能aed rescore的作用是用来校正ctc的n-best的，既然前提是在ctc n-best空间范围内重新选一条，所以ctc n-best一定是很有说服力的；</li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220510111818545.png" alt="image-20220510111818545" style="zoom: 67%;">

<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><ul>
<li><p>Joint CTC&#x2F;AED training：</p>
<ul>
<li>Loss function：$\large L_{combined}(x,y) &#x3D; \lambda L_ {CTC}(x,y) + (1-\lambda) L_{AED} (x,y)$</li>
<li>优势：加快收敛，提高训练稳定性，得到更好识别结果</li>
</ul>
</li>
<li><p>dynamic chunk training  ：</p>
<ul>
<li>训练时每个chunk里，只能看见从音频开头到当前chunk尾的长度信息；chunk大小是随机数，让模型学会预测任意长度chunk输出</li>
<li>chunk是帧数（这里的帧按下采样后的帧），基于chunk的attention，本质上是去限制attention的作用范围，可以通过attention mask来实现。（QK后接mask后得score，再softmax）</li>
<li>优势：实现了流式</li>
<li></li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/mask-encoder-attention.png" alt="mask-encoder-attention" style="zoom: 67%;">

<h3 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h3><ul>
<li>训练：<ul>
<li>TorchScript 用来开发models；</li>
<li>Torchaudio 用来即时on-the-fly特征抽取； </li>
<li>Distributed Data Parallel (DDP)用来分布式训练；</li>
</ul>
</li>
<li>部署：<ul>
<li>torch Just In Time (JIT) 用来导出模型；</li>
<li>PyTorch quantization 用来量化模型；</li>
<li>LibTorch 用来上线使用 production runtime；</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220510111900464.png" alt="image-20220510111900464" style="zoom: 67%;">

<ul>
<li>Runtime<ul>
<li>x86 as server runtime  </li>
<li>Android as on-device runtime</li>
</ul>
</li>
</ul>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据集：aishell-1，150h train，10h dev，5h test；</li>
<li>特征：80维mfcc，25ms帧长，10ms帧移，specaugment（numf&#x3D;2，F&#x3D;10，numt&#x3D;2，F&#x3D;50）用来防止过拟合；</li>
<li>特征先经过两层3* 3 kernel，stride&#x3D;2的卷积，进行下采样，再送入encoder；</li>
<li>encoder：12个transformer层；decoder：6个transformer层；</li>
<li>25000步warm-up，adam优化器；</li>
<li>average top-K 最低cv_loss作为最终模型；</li>
<li>可以用简单的2gram phone lm代替ctc n-best给attention用吗？？？？？</li>
<li>CER结果：</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220510123816315.png" alt="image-20220510123816315" style="zoom: 67%;">

<ul>
<li>量化CER对比：可以看出错误率很差得很小</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220510164639096.png" alt="image-20220510164639096" style="zoom: 67%;">

<ul>
<li>RTF：可以看出实时率很不错<ul>
<li>更小的chunk反而有更高的RTF，因为一条音频分的chunk数变多了，前向计算的次数变多了（chunk越小的好处是时延小）；</li>
<li>在安卓端上，量化会带来速度的两倍提升；但在x86服务端上提升不大；</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220510164730235.png" alt="image-20220510164730235" style="zoom: 67%;">

<ul>
<li>Latency<ul>
<li>通过构造WebSocket server&#x2F;client  来仿真测试真实流式应用，来评估时延；</li>
<li>model latency：由于等待模型计算而引入的延迟，计算为 $(chunk&#x2F;2 * 4 + 6)*10(ms)$，4是下采样率，6是一开始两层cnn要lookahead一些帧（6帧），10是帧移；</li>
<li>rescoring cost，二遍解码的延迟；</li>
<li>final latency，用户感受到的时延，是从用户停止说话 到 得到识别结果 之间的时长</li>
<li>接收到用户停止发语音后，发送到ctc decoder拿到ctc的n-best，给attention decoder；</li>
<li>网络延迟未考虑（因为测试时server&#x2F;client在同一台机子）</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220510171629404.png" alt="image-20220510171629404" style="zoom: 67%;">

<h3 id="实验2"><a href="#实验2" class="headerlink" title="实验2"></a>实验2</h3><ul>
<li>数据集15,000-hour  （1.5w小时）普通话数据</li>
<li>累计4个步长的梯度，才更新，能更稳定地训练</li>
<li>分析attention rescore对于长音频会有优势（大于5s）</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Zhang, Binbin, et al. “WeNet 2.0: More Productive End-to-End Speech Recognition Toolkit.” <em>arXiv preprint arXiv:2203.15455</em> (2022).&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><ul>
<li>为了提高ASR识别率，提出U2++（通过双向attention decoder来统一two-pass的框架），<ul>
<li>训练阶段：双向 从后往前的attention decoder使得获得未来一段时间的信息，</li>
<li>解码阶段：结合从前和从后的预测结果</li>
<li>改善了shared encoder，并提高rescore的识别率（比单向提高10%）；</li>
</ul>
</li>
<li><strong>U2++框架</strong>：a unified two-pass joint CTC&#x2F;AED framework   <ul>
<li>Shared Encoder：给声学特征建模，由多个transformer或conformer组成，only takes limited right contexts into account to keep a balanced latency  </li>
<li>CTC Decoder：建模声学特征和token单元的帧级别对齐，由一个线性层组成，which transforms the Shared Encoder output to the CTC activation  </li>
<li>Attention Decoder：<ul>
<li>Left-to-Right Attention Decoder (L2R) ：models the ordered token sequence from left to right to represent the past contextual information.  </li>
<li>A Right-to-Left Attention Decoder (R2L) ：models the reversed token sequence from right to left to represent the future contextual information.  </li>
<li>The L2R and R2L Attention Decoders consist of multiple Transformer decoder layers.   </li>
<li>用一个超参数调节二者的loss比例：$L_{AED}(x,y)&#x3D;(1-\alpha)L_{L2R}(x,y)+\alpha L_{R2L}(x,y)$</li>
<li>在dynamic chunk训练里，chunk给特征都是从前往后给的，然后L2R对现有的chunk从前往后做，R2L是从后往前做；</li>
</ul>
</li>
<li>two pass：During the decoding stage, the CTC Decoder runs in the streaming mode in the first pass and the L2R and R2L Attention Decoders do rescore in the non-streaming mode to improve the performance in the second pass.</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220511114046236.png" alt="image-20220511114046236" style="zoom:67%;">

<ul>
<li><strong>N-gram Language Model</strong> ：在Wenet2.0中引入了基于wfst的<strong>n-gram</strong>语言模型；在CTC解码中加入，提高8%<ul>
<li>（雷博说）对于垂直领域，训练lm用的通用文本 + 一些垂直领域文本</li>
<li>TLG：compiles the n-gram LM (G), lexicon (L), and end-to-end modeling CTC topology (T) into a WFST-based decoding graph (TLG)  $TLG&#x3D;T\circ min(det(L\circ G))$</li>
<li>denoted as CTC WFST beam search in the WeNet 2.0  </li>
<li>To speedup decoding, blank frame skipping technique is adopted  (参考”Phone synchronous decoding with ctc lattice”)</li>
<li>用n-gram进行语言模型训练，这是因为更符合工业使用</li>
<li>解码时为了加速解码，blank符号概率大于0.98的，跳过该帧，就是说 不考虑很可能是blank的帧的概率，可以加速解码，因为blank其实没啥用；</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220511121210127.png" alt="image-20220511121210127">





<ul>
<li><p><strong>Contextual Biasing</strong>  ：设计了一种联合<strong>contextual biasing</strong>框架，更适配特定语境，比如通讯录；【TODO 看三篇论文】</p>
<ul>
<li><p>（雷博说）contextual bias是为了解决 &#x3D;&#x3D;热词&#x3D;&#x3D; 问题，用来生成一些热词，但是权重需要经验构造，不是一个非常靠谱的方案；</p>
</li>
<li><p>在解码中用，有LM和没有LM的解码过程都可以引入，从而适配语境</p>
</li>
<li><p>已知biasing phrases短语，实时构建contextual wfst图；首先，biasing phrases通过词典或模型拆分成biasing unit，把biasing unit的arc权重提高</p>
</li>
<li><p>a special failure arc with a negative accumulated boosted score is added ，当只匹配部分bias unit而不是整个bias phrase时，失败弧用于move提高的权重</p>
<p>（也就是加一条空边（有权重）的弧回去，平衡这个提高的权重）</p>
</li>
<li><p>$\large y^*&#x3D;arg\max\limits_y logP(y|x) + \lambda logP_C(y)$，其中$P_C(y)$ 是bias score</p>
</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220511142320509.png" alt="image-20220511142320509" style="zoom: 80%;">

<ul>
<li>设计了一种联合Unified  IO（UIO）来支持大规模数据训练<ul>
<li>对于小数据集，UIO随机访问样本；</li>
<li>对于大数据集，UIO先把样本聚集在一个块里（类似kaldi的egs）（tar压缩，压缩是为了防止OOM），之后训练、随机访问的就是这个块shard（解压来训练）</li>
<li>inspired by TFReord (Tensorflow)  and AIStore  </li>
<li><a href="https://wenet.org.cn/wenet/UIO.html">https://wenet.org.cn/wenet/UIO.html</a></li>
<li>Chain IO  [TODO]</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220511113104350.png" alt="image-20220511113104350" style="zoom:67%;">

<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><ul>
<li>dynamic chunk值选取：在均匀分布$C \sim U(1,maxbatchlengthT)$中随机选取，</li>
</ul>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据集aishell-1、wenetspeech</li>
</ul>
<p>$\large x\in f\times T$</p>
<p>$\large z\in f’\times T$</p>
<p>$\large y\in e\times L$</p>
<hr>
<h1 id="大规模训练"><a href="#大规模训练" class="headerlink" title="大规模训练"></a>大规模训练</h1><blockquote>
<p>&#x3D;&#x3D;Kim, Chanwoo, et al. “End-to-end training of a large vocabulary end-to-end speech recognition system.” <em>2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>. IEEE, 2019.&#x3D;&#x3D;</p>
</blockquote>
<h5 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><p>- </p>
<h5 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><p>- </p>
<h5 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h5><p>- </p>
<h5 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h5><p>- </p>
<h3 id="论文思路"><a href="#论文思路" class="headerlink" title="论文思路"></a>论文思路</h3><ul>
<li>提出了一个端到端语音识别系统的训练框架，数据读取、数据增广、参数更新都能是on-the-fly（即时）的；</li>
<li>训练用了Horovod allreduce approach   </li>
<li>训练CPU部分用的Example Servers (ES) and workers</li>
</ul>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220512162312294.png" alt="image-20220512162312294"></p>
<ul>
<li>数据加载，用的tf.data的data queue（没用QueueRunner ）</li>
<li>训练在Horovod用的allreduce 方法（没用server-worker structure  ）</li>
<li>模型：</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220512165113089.png" alt="image-20220512165113089" style="zoom: 67%;">

<h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据集：librispeech、10,000-hr anonymized Bixby English dataset （三星的智能助手） </li>
<li>机器：Each GPU node of the GPU cluster has eight Nvidia™P-40, P-100 or V-100 GPUs and two Intel E5-2690 v4 CPUs, Each of these CPUs has 14 cores.</li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul>
<li>AM与transformer LM进行shallow fusion，WER：2.44 %  （librispeech test-clean）</li>
</ul>
<p>TODO 没看完</p>
<hr>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>识别论文笔记（三）声学模型</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="声学模型"><a href="#声学模型" class="headerlink" title="声学模型"></a>声学模型</h1><blockquote>
<p>&#x3D;&#x3D;Vaswani, Ashish, et al. “Attention is all you need.” <em>Advances in neural information processing systems</em> 30 (2017).&#x3D;&#x3D;citations：42175</p>
<p>官方 github tensorflow：<a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a>  </p>
<p>gihub Chainer：<a href="https://github.com/soskek/attention_is_all_you_need">https://github.com/soskek/attention_is_all_you_need</a></p>
<p>github pytorch：<a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch">https://github.com/jadore801120/attention-is-all-you-need-pytorch</a></p>
<p>github tensorflow：<a href="https://github.com/Kyubyong/transformer">https://github.com/Kyubyong/transformer</a></p>
<p>github：<a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
<p>公众号：<a href="https://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&mid=2247503240&idx=3&sn=6a18f24c9a030b4186488f6c51875135&chksm=eb53d91bdc24500d26f17f40953cfdba3a358d92a783fc5b7201f69c108334504cee2b43aae3&mpshare=1&scene=1&srcid=0611Osv6LaxD6g0XcYPZ6EmF&sharer_sharetime=1652854390830&sharer_shareid=7dfde0689a805163a3af5547f5e7bbff&version=4.0.0.6023&platform=win#rd">位置编码在注意机制中的作用</a></p>
<p>知乎：<a href="https://www.zhihu.com/question/347678607">如何理解Transformer论文中的positional encoding，和三角函数有什么关系？</a></p>
<p><a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/#the-intuition">https://kazemnejad.com/blog/transformer_architecture_positional_encoding/#the-intuition</a></p>
<p><a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html">https://nlp.seas.harvard.edu/2018/04/03/attention.html</a> [待看，据说很好]</p>
<p><a href="http://jalammar.github.io/illustrated-transformer/">http://jalammar.github.io/illustrated-transformer/</a></p>
</blockquote>
<h5 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><ul>
<li>提出一种新的序列模型，效果好，简单，没用到RNN&#x2F;CNN；</li>
<li>之前的序列模型想要建模 序列内不同位置的特征之间关系 是 随着特征之间距离远近而计算量大或小的；</li>
</ul>
<h5 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><ul>
<li>改变了以往的序列模型结构，采用了self-attention机制，encoder-decoder，point-wise feedward；</li>
</ul>
<h5 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h5><ul>
<li>机器翻译任务 28.4 BLEU on the WMT 2014 Englishto-German translation task；</li>
</ul>
<h5 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h5><ul>
<li>由于encoder的attention是注意整个输入，因此非流式</li>
</ul>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出一种新的简单的序列转换模型（sequence transduction models），Transformer，完全基于注意力机制，没使用递归和卷积；使用stacked self-attention，encoder和decoder只使用position-wise（point-wise）的全连接层；</li>
<li>Self-attention  ：是一种将单个序列的不同位置联系起来的注意力机制；</li>
<li>Transformer结构图：</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220517152824052.png" alt="image-20220517152824052" style="zoom:80%;">

<ul>
<li><p><strong>Encoder</strong>：input sequence of symbol representations  X 到sequence of continuous representations  Z 的映射；</p>
<ul>
<li>stack堆叠了6层相同的层，每层有两个子层，第一层是多头注意力机制multi-head self-attention mechanism  ，第二层是按位置的全连接前馈层 position-wise fully connected feed-forward network ，子层都用了残差结构，残差相加再layernorm层归一化，$LayerNorm(x + Sublayer(x))  $，再embedding，$\large d_{model}&#x3D;512$，因此encoder输出512维embedding；</li>
</ul>
</li>
<li><p><strong>Decoder</strong>：给定整条Z序列，生成输出序列，一次一个输出，auto-regressive 自回归的；在生成下一个符号时，使用先前生成的符号作为额外的输入</p>
<ul>
<li>stack堆叠了6层相同的层，每层有三个子层：</li>
<li>第一层是多头注意力机制multi-head self-attention mechanism ，masking：decoder里的attention只关注前面的position信息；</li>
<li>第二层对encoder的embedding做多头注意力机制，叫”encoder-decoder attention” layers  ，query序列来自上一层的deocder层，key和value来自encoder输出的embedding序列；</li>
<li>第三层也是position-wise fully connected feed-forward network，子层都用了残差结构，残差相加再layernorm层归一化；</li>
</ul>
</li>
<li><p><strong>Attention</strong>函数：对于一个输出，是一个query和一组key，value对的映射关系，获得映射关系叫做attention；</p>
<ul>
<li>output：value向量的加权和，其中“权重”表示query和key的相关程度；</li>
</ul>
</li>
<li><p><strong>Scaled Dot-Product Attention</strong> ：transformer里使用的attention叫按比例点乘（Scaled Dot-Product）的attention；query向量维度 $d_k$ ，key向量维度 $d_k$ ， value向量维度 $d_v$ ，</p>
<p>除以$\sqrt{d_k}$ （scaled），对weight用softmax进行标准化；</p>
<p>$\large Attention(Q,K,V)&#x3D;softmax(\frac{QK^T}{\sqrt{d_k}})V$</p>
<p>其中，$\large Q \in \mathbb{R}^{L_q \times d_k}$  ,  $\large K \in \mathbb{R}^{L\times d_k}$,   $\large V \in \mathbb{R}^{L \times d_v}$</p>
<p>这里Q,K,V对应下面multi-head的Q&#x3D;qW，下面虽然写的QW，但其实是Q&#x3D;qW，或者说Q&#x3D;EW，E是输入，维度是L*d_k</p>
<p>点乘：对应位置相乘，求和 ：$\large q\cdot k&#x3D;\sum_{i&#x3D;1}^{d_k}q_ik_i$</p>
<p>不加scaled的话，点乘结果会很大，softmax之后，反向传播梯度很小；</p>
<p>输出序列z，其中元素 $z_i \in \mathbb{R}^d$  , 输入序列x，其中元素 $x_i\in \mathbb{R}^d$</p>
<p>对每个元素z_i，是由输入通过线性变换的加权求和得到的：$\large z_i&#x3D;\sum\limits_{j&#x3D;1}^n\alpha_{ij}(x_jW^V)$</p>
<p>对每个权重系数，是通过softmax函数计算得到：$\large \alpha_{ij}&#x3D;\frac{\exp e_{ij}}{\sum_{k&#x3D;1}^n\exp e_{ik}}$</p>
<p>对每个$e_{ij}$，是通过compatibility function来比较两个输入元素：$\large e_{ij}&#x3D;\frac{(x_iW^Q)(x_jW^K)^T}{\sqrt{d_z}}$     ，这里的compatibility function用的是Scaled dot product   缩放点乘</p>
<p>$\large W^Q, W^K, W^V \in \mathbb{R}^{d_x\times d_z}$</p>
<p>self-attention：把input 经过三个不同的transform W，得到Q,K,V矩阵，然后Q和K点乘（matmul），softmax得到A’，A’与V矩阵想乘（乘完加）得到输出编码向量O</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220517154501406.png" alt="image-20220517154501406" style="zoom:80%;">

<ul>
<li><strong>Multi-Head Attention</strong> ：</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220517160647491.png" alt="image-20220517160647491" style="zoom:80%;">

<p>举例，multi分开，和只用一个大矩阵确实是不同的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="comment"># x=torch.Tensor([[0.1,0.2],[0.3,0.4]])</span></span><br><span class="line">x=torch.randn([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line"><span class="comment"># wq=torch.Tensor([[0.1,0.1],[0.2,0.2]])</span></span><br><span class="line">wq=torch.randn([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">wq1=wq[:,<span class="number">0</span>].unsqueeze(<span class="number">1</span>) <span class="comment">#torch.Tensor([[0.1],[0.2]])</span></span><br><span class="line">wq2=wq[:,<span class="number">1</span>].unsqueeze(<span class="number">1</span>) <span class="comment">#torch.Tensor([[0.1],[0.2]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># wk=torch.Tensor([[0.2,0.1],[0.3,0.4]])</span></span><br><span class="line">wk=torch.randn([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">wk1=wk[:,<span class="number">0</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line">wk2=wk[:,<span class="number">1</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># wk1=torch.Tensor([[0.2],[0.3]])</span></span><br><span class="line"><span class="comment"># wk2=torch.Tensor([[0.1],[0.4]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># wv=torch.Tensor([[0.1,0.4],[0.5,0.4]])</span></span><br><span class="line">wv=torch.randn([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">wv1=wv[:,<span class="number">0</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line">wv2=wv[:,<span class="number">1</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># wv1=torch.Tensor([[0.1],[0.5]])</span></span><br><span class="line"><span class="comment"># wv2=torch.Tensor([[0.4],[0.4]])</span></span><br><span class="line"></span><br><span class="line">q=torch.matmul(x,wq)</span><br><span class="line">q1=torch.matmul(x,wq1)</span><br><span class="line">q2=torch.matmul(x,wq2)</span><br><span class="line"></span><br><span class="line">k=torch.matmul(x,wk)</span><br><span class="line">k1=torch.matmul(x,wk1)</span><br><span class="line">k2=torch.matmul(x,wk2)</span><br><span class="line"></span><br><span class="line">v=torch.matmul(x,wv)</span><br><span class="line">v1=torch.matmul(x,wv1)</span><br><span class="line">v2=torch.matmul(x,wv2)</span><br><span class="line"></span><br><span class="line">soft=nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.matmul(soft(torch.matmul(q1,k1.T)),v1))</span><br><span class="line"><span class="built_in">print</span>(torch.matmul(soft(torch.matmul(q2,k2.T)),v2))</span><br><span class="line"><span class="built_in">print</span>(torch.matmul(soft(torch.matmul(q,k.T)),v))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;**********&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(torch.matmul((torch.matmul(q1,k1.T)),v1))</span><br><span class="line"><span class="built_in">print</span>(torch.matmul((torch.matmul(q2,k2.T)),v2))</span><br><span class="line"><span class="built_in">print</span>(torch.matmul((torch.matmul(q,k.T)),v))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">tensor([[<span class="number">2.0207</span>],</span><br><span class="line">        [<span class="number">1.9740</span>]])</span><br><span class="line">tensor([[-<span class="number">5.3267</span>],</span><br><span class="line">        [-<span class="number">5.5147</span>]])</span><br><span class="line">tensor([[ <span class="number">2.1874</span>, -<span class="number">5.1253</span>],</span><br><span class="line">        [ <span class="number">2.2269</span>, -<span class="number">5.2313</span>]])</span><br><span class="line">**********</span><br><span class="line">tensor([[-<span class="number">3.9927</span>],</span><br><span class="line">        [-<span class="number">6.4066</span>]])</span><br><span class="line">tensor([[-<span class="number">20.5387</span>],</span><br><span class="line">        [-<span class="number">31.8073</span>]])</span><br><span class="line">tensor([[  <span class="number">4.7729</span>, -<span class="number">11.1790</span>],</span><br><span class="line">        [  <span class="number">7.1683</span>, -<span class="number">16.7890</span>]])</span><br></pre></td></tr></table></figure>





<ul>
<li><p><strong>Position-wise Feed-Forward Networks</strong>  ：由两个线性层组成，中间的激活函数用relu，不同位置的输入作用都是一样的（就是位置无关），逐位置，</p>
<ul>
<li>$\large FFN(x) &#x3D; \max(0; xW_1 + b_1)W_2 + b_2 $ </li>
<li>输入输出维度都是512，神经元结点2048；</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5be05ou_6LWr,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img" style="zoom:80%;">

<ul>
<li>Feed Forward Module作用：<ul>
<li>非线性变换，强化模型的表达能力</li>
<li>输入映射到高维再映射到低维，模型学习到更加抽象的特征</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Embeddings and Softmax</strong>  ：在embedding层，权重乘以$\sqrt {d_{model}}$</p>
</li>
<li><p><strong>Positional Encoding</strong>  ：序列模型要有序列性（就是要有个顺序），而attention是当前帧和其他所有帧点乘，因此其它帧的相对位置信息，attention是考虑不到的，因此要加上位置编码来表示位置信息；</p>
<ul>
<li><p>Positional Encoding和token embedding<strong>相加</strong>，作为encoder和decoder的底部输入。Positional Encoding和embedding具有同样的维度$d_{model}$，因此这两者可以直接相加。</p>
</li>
<li><p>$\large PE_{(pos,2i)}&#x3D;sin(pos&#x2F;10000^{2i&#x2F;d_{model}})$</p>
<p>$\large PE_{(pos,2i+1)}&#x3D;cos(pos&#x2F;10000^{2i&#x2F;d_{model}})$</p>
<p>其中，i是第i维 $i\in[0,d_{model}&#x2F;2)$；pos表示token在序列中的位置，比如第一个token就是0；</p>
<p>每一维做的操作不一样（sin或cos）</p>
<p>比如：第二个token，即PE(1)，有$d_{model}$维，比如是512维，表示为：$PE(1)&#x3D;[sin(1&#x2F;10000^0),cos(1&#x2F;10000^0),sin(1&#x2F;10000^{2&#x2F;512}),cos(1&#x2F;10000^{2&#x2F;512}),…]$</p>
</li>
<li><p>出发点是三角函数 $sin(a+b) &#x3D; sin(a)cos(b) + cos(b)sin(a)$， b 是一个固定的 offset 也就是常数了，所以 pos+k 的编码就可以通过 pos 的编码来线性表示了。不同位置就是同一个频率的不同相位。</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220518151014315.png" alt="image-20220518151014315" style="zoom:80%;">
</li>
<li><p>每一组单位向量会随着 pos 的增大而旋转，但是旋转周期不同，按照论文里面的设置，最小的旋转周期是 2pi，最大的旋转周期是 10000 x 2pi。把 position 表示成多组不同旋转周期的单位向量，能有助于泛化到训练时没有见过的长度；</p>
</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220518150310638.png" alt="image-20220518150310638" style="zoom:80%;">

<ul>
<li><p>训练的loss：输出符号与真实标签的cross entropy；训练时decoder输入：真实标签groundtruth；输出是词表vocabulary的大小</p>
</li>
<li><p>测试时decoder输入：一开始BEIGIN符号，然后一个输出；<br>把第一个输出作为第二个输入，得到第二个输出；<br>把第二个输出作为第三个输入，得到第三个输出……</p>
</li>
<li><p>绝对位置编码中，Q、K、V都要加位置编码</p>
</li>
<li><p>复杂度比较：</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220517164139955.png" alt="image-20220517164139955" style="zoom:80%;">

<h3 id="抽象"><a href="#抽象" class="headerlink" title="抽象"></a>抽象</h3><blockquote>
<p><a href="https://www.jiqizhixin.com/articles/2017-06-28-5">https://www.jiqizhixin.com/articles/2017-06-28-5</a></p>
</blockquote>
<p>self attention：相比 recurrent 不存在梯度消失问题，这点显然。对比 CNN 更加适合文本，因为能够看到更远距离的信息，这点展开说明——因为文本语义的抽象不同于图像语义的抽象，后者看下一层的局部就行，前者经常需要看很远的地方。比如现在 “苹果” 这个词我要对它做一个抽象，按 “苹果公司” 抽象还是按 “水果” 抽象呢？这个选择可能依赖于几十个 step 之外的词。诚然，CNN 叠高了之后可以看到很远的地方，但是 CNN 本来需要等到很高层的时候才能完成的抽象，self attention 在很底层的时候就可以做到，这无疑是非常巨大的优势。</p>
<p>RNN是指不同 step 之间要顺序执行从影响速度的 recurrence。而这个 decoder 每一层对不同位置的计算是并行的。当前位置的计算不依赖前面位置的计算结果。 当然这也是因为他使用的是 ground truth 做输入，砍掉相邻两步之间 hidden state 这条连接了。 为了并行， 模型的灵活性受到了限制。不过，在测试阶段 decode 下一个词依赖于上一个输出，所以仍然是 recurrence 的。</p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Chorowski, Jan K., et al. “Attention-based models for speech recognition.” <em>Advances in neural information processing systems</em> 28 (2015).&#x3D;&#x3D;citations：2267</p>
</blockquote>
<h5 id="解决什么问题-1"><a href="#解决什么问题-1" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><ul>
<li>attention用在语音识别任务里效果不好的问题；机器翻译的注意力机制模型 直接用来做语音识别任务时，会出现只对训练集类似的话才识别得好 的问题、它只适用于track跟踪它所识别的内容在输入序列中的绝对位置absolute localtion；</li>
</ul>
<h5 id="用了什么方法-1"><a href="#用了什么方法-1" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><ul>
<li><ol>
<li>在注意力机制中引入location-awareness；2. 改变注意力机制，防止它过多地注意在单个帧上；</li>
</ol>
</li>
</ul>
<h5 id="效果如何-1"><a href="#效果如何-1" class="headerlink" title="效果如何"></a>效果如何</h5><ul>
<li>引入location-awareness，PER从18.7%下降到18%；防止只注意单帧，PER下降到17.6%</li>
</ul>
<h5 id="还存在什么问题-1"><a href="#还存在什么问题-1" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h5><p>- </p>
<h3 id="论文思路"><a href="#论文思路" class="headerlink" title="论文思路"></a>论文思路</h3><ul>
<li><p>为什么机器翻译和手写识别的attention不能直接用与语音识别任务：</p>
<ul>
<li>机器翻译和语音识别任务的区别：机器翻译的输入长度短（只有几十个词），识别是几千帧，因此很多语音片段是相似的，区分它们是一个挑战；</li>
<li>手写识别和语音识别任务的区别：笔迹和背景区分明显，“噪声小”，语音识别的背景噪声可能很大，信噪比低，没有清晰的结构；</li>
<li>因此对识别任务的attention model的要求是：<strong>能够处理长输入和带噪输入</strong>；</li>
</ul>
</li>
<li><p>机器翻译模型直接用于语音识别任务会带来的问题：</p>
<ul>
<li>长句子错误率高；</li>
<li>只适用于跟踪它所识别的内容在输入序列中的绝对位置；因此短句尚可，对于长句不可行；</li>
</ul>
</li>
<li><p>修改注意力机制：</p>
<ul>
<li>目的：使之能够注意到：1）前一个step的焦点位置（the location of the focus from the previous step ）、2）输入序列的特征（the features of the input sequence）</li>
<li>如何实现：在注意力机制的输入中，添加辅助卷积特征；该卷积特征是从对前一个step的attention权重进行卷积而来的；（location awareness）</li>
</ul>
</li>
<li><p>早期的注意力机制公式：</p>
<ul>
<li>content-based 注意力机制：$\large \alpha_i&#x3D;Attend(s_{i-1},h)$</li>
</ul>
<p>**Attend **操作：对h中的每个元素分别打分并将分数标准化：$\large e_{i,j}&#x3D;Score(s_{i-1},h_j)$、     $\large \alpha_{i,j}&#x3D;exp(e_{i,j})&#x2F;\sum\limits_{j&#x3D;1}^Lexp(e_{i,j})$</p>
<p>可以看出，在不同位置处的$h_j$如果元素值很相似，score分数会很接近，这就是相似语音片段“similar speech fragments” 问题，该问题可通过encoder用 BiRNN，或编码了h的上下文信息的CNN来缓解；但是h能力有限，因此通过上下文进行消歧的可能性是有限的；</p>
<p>因此，提出 location-based 注意力机制来缓解没考虑h位置的问题：</p>
<ul>
<li>location-based 注意力机制：$\large \alpha_i&#x3D;Attend(s_{i-1},\alpha_{i-1})$</li>
</ul>
<p>但是，这样也有问题，没依赖输入h，只依赖s，这样得到的距离信息方差很大；</p>
<p>因此，提出混合location和content的注意力机制：</p>
<ul>
<li>hybrid 注意力机制：$\large \alpha_i&#x3D;Attend(s_{i-1},\alpha_{i-1},h)$</li>
</ul>
<p>使用前一个的对齐$\alpha_{i−1}$从h中选择一个短的元素列表（content-based attention ）；</p>
<p>获得注意力机制权重后，神经网络的走向：</p>
<p>$\large g_i&#x3D;\sum\limits_{j&#x3D;1}^L\alpha_{i,j}h_j$</p>
<p>$\large y_i \sim Generate(s_{i-1},g_i)$</p>
<p>$\large s_i&#x3D;Recurrency(s_{i-1},g_i,y_i)$</p>
<p>其中，$\alpha_i \in R^L$ 是attention权重，称为alignment；$g_i$ ：glimpse；Recurrency  为GRU或LSTM；</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220516120833285.png" alt="image-20220516120833285" style="zoom: 67%;">

<ul>
<li><p>attention-based recurrent sequence generator （ARSG）with Convolutional Features  ：</p>
<p>content-based注意力机制的 <strong>score</strong> 操作：$\large e_{i,j}&#x3D;Score(s_{i-1},h_j)&#x3D;w^Ttanh(Ws_{i-1}+Vh_j)+b$</p>
<p>将content-based扩展为location-aware：通过考虑前一个step的alignment $\alpha_{i-1}$：对previous alignment $\alpha_{i-1}$的每个位置 $j$ ，通过与矩阵$F$卷积（$F\in R^{k \times r}$），来提取 $k$ 向量（$\large f_{i,j}\in R^k$）:</p>
<p>$\large f_i&#x3D;F*\alpha_{i-1}$</p>
<p>因此hybrid的 <strong>score</strong> 操作为：$\large e_{i,j}&#x3D;Score(s_{i-1},\alpha_{i-1},h)&#x3D;w^Ttanh(Ws_{i-1}+Vh_j+Uf_{i,j})+b$</p>
</li>
<li><p>Score Normalization: Sharpening and Smoothing</p>
<p>score操作完，标准化后得到权重α，但是这个标准化 $\large \alpha_{i,j}&#x3D;exp(e_{i,j})&#x2F;\sum\limits_{j&#x3D;1}^Lexp(e_{i,j})$ 有几个问题：</p>
<ol>
<li>$h$ 序列很长时，$g_i$会更容易从无关 $h_j$ 获得信息，就是噪声信息了，（因为score $\alpha_{i,j}$总为正数且和为1），这样对于每一帧 $i$ ，都会更不容易关注到与 $i$ 真正相关的帧信息；</li>
<li>$h$ 序列很长时，计算复杂度会显得很大，注意力机制每帧都要考虑所有帧，$O(LT)$；</li>
</ol>
<p>但是用softmax标准化的好处是会只关注于单个特征向量$h_j$，而不是多个不同 j 的h；</p>
<p>解决noisy glimpse方法：通过 <strong>Sharpening</strong> 化，锐化，具体实现的方法有：</p>
<ul>
<li>方法1：让$\alpha$分布更极端，区分更大；通过引入inverse temperature β &gt; 1</li>
</ul>
<p>$\large \alpha_{i,j}&#x3D;exp(\beta e_{i,j})&#x2F;\sum\limits_{j&#x3D;1}^Lexp(\beta e_{i,j})$</p>
<p>或者keep only the top-k frames according to the scores and re-normalize them ，但是复杂度没下降，还可能会更关注更窄的帧；</p>
<ul>
<li>方法2：windows attention机制：只看窗口长度的h：$\large \tilde h&#x3D;(h_{p_i-w,…h_{p_i+w-1}})$ ，复杂度$O(L+T)$；训练和推理阶段都能用；</li>
</ul>
<p>Sharpening对长句子有效，但是也会降低短句子性能，这个现象，论文作者认为，假设Sharpening的作用是有助于模型从多个得分最高的帧中进行选择。。。。</p>
<p>把无界的exp函数换成有界的sigmoid函数：称为 <strong>smoothing</strong> 化：</p>
<ul>
<li>Smoothing  :   $\large \alpha_{i,j}&#x3D;\sigma(e_{i,j}&#x2F;\sum\limits_{j&#x3D;1}^L\sigma(e_{i,j}))$</li>
</ul>
</li>
</ul>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul>
<li>建模单元phoneme，61个phone，一个eos token，39？</li>
<li>Timit数据集，这个数据集都是很短的小于5s，测试时会特地把音频拼接构造长句子，输入特征40维，一阶二阶差分120维，3维能量，共123维；</li>
<li>不同的参数子集被重复使用的次数不同; 编码器的为T次，注意权重为LT, ARSG的所有其他参数为L次。 这使得导数的尺度变化很大，因此用自适应学习率算法<strong>AdaDelta</strong>优化器（两个超参$\epsilon$和$\rho$）</li>
<li>初始化为标准差0.01的高斯分布，RNN进一步正交初始化；</li>
<li>batchsize&#x3D;1！由于TIMIT数据集很小，一开始加正则，后面没加正则；100K参数量；</li>
<li>encoder：3层 Bi GRU，256结点；encoder输出 h：512维；generator ：单层 GRU，256结点，输出64维？；</li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>不同模型结果：</p>
<p>baseline其实并不差，并且也能学到对齐信息，</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220516162335200.png" alt="image-20220516162335200" style="zoom:80%;">

<p>锐化里windows方法对齐效果最好：</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220516162155924.png" alt="image-20220516162155924" style="zoom: 80%;">



<p>对于repeat phone：</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220516162653073.png" alt="image-20220516162653073" style="zoom:80%;">







<hr>
<blockquote>
<p>&#x3D;&#x3D;Prabhavalkar, Rohit, et al. “A Comparison of Sequence-to-Sequence Models for Speech Recognition.” <em>Interspeech</em>. 2017.&#x3D;&#x3D; google citations：268</p>
</blockquote>
<h5 id="解决什么问题-2"><a href="#解决什么问题-2" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><ul>
<li>比较了识别模型的性能，对比了多个端到端模型在识别任务的性能；</li>
</ul>
<h5 id="用了什么方法-2"><a href="#用了什么方法-2" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><ul>
<li>不同模型都以字母建模，CTC、RNN-T、attention based、RNNT with attention的端到端识别模型，不加LM；</li>
</ul>
<h5 id="效果如何-2"><a href="#效果如何-2" class="headerlink" title="效果如何"></a>效果如何</h5><ul>
<li>在口述测试集、数值测试集优于baseline，但在有较多专有名词的问答搜索测试集，会比basline差；</li>
<li>总的来说只用字母建模，没有用语言模型，这个声学模型的建模能力还是非常牛逼的；</li>
</ul>
<h5 id="还存在什么问题-2"><a href="#还存在什么问题-2" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h5><ul>
<li>端到端模型与LM的结合实验；</li>
</ul>
<h3 id="论文思路-1"><a href="#论文思路-1" class="headerlink" title="论文思路"></a>论文思路</h3><ul>
<li><p>比较CTC、RNN-T、attention based、RNNT with attention的端到端识别模型，（比较时它们都是用grapheme字母建模，没有词典、lm）</p>
</li>
<li><p>attention based依赖LM，否则在不同数据集上表现差异很大</p>
</li>
<li><p>发现端到端模型可以隐式学习从口语到书面形式的映射（比如说”one hundred dollars” 能输出 “$100”）（以前这种问题更多是用正则做的）</p>
</li>
<li><p>端到端模型结构：</p>
<ul>
<li>RNNT：可流式识别，但用双向encoder，就不流式了；</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220513112532431.png" alt="image-20220513112532431" style="zoom:80%;">

<ul>
<li>attention-based：比如las、</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220513112556714.png" alt="image-20220513112556714" style="zoom:80%;">

<ul>
<li><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220513112646296.png" alt="image-20220513112646296" style="zoom: 80%;">
   - RNN Transducer with Attention :把RNN-T里的prediction network换成las里的attention decoder；和las相同，要添加sos和eos label，</li>
</ul>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><ul>
<li>数据集：12500 h</li>
<li>数据扩展（即使1w小时了也还要数据扩展）目的是对噪声和混响更robust：生成multicondition training (MTR) data：distorted using a room simulator 、by adding in noise samples extracted from YouTube videos and environmental recordings of daily events 、</li>
<li>the overall SNR is between 0dB and 30dB, with an average of 12dB  ，信噪比不低于0dB，不高于30dB，平均12dB</li>
<li>log-mel  特征80维，25ms帧长，10ms帧移，送给模型时下采样3倍，</li>
<li>标签：26个字母a-z，10个数字0-9，空格，标签符号</li>
<li>ctc：encoder：5层 blstm，350结点（700结点），用这个训好（收敛了）的encoder权重，作为其他端到端模型的初始权重，这可以加速其他模型的收敛；</li>
<li>rnnt：encoder和上同，prediction network 单层gru，700结点；joint network 单层前馈网络，700结点，tanh激活函数；解码 beam search 的beam&#x3D;15</li>
<li>attention-based  ：decoder：一或两层gru，700结点；</li>
<li>baseline：ctc模型，训好用smbr再训，8192 CD phonemes，解码：pruned, first-pass, 5-gram language model   ，再用更大的5-gramLM进行rescore ；词典 包含百万个词</li>
<li>RNN-T剪枝是走了t步剪枝（frame-synchronous decoding）；attention剪枝是输出u个符号剪枝（label-synchronous decoding）</li>
<li>为了防止attention-based模型输出非常短的话语，只有当模型输出一个概率大于阈值的<eos>标签时，才允许终止下一个标签预测过程；</eos></li>
</ul>
<h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h3><ul>
<li>CTC直接解码字母时，不接语言模型会非常差</li>
<li>这样看来attention-based model效果比RNNT好</li>
<li>在numeric 测试集（从口语映射到书面领域），attention和rnnt相比于baseline有明显改善，认为 the ability to examine the input acoustics in addition to the previous sequence of predicted tokens is particularly helpful</li>
<li>在voice-search  测试集，比baseline差，分析是因为没加LM；</li>
<li>发现端到端模型很难识别专有名词proper nouns  （比如地名、实体名）</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/image-20220513143125662.png" alt="image-20220513143125662" style="zoom:80%;">

]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>识别论文笔记（二）语言模型融合</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="语言模型融合"><a href="#语言模型融合" class="headerlink" title="语言模型融合"></a>语言模型融合</h1><blockquote>
<p>&#x3D;&#x3D;Cabrera, Rodrigo, et al. “Language model fusion for streaming end to end speech recognition.” <em>arXiv preprint arXiv:2104.04487</em> (2021).&#x3D;&#x3D;</p>
</blockquote>
<h5 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><ul>
<li>通过使用在和训练不匹配的文本数据上训练的语言模型(LM)来解决流式和尾部识别的挑战，以增强端到端模型；</li>
<li>解决tail phenomena 的问题，比如专有名词，数值，口音 ？</li>
</ul>
<h5 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><ul>
<li>扩展了流式RNNT中声学模型和语言模型融合shallow fusion 和 cold fusion方法，提出两种新的competitive fusion方法</li>
</ul>
<h5 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h5><ul>
<li>8%改善识别率</li>
</ul>
<h5 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h5><ul>
<li><p>tail phenomena  ？</p>
</li>
<li><p>加了lm对rtf、内存、延时有影响吗？多大影响？</p>
</li>
<li><p>好的多语种识别模型一般是怎么样的？是按论文所说的各自训练一个语种的am&#x2F;lm模型，再多个模型融合吗？</p>
</li>
</ul>
<h3 id="论文思路"><a href="#论文思路" class="headerlink" title="论文思路"></a>论文思路</h3><ul>
<li><p>通过使用在和训练不匹配的文本数据上训练的语言模型(LM)来解决流式和尾部识别的挑战，以增强端到端模型；</p>
</li>
<li><p>扩展了流式RNNT中shallow fusion 和 cold fusion方法，提出两种新的competitive fusion方法</p>
</li>
<li><p>端到端模型中，可以用纯文本训练LM，来进行模型融合，常用的有shallow fusion，deep fusion，cold fusion，component fusion，他们大多用神经网络LM，少部分用n-gram fst LM；</p>
<p>但是这些融合模型是非流式的，流式的融合模型还没怎么有论文</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220511171437884.png" alt="image-20220511171437884" style="zoom:80%;">

<ul>
<li><p>RNN-LM：对于一个wordpiece序列，语言模型概率为 $\large P(w_1^T)&#x3D;\prod\limits_{i&#x3D;1}^TP(w_i|w_1,w_2,…,w_{i-1})$</p>
<p>训练LM时没有blank，但是RNNT里有，因此推理时要给RNN-LM一个blank概率，文中定义blank概率等于RNNT里blank的输出概率，即 $\large logP_{lm}(<blank>)&#x3D;logP_{rnnt}(<blank>)$</blank></blank></p>
<p>这意味着当RNNT模型输出blank时，RNN-LM不更新，融合后blank的概率保持不变。。？</p>
</li>
<li><p>shallow fusion：把RNNT的概率和RNN-LM的概率log线性相加，再送入softmax层： $\large logP(y_t)&#x3D;logP_{rnnt}(y_t)+\beta logP_{lm}(y_t)$  ，其中$y_t$是t帧时的输出符号</p>
<ul>
<li>RNNT和LM分开训练（不同数据）各训各的，</li>
<li>注意，这里应该就不是联合训练，没有训练过程，而是各自训练好了，融合到一块，得到每帧下每个符号的概率</li>
<li>因此，$\beta$ 和 blank惩罚这两个超参数就要精细调节，才能有好的识别率</li>
</ul>
</li>
<li><p>Early Shallow Fusion  </p>
<ul>
<li>因为RNNT里的预测网络prediction network被比作LM，受此启发，将该LM和预训练LM进行log线性插值融合，再送入RNNT里的joint network；</li>
<li>$l_t^{Pred}&#x3D;DNN(h_t^{Pred})$  ， $h_t&#x3D;l_t^{Pred}+\beta l_t^{LM}$</li>
<li>只在推理阶段用</li>
</ul>
</li>
<li><p>Cold Fusion</p>
<ul>
<li><p>预训练LM参与rnnt训练，但是rnnt参数更新，lm参数不更新</p>
</li>
<li><p>用fine-grained gating方法，这样对于非训练集之外的场景效果会更好[TODO]？</p>
</li>
<li><p>$\large h_t^{LM} &#x3D; DNN (l_t^{LM})$</p>
<p>$\large g_t&#x3D;\sigma(W[s_t^{jn};\dot h_t^{LM}]+b)$</p>
<p>$\large s_t&#x3D;[s_t^{jn};g_t h_t^{LM}]$</p>
<p>$\large r_t&#x3D;DNN(s_t)$</p>
<p>$\large \hat P(y_t|x,y&lt;t)&#x3D;softmax(r_t)$</p>
<p>？ 公式有写错吗</p>
</li>
<li><p>推理时还需要用LM吗？</p>
</li>
</ul>
</li>
<li><p>Early Cold Fusion</p>
<ul>
<li><p>训练推理阶段都用</p>
</li>
<li><p>$\large h_t^{LM}&#x3D;DNN(l_t^{LM})$</p>
<p>$\large g_t&#x3D;\sigma(W[h_t^{Pred};h_t^{LM}]+b)$ </p>
<p>$\large h_t&#x3D;[h_t^{Pred};g_t \dot h_t^{LM}]$</p>
</li>
</ul>
</li>
</ul>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul>
<li><p>模型：RNNT：</p>
<ul>
<li>encoder network   ：8层单向LSTM，2048结点，640维projection层；</li>
<li>prediction network   ：2层单向LSTM，2048结点，640维projection层；</li>
<li>joint network：前馈层，640结点；</li>
<li>参数量：120M</li>
<li>建模单元：wordpieces（WPE），vocabulary&#x3D;4096</li>
<li>A stacking layer is inserted after the second layer, which stacks the outputs of two neighboring frames with a stride of 2 for speed improvement.</li>
</ul>
</li>
<li><p>模型：RNN-LM：</p>
<ul>
<li>2层单向LSTM，2048结点，128维embedding层；60M参数量；</li>
<li>建模单元：wordpieces（WPE），vocabulary&#x3D;4096</li>
</ul>
</li>
<li><p>RNNT数据集：不同数据量的的多语种实验（三种语言），</p>
<ul>
<li>Greek  ：6700h</li>
<li>Norwegian  ：3500h</li>
<li>Sinhala  ：160h</li>
<li>数据扩展：room simulator ，加噪，混响，平均信噪比12dB</li>
</ul>
</li>
<li><p>RNN-LM训练数据：60%来自RNNT训练文本，40%来自其他；</p>
<ul>
<li>Greek  ：10亿条文本</li>
<li>Norwegian   ：10亿条文本</li>
<li>Sinhala  ：2亿条文本</li>
</ul>
</li>
<li><p>RNN-LM训练准则：最小化log困惑度</p>
</li>
<li><p>最终用的模型：不同语种模型进行模型融合得到的一个模型；</p>
</li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul>
<li>对于attention base 模型，shallow fusion 优于 cold fusion；（文中没做该实验，该结论来自las论文）</li>
<li>对于RNNT models 模型，cold fusion 优于 shallow fusion；</li>
</ul>
<h3 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h3><ul>
<li>预训练的RNN-LM和声学模型联合训练（只训练声学模型参数）会提高识别率</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Liu, Yufei, et al. “Internal language model estimation through explicit context vector learning for attention-based encoder-decoder ASR.” <em>arXiv preprint arXiv:2201.11627</em> (2022).&#x3D;&#x3D;</p>
</blockquote>
<h4 id="解决什么问题-1"><a href="#解决什么问题-1" class="headerlink" title="解决什么问题"></a>解决什么问题</h4><p>E2E模型已经学了一些语言模型信息（称为biased internal language model（ILM）），这时候如果想用外部语言模型的分数，内部lm的分数要先减掉，然后才能加外部lm分数，不然就加太多；因此需要知道怎么评估ILM的分数，才能获取该分数。</p>
<p>也可以不减掉这个内部lm分数，但是要尽量让内部lm的bias作用不明显，就是可以用外部lm的训练数据去训练这个内部lm，到时候不需要外部lm，直接用内部lm，也是起到了外部lm参与的效果；</p>
<p>本文的E2E模型是LAS模型；</p>
<h4 id="用了什么方法-1"><a href="#用了什么方法-1" class="headerlink" title="用了什么方法"></a>用了什么方法</h4><p>两种方法来评估ILM：</p>
<ol>
<li>把LAS decoder里的context vector（AttentionContext ）换成参数可学习可更新的vector；</li>
<li>query vector通过前馈网络映射到context vector，使得context vector不依赖encoder信息（声学信息）；</li>
</ol>
<p>只更新上述两种方法里的参数，LAS其他参数固定不更新，用纯文本训练他们，就相当于训练一个外部LM了，目标函数是最小化perplexity；</p>
<p>[TODO] 方法2. c只来源于文本不需要声学信息，那声学信息在哪里作用？？encoder信息不需要了吗。。。</p>
<h4 id="效果如何-1"><a href="#效果如何-1" class="headerlink" title="效果如何"></a>效果如何</h4><p>在多个数据集上，优于shallow fusion的方法，优于前人的两种Internal Language Model Estimation (ILME)  方法；</p>
<p>没有额外LM参与，没有额外的耗时，保证了RTF不会很大；</p>
<h4 id="应用到我的任务"><a href="#应用到我的任务" class="headerlink" title="应用到我的任务"></a>应用到我的任务</h4><p>用conformer encoder+ctc decoder和attention decoder，这里可以把attention decoder全替换成外部lm训练数据训练的lm，</p>
<ol>
<li>用ctc出来n best做rescore（和wenet的attention rescore方法相同，只是attention decoder换了，不需要encoder信息），该方法叫rescore</li>
<li>shallow fusion，</li>
<li><del>attention decoder输入的embedding层就用ctc decoder出来的，当blank概率不要很大的帧送进去解码（作为attention decoder的输入embedding层），非自回归（不使用attentiondecoder的输出信息作为下一个符号的输入），然后把ctcdecoder给的全送进去，得到N个V向量，做beam search；</del></li>
</ol>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>识别论文笔记（四）语言模型</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h1><blockquote>
<p>&#x3D;&#x3D;Dauphin Y N, Fan A, Auli M, et al. Language modeling with gated convolutional networks[C]&#x2F;&#x2F;International conference on machine learning. PMLR, 2017: 933-941.&#x3D;&#x3D; citations：1542 1Facebook  </p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li>用于语言模型建模中，用stacked conv，gated temporal convolutions  代替rnn，用了gated linear units（GLU），比RNN低延迟，效果好；</li>
<li>门控线性单元通过为梯度提供线性路径，同时保持非线性能力，减少了深度架构的梯度消失问题；</li>
<li>提出新的gated convolutional networks，卷积网络可以通过堆叠来表示较大的上下文大小，并在越来越大的上下文中提取具有更抽象特征的层次特征</li>
<li>$\text{GLU}(a, b) &#x3D; a \otimes \sigma(b)$</li>
<li>：<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220531121501451.png" alt="image-20220531121501451" style="zoom:80%;"></li>
</ul>
<p>输出 $\large h\in \mathbb R^{N\times n}$</p>
<p>通过两个仿射变换，其中一个仿射变化通过激活函数，然后二者再做对应位置相乘</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220531121429219.png" alt="image-20220531121429219" style="zoom:80%;">



<ul>
<li><p><strong>Gating Mechanisms</strong>  ：RNN中，没有input门和forget门，信息很容易通过每个时间步的转换消失。但是卷积网络不存在同样的消失梯度，我们通过实验发现它们不需要遗忘门。因此只需要考虑output gate输出门</p>
<ul>
<li>考虑只拥有输出门的模型，它允许网络控制哪些信息应该通过层的层次传播。</li>
</ul>
</li>
<li><p>gated linear unit  梯度：<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220531144046865.png" alt="image-20220531144046865" style="zoom:80%;"></p>
</li>
<li><p>之前的那种，lstm式门控的梯度gated tanh unit  （GTU）： <img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220531144405468.png" alt="image-20220531144405468" style="zoom:80%;"></p>
</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Yan H, Deng B, Li X, et al. TENER: adapting transformer encoder for named entity recognition[J]. arXiv preprint arXiv:1911.04474, 2019.&#x3D;&#x3D;</p>
</blockquote>
<h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><ul>
<li>为什么位置编码只加在attention层的输入是不够的，说的是输入位置编码PE经过W后，$PEWqWk^TPE^T$会失去了位置信息（不同位置的关系不明显了），即使网络更新了W参数，位置信息也不明显，所以要给位置信息单独的参数来更新，不和输入E的参数共享</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220602114200130.png" alt="image-20220602114200130" style="zoom:80%;">





<hr>
<blockquote>
<p>&#x3D;&#x3D;Shaw, Peter, Jakob Uszkoreit, and Ashish Vaswani. “Self-attention with relative position representations.” <em>arXiv preprint arXiv:1803.02155</em> (2018).&#x3D;&#x3D;citation 988 Google </p>
<p><a href="https://medium.com/@_init_/how-self-attention-with-relative-position-representations-works-28173b8c245a">How Self-Attention with Relative Position Representations works</a></p>
<p>github：tensor2tensor：<a href="https://github.com/tensorflow/tensor2tensor/blob/9e0a894034d8090892c238df1bd9bd3180c2b9a3/tensor2tensor/layers/common_attention.py#L1556-L1587">https://github.com/tensorflow/tensor2tensor/blob/9e0a894034d8090892c238df1bd9bd3180c2b9a3/tensor2tensor/layers/common_attention.py#L1556-L1587</a></p>
<p>[好] 知乎：<a href="https://zhuanlan.zhihu.com/p/105001610">Transformer改进之相对位置编码(RPE)</a></p>
<p>博客园：[<a href="https://www.cnblogs.com/shiyublog/p/11185625.html">NLP] 相对位置编码(一) Relative Position Representatitons (RPR) - Transformer </a></p>
<p>csdn <a href="https://blog.csdn.net/DBC_121/article/details/107939242">论文阅读笔记：Self-Attention with Relative Position Representations</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/364828960">https://zhuanlan.zhihu.com/p/364828960</a></p>
</blockquote>
<h3 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>为什么只在输入加位置信息是不够的：<a href="https://zhuanlan.zhihu.com/p/105001610%EF%BC%8C%E5%9B%A0%E4%B8%BA%E8%BE%93%E5%85%A5%E6%9C%89%E4%BD%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%EF%BC%8C%E7%BB%8F%E8%BF%87%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2W%E5%90%8E%E4%BD%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E5%B0%B1%E6%B2%A1%E4%BA%86%EF%BC%8C%E5%B9%B6%E4%B8%94%E8%AE%AD%E7%BB%83%E6%9B%B4%E6%96%B0%E5%8F%82%E6%95%B0%E5%90%8E%EF%BC%8C%E6%89%93%E5%8D%B0%E5%87%BA%E6%9D%A5%E7%9C%8B%E4%BE%9D%E7%84%B6%E6%B2%A1%E6%9C%89%E4%BA%86%E4%BD%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%EF%BC%9B">https://zhuanlan.zhihu.com/p/105001610，因为输入有位置信息，经过仿射变换W后位置信息就没了，并且训练更新参数后，打印出来看依然没有了位置信息；</a></p>
</li>
<li><p>提出相对位置编码 Relative Position Representations  (RPR)，之前的transformer的位置编码只在encoder和decoder的输入，现在在模型中加入可训练的位置编码，表示距离；</p>
</li>
<li><p>Relation-aware Self-Attention  ：对attention里的k，v引入输入pair之间的edge信息；将输入建模为一个标记的、有向的、完全连通的图</p>
</li>
<li><p>具体做法是在计算attention score和weighted value时各加入一个可训练的表示相对位置的参数，并且multi head之间可以共享。具体的：</p>
<p>输入元素 $x_i$ 和 $x_j$ 之间的edge记为向量 $\large \alpha _{ij}^V, \alpha _{ij}^K \in \mathbb{R}^{d_a} $， 可以在关注头head之间共享</p>
<p>有2个RPR的表征</p>
<p>attention机制里的<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220519103208774.png" alt="image-20220519103208774" style="zoom: 80%;">变为：<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220519103224268.png" alt="image-20220519103224268" style="zoom: 80%;"></p>
<p>attention机制里的<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220519103257357.png" alt="image-20220519103257357" style="zoom: 80%;">变为<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220519103321485.png" alt="image-20220519103321485" style="zoom: 80%;"></p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220519102007123.png" alt="image-20220519102007123" style="zoom:80%;">



<ul>
<li><p>对于线性序列，边缘可以捕获输入元素之间相对位置差的信息。本文的最大相对位置被裁剪到k的最大绝对值。这是基于假设：精确的相对位置信息在一定距离以外是没有用的。剪切最大距离还可以使模型推广到训练中没有看到的序列长度。因此，本文只考虑2k + 1个unique edge labels  唯一边标签</p>
<p>最大单词数被clipped在一个绝对的值k以内。向左k个, 再左边均为0， 向右k个，再右边均为k, 所表示的index范围</p>
<p>$a_{ik}^K$   ， $a_{ik}^V$  就表示了xi和xj的相对位置信息，所以他们只和 i 和 j 的差值k有关。具体如下：</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220519102853385.png" alt="image-20220519102853385" style="zoom:80%;">

<ul>
<li>实现：</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220519104753501.png" alt="image-20220519104753501" style="zoom:80%;">

























<hr>
<blockquote>
<p>&#x3D;&#x3D;Dai, Zihang, et al. “Transformer-xl: Attentive language models beyond a fixed-length context.” <em>arXiv preprint arXiv:1901.02860</em> (2019).&#x3D;&#x3D; citations：1864 Google Brain  </p>
<p>github：<a href="https://github.com/kimiyoung/transformer-xl">https://github.com/kimiyoung/transformer-xl</a>  </p>
<p>github：<a href="https://github.com/huggingface/transformers/blob/0a6b9048d1d5de5b965a8757dd56fef87ed9d7e1/src/transformers/models/transfo_xl/modeling_transfo_xl.py">https://github.com/huggingface/transformers/blob/0a6b9048d1d5de5b965a8757dd56fef87ed9d7e1/src/transformers/models/transfo_xl/modeling_transfo_xl.py</a></p>
<p><a href="https://towardsdatascience.com/transformer-xl-explained-combining-transformers-and-rnns-into-a-state-of-the-art-language-model-c0cfe9e5a924">Transformer-XL Explained: Combining Transformers and RNNs into a State-of-the-art Language Model</a></p>
<p>博客园 <a href="https://www.cnblogs.com/jiangxinyang/p/11534492.html">NLP中的预训练语言模型（三）—— XL-Net和Transformer-XL</a></p>
<p><a href="https://jaketae.github.io/study/relative-positional-encoding/">https://jaketae.github.io/study/relative-positional-encoding/</a></p>
<p><a href="https://blog.csdn.net/qq_34914551/article/details/119866975">https://blog.csdn.net/qq_34914551/article/details/119866975</a></p>
<p>科学空间：<a href="https://kexue.fm/archives/8130">让研究人员绞尽脑汁的Transformer位置编码</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/334355417">相对位置编码和绝对位置编码原理及源码</a></p>
<p>[很不错]  博客园：[<a href="https://www.cnblogs.com/shiyublog/p/11236212.html">NLP] 相对位置编码(二) Relative Positional Encodings - Transformer-XL </a></p>
<p>&#x3D;&#x3D;知乎 chao yang：<a href="https://zhuanlan.zhihu.com/p/344604604">Conformer ASR中的Relative Positional Embedding&#x3D;&#x3D;</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/397269153">https://zhuanlan.zhihu.com/p/397269153</a></p>
<p><a href="https://gudgud96.github.io/2020/04/01/annotated-music-transformer/">https://gudgud96.github.io/2020/04/01/annotated-music-transformer/</a></p>
<p>公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247571522&idx=3&sn=5220cd96db90f5e5a180ae04be755c66&chksm=ec1d35bbdb6abcad5af3f387e0a55c76f8a9ff21f27c9c1a6d20ecb1af5b8e316b565d210328&mpshare=1&scene=1&srcid=0518S7ex1MAJiZw3NGDWc5RB&sharer_sharetime=1653906114213&sharer_shareid=7dfde0689a805163a3af5547f5e7bbff&version=4.0.0.6023&platform=win#rd">实践教程 | PyTorch中相对位置编码的理解</a></p>
</blockquote>
<h5 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h5><ul>
<li>让transformer模型有机会学习更长的依赖关系；</li>
</ul>
<h5 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h5><ul>
<li>提出一个叫Tansformer-XL的结构，组成由segment-level recurrence mechanism 和 a novel positional encoding scheme</li>
</ul>
<h5 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h5><ul>
<li>80% longer than RNNs and 450% longer than vanilla Transformers</li>
</ul>
<h5 id="还存在什么问题"><a href="#还存在什么问题" class="headerlink" title="还存在什么问题"></a>还存在什么问题</h5><p>- </p>
<h3 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h3><ul>
<li>Transformers模型可以学会很长的依赖关系，但是由于训练集的长度不是很长，一般没有机会学会很长的依赖，本文提出一种Transformer-XL架构，不干扰时序相关性的前提下，能够学习超出固定长度的更长的依赖性。Transformer-XL 由segment-level 分段递归结构和novel 位置编码组成；</li>
<li>之前的transformer训练时是固定长度（固定长度比如512个字符，一篇文章截断成固定长度片段），并且固定长度的片段是通过选择连续的符号块来创建的，而不考虑句子或任何其他语义边界，预测前面几个symbols时能用到的上下文信息就很少，该问题称为context fragmentation 。因此，在self-attention network  中引入 <strong>recurrence</strong> 递归的思想，复用previous segments的隐状态作为当前current segment的记忆（<strong>memory</strong>）模块；并且传递来自上一段的信息也可以解决上下文碎片context fragmentation的问题。</li>
<li>建模语言模型：Given a corpus of tokens $x&#x3D;(x_1,…,x_T)$, 语言模型的任务是估计联合概率$P(x)$，其中，$\large P(x)&#x3D;\prod_tP(x_t|x_{&lt;t})$</li>
<li>之前的transormer： vanilla Transformer model   （Al-Rfou et al. (2018)  ）：信息只在segment内部流动（其实这个segment长度也是很长的，但是对于特别特别长，篇章级别的文本，就无法处理，因为训练时把篇章截断成segment了）</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220516170152731.png" alt="image-20220516170152731" style="zoom:80%;">

<ul>
<li>Transformer-XL：<strong>segment-level recurrence mechanism</strong></li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220516170208952.png" alt="image-20220516170208952" style="zoom:80%;">



<p>第n层，第$\tau$个segment（d维）$s_{\tau}$，其神经元结点 $h_{\tau}^n \in R^{L\times d}$ ，则 下一个segment $s_{\tau+1}$为：</p>
<p>(extended context)  ：$\large \tilde h_{\tau+1}^{n-1}&#x3D;[SG(h_{\tau}^{n-1}) \circ h_{\tau+1}^{n-1}]$</p>
<p>(query, key, value vectors)  ：$\large q_{\tau + 1}^n , k_{\tau+1}^n, v_{\tau+1}^n &#x3D; h_{\tau+1}^{n-1}W_q^T, \tilde h_{\tau+1}^{n-1}W_k^T, \tilde h_{\tau+1}^{n-1}W_v^T$</p>
<p>(self-attention + feed-forward)  ：$\large h_{\tau+1}^{n}&#x3D;TransformerLayer(q_{\tau+1}^n,k_{\tau+1}^n,v_{\tau+1}^n)$</p>
<p>其中，SG(·) 表示 stop-gradient，就是里面的参数不更新了 ，[hu ◦ hv] 表示沿着length维度，把两个隐层序列concatenate起来；</p>
<p>由于扩展上下文$\tilde h_{\tau+1}^{n-1}$是和前一个segment $h_{\tau}^{n-1}$有关的（因为拼接了前一个segment的h），因此计算当前segment的qkv，也是和前一个segment有关的；[recurrence 递归、循环]</p>
<p>（RNN-LM是接收前一个符号，层都是当前层，这个transformer-xl是接收前一segment符号<strong>序列</strong>，并且是作用到下一层）</p>
<p>复杂度$O(N\times L)$，L是每个segment长度，N是层数</p>
<ul>
<li><p>faster evaluation ： 计算下一个segment时，可以reuse上一个segment信息，上一个segment信息已经有了，当前segment不需要重新计算，因此比 vanilla model在推理时快了1800倍；</p>
</li>
<li><p>&#x3D;&#x3D;relative position embedding scheme&#x3D;&#x3D;：之前的位置编码，对于不同segment，同一内部的位置编码结果都是一样的，这区分不开不同segment位置，因此用相对位置编码（其实绝对位置编码，相对位置编码，对于不同segment编码还是一样的，相对位置编码感觉并没有解决不同segment内部的编码位置结果可以做到不一样）；</p>
<ul>
<li><p>之前的：$\large h_{\tau+1}&#x3D;f(h_\tau,    E_{s_{\tau+1}}+U_{1:L})$              、        $\large h_{\tau}&#x3D;f(h_{\tau-1}, E_{s_{\tau}}+U_{1:L})$   </p>
<p>其中，$E_{s_{\tau}}\in \mathbb R^{d\times L}$表示$s_{\tau}$的词向量，$f$表示transformation函数，$\large U\in  R^{L_{max},d}$，   可以看出位置编码是一样的，</p>
<p><strong>绝对位置编码</strong>，计算attention分数 ：</p>
<p>$\large A_{i,j}^{abs}&#x3D;E_{x_i}^TW_q^TW_kE_{x_j} + E_{x_i}^TW_q^TW_kU_j + U_i^TW_q^TW_kE_{x_j} + U_i^TW_q^TW_kU_j&#x3D;(E_{x_i}^T+U_i^T)W_q^TW_k(E_{x_i}+U_i)$</p>
</li>
</ul>
<p>​       其中，$ E_{x_i} \in \mathbb{R}^{d\times 1}$，$ W \in \mathbb{R}^{d\times d}$</p>
<p>​	 绝对位置编码中，Q、K、V都要加位置编码；</p>
<p>​	（相对位置编码，V没做）</p>
<ul>
<li><p>下面提出改进绝对位置编码的“相对位置编码”，感觉并不是为了不同segment，而是就是想用一个相对值，并且$R_{i,j}$也不是本文提出的，但是本文提出了不依赖位置的$u$，$v$ ；</p>
</li>
<li><p><strong>相对位置编码</strong>：它是每个注意力模块的一部分（有参数需要更新），而不是仅在第一层之前编码位置，并且基于标记之间的相对距离而不是它们的绝对位置。</p>
</li>
<li><p>要知道 $k_{\tau,j}$ 和 $q_{\tau,i}$ 的相对距离，即 $i-j$</p>
</li>
<li><p>相对位置编码，计算attention分数：</p>
<p>$\large A_{i,j}^{rel}&#x3D;E_{x_i}^TW_q^TW_{k,E}E_{x_j} + E_{x_i}^TW_q^TW_{k,R}R_{i-j} + u^TW_{k,E}E_{x_j} + v^TW_{k,R}R_{i-j}$</p>
<p>$\large &#x3D;(E_{x_i}^TW_q^T+u^T)W_{k,E}E_{x_j} + (E_{x_i}^TW_q^T + v^T )W_{k,R}R_{i-j}  $</p>
<p>输出维度 $\in \mathbb{R}^{L\times L}$</p>
<p>其中，$\large R \in \mathbb{R}^{L_{max}\times d}$是正弦函数矩阵sinusoid encoding matrix，这个是直接计算出来的，里面没有要学习&#x2F;更新的参数；</p>
<p>（感觉公式里是反过来的，E是d * L而不是L *  d）</p>
<p>$u \in \mathbb{R}^d$ ，是一个向量，代替query   $U_i^TW_q^T$     ，所有query位置的query向量都是相同的，这意味着无论查询位置如何，对不同单词的attentive bias都应该是相同的；</p>
<p>$v \in \mathbb{R}^d$ 代替   $U_i^TW_q^T$  ；（不需要给query位置编码）</p>
<p>引入了上一片段的隐层表示只会用在key和value上，对于query还是保持原来的样子，query只是表示查询的词，而key，value表示的是表示这个查询的词的相关信息，我们要改变的是只是信息；</p>
<p>因为是相对位置，所以query的绝对位置信息U_i就不需要了</p>
<p>$W_{k,E} \in \mathbb{R}^{d\times d}$：content-based key vectors；$W_{k,R} \in \mathbb{R}^{d\times d}$：location-based key vectors；</p>
<p>因此要学习&#x2F;更新的参数是：u，v，$W_{k,E}$、$W_{k,R}$</p>
<p>相对位置编码计算attention分数的公式中</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220517170411148.png" alt="image-20220517170411148" style="zoom:80%;">

<p>　　a）基于内容的“寻址”，即没有添加位置向量，词对词的分数。</p>
<p>　　b）基于内容的位置偏置，相当于当前内容的位置偏差。</p>
<p>　　c）全局的内容偏置，用于衡量key的重要性。</p>
<p>　　d）全局的位置偏置，根据key和query调整位置的重要性。</p>
<p>a）部分基本不变，只是对于key的位置向量的权重矩阵和词向量的权重矩阵不再共享；b）部分引入了相对位置向量$R_{i−j}$，是一个的预先给定好的正弦编码矩阵，不需要学习；c）对于query的位置向量采用可以学习的初始化向量来表示，$u^T$表示对key中词E的位置向量，d）同上，$v^T$表示对key中位置R的位置向量；</p>
</li>
</ul>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220518201007774.png" alt="image-20220518201007774" style="zoom:80%;">

<ul>
<li><p>一个N层Transformer-XL 的前向过程（以单头注意力机制为例）：</p>
<p>$\large \tilde h_{\tau}^{n-1}&#x3D;[SG(m_{\tau}^{n-1}) \circ h_{\tau}^{n-1}]$</p>
<p>$\large q_{\tau }^n , k_{\tau}^n, v_{\tau}^n &#x3D; h_{\tau}^{n-1}W{<em>q^n}^T, \tilde h</em>{\tau}^{n-1}W{<em>{k,E}^n}^T, \tilde h</em>{\tau}^{n-1}W{_v^n}^T$</p>
<p>$\large A_{\tau,i,j}^n&#x3D;{q_{\tau,i}^n}^Tk$………………….没写完，看下面：</p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220517170434999.png" alt="image-20220517170434999" style="zoom:80%;">
</li>
<li><p>简化相对位置编码计算过程：</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220531104156028.png" alt="image-20220531104156028" style="zoom:80%;">



<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220531104230759.png" alt="image-20220531104230759" style="zoom:80%;">





<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220518210923007.png" alt="image-20220518210923007" style="zoom:80%;">

<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/image-20220517151401322.png" alt="image-20220517151401322" style="zoom:80%;">



<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/1453927-20191008092720538-235885034.png" alt="img" style="zoom:80%;">

<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/1453927-20191008092738028-1669727199.png" alt="img" style="zoom:80%;">

<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>数据集：WikiText-103   </p>
<p>评价指标：困惑度：20.5 to 18.3  </p>
<p>等等</p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>语音识别预训练技术的发展和应用 分享</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h1 id="预训练技术"><a href="#预训练技术" class="headerlink" title="预训练技术"></a>预训练技术</h1><blockquote>
<p>狗熊会 <a href="https://www.xiong99.com.cn/detail/v_62874489e4b09dda126b08e7/3?from=p_5efd4ce4779bc_hgZJtgAY&type=8&parent_pro_id=p_62635f3ce4b01c509aa7070f">腾讯云小微曹松军研究员：语音识别预训练技术的发展和应用</a></p>
</blockquote>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523182802701.png" alt="image-20220523182802701"></p>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523182828056.png" alt="image-20220523182828056" style="zoom:80%;">





<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523182914852.png" alt="image-20220523182914852" style="zoom:80%;">





<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523182943370.png" alt="image-20220523182943370" style="zoom:80%;">





<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183036908.png" alt="image-20220523183036908"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183116550.png" alt="image-20220523183116550"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183154447.png" alt="image-20220523183154447"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183238154.png" alt="image-20220523183238154"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183326735.png" alt="image-20220523183326735"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183446589.png" alt="image-20220523183446589"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183526190.png" alt="image-20220523183526190"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183545577.png" alt="image-20220523183545577"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183614384.png" alt="image-20220523183614384"></p>
<h2 id="腾讯云小微"><a href="#腾讯云小微" class="headerlink" title="腾讯云小微"></a>腾讯云小微</h2><p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183714332.png" alt="image-20220523183714332"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183749436.png" alt="image-20220523183749436"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523183927787.png" alt="image-20220523183927787"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523184007633.png" alt="image-20220523184007633"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523184050847.png" alt="image-20220523184050847"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523184153121.png" alt="image-20220523184153121"></p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E9%A2%84%E8%AE%AD%E7%BB%83%E6%8A%80%E6%9C%AF/image-20220523184254195.png" alt="image-20220523184254195"></p>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练模型</title>
    <url>/2022/01/04/%E8%AF%86%E5%88%AB/%E9%A2%84%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<h1 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h1><p>预训练模型 wav2vec2.0、datavec</p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Schneider, Steffen, et al. “wav2vec: Unsupervised pre-training for speech recognition.” <em>arXiv preprint arXiv:1904.05862</em> (2019).&#x3D;&#x3D;Facebook</p>
<p>github：<a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出一种用无监督预训练来改善有监督语音识别的方法；训练一个无监督预训练模型，用来给下游的语音识别任务作为输入；</li>
<li>该无监督预训练模型叫做wav2vec；该模型输入是原始音频，输出是embedding，这个embedding是用大量无标签音频训练得到的，能表示一定的输入音频信息，模型结构用的CNN；loss function是contrastive loss，从negative中鉴别出哪个是真实的 future audio sample；</li>
</ul>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ul>
<li><p>输入原始音频x通过encoder网络，得到具有上下文表示的输出z；</p>
<p>The encoder layers have kernel sizes (10; 8; 4; 4; 4) and strides (5; 4; 2; 2; 2).   </p>
<p>causal convolution with 512 channels, a group normalization layer and a ReLU nonlinearity.   </p>
<p>输入30ms窗长，10ms窗移，16kHz音频，输出低频特征；</p>
</li>
<li><p>然后经过一个context network $g:Z -&gt;   C$ ，把encoder的输出z，多个z concat起来经过g得到c：$\large c_i&#x3D;g(z_i…z_{i-v})$，其中v是感受野，是一个超参；</p>
<p>The context network has nine layers with kernel size three and stride one  ，感受野210ms；</p>
<p>causal convolution with 512 channels, a group normalization layer and a ReLU nonlinearity.   </p>
<p>group norm：我们发现选择一种对输入的缩放和偏移量无关的归一化方案是很重要的，该归一化方法对于跨数据集泛化性更好；</p>
</li>
</ul>
<img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E9%A2%84%E8%AE%AD%E7%BB%83/image-20220626160341868.png" alt="image-20220626160341868" style="zoom: 40%;">

<ul>
<li><p>loss function：we optimize our model (§2.1) to predict future samples from a given signal context.   </p>
<p>不是对 $p(x)$ 建模，而是在时间轴建模 $\large p(z_{i+k}|z_i…z_{i-r})&#x2F;p(z_{i+k})$</p>
<p><strong>loss function：</strong></p>
<p>作者利用了负采样技术，作者从一个概率分布 $p_n$ 中采样出负样本 $\tilde z$，，最终模型的loss为区分正例和反例的contrastive loss：</p>
<p><img src="/2022/01/04/%E8%AF%86%E5%88%AB/%E9%A2%84%E8%AE%AD%E7%BB%83/image-20220626163406378.png" alt="image-20220626163406378"></p>
</li>
</ul>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><hr>
<blockquote>
<p>&#x3D;&#x3D;Baevski, Alexei, et al. “wav2vec 2.0: A framework for self-supervised learning of speech representations.” <em>Advances in Neural Information Processing Systems</em> 33 (2020): 12449-12460.&#x3D;&#x3D;</p>
</blockquote>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Baevski, Alexei, et al. “Data2vec: A general framework for self-supervised learning in speech, vision and language.” <em>arXiv preprint arXiv:2202.03555</em> (2022).&#x3D;&#x3D;</p>
<p><a href="https://ai.facebook.com/research/data2vec-a-general-framework-for-self-supervised-learning-in-speech-vision-and-language/">https://ai.facebook.com/research/data2vec-a-general-framework-for-self-supervised-learning-in-speech-vision-and-language/</a></p>
<p>github：<a href="https://github.com/pytorch/fairseq/tree/main/examples/data2vec">https://github.com/pytorch/fairseq/tree/main/examples/data2vec</a></p>
</blockquote>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Chen, Sanyuan, et al. “Wavlm: Large-scale self-supervised pre-training for full stack speech processing.” <em>arXiv preprint arXiv:2110.13900</em> (2021).&#x3D;&#x3D;</p>
<p>github：<a href="https://github.com/microsoft/unilm/tree/master/wavlm">https://github.com/microsoft/unilm/tree/master/wavlm</a></p>
</blockquote>
<h2 id="中文预训练模型"><a href="#中文预训练模型" class="headerlink" title="中文预训练模型"></a>中文预训练模型</h2><blockquote>
<p><a href="https://github.com/wenet-e2e/wenet/blob/main/docs/pretrained_models.md">https://github.com/wenet-e2e/wenet/blob/main/docs/pretrained_models.md</a></p>
<p><a href="https://github.com/wenet-e2e/wenet/tree/main/examples/openasr2021/s0">https://github.com/wenet-e2e/wenet/tree/main/examples/openasr2021/s0</a></p>
</blockquote>
]]></content>
      <categories>
        <category>语音识别</category>
      </categories>
      <tags>
        <tag>语音识别</tag>
      </tags>
  </entry>
  <entry>
    <title>Fusion论文笔记（一）语言模型融合声学模型</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/Fusion%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="语言模型融合声学模型"><a href="#语言模型融合声学模型" class="headerlink" title="语言模型融合声学模型"></a>语言模型融合声学模型</h1><p>Fusion解释：fusing E2E models with LMs trained with text data (usually referred to this as fusion)  </p>
<blockquote>
<p>&#x3D;&#x3D;Gulcehre, Caglar, et al. “On using monolingual corpora in neural machine translation.” <em>arXiv preprint arXiv:1503.03535</em> (2015).&#x3D;&#x3D; citations：474</p>
</blockquote>
<h4 id="解决什么问题"><a href="#解决什么问题" class="headerlink" title="解决什么问题"></a>解决什么问题</h4><p>用于机器翻译中，提出一种方法，将仅在单语言数据(目标语言)上训练的语言模型(LM)集成到NMT系统中；</p>
<h4 id="用了什么方法"><a href="#用了什么方法" class="headerlink" title="用了什么方法"></a>用了什么方法</h4><p>集成LM到NMT模型的方法：</p>
<ul>
<li><p>方法1. shallow fusion  ：每个时间步，NMT模型有一系列个候选词（每个候选词是一个类别），通过LM分+NMT输出分+路径分，取nbest路径分，新来一个word，它的分数计算为：</p>
<p>$\large \log p(y_t&#x3D;k)&#x3D;\log p_{TM}(y_t&#x3D;k)+\beta \log p_{LM}(y_t&#x3D;k)$</p>
<p>得到这个word的分数，然后再加上路径分数，再从路径中取n-best路径，（再把路径送入LM，）</p>
</li>
<li><p>方法2. deep fusion  ：</p>
</li>
</ul>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/Fusion%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220726161726854.png" alt="image-20220726161726854" style="zoom:80%;">

<h4 id="效果如何"><a href="#效果如何" class="headerlink" title="效果如何"></a>效果如何</h4><h4 id="还有什么问题"><a href="#还有什么问题" class="headerlink" title="还有什么问题"></a>还有什么问题</h4>]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>LM shallow fusion</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/LM%20fusion/</url>
    <content><![CDATA[<h1 id="LM-shallow-fusion"><a href="#LM-shallow-fusion" class="headerlink" title="LM shallow fusion"></a>LM shallow fusion</h1><blockquote>
<p>github 项目 <a href="https://github.com/Alexander-H-Liu/End-to-end-ASR-Pytorch">End-to-end-ASR-Pytorch</a></p>
<p>github 项目 <a href="https://github.com/espnet/espnet">espnet</a></p>
<p>[重点参考] github 项目 <a href="https://github.com/hirofumi0810/neural_sp">neural_sp</a></p>
<p>Two-Pass End-to-End Speech Recognition <a href="https://paperswithcode.com/paper/two-pass-end-to-end-speech-recognition">https://paperswithcode.com/paper/two-pass-end-to-end-speech-recognition</a></p>
<p>Accelerating RNN Transducer Inference via One-Step Constrained Beam Search <a href="https://paperswithcode.com/paper/accelerating-rnn-transducer-inference-via-one">https://paperswithcode.com/paper/accelerating-rnn-transducer-inference-via-one</a></p>
<p>Sequence Transduction with Recurrent Neural Networks <a href="https://paperswithcode.com/paper/sequence-transduction-with-recurrent-neural">https://paperswithcode.com/paper/sequence-transduction-with-recurrent-neural</a></p>
<p><a href="https://paperswithcode.com/search?q_meta=&amp;q_type=&amp;q=rnn+transducer">https://paperswithcode.com/search?q_meta=&amp;q_type=&amp;q=rnn+transducer</a></p>
<p><a href="https://developers.deepgram.com/blog/2022/07/python-speech-recognition-locally-torchaudio/">https://developers.deepgram.com/blog/2022/07/python-speech-recognition-locally-torchaudio/</a></p>
<p>Deep Speech: Scaling up end-to-end speech recognition <a href="https://paperswithcode.com/paper/deep-speech-scaling-up-end-to-end-speech">https://paperswithcode.com/paper/deep-speech-scaling-up-end-to-end-speech</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/74696938">https://zhuanlan.zhihu.com/p/74696938</a></p>
<p>Listen, Attend and Spell <a href="https://paperswithcode.com/paper/listen-attend-and-spell">https://paperswithcode.com/paper/listen-attend-and-spell</a></p>
<p><a href="https://github.com/Alexander-H-Liu/End-to-end-ASR-Pytorch">https://github.com/Alexander-H-Liu/End-to-end-ASR-Pytorch</a></p>
<p><a href="https://paperswithcode.com/search?q_meta=&amp;q_type=&amp;q=shallow+fusion">https://paperswithcode.com/search?q_meta=&amp;q_type=&amp;q=shallow+fusion</a></p>
<p><a href="https://huggingface.co/models?sort=downloads&amp;search=gpt-chinese">https://huggingface.co/models?sort=downloads&amp;search=gpt-chinese</a></p>
<p><a href="https://huggingface.co/uer/gpt2-chinese-cluecorpussmall">https://huggingface.co/uer/gpt2-chinese-cluecorpussmall</a></p>
<p><a href="https://github.com/Morizeyao/GPT2-Chinese">https://github.com/Morizeyao/GPT2-Chinese</a></p>
<p><a href="https://huggingface.co/espnet/simpleoier_chime6_asr_transformer_wavlm_lr1e-3">https://huggingface.co/espnet/simpleoier_chime6_asr_transformer_wavlm_lr1e-3</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/532959045">https://zhuanlan.zhihu.com/p/532959045</a></p>
</blockquote>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第8章 语言模型————RNN LM</title>
    <url>/2023/01/10/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/RNN%20LM/</url>
    <content><![CDATA[<h1 id="RNN-LM"><a href="#RNN-LM" class="headerlink" title="RNN LM"></a>RNN LM</h1><blockquote>
<p>《语音识别原理与技术》洪青阳 P152</p>
</blockquote>
<p><img src="/2023/01/10/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/RNN%20LM/image-20230112181444005.png" alt="image-20230112181444005"></p>
<p>在 RNNLM 中, 词统计概率表示如下:<br>$$<br>P\left(w_t \mid w_1 \cdots w_{t-1}\right) \approx P\left(w_t \mid w_{t-1}, h_{t-1}\right)&#x3D;P\left(w_t \mid h_t\right)<br>$$<br>其中, $h_{t-1}$ 是隐藏层向量, 代表 $t$ 时刻之前的词序列 $w_1 \cdots w_{t-1}$ 。</p>
<p>在 RNN 的输人层, 每个词都被映射为 $N$ 维的 1-of- $N$ 向量, 即只有该词对应 的元素为 1 , 向量其余元素为 0 。如在以上词典中, “一个” 对应的 $1-\mathrm{of}-~ N$ 向量为 ${1,0,0,0, \cdots, 0,0}$ 。</p>
<p>输人的词 $w_t$ 被转换为 1-of-N 向量后, 将其输人 RNN 网络。 <strong>输出层的输出 $y_t$ 也是一个向量, 向量的每个元素与词典的词一一对应</strong>, 即 $y_t$ 的维度也是 $N$ 。（输入输出维度相同，每维代表的意义相同）</p>
<p><img src="/2023/01/10/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/RNN%20LM/image-20230112181458927.png" alt="image-20230112181458927"></p>
<p>由于词很多 N会很大，运算复杂度很高，并且会很稀疏（one-hot编码）。一种有效办法是对单词进行分类。按类别训练语言模型。<br>$$<br>P\left(w_{t+1} \mid w_c\right)&#x3D;P\left(C_{t+1} \mid C_t\right) P\left(w_t \mid C_t\right) P\left(w_{t+1} \mid C_{t+1}\right)<br>$$<br>例如：<br>$$<br>P(\text { 北京 } \mid \text { 中国 })&#x3D;P(\text { 名词|名词 }) P(\text { 中国|名词 }) P(\text { 北京|名词 })<br>$$<br>其中, 词与类别的组合概率可通过词频数统计得到。这样，即使在训练语料里没 有 “中国 北京” 的组合，但通过类别间概率和词与类别的概率，也可间接计算出这两个词的组合概率, 从而有效地避免了训练数据的稀疏。</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>《语音识别原理与应用》</tag>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP学习笔记</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/NLP%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="NLP学习笔记"><a href="#NLP学习笔记" class="headerlink" title="NLP学习笔记"></a>NLP学习笔记</h1><blockquote>
<p><a href="http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/">http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/</a></p>
</blockquote>
<h2 id="CLS-token"><a href="#CLS-token" class="headerlink" title="[CLS] token"></a>[CLS] token</h2><blockquote>
<p><a href="https://datascience.stackexchange.com/questions/66207/what-is-purpose-of-the-cls-token-and-why-is-its-encoding-output-important">https://datascience.stackexchange.com/questions/66207/what-is-purpose-of-the-cls-token-and-why-is-its-encoding-output-important</a></p>
</blockquote>
<p>用来作为句子级别的分类，是同一个句子or下一个句子，因为其他输入都是单词级别，只有这个没有输入，代表句子级别输出分类</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>code-switch语言模型</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/code-switch%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="code-switch语言模型"><a href="#code-switch语言模型" class="headerlink" title="code-switch语言模型"></a>code-switch语言模型</h1><blockquote>
<p>github：<a href="https://github.com/sagorbrur/codeswitch">https://github.com/sagorbrur/codeswitch</a></p>
<p><a href="https://huggingface.co/sagorsarker/codeswitch-hineng-lid-lince">https://huggingface.co/sagorsarker/codeswitch-hineng-lid-lince</a></p>
<p><a href="https://huggingface.co/models?sort=downloads&amp;search=code-switch">https://huggingface.co/models?sort=downloads&amp;search=code-switch</a></p>
</blockquote>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>huggingface使用</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/huggingface/</url>
    <content><![CDATA[<h1 id="huggingface使用"><a href="#huggingface使用" class="headerlink" title="huggingface使用"></a>huggingface使用</h1><blockquote>
<p><a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
<p><a href="https://github.com/tal-tech/edu-bert">https://github.com/tal-tech/edu-bert</a></p>
<p>李理 <a href="http://fancyerii.github.io/2021/05/11/huggingface-transformers-1/">Huggingface Transformer教程(一)</a></p>
<p>Tokenizer：<a href="https://huggingface.co/docs/transformers/tokenizer_summary">https://huggingface.co/docs/transformers/tokenizer_summary</a></p>
</blockquote>
<p>用huggingface调用好未来预训练模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;/home/yelong/data/edu-bert/models/TAL-EduBERT&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li><p>模型文件夹要放：</p>
<ul>
<li>配置文件，config.json</li>
<li>词典文件，vocab.txt</li>
<li>预训练模型文件，pytorch_model.bin</li>
<li>额外的文件，tokenizer_config.json、special_tokens_map.json，这是tokenizer需要使用的文件，如果出现的话，也需要保存下来。没有的话，就不必在意。</li>
</ul>
</li>
</ul>
<p>huggingface的transformers框架主要有三个类model类、configuration类、tokenizer类，这三个类，所有相关的类都衍生自这三个类，他们都有from_pretained()方法和save_pretrained()方法。</p>
<p>from_pretrained方法的第一个参数都是pretrained_model_name_or_path，这个参数设置为我们下载的文件目录即可。</p>
<p>用huggingface调用model hub的预训练模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classifier = pipeline(<span class="string">&#x27;sentiment-analysis&#x27;</span>, model=<span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>)</span><br></pre></td></tr></table></figure>



<p>除了通过名字来制定model参数，我们也可以传给model一个包含模型的目录的路径，也可以传递一个模型对象。如果我们想传递模型对象，那么也需要传入tokenizer。</p>
<p>我们需要两个类，一个是<a href="https://huggingface.co/transformers/model_doc/auto.html#transformers.AutoTokenizer">AutoTokenizer</a>，我们将使用它来下载和加载与模型匹配的Tokenizer。另一个是<a href="https://huggingface.co/transformers/model_doc/auto.html#transformers.AutoModelForSequenceClassification">AutoModelForSequenceClassification</a>(如果用TensorFlow则是<a href="https://huggingface.co/transformers/model_doc/auto.html#transformers.TFAutoModelForSequenceClassification">TFAutoModelForSequenceClassification</a>)。注意：模型类是与任务相关的，我们这里是情感分类的分类任务，所以是AutoModelForSequenceClassification。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_name)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">classifier = pipeline(<span class="string">&#x27;sentiment-analysis&#x27;</span>, model=model, tokenizer=tokenizer)</span><br></pre></td></tr></table></figure>



<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>Tokenizer和模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification</span><br><span class="line">model_name = <span class="string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span></span><br><span class="line">pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br></pre></td></tr></table></figure>

<h3 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h3><p>其中，Tokenizer的作用大致就是分词，然后把词变成的整数ID，当然有些模型会使用subword。但是不管怎么样，最终的目的是把一段文本变成ID的序列。当然它也必须能够反过来把ID序列变成文本。</p>
<p>细节见：<a href="https://huggingface.co/docs/transformers/tokenizer_summary">https://huggingface.co/docs/transformers/tokenizer_summary</a></p>
<p>Tokenizer对象是callable，因此可以直接传入一个字符串，返回一个dict。最主要的是ID的list，同时也会返回<a href="https://huggingface.co/transformers/glossary.html#attention-mask">attention mask</a>：</p>
<p>我们也可以一次传入一个batch的字符串，这样便于批量处理。这时我们需要指定padding为True并且设置最大的长度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pt_batch = tokenizer(</span><br><span class="line">    [<span class="string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>, <span class="string">&quot;We hope you don&#x27;t hate it.&quot;</span>],</span><br><span class="line">    padding=<span class="literal">True</span>,</span><br><span class="line">    truncation=<span class="literal">True</span>,</span><br><span class="line">    max_length=<span class="number">512</span>,</span><br><span class="line">    return_tensors=<span class="string">&quot;pt&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>



<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>Tokenizer的处理结果可以输入给模型，对于TensorFlow来说直接输入就行，而对于PyTorch则需要使用**来展开参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># PyTorch</span></span><br><span class="line">pt_outputs = pt_model(**pt_batch)</span><br><span class="line"><span class="comment"># TensorFlow</span></span><br><span class="line">tf_outputs = tf_model(tf_batch)</span><br></pre></td></tr></table></figure>

<p>Transformers的所有输出都是tuple，即使只有一个结果也会是长度为1的tuple：</p>
<p>分类任务：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(pt_outputs)</span><br><span class="line">(tensor([[-<span class="number">4.0833</span>,  <span class="number">4.3364</span>],</span><br><span class="line">        [ <span class="number">0.0818</span>, -<span class="number">0.0418</span>]], grad_fn=&lt;AddmmBackward&gt;),)</span><br></pre></td></tr></table></figure>

<p>Transformers的模型默认返回logits，如果需要概率，可以自己加softmax：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pt_predictions = F.softmax(pt_outputs[<span class="number">0</span>], dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>得到和前面一样的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(pt_predictions)</span><br><span class="line">tensor([[<span class="number">2.2043e-04</span>, <span class="number">9.9978e-01</span>],</span><br><span class="line">        [<span class="number">5.3086e-01</span>, <span class="number">4.6914e-01</span>]], grad_fn=&lt;SoftmaxBackward&gt;)</span><br></pre></td></tr></table></figure>

<p>如果我们有输出分类对应的标签，那么也可以传入，这样它除了会计算logits还会loss：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch, labels = torch.tensor([<span class="number">1</span>, <span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<p>输出为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">SequenceClassifierOutput(loss=tensor(<span class="number">0.3167</span>, grad_fn=&lt;NllLossBackward&gt;), logits=tensor([[-<span class="number">4.0833</span>,  <span class="number">4.3364</span>],</span><br><span class="line">        [ <span class="number">0.0818</span>, -<span class="number">0.0418</span>]], grad_fn=&lt;AddmmBackward&gt;), hidden_states=<span class="literal">None</span>, attentions=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>



<h3 id="语言模型-MLM【没用上，可以不看】"><a href="#语言模型-MLM【没用上，可以不看】" class="headerlink" title="语言模型 MLM【没用上，可以不看】"></a>语言模型 MLM【没用上，可以不看】</h3><p>和前面的任务相比，语言模型本身一般很少作为一个独立的任务。它的作用通常是用来预训练基础的模型，然后也可以使用领域的未标注数据来fine-tuning语言模型。比如我们的任务是一个文本分类任务，我们可以基于基础的BERT模型在我们的分类数据上fine-tuning模型。但是BERT的基础模型是基于wiki这样的语料库进行预训练的，不一定和我们的任务很match。而且标注的成本通常很高，我们的分类数据量通常不大。但是领域的未标注数据可能不少。这个时候我们我们可以用领域的未标注数据对基础的BERT用语言模型这个任务进行再次进行pretraining，然后再用标注的数据fine-tuning分类任务。</p>
<p>如果我们需要fine-tuning MLM，可以参考 run_mlm.py。下面是用pipeline的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nlp = pipeline(<span class="string">&quot;fill-mask&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pprint(nlp(<span class="string">f&quot;HuggingFace is creating a <span class="subst">&#123;nlp.tokenizer.mask_token&#125;</span> that the community uses to solve NLP tasks.&quot;</span>))</span><br><span class="line">[&#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.1792745739221573</span>,</span><br><span class="line">  <span class="string">&#x27;sequence&#x27;</span>: <span class="string">&#x27;&lt;s&gt;HuggingFace is creating a tool that the community uses to &#x27;</span></span><br><span class="line">              <span class="string">&#x27;solve NLP tasks.&lt;/s&gt;&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;token&#x27;</span>: <span class="number">3944</span>,</span><br><span class="line">  <span class="string">&#x27;token_str&#x27;</span>: <span class="string">&#x27;Ġtool&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.11349421739578247</span>,</span><br><span class="line">  <span class="string">&#x27;sequence&#x27;</span>: <span class="string">&#x27;&lt;s&gt;HuggingFace is creating a framework that the community uses &#x27;</span></span><br><span class="line">              <span class="string">&#x27;to solve NLP tasks.&lt;/s&gt;&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;token&#x27;</span>: <span class="number">7208</span>,</span><br><span class="line">  <span class="string">&#x27;token_str&#x27;</span>: <span class="string">&#x27;Ġframework&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.05243554711341858</span>,</span><br><span class="line">  <span class="string">&#x27;sequence&#x27;</span>: <span class="string">&#x27;&lt;s&gt;HuggingFace is creating a library that the community uses to &#x27;</span></span><br><span class="line">              <span class="string">&#x27;solve NLP tasks.&lt;/s&gt;&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;token&#x27;</span>: <span class="number">5560</span>,</span><br><span class="line">  <span class="string">&#x27;token_str&#x27;</span>: <span class="string">&#x27;Ġlibrary&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.03493533283472061</span>,</span><br><span class="line">  <span class="string">&#x27;sequence&#x27;</span>: <span class="string">&#x27;&lt;s&gt;HuggingFace is creating a database that the community uses &#x27;</span></span><br><span class="line">              <span class="string">&#x27;to solve NLP tasks.&lt;/s&gt;&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;token&#x27;</span>: <span class="number">8503</span>,</span><br><span class="line">  <span class="string">&#x27;token_str&#x27;</span>: <span class="string">&#x27;Ġdatabase&#x27;</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.02860250137746334</span>,</span><br><span class="line">  <span class="string">&#x27;sequence&#x27;</span>: <span class="string">&#x27;&lt;s&gt;HuggingFace is creating a prototype that the community uses &#x27;</span></span><br><span class="line">              <span class="string">&#x27;to solve NLP tasks.&lt;/s&gt;&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;token&#x27;</span>: <span class="number">17715</span>,</span><br><span class="line">  <span class="string">&#x27;token_str&#x27;</span>: <span class="string">&#x27;Ġprototype&#x27;</span>&#125;]</span><br></pre></td></tr></table></figure>

<p>上面会用到nlp.tokenizer.mask_token，它就是特殊的这个token。我们也可以自己构造Tokenizer和模型，步骤为：</p>
<ul>
<li>构造Tokenizer和模型。比如可以使用DistilBERT从checkpoint加载预训练的模型</li>
<li>构造输入序列，把需要mask的词替换成tokenizer.mask_token</li>
<li>用tokenizer把输入变成ID list</li>
<li>获取预测的结果，它的size是词典大小，表示预测某个词的概率</li>
<li>获取topk个概率最大的词</li>
</ul>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelWithLMHead, AutoTokenizer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;distilbert-base-cased&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model = AutoModelWithLMHead.from_pretrained(<span class="string">&quot;distilbert-base-cased&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sequence = <span class="string">f&quot;Distilled models are smaller than the models they mimic. Using them instead of the large versions would help <span class="subst">&#123;tokenizer.mask_token&#125;</span> our carbon footprint.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">input</span> = tokenizer.encode(sequence, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask_token_index = torch.where(<span class="built_in">input</span> == tokenizer.mask_token_id)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>token_logits = model(<span class="built_in">input</span>).logits</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask_token_logits = token_logits[<span class="number">0</span>, mask_token_index, :]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>top_5_tokens = torch.topk(mask_token_logits, <span class="number">5</span>, dim=<span class="number">1</span>).indices[<span class="number">0</span>].tolist()</span><br></pre></td></tr></table></figure>

<p>注意这里需要使用AutoModelWithLMHead构造模型。</p>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> token <span class="keyword">in</span> top_5_tokens:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))</span><br><span class="line">Distilled models are smaller than the models they mimic. Using them instead of the large versions would <span class="built_in">help</span> reduce our carbon footprint.</span><br><span class="line">Distilled models are smaller than the models they mimic. Using them instead of the large versions would <span class="built_in">help</span> increase our carbon footprint.</span><br><span class="line">Distilled models are smaller than the models they mimic. Using them instead of the large versions would <span class="built_in">help</span> decrease our carbon footprint.</span><br><span class="line">Distilled models are smaller than the models they mimic. Using them instead of the large versions would <span class="built_in">help</span> offset our carbon footprint.</span><br><span class="line">Distilled models are smaller than the models they mimic. Using them instead of the large versions would <span class="built_in">help</span> improve our carbon footprint.</span><br></pre></td></tr></table></figure>



<h3 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/383585103">huggingface获取生成模型的输出概率</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">model1 = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;/home/yelong/data/edu-bert/models/TAL-EduBERT&quot;</span>, return_dict_in_generate=<span class="literal">True</span>,is_decoder=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>



<h2 id="input"><a href="#input" class="headerlink" title="input"></a>input</h2><p>输入一般会包含开头的[CLS]和结尾的[SEP]，如果不想要这两个，可以通过添加<code>add_special_tokens=False</code>来去掉</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tokenizer = BertTokenizer.from_pretrained(path_to_TAL_EduBERT)</span><br><span class="line"></span><br><span class="line">inputs = tokenizer(<span class="string">&quot;today is a nice day&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)  <span class="comment"># [1, 7]</span></span><br><span class="line">inputs = tokenizer(<span class="string">&quot;today is a nice day&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>, add_special_tokens=<span class="literal">False</span>)  <span class="comment"># [1, 5]</span></span><br></pre></td></tr></table></figure>



<h2 id="输出语言模型概率"><a href="#输出语言模型概率" class="headerlink" title="输出语言模型概率"></a>输出语言模型概率</h2><p>我们要用到每个单词的概率，以及整句话的概率分数，输出的不是概率，最后一层没有softmax，要加softmax才是概率（没有log的概率，纯概率值）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = BertForMaskedLM.from_pretrained(path_to_TAL_EduBERT)</span><br><span class="line">inputs = tokenizer(<span class="string">&quot;today is a nice day&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>, add_special_tokens=<span class="literal">False</span>) </span><br><span class="line">outputs = model(**inputs).logits	<span class="comment"># [1,3,21128]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 详细：</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer,BertForMaskedLM</span><br><span class="line">path_to_TAL_EduBERT = <span class="string">&quot;/home/yelong/data/edu-bert/models/TAL-EduBERT&quot;</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(path_to_TAL_EduBERT)</span><br><span class="line">model = BertForMaskedLM.from_pretrained(path_to_TAL_EduBERT)</span><br><span class="line">inputs=tokenizer(<span class="string">&quot;today is a good day&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>, add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">outputs=model(**inputs).logits</span><br><span class="line">logit = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(outputs[<span class="number">0</span>])):</span><br><span class="line">    <span class="comment"># print(outputs[0][i][inputs[&#x27;input_ids&#x27;][0][i]])</span></span><br><span class="line">    logit = logit + outputs[<span class="number">0</span>][i][inputs[<span class="string">&#x27;input_ids&#x27;</span>][<span class="number">0</span>][i]].item()</span><br><span class="line"><span class="built_in">print</span>(logit)</span><br></pre></td></tr></table></figure>



<h1 id="联调"><a href="#联调" class="headerlink" title="联调"></a>联调</h1><p>和CTC decoder输出的句子进行联调，看wer改进</p>
<ol>
<li>CTC出来n-best文本，经过lm选lm概率大的一条路径，见10.22.24.2：&#x2F;home&#x2F;yelong&#x2F;data&#x2F;wenet&#x2F;examples&#x2F;aishell&#x2F;s0&#x2F;compute-wer-lm.py</li>
<li>CTC出来n-best文本以及分数，经过lm选lm概率+CTC分数加权求和最大的一条路径</li>
</ol>
<h2 id="用自有数据pretrain-LM"><a href="#用自有数据pretrain-LM" class="headerlink" title="用自有数据pretrain LM"></a>用自有数据pretrain LM</h2><blockquote>
<p>&#x2F;home&#x2F;yelong&#x2F;data&#x2F;transformers&#x2F;examples&#x2F;pytorch&#x2F;language-modeling&#x2F;run_mlm.py</p>
<p><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling">https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling</a></p>
</blockquote>
<p>官方例子：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python run_mlm.py \</span><br><span class="line">    --model_name_or_path roberta-base \</span><br><span class="line">    --dataset_name wikitext \</span><br><span class="line">    --dataset_config_name wikitext-2-raw-v1 \</span><br><span class="line">    --per_device_train_batch_size 8 \</span><br><span class="line">    --per_device_eval_batch_size 8 \</span><br><span class="line">    --do_train \</span><br><span class="line">    --do_eval \</span><br><span class="line">    --output_dir /tmp/test-mlm</span><br></pre></td></tr></table></figure>

<p>要在您自己的训练和验证文件上运行，请使用以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python run_mlm.py \</span><br><span class="line">    --model_name_or_path roberta-base \</span><br><span class="line">    --train_file path_to_train_file \</span><br><span class="line">    --validation_file path_to_validation_file \</span><br><span class="line">    --per_device_train_batch_size 8 \</span><br><span class="line">    --per_device_eval_batch_size 8 \</span><br><span class="line">    --do_train \</span><br><span class="line">    --do_eval \</span><br><span class="line">    --output_dir /tmp/test-mlm</span><br></pre></td></tr></table></figure>

<p>具体例子为：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python run_mlm.py \</span><br><span class="line">    --model_name_or_path /home/yelong/data/edu-bert/models/TAL-EduBERT \</span><br><span class="line">    --train_file data/train/data.txt \</span><br><span class="line">    --validation_file data/dev/data.txt \</span><br><span class="line">    --per_device_train_batch_size 1 \</span><br><span class="line">    --per_device_eval_batch_size 1 \</span><br><span class="line">    --do_train \</span><br><span class="line">    --do_eval \</span><br><span class="line">    --output_dir test-mlm2 \</span><br><span class="line">    --num_train_epochs 5</span><br></pre></td></tr></table></figure>

<p>其中，data&#x2F;train&#x2F;data.txt就是纯文本</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>huggingface训练代码</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/huggingface%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<h1 id="huggingface训练代码"><a href="#huggingface训练代码" class="headerlink" title="huggingface训练代码"></a>huggingface训练代码</h1><blockquote>
<p><a href="https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one">https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one</a></p>
<p><a href="https://huggingface.co/transformers/v4.1.1/_modules/transformers/training_args.html">https://huggingface.co/transformers/v4.1.1/_modules/transformers/training_args.html</a></p>
<p><a href="https://finance.sina.com.cn/tech/2021-01-17/doc-ikftpnnx8354067.shtml">https://finance.sina.com.cn/tech/2021-01-17/doc-ikftpnnx8354067.shtml</a></p>
<p><a href="https://huggingface.co/docs/transformers/model_doc/bert">https://huggingface.co/docs/transformers/model_doc/bert</a></p>
<p><a href="https://www.cnblogs.com/wwj99/p/12283799.html">https://www.cnblogs.com/wwj99/p/12283799.html</a></p>
<p><a href="https://huggingface.co/docs/transformers/training">https://huggingface.co/docs/transformers/training</a></p>
<p><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb#scrollTo=JEA1ju653l-p">https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb#scrollTo=JEA1ju653l-p</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/363014957">https://zhuanlan.zhihu.com/p/363014957</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/360988428">https://zhuanlan.zhihu.com/p/360988428</a></p>
<p><a href="https://www.yanxishe.com/columnDetail/26409">https://www.yanxishe.com/columnDetail/26409</a></p>
<p>Trainer：<a href="https://huggingface.co/docs/transformers/main_classes/trainer">https://huggingface.co/docs/transformers/main_classes/trainer</a></p>
</blockquote>
<h2 id="用pretained-LM作为基础模型，finetune自有数据训练LM"><a href="#用pretained-LM作为基础模型，finetune自有数据训练LM" class="headerlink" title="用pretained LM作为基础模型，finetune自有数据训练LM"></a>用pretained LM作为基础模型，finetune自有数据训练LM</h2><p>路径：10.22.24.2：&#x2F;home&#x2F;yelong&#x2F;data&#x2F;transformers&#x2F;run_mlm.py</p>
<p>训练，进入loop训练：</p>
<p>从train_result &#x3D; trainer.train(resume_from_checkpoint&#x3D;checkpoint)跳入&#x2F;home&#x2F;yelong&#x2F;data&#x2F;miniconda3&#x2F;envs&#x2F;wenet&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;transformers&#x2F;trainer.py</p>
<p>（或者&#x2F;data_local&#x2F;yelong&#x2F;transformers&#x2F;src&#x2F;transformers&#x2F;trainer.py，这个是我在transformers的git路径下进行了编译<code>pip install -e .</code> 导致transformers路径变了，不是原来的<code>pip install transformers</code>的路径了）</p>
<p>inner_training_loop</p>
<p>再跳入函数 _inner_training_loop 中的 for step, inputs in enumerate(epoch_iterator)</p>
<p>loss计算：tr_loss_step &#x3D; self.training_step(model, inputs)，跳到def training_step(self, model: nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -&gt; torch.Tensor:</p>
<p>然后loss &#x3D; self.compute_loss(model, inputs)只计算masked token的交叉熵，没masked的不计算loss（实现过程：把label非masked部分置为-100 ）</p>
<p>模型为：&#x2F;data_local&#x2F;yelong&#x2F;transformers&#x2F;src&#x2F;transformers&#x2F;models&#x2F;bert&#x2F;modeling_bert.py：class BertModel(BertPreTrainedModel):</p>
<p>class BertForMaskedLM(BertPreTrainedModel):</p>
<p> run_mlm.py中：model:BertForMaskedLM</p>
<h2 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h2><p>见： &#x2F;home&#x2F;yelong&#x2F;data&#x2F;transformers&#x2F;src&#x2F;transformers&#x2F;training_args.py</p>
<p>可以在run_mlm.py中传入参数</p>
<h3 id="GPU、CPU"><a href="#GPU、CPU" class="headerlink" title="GPU、CPU"></a>GPU、CPU</h3><p>想要用CPU：</p>
<p><strong>export CUDA_VISIBLE_DEVICES&#x3D;8，指定一个没有的卡，就能用CPU了</strong></p>
<p>想要指定某张GPU：</p>
<p>在最上面import os后接os.environ[‘CUDA_VISIBLE_DEVICES’] &#x3D; ‘5’ </p>
<p>现在用7G数据训练</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python run_mlm.py \</span><br><span class="line">    --model_name_or_path roberta-base \</span><br><span class="line">    --dataset_name wikitext \</span><br><span class="line">    --dataset_config_name wikitext-2-raw-v1 \</span><br><span class="line">    --per_device_train_batch_size 8 \</span><br><span class="line">    --per_device_eval_batch_size 8 \</span><br><span class="line">    --do_train \</span><br><span class="line">    --do_eval \</span><br><span class="line">    --output_dir ./test-mlm </span><br><span class="line">    </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">自己数据：</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">python run_mlm.py \</span><br><span class="line">    --model_name_or_path /home/yelong/data/edu-bert/models/TAL-EduBERT \</span><br><span class="line">    --train_file data/train/data.txt \</span><br><span class="line">    --validation_file data/dev/data.txt \</span><br><span class="line">    --per_device_train_batch_size 1 \</span><br><span class="line">    --per_device_eval_batch_size 1 \</span><br><span class="line">    --do_train \</span><br><span class="line">    --do_eval \</span><br><span class="line">    --output_dir test-mlm2 \</span><br><span class="line">    --num_train_epochs 5</span><br></pre></td></tr></table></figure>

<p>注意，虽然是device: cuda:0，但其实指的是gpu的5卡</p>
<p>当只使用一块GPU的时候，不管你设置的是服务器上的几号GPU，在代码运行中，都是当做GPU0</p>
<p>当使用多块GPU的时候，不管你设置的使用服务器上的哪几块GPU，在代码运行中，都是按照GPU0，GPU1…进行编号</p>
<p>CUDA_VISIBLE_DEVICES&#x3D;2,0,3  只有编号为0,2,3的GPU对程序是可见的，但是在代码中gpu[0]指的是第2块儿，gpu[1]指的是第0块儿，gpu[2]指的是第3块儿</p>
<p>测试wer：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_checkpoint-1849500 &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;run_mlm_pppl.py&quot;, line 28, in &lt;module&gt;</span><br><span class="line">    logit = scorer.score_sentences([words[1]])[0]</span><br><span class="line">  File &quot;/data_local/yelong/mlm-scoring/src/mlm/scorers.py&quot;, line 167, in score_sentences</span><br><span class="line">    return self.score(corpus, **kwargs)[0]</span><br><span class="line">  File &quot;/data_local/yelong/mlm-scoring/src/mlm/scorers.py&quot;, line 757, in score</span><br><span class="line">    out = out[list(range(split_size)), token_masked_ids]</span><br><span class="line">IndexError: too many indices for tensor of dimension 1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>jieba分词</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/jieba%E5%88%86%E8%AF%8D/</url>
    <content><![CDATA[<h1 id="jieba分词"><a href="#jieba分词" class="headerlink" title="jieba分词"></a>jieba分词</h1><p>注意，依然会有oov，即使用词典分的，用词典分的不好，不如不加词典的</p>
<p>注意，有个坑，let’s 分完会变成 let ‘ s，分完的数据要进行：<code>  sed &#39;s/ &#39;\&#39;&#39;/&#39;\&#39;&#39;/g&#39;</code> ， 然后再 <code>sed &#39;s/&#39;\&#39;&#39; /&#39;\&#39;&#39;/g&#39;</code> 把分开的再合上</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>kenlm</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/kenlm/</url>
    <content><![CDATA[<h1 id="kenlm"><a href="#kenlm" class="headerlink" title="kenlm"></a>kenlm</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> kenlm</span><br><span class="line"> </span><br><span class="line"><span class="comment">## 将文件导入到 kenlm 语言模型中</span></span><br><span class="line">model = kenlm.LanguageModel(<span class="string">&quot;/data/NLP/Language_Models/lm.bin&quot;</span>)</span><br><span class="line"><span class="comment"># 使用语言模型对句子进行打分</span></span><br><span class="line">sentence = <span class="string">&#x27;you are a good man&#x27;</span></span><br><span class="line">model.score(sentence)<span class="comment">#-20.92301368713379</span></span><br><span class="line">sentence = <span class="string">&quot;I&#x27;m fine,thinks&quot;</span></span><br><span class="line">model.score(sentence)<span class="comment">#-21.117055892944336</span></span><br><span class="line">sentence = <span class="string">&quot;wos as dadawnqsao asd aa aa aa&quot;</span></span><br><span class="line">model.score(sentence)<span class="comment">#-46.037437438964844</span></span><br></pre></td></tr></table></figure>



<h1 id="py-kenlm-model"><a href="#py-kenlm-model" class="headerlink" title="py-kenlm-model"></a>py-kenlm-model</h1><blockquote>
<p><a href="https://github.com/mattzheng/py-kenlm-model">https://github.com/mattzheng/py-kenlm-model</a></p>
</blockquote>
<p>旺旺教：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> kenlm</span><br><span class="line"></span><br><span class="line">path = <span class="string">&quot;/data_local/slm/chinese_csc_1268.bin&quot;</span></span><br><span class="line">model = kenlm.LanguageModel(path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;-gram model&#x27;</span>.<span class="built_in">format</span>(model.order))</span><br><span class="line"></span><br><span class="line">sentence = <span class="string">&#x27;今天 天气 很 好&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(model.score(sentence))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># for item in model.full_scores(sentence):</span></span><br><span class="line"><span class="comment">#     print(item)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check that total full score = direct score</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(prob <span class="keyword">for</span> prob, _, _ <span class="keyword">in</span> model.full_scores(s))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> (<span class="built_in">abs</span>(score(sentence) - model.score(sentence)) &lt; <span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show scores and n-gram matches</span></span><br><span class="line">words = [<span class="string">&#x27;&lt;s&gt;&#x27;</span>] + sentence.split() + [<span class="string">&#x27;&lt;/s&gt;&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i, (prob, length, oov) <span class="keyword">in</span> <span class="built_in">enumerate</span>(model.full_scores(sentence)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125; &#123;1&#125;: &#123;2&#125;&#x27;</span>.<span class="built_in">format</span>(prob, length, <span class="string">&#x27; &#x27;</span>.join(words[i + <span class="number">2</span> - length:i + <span class="number">2</span>])))</span><br><span class="line">    <span class="keyword">if</span> oov:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\t&quot;&#123;0&#125;&quot; is an OOV&#x27;</span>.<span class="built_in">format</span>(words[i + <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find out-of-vocabulary words</span></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> words:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> w <span class="keyword">in</span> model:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&quot;&#123;0&#125;&quot; is an OOV&#x27;</span>.<span class="built_in">format</span>(w))</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Ngram LM实验（一）</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ngram%20LM/</url>
    <content><![CDATA[<h1 id="Ngram-LM"><a href="#Ngram-LM" class="headerlink" title="Ngram LM"></a>Ngram LM</h1><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/273606445">https://zhuanlan.zhihu.com/p/273606445</a></p>
</blockquote>
<ol>
<li>训练一个ngram LM：数据：<strong>train set（2715万条，带英文的212万条）</strong></li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">local/train_lms_1gram.sh ngram_test/lang_char.txt.bpe_500_eng1000_chi5200_all6200 ngram_test/text_token_bpe500 ngram_test/lm</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>计算句子ppl：</p>
<ol>
<li>先把10best的脚本，spm.decode恢复（注意这里不把▁替换回来），然后过一遍bpe.model进行encode，得到encode后的文本（ngram_test&#x2F;test&#x2F;text）</li>
<li>计算1.4w条测试集总体的PPL：</li>
</ol>
<p>file ngram_test&#x2F;test&#x2F;text: 14504 sentences, 587117 words, 0 OOVs<br>0 zeroprobs, logprob&#x3D; -1166876 ppl&#x3D; 87.00666 ppl1&#x3D; 97.15536</p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ngram -debug 2 -lm ngram_test/lm/srilm/srilm.o3g.kn.gz -ppl ngram_test/test/text &gt; ngram_test/test/ppl</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（字按空格分开）</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;你 好 啊&quot;</span> | ngram -debug 2 -lm ngram_test/lm/srilm/srilm.o3g.kn.gz -ppl -</span></span><br></pre></td></tr></table></figure>

<h4 id="ngram计算ppl说明："><a href="#ngram计算ppl说明：" class="headerlink" title="ngram计算ppl说明："></a>ngram计算ppl说明：</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ngram</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#功能</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">用于评估语言模型的好坏，或者是计算特定句子的得分，用于语音识别的识别结果分析。</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#参数</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">计算得分：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> -order 模型阶数，默认使用3阶</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> -lm 使用的语言模型</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> -ppl 后跟需要打分的句子（一行一句，已经分词），ppl表示所有单词，ppl1表示除了&lt;/s&gt;以外的单词</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   -debug 0 只输出整体情况</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   -debug 1 具体到句子</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   -debug 2 具体每个词的概率</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">产生句子：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> -gen 产生句子的个数</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> -seed 产生句子用到的random seed</span></span><br><span class="line">ngram -lm $&#123;lm&#125; -order 2 -ppl $&#123;file&#125; -debug 1 &gt; $&#123;ppl&#125;</span><br></pre></td></tr></table></figure>

<p>计算10best的每句话的ppl：</p>
<p>首先把10best 带 bpe 的句子英文以空格区分开【也可以不用下面这个操作！，直接用  <code>tools/text2token.py -s 1 -n 1 -m data/lang_char/train_unigram500.model exp/seewo/conformer/test_xueyuan1/text_bpe --trans_type cn_char_en_bpe </code>就行【甚至更好】！】：</p>
<p>（不是bpe格式的加空格方法：<code>tools/text2token.py -s 0 -n 1 text --trans_type phn &gt; ...</code>）</p>
<p>add_space.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> re, sys, unicodedata</span><br><span class="line">spacelist= [<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;\t&#x27;</span>, <span class="string">&#x27;\r&#x27;</span>, <span class="string">&#x27;\n&#x27;</span>]</span><br><span class="line">puncts = [<span class="string">&#x27;!&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;?&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;、&#x27;</span>, <span class="string">&#x27;。&#x27;</span>, <span class="string">&#x27;！&#x27;</span>, <span class="string">&#x27;，&#x27;</span>, <span class="string">&#x27;；&#x27;</span>, <span class="string">&#x27;？&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;：&#x27;</span>, <span class="string">&#x27;「&#x27;</span>, <span class="string">&#x27;」&#x27;</span>, <span class="string">&#x27;︰&#x27;</span>,  <span class="string">&#x27;『&#x27;</span>, <span class="string">&#x27;』&#x27;</span>, <span class="string">&#x27;《&#x27;</span>, <span class="string">&#x27;》&#x27;</span>]</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">characterize</span>(<span class="params">string</span>) :</span><br><span class="line">  res = []</span><br><span class="line">  i = <span class="number">0</span></span><br><span class="line">  <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(string):</span><br><span class="line">    char = string[i]</span><br><span class="line">    <span class="keyword">if</span> char <span class="keyword">in</span> puncts:</span><br><span class="line">      i += <span class="number">1</span></span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    cat1 = unicodedata.category(char)</span><br><span class="line">    <span class="comment">#https://unicodebook.readthedocs.io/unicode.html#unicode-categories</span></span><br><span class="line">    <span class="keyword">if</span> cat1 == <span class="string">&#x27;Zs&#x27;</span> <span class="keyword">or</span> cat1 == <span class="string">&#x27;Cn&#x27;</span> <span class="keyword">or</span> char <span class="keyword">in</span> spacelist: <span class="comment"># space or not assigned</span></span><br><span class="line">       i += <span class="number">1</span></span><br><span class="line">       <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> cat1 == <span class="string">&#x27;Lo&#x27;</span>: <span class="comment"># letter-other</span></span><br><span class="line">       res.append(char)</span><br><span class="line">       i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">       <span class="comment"># some input looks like: &lt;unk&gt;&lt;noise&gt;, we want to separate it to two words.</span></span><br><span class="line">       sep = <span class="string">&#x27; &#x27;</span></span><br><span class="line">       <span class="keyword">if</span> char == <span class="string">&#x27;&lt;&#x27;</span>: sep = <span class="string">&#x27;&gt;&#x27;</span></span><br><span class="line">       j = i+<span class="number">1</span></span><br><span class="line">       <span class="keyword">while</span> j &lt; <span class="built_in">len</span>(string):</span><br><span class="line">         c = string[j]</span><br><span class="line">         <span class="keyword">if</span> <span class="built_in">ord</span>(c) &gt;= <span class="number">128</span> <span class="keyword">or</span> (c <span class="keyword">in</span> spacelist) <span class="keyword">or</span> (c==sep):</span><br><span class="line">           <span class="keyword">break</span></span><br><span class="line">         j += <span class="number">1</span></span><br><span class="line">       <span class="keyword">if</span> j &lt; <span class="built_in">len</span>(string) <span class="keyword">and</span> string[j] == <span class="string">&#x27;&gt;&#x27;</span>:</span><br><span class="line">         j += <span class="number">1</span></span><br><span class="line">       res.append(string[i:j])</span><br><span class="line">       i = j</span><br><span class="line">  <span class="keyword">return</span> res</span><br><span class="line">sp = spm.SentencePieceProcessor()</span><br><span class="line">sp.Load(<span class="string">&#x27;data/lang_char/train_unigram500.model&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> codecs.<span class="built_in">open</span>(<span class="string">&#x27;exp/seewo/conformer/test_xueyuan1/text_bpe&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fh:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fh:</span><br><span class="line">        array = characterize(line)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>.join(array))</span><br></pre></td></tr></table></figure>

<p>然后计算逐句ppl，存到文件中</p>
<ol start="3">
<li><p>逐句的PPL：在python脚本里调用：暂时不会</p>
</li>
<li><p>计算wer</p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_ngram &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_14</span><br></pre></td></tr></table></figure>

<p>结果最好为： wer_am_lm_alpha_0.1：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Overall -&gt; 4.15 % N=57114 C=55071 S=1576 D=467 I=326</span><br><span class="line">Mandarin -&gt; 3.84 % N=56894 C=55018 S=1506 D=370 I=308</span><br><span class="line">English -&gt; 84.09 % N=220 C=53 S=70 D=97 I=18</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">原 wer_1best：</span></span><br><span class="line">Overall -&gt; 4.31 % N=57114 C=54985 S=1685 D=444 I=331</span><br><span class="line">Mandarin -&gt; 4.00 % N=56894 C=54932 S=1604 D=358 I=315</span><br><span class="line">English -&gt; 83.18 % N=220 C=53 S=81 D=86 I=16</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">仅仅提升3.7%！提升太少了！！</span></span><br></pre></td></tr></table></figure>





<h3 id="用5gram："><a href="#用5gram：" class="headerlink" title="用5gram："></a>用5gram：</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">local/train_lms_1gram.sh ngram_test/lang_char.txt.bpe_500_eng1000_chi5200_all6200 ngram_test/text_token_bpe500 ngram_test/lm_5gram</span><br></pre></td></tr></table></figure>

<p>结果</p>
<ol>
<li>am_logprob + lm_logprob： wer_am_lm_alpha_0.3</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Overall -&gt; 4.18 % N=57114 C=55005 S=1557 D=552 I=276</span><br><span class="line">Mandarin -&gt; 3.87 % N=56894 C=54954 S=1490 D=450 I=259</span><br><span class="line">English -&gt; 84.55 % N=220 C=51 S=67 D=102 I=17</span><br></pre></td></tr></table></figure>

<p>比3gram还差，应该是数据更稀疏？但是ppl又有一丢丢提升，说明不是数据稀疏，而是就该用lm的ppl，不该用logprob？</p>
<ol start="2">
<li>am_logprob + lm_ppl： wer_am_lm_alpha_0.06</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Overall -&gt; 4.13 % N=57114 C=55078 S=1578 D=458 I=324</span><br><span class="line">Mandarin -&gt; 3.83 % N=56894 C=55023 S=1506 D=365 I=307</span><br><span class="line">English -&gt; 82.73 % N=220 C=55 S=72 D=93 I=17</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提升 4.17%</span></span><br></pre></td></tr></table></figure>



<h3 id="增加数据："><a href="#增加数据：" class="headerlink" title="增加数据："></a>增加数据：</h3><p>用7G test set（1302万条，带英文的437万条）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tools/text2token.py -s 1 -n 1 -m data_4000_add_we/lang_char/train_unigram500.model data_4000_add_we_bpe/test/text --trans_type cn_char_en_bpe &gt; data_4000_add_we_bpe/test/text_token_bpe500</span><br></pre></td></tr></table></figure>

<p>总数据就有4018万条，带英文的650万条</p>
<p>分别尝试字典：</p>
<ul>
<li><input checked disabled type="checkbox"> <strong>英文bpe500，对应1000个分词，中文5200</strong>（对应 ngram_test&#x2F;lang_char.txt.bpe_500_eng1000_chi5200_all6200 ）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">local/train_lms_1gram.sh ngram_test/lang_char.txt.bpe_500_eng1000_chi5200_all6200 ngram_7g_train/text_token_bpe500 ngram_7g_train/lm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算1.4w条ppl：</span></span><br><span class="line">ngram -debug 2 -lm ngram_7g_train/lm/srilm/srilm.o3g.kn.gz -ppl ngram_test/test/text &gt;  ngram_7g_train/lm/ppl_1.4w</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_lm_7g_train &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span></span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">Overall -&gt; 3.95 % N=57162 C=55197 S=1486 D=479 I=292</span><br><span class="line">Mandarin -&gt; 3.62 % N=56894 C=55125 S=1406 D=363 I=289</span><br><span class="line">English -&gt; 74.06 % N=266 C=72 S=80 D=114 I=3</span><br><span class="line">Other -&gt; 100.00 % N=2 C=0 S=0 D=2 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">原来</span></span><br><span class="line">Overall -&gt; 4.32 % N=57162 C=55001 S=1695 D=466 I=306</span><br><span class="line">Mandarin -&gt; 3.98 % N=56894 C=54932 S=1604 D=358 I=304</span><br><span class="line">English -&gt; 74.81 % N=266 C=69 S=91 D=106 I=2</span><br><span class="line">Other -&gt; 100.00 % N=2 C=0 S=0 D=2 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提升8.5%</span></span><br></pre></td></tr></table></figure>



<ul>
<li><input checked disabled type="checkbox"> <strong>英文bpe500，对应1000个分词，中文用4018万条去重的所有的</strong>（对应ngram_7g_train&#x2F;lexicon_bpe500）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">local/train_lms_1gram.sh ngram_7g_train/lexicon_bpe500 ngram_7g_train/text_token_bpe500 ngram_7g_train/lm_all_cn/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算1.4w条ppl：</span></span><br><span class="line">ngram -debug 2 -lm ngram_7g_train/lm_all_cn/srilm/srilm.o3g.kn.gz -ppl ngram_test/test/text &gt;  ngram_7g_train/lm_all_cn/ppl_1.4w</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_lm_all_cn_7g_train &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span></span><br></pre></td></tr></table></figure>

<p>结果：	</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am_lm_alpha_0.13</span></span><br><span class="line">Overall -&gt; 3.95 % N=57162 C=55197 S=1486 D=479 I=292</span><br><span class="line">Mandarin -&gt; 3.62 % N=56894 C=55125 S=1406 D=363 I=289</span><br><span class="line">English -&gt; 74.06 % N=266 C=72 S=80 D=114 I=3</span><br><span class="line">Other -&gt; 100.00 % N=2 C=0 S=0 D=2 I=0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提升8.5%</span></span><br></pre></td></tr></table></figure>

<p>&#x3D;&#x3D;7G数据有用&#x3D;&#x3D;</p>
<p>可能更多的中文词，对于该测试集刚好是相同的，所以第二个实验和第一个实验结果相同；</p>
<h2 id="ngram-LM-的英文用word建模，不用bpe了，中文用字"><a href="#ngram-LM-的英文用word建模，不用bpe了，中文用字" class="headerlink" title="ngram LM 的英文用word建模，不用bpe了，中文用字"></a>ngram LM 的英文用word建模，不用bpe了，中文用字</h2><p>直接用：&#x2F;home&#x2F;yelong&#x2F;data&#x2F;wenet&#x2F;examples&#x2F;multi_cn&#x2F;s0&#x2F;data_4000_add_we&#x2F;test_7g&#x2F;text 通过add_space 得到中文字、英文词，空格区分，见 test_7g&#x2F;text_space</p>
<p>加上上面的训练集</p>
<p>lexicon就用所有的中文字&#x2F;英文词作为lexicon：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo  &quot;&lt;UNK&gt; 0&quot; &gt;&gt; lexicon_cn_char_en_char</span><br><span class="line">cat text_space | tr &quot; &quot; &quot;\n&quot; | sort | uniq | grep -a -v -e &#x27;^\s*$&#x27; | grep -v &#x27;·&#x27; | grep -v &#x27;“&#x27; | grep -v &quot;”&quot; | grep -v &quot;\[&quot; | grep -v &quot;\]&quot; | grep -v &quot;…&quot; | awk &#x27;&#123;print $0 &quot; &quot; NR&#125;&#x27; &gt;&gt; lexicon_cn_char_en_char</span><br></pre></td></tr></table></figure>

<p>英文有点太多，都2.6万个词了？其实也还好，中文才8千个字</p>
<p>生成ngram LM：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">local/train_lms_1gram.sh ngram_test/lexicon_cn_char_en_char ngram_test/text_space ngram_test/lm_cn_char_en_char_3gram</span><br></pre></td></tr></table></figure>

<p>计算1.4w条的ppl：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ngram -debug 2 -lm ngram_test/lm_cn_char_en_char_3gram/srilm/srilm.o3g.kn.gz -ppl ngram_test/test/text_space &gt;  ngram_test/test/ppl_space</span><br></pre></td></tr></table></figure>

<p>计算wer：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_3gram_space &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span><br></pre></td></tr></table></figure>

<p>一般般 WER：4.17%</p>
<p>不太行，肯定要稀疏了？，不然英文用大的bpe（上面用的500，dict是1000），比如1000个建模好了？（实际dict 1500）</p>
<p>训练 3gram LM</p>
<h2 id="ngram-LM-的英文用word建模，不用bpe了，中文用词-，解码nbest先jieba分词，再用ngram计算ppl"><a href="#ngram-LM-的英文用word建模，不用bpe了，中文用词-，解码nbest先jieba分词，再用ngram计算ppl" class="headerlink" title="ngram LM 的英文用word建模，不用bpe了，中文用词 ，解码nbest先jieba分词，再用ngram计算ppl"></a>ngram LM 的英文用word建模，不用bpe了，中文用词 ，解码nbest先jieba分词，再用ngram计算ppl</h2><p>离了大谱了，中文有70万个词？，不然先用其他的lexicon：花哥说：先用DaCidian，英文也用公开的词典</p>
<p>Dacidian有50万个词，也很多</p>
<ol>
<li>只用训练集，先用自有词典（76万个词），生成ngram LM：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">local/train_lms_1gram.sh ngram_train_word/lexicon_word ngram_train_word/text ngram_train_word/lm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">计算14w条的ppl：</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">ngram -debug 2 -lm ngram_train_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_train_word/text_1.4w &gt;  ngram_train_word/lm/ppl_1.4w</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意 这里分词的text_10best_word是给定word词典的，避免有OOV</span></span><br><span class="line">ngram -debug 2 -lm ngram_train_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_train_word/text_10best_word &gt;  ngram_train_word/lm/ppl_value</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算wer：</span></span><br><span class="line">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_train_word &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span><br></pre></td></tr></table></figure>

<ul>
<li>测试集直接jieba分词：<ul>
<li>直接测试：<strong>结果不好</strong>，计算ppl时分词了太多OOV了，最好jieba还是给定词典再分词比较好【不好，还是很多OOV】</li>
<li>把测试集OOV添加进words.txt中：然后需要重新训练LM！不能不训练，不然LM没变化；</li>
</ul>
</li>
<li>测试集分词，遇到words.txt没有的词，再次分词（脚本word_segment_again.py）：<ul>
<li>直接拆成字：结果：<strong>结果不好</strong></li>
<li>最大匹配算法，再次拆成词：结果：TODO</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python word_segment_again.py  &gt; ngram_train_word/text_10best_word_again</span><br><span class="line"></span><br><span class="line">ngram -debug 2 -lm ngram_train_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_train_word/text_10best_word_again &gt;  ngram_train_word/lm/ppl_value_again</span><br><span class="line"></span><br><span class="line">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_train_word_again &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span><br></pre></td></tr></table></figure>

<p>word_segment_again.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="comment">#trans_file=&#x27;/home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/train/split_word/text_bigletter&#x27;</span></span><br><span class="line"><span class="comment">#trans_file=&#x27;/home/data/yelong/kaldi/egs/librispeech1/s5/ngram_train_word/text_10best_smallletter&#x27;</span></span><br><span class="line"><span class="comment">#trans_file=&#x27;/home/data/yelong/kaldi/egs/librispeech1/s5/ngram_train_word/text_10best&#x27;</span></span><br><span class="line">trans_file=<span class="string">&#x27;/home/data/yelong/kaldi/egs/librispeech1/s5/ngram_testset/text&#x27;</span></span><br><span class="line"><span class="comment"># jieba.set_dictionary(&#x27;lm_seewo/words.txt&#x27;)</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">lexicon=&#123;&#125;</span><br><span class="line"><span class="comment">#for line in open(&#x27;ngram_train_word/lexicon_word&#x27;):</span></span><br><span class="line"><span class="comment">#for line in open(&#x27;ngram_7g_train_30w_2017_seewo_eng_word/lexicon&#x27;):</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;ngram_7g_train_30w_2017_seewo_eng_word/1&#x27;</span>):</span><br><span class="line"><span class="comment">#for line in open(&#x27;lm_seewo/words.txt&#x27;):</span></span><br><span class="line"><span class="comment">#for line in open(&#x27;lm_from_wanglin/dict_seewo/20190729_lexicon.txt&#x27;):</span></span><br><span class="line">    trans = line.strip().split()</span><br><span class="line">    <span class="comment"># print(trans)</span></span><br><span class="line">    lexicon[trans[<span class="number">0</span>]] = trans[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">pattern_zn = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fa5])&#x27;</span>)</span><br><span class="line">pattern_en =re.<span class="built_in">compile</span>(<span class="string">r&#x27;([a-zA-Z])&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(trans_file):</span><br><span class="line">    trans = line.strip()</span><br><span class="line">    seg_list = jieba.cut(trans)  <span class="comment"># 默认是精确模式</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> seg_list:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> lexicon:</span><br><span class="line">            chars = pattern_zn.split(i)</span><br><span class="line">            chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(chars), end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:    </span><br><span class="line">            <span class="built_in">print</span>(i, end = <span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(end=<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>word_segment_again.old.py：【错！不要分！就要保留oov，这样错误的词概率才低！！】</p>
<p>[2022.7.25]别用jieba了！用lac</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="comment"># trans_file=&#x27;/home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/train/split_word/text_bigletter&#x27;</span></span><br><span class="line">trans_file=<span class="string">&#x27;/home/data/yelong/kaldi/egs/librispeech1/s5/ngram_train_word/text_10best&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># jieba.set_dictionary(&#x27;lm_seewo/words.txt&#x27;)</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">lexicon=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;ngram_train_word/lexicon_word&#x27;</span>):</span><br><span class="line">    trans = line.strip().split()</span><br><span class="line">    <span class="comment"># print(trans)</span></span><br><span class="line">    lexicon[trans[<span class="number">0</span>]] = trans[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">pattern_zn = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fa5])&#x27;</span>)</span><br><span class="line">pattern_en =re.<span class="built_in">compile</span>(<span class="string">r&#x27;([a-zA-Z])&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(trans_file):</span><br><span class="line">    trans = line.strip()</span><br><span class="line">    seg_list = jieba.cut(trans)  <span class="comment"># 默认是精确模式</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> seg_list:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> lexicon:</span><br><span class="line">            chars = pattern_zn.split(i)</span><br><span class="line">            chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> chars:</span><br><span class="line">                <span class="keyword">if</span> j <span class="keyword">in</span> lexicon:</span><br><span class="line">                    <span class="built_in">print</span>(j, end = <span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    chars_en = pattern_en.split(j)</span><br><span class="line">                    chars_en = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars_en <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> chars_en:</span><br><span class="line">                        <span class="keyword">if</span> k <span class="keyword">in</span> lexicon:</span><br><span class="line">                            <span class="built_in">print</span>(k, end = <span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="built_in">print</span>(<span class="string">&quot;error&quot;</span>, end = <span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:    </span><br><span class="line">            <span class="built_in">print</span>(i, end = <span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(end=<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>用训练集+7G数据：10.22.24.2：multi_cn&#x2F;s0&#x2F;data_4000_add_we&#x2F;test_7g_train&#x2F;text；或 24.4：librispeech1&#x2F;s5&#x2F;ngram_7g_train_word</li>
</ol>
<p>给定词典：</p>
<ul>
<li><p>词典：lm_seewo&#x2F;words.txt</p>
<p>需要重新对文本做一个分词，不然太多oov了</p>
<ul>
<li><pre><code class="shell">local/train_lms_1gram.sh lm_seewo/words.txt ngram_7g_train_word/text ngram_7g_train_word/lm_seewo

python word_segment_again.py  &gt; ngram_7g_train_word/text_10best_word_seewo

ngram -debug 2 -lm ngram_7g_train_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_7g_train_word/text_10best_word_seewo &gt;  ngram_7g_train_word/lm_seewo/ppl_value
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  - </span><br><span class="line"></span><br><span class="line">- 去重的词典 （暂时先用train去重的词典ngram_train_word/lexicon_word）</span><br><span class="line"></span><br><span class="line">  - ```shell</span><br><span class="line">    local/train_lms_1gram.sh ngram_train_word/lexicon_word ngram_7g_train_word/text ngram_7g_train_word/lm_train</span><br><span class="line">    </span><br><span class="line">    python word_segment_again.py  &gt; ngram_7g_train_word/text_10best_word_train</span><br><span class="line">    </span><br><span class="line">    ngram -debug 2 -lm ngram_7g_train_word/lm_train/srilm/srilm.o3g.kn.gz -ppl ngram_7g_train_word/text_10best_word_train &gt;  ngram_7g_train_word/lm_train/ppl_value</span><br><span class="line">    </span><br><span class="line">    python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_lm_7g_train_word &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
<li><p>结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am_lm_alpha_0.005</span></span><br><span class="line">Overall -&gt; 4.13 % N=57162 C=55106 S=1575 D=481 I=303</span><br><span class="line">Mandarin -&gt; 3.79 % N=56894 C=55038 S=1491 D=365 I=300</span><br><span class="line">English -&gt; 75.56 % N=266 C=68 S=84 D=114 I=3</span><br><span class="line">Other -&gt; 100.00 % N=2 C=0 S=0 D=2 I=0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提升4.6%</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>测试文本分词重新做一次，测试文本不word_segment_again到最小单元，只是进行分词，如果分到的词，词典里没有，不管！不要强行拆分！！oov概率低，这句话ppl大！符合我们想要的！!</p>
</li>
<li><pre><code class="shell">python word_segment.py &gt; ngram_train_word/text_10best_word_train

ngram -debug 2 -lm ngram_7g_train_word/lm_train/srilm/srilm.o3g.kn.gz -ppl ngram_train_word/text_10best_word_train  &gt;  ngram_7g_train_word/lm_train/ppl_value_oov

python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_7g_train_word_oov &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 修改 ngram_7g_train_word/lm_train/srilm/srilm.o3g.kn.gz，因为oov的logprob为-inf，都没有累计到！因此把这个oov变成随便一个概率很低的word！</span><br><span class="line"></span><br><span class="line">  注意，jieba分词时不要给词典会好一点（不要jieba.set_dictionary(&#x27;ngram_train_word/lexicon_word&#x27;)）不然会出现“ 如果 想收 集 画板”这种分词分得很不好的情况</span><br><span class="line"></span><br><span class="line">  用概率，不用ppl</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  # 注意，jieba分词时不要给词典会好一点（不要jieba.set_dictionary(&#x27;ngram_train_word/lexicon_word&#x27;)）不然会出现“ 如果 想收 集 画板”这种分词分得很不好的情况</span><br><span class="line">  ngram -debug 2 -map-unk ABELL -lm ngram_7g_train_word/lm_train/srilm/srilm.o3g.kn.gz -ppl ngram_7g_train_word/text_10best_word_train  &gt;  ngram_7g_train_word/lm_train/ppl_value_oov_unk</span><br><span class="line">  </span><br><span class="line">  python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_7g_train_word_oov_unk &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
<li><p>结果：</p>
</li>
<li><p>&#96;&#96;&#96;shell</p>
<h1 id="wer-am-lm-alpha-0-6"><a href="#wer-am-lm-alpha-0-6" class="headerlink" title="wer_am_lm_alpha_0.6"></a>wer_am_lm_alpha_0.6</h1><p>Overall -&gt; 4.08 % N&#x3D;57162 C&#x3D;55066 S&#x3D;1489 D&#x3D;607 I&#x3D;236<br>Mandarin -&gt; 3.74 % N&#x3D;56894 C&#x3D;54999 S&#x3D;1416 D&#x3D;479 I&#x3D;233<br>English -&gt; 75.94 % N&#x3D;266 C&#x3D;67 S&#x3D;73 D&#x3D;126 I&#x3D;3<br>Other -&gt; 100.00 % N&#x3D;2 C&#x3D;0 S&#x3D;0 D&#x3D;2 I&#x3D;0</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line">  - </span><br><span class="line"></span><br><span class="line">**他们的words.txt，他们的TLG里的G是词，有59万个词（9万个英文，50万字中文词）** 路径：24.2：/home/yelong/data/wenet/examples/aishell/s0/lm_seewo</span><br><span class="line"></span><br><span class="line">按他们的words.txt对7G+train set进行分词：</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">python word_segment_again.py &gt; /home/yelong/data/wenet/examples/multi_cn/s0/data_4000_add_we/train/split_word_by_seewo_words/2</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<p>最好不要有OOV，把测试集的没在词典里的都添加进词典里？</p>
<h2 id="琳姐训练的ngram-LM，测试"><a href="#琳姐训练的ngram-LM，测试" class="headerlink" title="琳姐训练的ngram LM，测试"></a>琳姐训练的ngram LM，测试</h2><p>路径：10.22.24.4：&#x2F;home&#x2F;data&#x2F;data_to_yelong&#x2F;lm_from_wanglin&#x2F;&#x2F;bigfat_30w10wlwwCE_merge_20190709_7e-10.lm；词典，英文8千个词，中文12万个词，5gram</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python word_segment_again.py  &gt; ngram_lin/text_10best_word_lin	</span><br><span class="line">sed -i &quot;s/\([a-zA-Z]\) &#x27; \([a-zA-Z]\)/\1&#x27;\2/g&quot; ngram_lin/text_10best_word_lin	# bpe会把&#x27;cut成分开的词</span><br><span class="line"></span><br><span class="line">ngram -order 5 -debug 2 -lm lm_from_wanglin/bigfat_30w10wlwwCE_merge_20190709_7e-10.lm -ppl ngram_lin/text_10best_word_lin &gt;  ngram_lin/ppl_value</span><br><span class="line"></span><br><span class="line">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_lin &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am_lm_alpha_0.005</span></span><br><span class="line">Overall -&gt; 4.14 % N=57162 C=55082 S=1597 D=483 I=289</span><br><span class="line">Mandarin -&gt; 3.81 % N=56894 C=55014 S=1507 D=373 I=286</span><br><span class="line">English -&gt; 75.56 % N=266 C=68 S=90 D=108 I=3</span><br><span class="line">Other -&gt; 100.00 % N=2 C=0 S=0 D=2 I=0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提升4.3%</span></span><br></pre></td></tr></table></figure>



<h2 id="ngram-LM-的中文英文都用bpe分词-，解码nbest先jieba分词，再bpe分词，再用ngram计算ppl"><a href="#ngram-LM-的中文英文都用bpe分词-，解码nbest先jieba分词，再bpe分词，再用ngram计算ppl" class="headerlink" title="ngram LM 的中文英文都用bpe分词 ，解码nbest先jieba分词，再bpe分词，再用ngram计算ppl"></a>ngram LM 的中文英文都用bpe分词 ，解码nbest先jieba分词，再bpe分词，再用ngram计算ppl</h2><p>预感效果介于字和词之间，不想做了。</p>
<h2 id="ngram-LM-的英文用bpe1000建模，中文用词-，解码nbest先jieba分词，再用ngram计算ppl"><a href="#ngram-LM-的英文用bpe1000建模，中文用词-，解码nbest先jieba分词，再用ngram计算ppl" class="headerlink" title="ngram LM 的英文用bpe1000建模，中文用词 ，解码nbest先jieba分词，再用ngram计算ppl"></a>ngram LM 的英文用bpe1000建模，中文用词 ，解码nbest先jieba分词，再用ngram计算ppl</h2><p>ngram LM 的英文用bpe1000建模，中文用词 ，解码nbest先jieba分词，再用ngram计算ppl</p>
<h2 id="最好的CTC-rescore后，attention再rescore"><a href="#最好的CTC-rescore后，attention再rescore" class="headerlink" title="最好的CTC rescore后，attention再rescore"></a>最好的CTC rescore后，attention再rescore</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">attention score + ctc*0.5 + \lambda PPL</span></span><br><span class="line">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/wav/text exp/seewo/conformer/test_xueyuan1/ppl_lm_all_cn_7g_train_attention &gt; exp/seewo/conformer/test_xueyuan1/wer_am_lm_alpha_0.01</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am_lm_alpha_0.13</span></span><br><span class="line">Overall -&gt; 3.92 % N=57162 C=55206 S=1462 D=494 I=285</span><br><span class="line">Mandarin -&gt; 3.58 % N=56894 C=55139 S=1378 D=377 I=282</span><br><span class="line">English -&gt; 75.94 % N=266 C=67 S=84 D=115 I=3</span><br><span class="line">Other -&gt; 100.00 % N=2 C=0 S=0 D=2 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">只提升了一丢丢？（不接attention，只用ctc+ppl是3.95%）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">不加lm，纯ctc + attention rescore：</span></span><br><span class="line">Overall -&gt; 4.10 % N=57162 C=55109 S=1564 D=489 I=289</span><br><span class="line">Mandarin -&gt; 3.75 % N=56894 C=55045 S=1478 D=371 I=286</span><br><span class="line">English -&gt; 77.07 % N=266 C=64 S=86 D=116 I=3</span><br><span class="line">Other -&gt; 100.00 % N=2 C=0 S=0 D=2 I=0</span><br></pre></td></tr></table></figure>





<h2 id="词建模的ngram的TLG-进行解码，限制，然后再-NN-LM-rescore"><a href="#词建模的ngram的TLG-进行解码，限制，然后再-NN-LM-rescore" class="headerlink" title="词建模的ngram的TLG 进行解码，限制，然后再 NN LM rescore"></a>词建模的ngram的TLG 进行解码，限制，然后再 NN LM rescore</h2><p>TODO</p>
<h2 id="词建模的ngram的TLG-进行解码，限制，然后再-ngram-LM-rescore"><a href="#词建模的ngram的TLG-进行解码，限制，然后再-ngram-LM-rescore" class="headerlink" title="词建模的ngram的TLG 进行解码，限制，然后再 ngram LM rescore"></a>词建模的ngram的TLG 进行解码，限制，然后再 ngram LM rescore</h2><p>10.22.23.17 docker</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./tools/decode.sh --nj 1 --beam 10.0 --lattice_beam 7.5 --max_active 7000  --blank_skip_thresh 0.98 --ctc_weight 0.5 --rescoring_weight 1.0 --chunk_size -1  --fst_path /home/data/yelong/docker_seewo/seewo/lm_seewo/TLG.fst  /home/data/yelong/docker_seewo/corpus/seewo/wav.scp /home/data/yelong/docker_seewo/corpus/seewo/text /home/data/yelong/docker_seewo/seewo/final.zip  /home/data/yelong/docker_seewo/seewo/lm_seewo/words.txt exp/seewo/conformer/lm_with_runtime</span><br></pre></td></tr></table></figure>



<h2 id="词建模ngram、字建模ngram，连同声学模型分数，三者加权求和，作为最后的分数"><a href="#词建模ngram、字建模ngram，连同声学模型分数，三者加权求和，作为最后的分数" class="headerlink" title="词建模ngram、字建模ngram，连同声学模型分数，三者加权求和，作为最后的分数"></a>词建模ngram、字建模ngram，连同声学模型分数，三者加权求和，作为最后的分数</h2><p>旺旺教的</p>
<p><img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ngram%20LM/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16564181575501-16566580451601.png" alt="img"></p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>ngram经验</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ngram%E7%BB%8F%E9%AA%8C/</url>
    <content><![CDATA[<h1 id="BIGO的端到端语音识别技术"><a href="#BIGO的端到端语音识别技术" class="headerlink" title="BIGO的端到端语音识别技术"></a>BIGO的端到端语音识别技术</h1><blockquote>
<p><a href="https://mp.weixin.qq.com/s/mDyBDcOSYLdZE167uCeJtA#at">BIGO的端到端语音识别技术</a></p>
</blockquote>
<p>在缺乏成对语音文本数据的任务中，浅层融合对识别率提升有很大的帮助。但一般的融合技术仅会选用一种外部LM，RNNLM (Recurrent Neural Network, RNNLM) 或n-gram LM。由于n-gram LM和RNNLM的固有特性不同，对不同场景的建模能力也不同。为了让模型更好地学习不同场景的上下文信息，BIGO设计two-pass机制汲取RNNLM及n-gram LM两者各自优势在不同场景彼此互补。</p>
<p>当有大量训练数据可用时，使用n-gram LM可以获得良好的泛化性能。但统计语言建模的关键问题是，对远程上下文相关性进行建模时往往会伴随数据稀疏问题。为解决此问题，可用基于连续和较低维向量空间中表示较长跨度历史环境的语言建模技术，例如RNNLM。</p>
<p>基于统计信息的语言模型用固定长度上下文，但是递归神经网络不使用有限的上下文。通过使用循环连接，信息可以在这些网络中循环任意长时间。基于递归神经网络的语言模型 (RNNLM) 提供了进一步的概括：代替仅考虑几个先前的单词，具有来自递归连接的输入的神经元被认为代表了短期记忆。这种神经网络方法可以解决稀疏问题，并且与n元语法模型相比，在困惑方面也能很好地概括。但是，这种方法的主要缺点是训练和测试时间很长。这个实际问题限制了RNNLM的数据量和可能的应用区域数量。</p>
<p>由于n-gram LM和RNNLM的固有特性不同的， BIGO设计two-pass机制汲取两者各自优势在不同场景可彼此互补。&#x3D;&#x3D;在第一遍解码中，解码器仅使用通用模型来生成多个识别假设，从中提取n-best列表&#x3D;&#x3D;。在第二遍解码中，使用特定领域的LM（例如&#x3D;&#x3D;高阶n-gram LM或RNNLM&#x3D;&#x3D;）&#x3D;&#x3D;对n-最佳列表的假设进行重新评分&#x3D;&#x3D;，然后获得最佳新假设。使用 n-gram 作为 E2E ASR 重打分。n-gram 作为一个统计模型，其最大的好处是，权重作为显式的表征，可以方便的做灵活的微调以适应各个不同的场景，以及实现不同用户的个性化识别结果。</p>
<p>集束搜索算法的每个解码步上，Attention-Decoder 和 CTC 根据编码结果<em>h</em>和之前的解码结果y&lt;给出当前解码步的语言学单位的后验概率，而RNNLM也根据之前的解码结果 给出当前解码步的语言学单位的后验概率，而后这两者的结果根据浅层融合架构结合。其过程表示为：</p>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ngram%E7%BB%8F%E9%AA%8C/640.jpeg" alt="img" style="zoom:80%;">

<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ngram%E7%BB%8F%E9%AA%8C/image-20220718165315866.png" alt="image-20220718165315866" style="zoom:80%;">

<p>在 CTC-ATT 实现的基础之上，&#x3D;&#x3D;得到的的 shallow fusion 的 N-best 结果送入 n-gram 做 context bias re-score&#x3D;&#x3D;，然后得到 1-best，故式3可以重写为： </p>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ngram%E7%BB%8F%E9%AA%8C/image-20220718165345863.png" alt="image-20220718165345863" style="zoom:80%;">

<p>这个其中需要特别指出的是，CTC和传统的HMM系统其实都是时间对齐的模型，也就是说输出的语言学序列标签长度是正比于特征序列长度的。但是attention-decoder 和 RNNLM 输出确是标签对齐的模型，输出的语言学序列的期望长度确是等于语言学序列长度的。故这两个联合模型需要统一CTC这个时间对齐的输出到标签对齐。这个算法在 [3] 给出过完整的解释，如何将CTC给出的标签分类，然后前向结合变成标签对齐的。</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Ngram LM实验（二）</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ngram%20LM%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h2 id="4000万条做语言模型G1，中英700万条做语言模型G2，模型融合，融合比例通过测试集整体的ppl来确定"><a href="#4000万条做语言模型G1，中英700万条做语言模型G2，模型融合，融合比例通过测试集整体的ppl来确定" class="headerlink" title="4000万条做语言模型G1，中英700万条做语言模型G2，模型融合，融合比例通过测试集整体的ppl来确定"></a>4000万条做语言模型G1，中英700万条做语言模型G2，模型融合，融合比例通过测试集整体的ppl来确定</h2><p>G1、G2分别对测试集计算ppl</p>
<ul>
<li>&#x3D;&#x3D;用词做&#x3D;&#x3D;</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">700万条中英文训练LM：</span></span><br><span class="line">local/train_lms_1gram.sh ngram_7g_train_eng_word/lexicon ngram_7g_train_eng_word/text ngram_7g_train_eng_word/lm</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试ppl：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_testset/text_word是1.4万条文本，进行jieba分词</span></span><br><span class="line">ngram -unk -map-unk &quot;嫫&quot; -order 3 -debug 2 -lm ngram_7g_train_eng_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset/text_word &gt;  ngram_testset/ppl/lm1.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 2316918 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 61085443 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 50367347 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -979696.3 ppl= 536.1027 ppl1= 699.4325</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4000万中文、中英文训练LM：（词典来自ngram_train_word/lexicon_word）</span></span><br><span class="line">ngram_7g_train_word/lm_train/srilm/srilm.o3g.kn.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试ppl：</span></span><br><span class="line">ngram -unk -map-unk &quot;嫫&quot; -order 3 -debug 2 -lm ngram_7g_train_word/lm_train/srilm/srilm.o3g.kn.gz -ppl ngram_testset/text_word &gt;  ngram_testset/ppl/lm2.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 767195 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 81671836 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 91884948 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -971651.7 ppl= 509.14 ppl1= 662.8064</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算合并比例</span></span><br><span class="line">compute-best-mix ngram_testset/ppl/* &gt; ngram_testset/ppl/best_mix</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_testset/ppl/best_mix：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3596414 non-oov words, best lambda (0.447615 0.552385)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pairwise cumulative lambda (1 0.552385)</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">合并模型</span></span><br><span class="line">ngram -order 3 -lm ngram_7g_train_eng_word/lm/srilm/srilm.o3g.kn.gz -lambda 0.447615 -mix-l`m ngram_7g_train_word/lm_train/srilm/srilm.o3g.kn.gz -write-lm ngram_merge_from_7g_train_eng_word_and_7g_train_word/merge_lm.arpa</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">合并后的模型，测试ppl</span></span><br><span class="line">ngram -unk -map-unk &quot;龢&quot; -order 3 -debug 2 -lm ngram_merge_from_7g_train_eng_word_and_7g_train_word/merge_lm.arpa -ppl ngram_testset/text_word &gt;  ngram_testset/ppl/lm_merge.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1.013367e+07 ppl= 657.2279 ppl1= 864.3976</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python compute_wer_lm_logprob.py --char=1 --v=1 data/xueyuan/text exp/seewo/conformer/test_xueyuan2/ppl_ngram_7g_train_eng_word &gt; exp/seewo/conformer/test_xueyuan2/wer_am_lm_alpha_1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am_lm_alpha_0.7</span></span><br><span class="line">Overall -&gt; 4.23 % N=591056 C=569560 S=15493 D=6003 I=3529</span><br><span class="line">Mandarin -&gt; 3.77 % N=587425 C=568766 S=14212 D=4447 I=3497</span><br><span class="line">English -&gt; 78.88 % N=3608 C=794 S=1278 D=1536 I=32</span><br><span class="line">Other -&gt; 100.00 % N=23 C=0 S=3 D=20 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">原来</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am</span></span><br><span class="line">Overall -&gt; 4.59 % N=591056 C=568410 S=18137 D=4509 I=4499</span><br><span class="line">Mandarin -&gt; 4.15 % N=587425 C=567509 S=16695 D=3221 I=4449</span><br><span class="line">English -&gt; 76.41 % N=3608 C=901 S=1437 D=1270 I=50</span><br><span class="line">Other -&gt; 100.00 % N=23 C=0 S=5 D=18 I=0</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<ul>
<li><p>&#x3D;&#x3D;用字做&#x3D;&#x3D;</p>
<p>用花哥的声学模型的字典，来作为语言模型的字典，一般来说是语言模型字典大于声学模型，包含了声学模型所有字，以防OOV，并且可以覆盖以后的字，但是我这边先用一样的好了，或者更多，训练集所有字，总之英文的bpe要换一下，先bpe搞一波</p>
<p>路径：（port 60000）10.22.24.4：&#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;librispeech1&#x2F;s5、（port 51720）10.22.22.2：&#x2F;home&#x2F;yelong&#x2F;data&#x2F;wenet&#x2F;examples&#x2F;multi_cn&#x2F;s0</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.22.24.2：~/data/wenet/examples/multi_cn/s0/data_4000_add_we/test_7g_train/text_space	这个把句子用空格分开了，但是英文还没有bpe分词</span></span><br><span class="line">[不靠谱！]tools/text2token.py -s 0 -n 1 data_4000_add_we/test_7g_train/text.... --trans_type phn &gt; data_4000_add_we/test_7g_train/text_space</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去除行首空格：sed -i <span class="string">&#x27;s/^ *//&#x27;</span> ....</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后，把英文之间的空格变成▁	！！[新] 用 split_sentence.py 的话，不需要把英文之间的空格变成▁！！！就是下面这步不用做了</span></span><br><span class="line">sed &#x27;s/\([A-Z]\) \([A-Z]\)/\1▁\2/g&#x27; data_4000_add_we/test_7g_train/text_space_eng | sed &#x27;s/\([A-Z]\) \([A-Z]\)/\1▁\2/g&#x27; | sed &#x27;s/\xEF\xBB\xBF//&#x27; &gt; data_4000_add_we/test_7g_train/text_space_eng_add_line</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">做bpe：</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">tools/text2token.py -s 0 -n 1 -m /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c007/100-101_unigram5000.model <span class="comment">#data_4000_add_we/test_7g_train/text_space_eng_add_line --trans_type cn_char_en_bpe &gt; data_4000_add_we/test_7g_train/text_space_eng_bpe_100-101_unigram5000</span></span></span><br><span class="line">    [旧]tools/text2token.py -s 0 -n 1 -m /home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/bpe.model data_4000_add_we/test_7g_train/text_space_eng_add_line --trans_type cn_char_en_bpe &gt; data_4000_add_we/test_7g_train/text_space_eng_bpe_aban_c009</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去除行首空格：sed -i <span class="string">&#x27;s/^ *//&#x27;</span> ....</span></span><br><span class="line">[更新]用tools/text2token.py不靠谱，还是用自己写的split_sentence.py！</span><br><span class="line">[新]python split_sentence.py &gt; data_4000_add_we/test_7g_train/text_space_eng_bpe_aban_c009</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">有一些space，乱码，要删除</span></span><br><span class="line">sed -i &#x27;/space/d&#x27;  data_4000_add_we/test_7g_train/text_space_eng_bpe_aban_c009</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">然后和中文一起</span></span><br><span class="line">cat data_4000_add_we/test_7g_train/text_space_cn data_4000_add_we/test_7g_train/text_space_eng_bpe_aban_c009 &gt; data_4000_add_we/test_7g_train/text_space_eng_bpe_aban_c009_and_cn</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试集同样也要做;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">700万条中英文训练LM（英文用bpe子词、中文用字）：</span></span><br><span class="line">local/train_lms_1gram.sh ngram_7g_train_hua_lexicon_eng/lexicon ngram_7g_train_hua_lexicon_eng/text_space_eng_bpe_aban_c009 ngram_7g_train_hua_lexicon_eng/lm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试ppl：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里 ngram_testset_char/text 是1.4万条文本</span></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_hua_lexicon_eng/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/text_space_eng_bpe_aban_c009 &gt;  ngram_testset_char/ppl/lm1.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 12358 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 5639846 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 31839516 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1052204 ppl= 54.52272 ppl1= 60.16961</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4000万中文、中英文训练LM（英文用bpe子词、中文用字）：</span></span><br><span class="line">local/train_lms_1gram.sh ngram_7g_train_hua_lexicon/lexicon ngram_7g_train_hua_lexicon/text_space_eng_bpe_aban_c009_and_cn ngram_7g_train_hua_lexicon/lm</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试ppl：</span></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_hua_lexicon/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/text_space_eng_bpe_aban_c009 &gt;  ngram_testset_char/ppl/lm2.ppl</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在xueyuan test_20best（已经是带▁的） 上测试ppl（为了rescore）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">首先对得到的带bpe的解码结果（没有空格）进行加空格，并且bpe分词：</span></span><br><span class="line">tools/text2token.py -s 0 -n 1 -m /home/data/yelong/wenet/examples/aishell/s0/aban-c009/bpe.model /ngram_testset_char/aban_c009_xueyuan/text --trans_type cn_char_en_bpe &gt; /ngram_testset_char/aban_c009_xueyuan/text_space_eng_bpe_aban_c009</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">去除行首空格：sed -i <span class="string">&#x27;s/^ *//&#x27;</span> ....</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算测试集ppl：</span></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_hua_lexicon_eng/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/aban_c009_xueyuan/text_space_eng_bpe_aban_c009 &gt; ngram_7g_train_hua_lexicon_eng/lm/ppl_aban_c009_xueyuan</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算wer</span></span><br><span class="line">python compute_wer_lm.py --char=1 --v=1 data/xueyuan/text exp/aban-c009/test_xueyuan/ppl_value_aban_c009_xueyuan_test &gt; exp/aban-c009/test_xueyuan/wer_am_lm_alpha_0.1</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p> split_sentence.py：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line">sp = spm.SentencePieceProcessor()</span><br><span class="line"><span class="comment">#sp.load(&quot;/home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/bpe.model&quot;)</span></span><br><span class="line">sp.load(<span class="string">&quot;/home/data/yelong/wenet/examples/aishell/s0/aban-c009/bpe.model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__tokenize_by_bpe_model</span>(<span class="params">sp, txt</span>):</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="comment"># CJK(China Japan Korea) unicode range is [U+4E00, U+9FFF], ref:</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fff])&#x27;</span>)</span><br><span class="line">    <span class="comment"># Example:</span></span><br><span class="line">    <span class="comment">#   txt   = &quot;你好 ITS&#x27;S OKAY 的&quot;</span></span><br><span class="line">    <span class="comment">#   chars = [&quot;你&quot;, &quot;好&quot;, &quot; ITS&#x27;S OKAY &quot;, &quot;的&quot;]</span></span><br><span class="line">    chars = pattern.split(txt.upper())</span><br><span class="line">    mix_chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ch_or_w <span class="keyword">in</span> mix_chars:</span><br><span class="line">        <span class="comment"># ch_or_w is a single CJK charater(i.e., &quot;你&quot;), do nothing.</span></span><br><span class="line">        <span class="keyword">if</span> pattern.fullmatch(ch_or_w) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            tokens.append(ch_or_w)</span><br><span class="line">        <span class="comment"># ch_or_w contains non-CJK charaters(i.e., &quot; IT&#x27;S OKAY &quot;),</span></span><br><span class="line">        <span class="comment"># encode ch_or_w using bpe_model.</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> sp.encode_as_pieces(ch_or_w):</span><br><span class="line">                tokens.append(p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line"><span class="comment"># txt=&quot;你好▁LET&#x27;S▁GO你 好&quot;</span></span><br><span class="line"><span class="comment"># print(&quot; &quot;.join(__tokenize_by_bpe_model(sp,txt)))</span></span><br><span class="line"><span class="comment">#src_file=&#x27;data_4000_add_we/test_7g_train/text_space_eng_add_line&#x27;</span></span><br><span class="line"><span class="comment">#src_file=&#x27;data_4000_add_we/test_7g_train/text_space_eng&#x27;</span></span><br><span class="line"><span class="comment">#src_file=&#x27;ngram_testset_char/text&#x27;</span></span><br><span class="line"><span class="comment">#src_file=&#x27;ngram_testset_char/text_add_line&#x27;</span></span><br><span class="line"><span class="comment">#src_file=&#x27;ngram_testset_char/aban_c009_xueyuan/text&#x27;</span></span><br><span class="line">src_file=<span class="string">&#x27;ngram_testset_char/aban_c009_xueyuan/text_bpe&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(src_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>) <span class="keyword">as</span> fs:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fs:</span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(__tokenize_by_bpe_model(sp,line)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>





















<p>结果分析：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对比加不加ngram rescore：</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">baseline：aban-c009 ctc prefix beam search</span></span><br><span class="line">Overall -&gt; 4.47 % N=591030 C=569205 S=17387 D=4438 I=4594</span><br><span class="line">Mandarin -&gt; 4.28 % N=587425 C=566713 S=16692 D=4020 I=4405</span><br><span class="line">English -&gt; 36.01 % N=3599 C=2492 S=694 D=413 I=189</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">预期能达到最好的情况（rescore能改善的空间）：</span></span><br><span class="line">python compute_wer_best.py --char=1 --v=1 data/xueyuan/text exp/aban-c009/test_xueyuan/text &gt; exp/aban-c009/test_xueyuan/wer_20best</span><br><span class="line"></span><br><span class="line">Overall -&gt; 2.56 % N=591032 C=578565 S=9711 D=2756 I=2678</span><br><span class="line">Mandarin -&gt; 2.43 % N=587425 C=575731 S=9235 D=2459 I=2571</span><br><span class="line">English -&gt; 24.27 % N=3601 C=2834 S=475 D=292 I=107</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">rescore结果：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_7g_train_hua_lexicon_eng/text2token/lm：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_7g_train_hua_lexicon_eng_lm_text2token/wer_am_lm_alpha_0.2</span></span><br><span class="line">Overall -&gt; 4.12 % N=591032 C=571202 S=14610 D=5220 I=4515</span><br><span class="line">Mandarin -&gt; 3.93 % N=587425 C=568694 S=14035 D=4696 I=4364</span><br><span class="line">English -&gt; 34.55 % N=3601 C=2508 S=574 D=519 I=151</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p>上面的比如 LET’S没有分开，优点问题，现在重新做了一次，用的split_sentence.py，现在是新的结果</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">700万条中英文训练LM（英文用bpe子词、中文用字）：</span></span><br><span class="line">local/train_lms_1gram.sh ngram_7g_train_hua_lexicon_eng/lexicon ngram_7g_train_hua_lexicon_eng/text_space_eng_bpe_aban_c009 ngram_7g_train_hua_lexicon_eng/lm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试ppl：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里 ngram_testset_char/text 是1.4万条文本</span></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_hua_lexicon_eng/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/text_space_eng_bpe_aban_c009 &gt;  ngram_testset_char/ppl/lm1.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 12358 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 5641167 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 31842760 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1052185 ppl= 54.49828 ppl1= 60.1414</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4000万中文、中英文训练LM（英文用bpe子词、中文用字）：</span></span><br><span class="line">local/train_lms_1gram.sh ngram_7g_train_hua_lexicon/lexicon ngram_7g_train_hua_lexicon/text_space_eng_bpe_aban_c009_and_cn ngram_7g_train_hua_lexicon/lm</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试ppl：</span></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_hua_lexicon/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/text_space_eng_bpe_aban_c009 &gt;  ngram_testset_char/ppl/lm2.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 12358 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 6916323 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 50028207 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1036973 ppl= 51.43724 ppl1= 56.6826</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算测试集ppl：</span></span><br><span class="line">python word_sentence.py &gt; ngram_testset_char/aban_c009_xueyuan/text_space_eng_bpe_aban_c009</span><br><span class="line"></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_hua_lexicon_eng/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/aban_c009_xueyuan/text_space_eng_bpe_aban_c009 &gt; ngram_7g_train_hua_lexicon_eng/lm/ppl_aban_c009_xueyuan</span><br><span class="line"></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_hua_lexicon/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/aban_c009_xueyuan/text_space_eng_bpe_aban_c009 &gt; ngram_7g_train_hua_lexicon/lm/ppl_aban_c009_xueyuan</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_7g_train_hua_lexicon_eng_lm：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am_lm_alpha_0.2</span></span><br><span class="line">Overall -&gt; 4.12 % N=591032 C=571208 S=14605 D=5219 I=4515</span><br><span class="line">Mandarin -&gt; 3.93 % N=587425 C=568695 S=14034 D=4696 I=4364</span><br><span class="line">English -&gt; 34.41 % N=3601 C=2513 S=570 D=518 I=151</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_7g_train_hua_lexicon_lm：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am_lm_alpha_0.18</span></span><br><span class="line">Overall -&gt; 4.10 % N=591032 C=571249 S=14659 D=5124 I=4453</span><br><span class="line">Mandarin -&gt; 3.91 % N=587425 C=568747 S=14077 D=4601 I=4303</span><br><span class="line">English -&gt; 34.68 % N=3601 C=2502 S=581 D=518 I=150</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p>​	</p>
<ul>
<li><p>&#x3D;&#x3D;中文用字，英文用词，这样就不用因为bpe.model而每次要重新训练LM&#x3D;&#x3D;</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">把测试集句子分成中文空格分开的字、英文空格分开的词</span></span><br><span class="line">python split_sentence_nobpe.py  &gt; ngram_testset_char/text_space</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">700万条中英文训练LM（英文用词、中文用字）：</span></span><br><span class="line">local/train_lms_1gram.sh ngram_7g_train_char/lexicon ngram_7g_train_char/text_space_eng ngram_7g_train_char/lm_eng</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试ppl：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里 ngram_testset_char/text_space 是1.4万条文本</span></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_char/lm_eng/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/text_space &gt; ngram_testset_char/ppl_char/lm1.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 34111 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 6114244 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 31739092 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1051788 ppl= 54.54516 ppl1= 60.19802</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4000万中文、中英文训练LM（英文用bpe子词、中文用字）：</span></span><br><span class="line">local/train_lms_1gram.sh ngram_7g_train_char/lexicon ngram_7g_train_char/text_space ngram_7g_train_char/lm_eng_cn</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试ppl：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这里 ngram_testset_char/text_space 是1.4万条文本</span></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_char/lm_eng_cn/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/text_space &gt; ngram_testset_char/ppl_char/lm2.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 34111 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 7389346 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 49923410 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1036779 ppl= 51.5195 ppl1= 56.77883</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算测试集ppl（20best）（29w条）</span></span><br><span class="line">python split_sentence_nobpe.py &gt; ngram_testset_char/aban_c009_xueyuan/text_space</span><br><span class="line"></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_char/lm_eng/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/aban_c009_xueyuan/text_space &gt; ngram_7g_train_char/lm_eng/ppl_aban_c009_xueyuan</span><br><span class="line"></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_char/lm_eng_cn/srilm/srilm.o3g.kn.gz -ppl ngram_testset_char/aban_c009_xueyuan/text_space &gt; ngram_7g_train_char/lm_eng_cn/ppl_aban_c009_xueyuan</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">有些地方是没有输出结果，计算ngram没有返回值，这些句子要手动空行</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">qq是只有一行的y空行</span></span><br><span class="line">sed -i &#x27;5600 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;11812 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;35862 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;58228 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;107511 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;117260 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;121642 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;208564 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;245827 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br><span class="line">sed -i &#x27;290460 r qq&#x27; ppl_value_aban_c009_xueyuan</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对比加不加ngram rescore：</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">baseline：aban-c009 ctc prefix beam search</span></span><br><span class="line">Overall -&gt; 4.47 % N=591030 C=569205 S=17387 D=4438 I=4594</span><br><span class="line">Mandarin -&gt; 4.28 % N=587425 C=566713 S=16692 D=4020 I=4405</span><br><span class="line">English -&gt; 36.01 % N=3599 C=2492 S=694 D=413 I=189</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">预期能达到最好的情况（rescore能改善的空间）：</span></span><br><span class="line">python compute_wer_best.py --char=1 --v=1 data/xueyuan/text exp/aban-c009/test_xueyuan/text &gt; exp/aban-c009/test_xueyuan/wer_20best</span><br><span class="line"></span><br><span class="line">Overall -&gt; 2.56 % N=591032 C=578565 S=9711 D=2756 I=2678</span><br><span class="line">Mandarin -&gt; 2.43 % N=587425 C=575731 S=9235 D=2459 I=2571</span><br><span class="line">English -&gt; 24.27 % N=3601 C=2834 S=475 D=292 I=107</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_7g_train_char/lm_eng：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_7g_train_char_lm_eng/wer_am_lm_alpha_0.2</span></span><br><span class="line">Overall -&gt; 4.12 % N=591032 C=571210 S=14609 D=5213 I=4518</span><br><span class="line">Mandarin -&gt; 3.93 % N=587425 C=568703 S=14030 D=4692 I=4363</span><br><span class="line">English -&gt; 34.68 % N=3601 C=2507 S=578 D=516 I=155</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">英文没有bpe分词的好，说明按英文word单词数还是有点太多，但是只变差一丢丢，计算方便了很多，所以用词直接建模也是OK的！！！！！！！！！！！；</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_7g_train_char/lm_eng_cn：</span></span><br><span class="line">Overall -&gt; 4.10 % N=591032 C=571281 S=14582 D=5169 I=4470</span><br><span class="line">Mandarin -&gt; 3.91 % N=587425 C=568779 S=13999 D=4647 I=4319</span><br><span class="line">English -&gt; 34.71 % N=3601 C=2502 S=582 D=517 I=151</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</li>
<li><p>&#x3D;&#x3D;小结&#x3D;&#x3D;：</p>
<ul>
<li><p>英文直接用词做LM没有bpe分词的好，说明按英文word单词数还是有点太多，但是只变差一丢丢，计算方便了很多，所以用词直接建模也是OK的！！！！！！！！！！！</p>
<p>但是，英文直接用词，会有可能出现测试集里有词典没有的词，OOV的出现！！用bpe就没有这个问题！！</p>
</li>
<li><p>训练LM纯中文文本多了（700中英 -&gt; 4000纯中文+中英），中文部分结果会变好，英文只变差了一丢丢；</p>
</li>
</ul>
</li>
</ul>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><ol>
<li>字建模的ngram LM比词建模的ngram LM的wer更低</li>
<li>只用3500小时对应的文本不够，7G垂直领域文本有用，比其他领域更多的中英数据还有用；</li>
<li>wer改善其实很小，对于英文的改善更小；</li>
<li>做按字的分词估计有点问题</li>
</ol>
<h1 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h1><ol>
<li><p>为什么字建模比词建模效果好？</p>
<ol>
<li>先排除oov的干扰，确认不是词的oov后，ngram建模出发来看，2gram的概率公式为$\large P(w_i|w_{i-1})&#x3D;\frac{count(w_{i-1}w_i)}{count(w_{i-1})}$，分子是同时发生的频次，分母是前一个词发生的频次，因此，以词建模的ngram有一下几个问题：<ol>
<li>词数多（几十万个），在比如“我”后面，可以接的词太多，概率都很低？</li>
<li>训练数据不够多，统计量分到词组少，就很少了，造成概率都偏低，nbest区分不明显；</li>
<li>错误词分词拆成字，反而概率更高：比如“黝黑”logprob-4，但是“呦 嘿”的logprob反而更大，造成错别字的ppl更小</li>
</ol>
</li>
<li>oov的影响：oov较多，概率不准确：ngram直接计算oov，oov对应logprob是-inf，但计算句子的logprob时这个-inf并没有加上，会造成错误</li>
</ol>
</li>
<li><p>（花哥教）从识别出nbest的角度进行解释：LM可以判断一句话像不像话，他的“顺序”判别能力 优于错别字的判别能力；而识别出来的nbest可能只是错一两个字，语序的错误并不多，因此难判断，还有就是比如“中国人民共和国”是一个词，如果nbest里错了一个字，则不是一个词了，该词的概率就没有了，就分词分成更小的了，这样它的概率优势就凸显不了了；</p>
</li>
<li><p>原理出发，来衡量n-best哪句话最像话，是否可以用ppl来衡量？</p>
<p>ppl适合来比较语言模型对某个数据集的匹配程度，能比较出来，比如这个语言模型比起另一个语言模型更匹配某个数据集；</p>
<p>可能它不适合在同一个语言模型下，比较两句话的ppl，来衡量哪句话更像话；</p>
</li>
</ol>
<p>ngram -unk  -map-unk “<UNK>“ -lm 11&#x2F;srilm&#x2F;srilm.o3g.kn.gz -order 2 -ppl 2 -debug 2</UNK></p>
<h2 id="用更多数据"><a href="#用更多数据" class="headerlink" title="用更多数据"></a>用更多数据</h2><p>用贤祥给的2400万条中英文本，还有7g_train一共700万条中英文本，一共3100万条（ngram_7g_train_30w_2017_seewo_eng_word&#x2F;text）24.4 &#x2F;home&#x2F;data&#x2F;yelong&#x2F;kaldi&#x2F;egs&#x2F;librispeech1&#x2F;s5&#x2F;</p>
<p>琳姐的词典，做一个LM</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat ngram_7g_train_eng_word/text 30w_2017_seewo/30w_2017_seewo_nopunc_freq_cn_en &gt; ngram_7g_train_30w_2017_seewo_eng_word/text</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">再把am的词典的字，合并进琳姐词典中（有600个生字是琳姐词典里没有的），得到ngram_7g_train_30w_2017_seewo_eng_word/lexicon</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">训练LM</span></span><br><span class="line">local/train_lms_1gram.sh ngram_7g_train_30w_2017_seewo_eng_word/lexicon ngram_7g_train_30w_2017_seewo_eng_word/text ngram_7g_train_30w_2017_seewo_eng_word/lm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 测试1.4w测试集ppl</span></span></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_30w_2017_seewo_eng_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset/text_word &gt;  ngram_testset/ppl_word/lm1.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 134090 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 43612597 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 55833679 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1066023 ppl= 514.9295 ppl1= 654.8651</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">计算测试集ppl：</span></span><br><span class="line">python word_segment_again.py &gt; ngram_testset/aban_c009_xueyuan/text_word</span><br><span class="line">sed -i &#x27;s/ &#x27;\&#x27;&#x27;/&#x27;\&#x27;&#x27;/g&#x27; ngram_testset/aban_c009_xueyuan/text_word</span><br><span class="line">sed -i &#x27;s/&#x27;\&#x27;&#x27; /&#x27;\&#x27;&#x27;/g&#x27; ngram_testset/aban_c009_xueyuan/text_word</span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_30w_2017_seewo_eng_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset/aban_c009_xueyuan/text_word &gt; ngram_7g_train_30w_2017_seewo_eng_word/lm/ppl_aban_c009_xueyuan</span><br><span class="line"></span><br><span class="line">for alpha in 0.02 0.005 0.01 0.015 0.018 0.022 0.03 0.04 0.05 0.06 0.07 0.08 0.09; do</span><br><span class="line">    python compute_wer_lm.py --char=1 --v=1 data/xueyuan/text exp/aban-c009/test_xueyuan/ngram_7g_train_30w_2017_seewo_eng_word_lm/ppl_value_aban_c009_xueyuan_test $alpha &gt; exp/aban-c009/test_xueyuan/ngram_7g_train_30w_2017_seewo_eng_word_lm/wer_am_lm_alpha_$alpha</span><br><span class="line">done</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">baseline：aban-c009 ctc prefix beam search</span></span><br><span class="line">Overall -&gt; 4.47 % N=591030 C=569205 S=17387 D=4438 I=4594</span><br><span class="line">Mandarin -&gt; 4.28 % N=587425 C=566713 S=16692 D=4020 I=4405</span><br><span class="line">English -&gt; 36.01 % N=3599 C=2492 S=694 D=413 I=189</span><br><span class="line">Other -&gt; 100.00 % N=6 C=0 S=1 D=5 I=0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ngram_7g_train_30w_2017_seewo_eng_word_lm：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wer_am_lm_alpha_0.007</span></span><br><span class="line">Overall -&gt; 4.32 % N=591032 C=570190 S=15903 D=4939 I=4702</span><br><span class="line">Mandarin -&gt; 4.14 % N=587425 C=567617 S=15300 D=4508 I=4521</span><br><span class="line">English -&gt; 33.55 % N=3601 C=2573 S=602 D=426 I=180</span><br><span class="line">Other -&gt; 116.67 % N=6 C=0 S=1 D=5 I=1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">中文提升3%，英文提升6%，加中英数据，英文变好了一点点，但是中文提升没之前多了，但是中文已经很好了</span></span><br></pre></td></tr></table></figure>



<p>对比三种词建模在1.4w条的ppl：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ngram -unk -map-unk &quot;嫫&quot; -order 3 -debug 2 -lm ngram_7g_train_eng_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset/text_word &gt;  ngram_testset/ppl/lm1.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 2316918 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 61085443 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 50367347 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1099945 ppl= 628.1117 ppl1= 804.9393</span></span><br><span class="line"></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_word/lm_train/srilm/srilm.o3g.kn.gz -ppl ngram_testset/text_word &gt;  ngram_testset/ppl/lm2.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 767195 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 81671836 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 91884948 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1087195 ppl= 582.9138 ppl1= 744.8724</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ngram -unk -map-unk &quot;厶&quot; -order 3 -debug 2 -lm ngram_7g_train_30w_2017_seewo_eng_word/lm/srilm/srilm.o3g.kn.gz -ppl ngram_testset/text_word &gt;  ngram_testset/ppl_word/lm1.ppl</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 134090 1-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 43612597 2-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">reading 55833679 3-grams</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 zeroprobs, logprob= -1066023 ppl= 514.9295 ppl1= 654.8651</span></span><br></pre></td></tr></table></figure>









<h2 id="一些脚本"><a href="#一些脚本" class="headerlink" title="一些脚本"></a>一些脚本</h2><p>把句子拆成空格间隔，bpe分词</p>
<p>（用text2token进行bpe分词，LET’S是拆不开的）</p>
<p>split_sentence.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line">sp = spm.SentencePieceProcessor()</span><br><span class="line">sp.load(<span class="string">&quot;/home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/bpe.model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__tokenize_by_bpe_model</span>(<span class="params">sp, txt</span>):</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="comment"># CJK(China Japan Korea) unicode range is [U+4E00, U+9FFF], ref:</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fff])&#x27;</span>)</span><br><span class="line">    <span class="comment"># Example:</span></span><br><span class="line">    <span class="comment">#   txt   = &quot;你好 ITS&#x27;S OKAY 的&quot;</span></span><br><span class="line">    <span class="comment">#   chars = [&quot;你&quot;, &quot;好&quot;, &quot; ITS&#x27;S OKAY &quot;, &quot;的&quot;]</span></span><br><span class="line">    chars = pattern.split(txt.upper())</span><br><span class="line">    mix_chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ch_or_w <span class="keyword">in</span> mix_chars:</span><br><span class="line">        <span class="comment"># ch_or_w is a single CJK charater(i.e., &quot;你&quot;), do nothing.</span></span><br><span class="line">        <span class="keyword">if</span> pattern.fullmatch(ch_or_w) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            tokens.append(ch_or_w)</span><br><span class="line">        <span class="comment"># ch_or_w contains non-CJK charaters(i.e., &quot; IT&#x27;S OKAY &quot;),</span></span><br><span class="line">        <span class="comment"># encode ch_or_w using bpe_model.</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> sp.encode_as_pieces(ch_or_w):</span><br><span class="line">                tokens.append(p)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line"><span class="comment"># txt=&quot;你好▁LET&#x27;S▁GO你 好&quot;</span></span><br><span class="line"><span class="comment"># print(&quot; &quot;.join(__tokenize_by_bpe_model(sp,txt)))</span></span><br><span class="line">src_file=<span class="string">&#x27;....&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(src_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>) <span class="keyword">as</span> fs:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fs:</span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(__tokenize_by_bpe_model(sp,line)))</span><br></pre></td></tr></table></figure>



<p>把句子拆成空格间隔，英文也拆开，没有bpe分词（假设没有标点符号）</p>
<p>split_sentence_nobpe.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment">#import sentencepiece as spm</span></span><br><span class="line"><span class="comment">#sp = spm.SentencePieceProcessor()</span></span><br><span class="line"><span class="comment">#sp.load(&quot;/home/yelong/data/wenet/examples/aishell/s0/exp/aban-c009/bpe.model&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__tokenize_by_bpe_model</span>(<span class="params">txt</span>):</span><br><span class="line">    tokens = []</span><br><span class="line">    <span class="comment"># CJK(China Japan Korea) unicode range is [U+4E00, U+9FFF], ref:</span></span><br><span class="line">    <span class="comment"># https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;([\u4e00-\u9fff])&#x27;</span>)</span><br><span class="line">    <span class="comment"># Example:</span></span><br><span class="line">    <span class="comment">#   txt   = &quot;你好 ITS&#x27;S OKAY 的&quot;</span></span><br><span class="line">    <span class="comment">#   chars = [&quot;你&quot;, &quot;好&quot;, &quot; ITS&#x27;S OKAY &quot;, &quot;的&quot;]</span></span><br><span class="line">    chars = pattern.split(txt.upper())</span><br><span class="line">    mix_chars = [w <span class="keyword">for</span> w <span class="keyword">in</span> chars <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> ch_or_w <span class="keyword">in</span> mix_chars:</span><br><span class="line">        <span class="comment"># ch_or_w is a single CJK charater(i.e., &quot;你&quot;), do nothing.</span></span><br><span class="line">        <span class="comment">#if pattern.fullmatch(ch_or_w) is not None:</span></span><br><span class="line">        tokens.append(ch_or_w)</span><br><span class="line">        <span class="comment"># ch_or_w contains non-CJK charaters(i.e., &quot; IT&#x27;S OKAY &quot;),</span></span><br><span class="line">        <span class="comment"># encode ch_or_w using bpe_model.</span></span><br><span class="line">        <span class="comment">#else:</span></span><br><span class="line">            <span class="comment">#for p in sp.encode_as_pieces(ch_or_w):</span></span><br><span class="line">            <span class="comment">#    tokens.append(p)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tokens</span><br><span class="line"><span class="comment"># txt=&quot;你好▁LET&#x27;S▁GO你 好&quot;</span></span><br><span class="line"><span class="comment"># print(&quot; &quot;.join(__tokenize_by_bpe_model(sp,txt)))</span></span><br><span class="line"><span class="comment">#src_file=&#x27;data_4000_add_we/test_7g_train/text_space_eng_add_line&#x27;</span></span><br><span class="line"><span class="comment">#src_file=&#x27;data_4000_add_we/test_7g_train/text_space_eng&#x27;</span></span><br><span class="line">src_file=<span class="string">&#x27;ngram_testset_char/text&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(src_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf8&quot;</span>) <span class="keyword">as</span> fs:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fs:</span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(__tokenize_by_bpe_model(line)))</span><br><span class="line">        <span class="comment">#print(&quot; &quot;.join(__tokenize_by_bpe_model(sp,line)))</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>困惑度 PPL perplexity</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%9B%B0%E6%83%91%E5%BA%A6/</url>
    <content><![CDATA[<h1 id="困惑度-PPL-perplexity"><a href="#困惑度-PPL-perplexity" class="headerlink" title="困惑度 PPL perplexity"></a>困惑度 PPL perplexity</h1><blockquote>
<p><a href="https://huggingface.co/docs/transformers/perplexity">https://huggingface.co/docs/transformers/perplexity</a></p>
<p><a href="https://huggingface.co/spaces/evaluate-metric/perplexity">https://huggingface.co/spaces/evaluate-metric/perplexity</a></p>
<p><a href="https://towardsdatascience.com/perplexity-in-language-models-87a196019a94">https://towardsdatascience.com/perplexity-in-language-models-87a196019a94</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1602293">https://cloud.tencent.com/developer/article/1602293</a></p>
<p><a href="https://stats.stackexchange.com/questions/402686/word-perplexity-on-a-subword-language-model">https://stats.stackexchange.com/questions/402686/word-perplexity-on-a-subword-language-model</a></p>
<p><a href="https://stats.stackexchange.com/questions/247842/calculating-test-time-perplexity-for-seq2seq-rnn-language-models">https://stats.stackexchange.com/questions/247842/calculating-test-time-perplexity-for-seq2seq-rnn-language-models</a></p>
<p><a href="https://docs.chainer.org/en/stable/examples/ptb.html">https://docs.chainer.org/en/stable/examples/ptb.html</a></p>
<p><a href="https://www.jianshu.com/p/9abeb65d1d10">https://www.jianshu.com/p/9abeb65d1d10</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/273606445">https://zhuanlan.zhihu.com/p/273606445</a></p>
<p><a href="http://fancyerii.github.io/dev287x/lm/#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0">http://fancyerii.github.io/dev287x/lm/#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0</a></p>
</blockquote>
<h1 id="ngram"><a href="#ngram" class="headerlink" title="ngram"></a>ngram</h1>]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>《语音识别原理与应用》洪青阳 第8章 语言模型————平滑技术</title>
    <url>/2023/01/10/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%B9%B3%E6%BB%91%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h1 id="语言模型平滑技术"><a href="#语言模型平滑技术" class="headerlink" title="语言模型平滑技术"></a>语言模型平滑技术</h1><blockquote>
<p>《语音识别原理与技术》洪青阳</p>
</blockquote>
<p>语言模型的概率需要通过大量的文本语料来估计，采用最大似然算法。但由于统计语料有限，所以会存在数据稀疏的情況，这可能导致零概率或估计不准的问题，因此对语料中未出现或少量出现的词序列，需要采用平滑技术进行间接预测。</p>
<p>概括起来，平滑技术主要有三种。</p>
<ul>
<li>折扣法( Discounting)：从已有观察值概率调配一些给未观察值概率，例如 Good-Turing（吉德-图灵）折扣法。</li>
<li>插值法（Interpolation）：将高阶模型和低阶模型做线性组合，如Jelinek-Mercer 插值法，也可做非线性组合，如Kneser-Ney 插值法。</li>
<li>回退法(Back-off）：基于低阶模型估计未观察到的高阶模型，例如Katz 回退法。</li>
</ul>
<h2 id="Good-Turing-折扣法"><a href="#Good-Turing-折扣法" class="headerlink" title="Good-Turing 折扣法"></a>Good-Turing 折扣法</h2><p>Good-Turing 折扣法是从已有观察值概率调配一些给未观察值概率。设总词数为 $N$，出现1次的词数为 $N_1$，出现 $c$ 次的词数为 $N$，因此有<br>$$<br>N&#x3D;\sum_ccN_c<br>$$<br>平滑后，出现次数 $c$ 被替换为 $c^*&#x3D;\frac{(c+1)N_{c+1}}{N_c}$，其对应的概率为<br>$$<br>P_{GT}&#x3D;\frac{c^*}{N}<br>$$</p>
<p>例如，给定分词后的句子语料（假设只有两句)：</p>
<ul>
<li>“我们 明年 会 有全新 的 开始”</li>
<li>“我们 彼此 祝福 着 等待 再见 那 一 天”</li>
</ul>
<p>统计词频数：“我们°出现2次，“明年”出现1次，……，“天” 出现1次，即</p>
<p>折扣前：$N&#x3D;16$， $N_1&#x3D;14$, $N_2 &#x3D;1$</p>
<p>折扣后：$P_0^*&#x3D;\frac{N_1}{N}&#x3D;\frac{14}{16}$ ，$P_1^*&#x3D;\frac{c_1^*}{N}&#x3D;\frac{2}{14*16}$</p>
<p>由于Good-Turing 折扣法设有考虑高阶模型和低阶模型之间的关系，所以一般不单独使用，而是作为其他平滑技术的一个配套方法。</p>
<h2 id="Jelinek-Mercer-插值法"><a href="#Jelinek-Mercer-插值法" class="headerlink" title="Jelinek-Mercer 插值法"></a>Jelinek-Mercer 插值法</h2><p>Jelinek-Mercer 是一种线性插值法。为了避免出现P(W)&#x3D;0或接近于零的情况，可以用三元模型、二元模型和一元模型的相对概率做插值。最简单的线性插值如下：<br>$$<br>\hat{P}\left(w_t \mid w_{t-2} w_{t-1}\right)&#x3D;\lambda_1 P\left(w_t \mid w_{t-2} w_{t-1}\right)+\lambda_2 P\left(w_t \mid w_{t-1}\right)+\lambda_3 P\left(w_t\right)<br>$$<br>其中, $\lambda_1+\lambda_2+\lambda_3&#x3D;1$ 。</p>
<p>还有一种方法是基于上下文设置权重系数，高频的上下文通常会有高的权重系数。把语料库分为 training data held-out data 和 test data 三部分，固定好 training<br>data 的n-gram 概率，寻求以下式子的最大值：<br>$$<br>\begin{aligned}<br>\hat{P}\left(w_t \mid w_{t-2} w_{t-1}\right) &amp; &#x3D;\lambda_1\left(w_{t-2}^{t-1}\right) P\left(w_t \mid w_{t-2} w_{t-1}\right)+\lambda_2\left(w_{t-2}^{t-1}\right) P\left(w_t \mid w_{t-1}\right) \<br>&amp; +\lambda_3\left(w_{t-2}^{t-1}\right) P\left(w_t\right)<br>\end{aligned}<br>$$<br>其中, $\lambda_1\left(w_{t-2}^{t-1}\right) 、 \lambda_2\left(w_{t-2}^{t-1}\right)$ 和 $\lambda_3\left(w_{t-2}^{t-1}\right)$ 基于 held-out data 通过最大似然优化得到, 即保持 $n$-gram 概率不变, 寻求使得这批集外数据预测概率最高的权重系数。</p>
<h2 id="Kneser-Ney-插值法"><a href="#Kneser-Ney-插值法" class="headerlink" title="Kneser-Ney 插值法"></a>Kneser-Ney 插值法</h2><p>在训练数据非常少的情况下，更适合采用 Kneser-Ney 插值法。Kneser-Ney是一种非线性插值法，它以 Absolote discounting（绝对折扣）插值方法该变而来。</p>
<p>Absolute discounting 方法充分利用高阶和低阶语言模型，把高阶的概率信息分配给低阶的一元模型。例如，针对二元模型，Absolute discounting 平滑公式表示如下：<br>$$<br>P_{\mathrm{abs}}\left(w_t \mid w_{t-1}\right)&#x3D;\frac{\max \left(c\left(w_{t-1} w_t\right)-d, 0\right)}{\sum_{w^{\prime}} c\left(w_{t-1} w^{\prime}\right)}+\lambda P_{\mathrm{abs}}\left(w_t\right)<br>$$<br>其中, $c\left(w_{t-1} w^{\prime}\right)$ 表示 $w_{t-1} w^{\prime}$ 的组合次数, $w^{\prime}$ 是任意一个词, $d$ 是一个固定的折扣 值, $\lambda$ 是一个规整常量。</p>
<p>$P_{abs}(w_t)$ 是一元模型，它按单词出 现次数进行统计，这样可能会存在出现次数异常偏大现象。比如“杯子〞 出现频次较高，因此单独的“杯子” 按出现次数统计可能会比 “茶” 出现次数多，即 $P_abs(杯子)&gt;P_{abs}(茶)$ ，这样会使 Absolote discounting平滑公式因 $P_{abs}(w)$ 值过大出现“喝杯子”比“喝茶”概率高的奇怪现象。</p>
<p>Kneser-Ney 插值法对此做了改进，保留了 Absolute discounting 平滑公式的第一部分，但重写了第二部分。第二部分中的概率不是词单独出现的概率，而是与其他词组合的概率。Kneser-Ney 平滑公式如下：<br>$$<br>P_{\mathrm{KN}}\left(w_t \mid w_{t-1}\right)&#x3D;\frac{\max \left(c\left(w_{t-1} w_t\right)-d, 0\right)}{\sum_{w^{\prime}} c\left(w_{t-1} w^{\prime}\right)}+\lambda \frac{\left|\left{w_{t-1}: c\left(w_{t-1}, w_t\right)&gt;0\right}\right|}{\left|\left{w_{j-1}: c\left(w_{j-1}, w_j\right)&gt;0\right}\right|}<br>$$<br>其中, $\lambda$ 是规整的常量, $d$ 是一个固定的折扣值, $w_{j-1} w_j$ 是任意两个词的组合。第 一部分的分母可进一步表示为一元模型统计, 因此 Kneser-Ney 平滑公式还可简 化为<br>$$<br>P_{\mathrm{KN}}\left(w_t \mid w_{t-1}\right)&#x3D;\frac{\max \left(c\left(w_{t-1} w_t\right)-d, 0\right)}{c\left(w_{t-1}\right)}+\lambda \frac{\left|\left{w_{t-1}: c\left(w_{t-1}, w_t\right)&gt;0\right}\right|}{\left|\left{w_{j-1}: c\left(w_{j-1}, w_j\right)&gt;0\right}\right|}<br>$$<br>Kneser-Ney 平滑法还有一个改进版本，其分别针对一元、二元、三元和三元以上的组合，设定不同的折扣值d，这种配置会取得更佳的平滑效果。</p>
<h2 id="Katz-回退法"><a href="#Katz-回退法" class="headerlink" title="Katz 回退法"></a>Katz 回退法</h2><p>Katz 在 1987 年发表的论文中, 在 Good-Turing 折扣法的基础上, 提出了蚥 进的平滑技术，其主要贡献是回退法。</p>
<p>例如, 计算 $P\left(w_t \mid w_{t-2} w_{t-1}\right)$, 当出现的三元统计次数不是很多时, 可以采用 Good-Turing 折扣法进行平滑。当完全没有相关的三元统计时, 可以使用二元语法来估计, 如果没有相关的二元统计, 那么我们就用一元模型估计。</p>
<p>综合起来, 采用 Katz 平滑技术的概率估计公式如下:<br>$$<br>P\left(w_t \mid w_{t-2} w_{t-1}\right)&#x3D;\left{\begin{array}{cl}<br>\frac{C\left(w_{t-2} w_{t-1} w_t\right)}{C\left(w_{t-2} w_{t-1}\right)}, &amp; \text { 当 } C&gt;C^{\prime} \text { 时 } \<br>d \frac{C\left(w_{t-2} w_{t-1} w_t\right)}{C\left(w_{t-2} w_{t-1}\right)}, &amp; \text { 当 } 0&lt;C&lt;C^{\prime} \text { 时 } \<br>\text { backoff }\left(w_{t-2} w_{t-1}\right) P\left(w_t \mid w_{t-1}\right) &amp;<br>\end{array}\right.<br>$$<br>其中, $C$ 是 $C\left(w_{t-2} w_{t-1} w_t\right)$ 的简写, 表示三个词同时出现的次数。 $C^{\prime}$ 是一个计数囯 值, 当 $C&gt;C^{\prime}$ 时, 直接采用最大似然法估计概率; 当 $0&lt;C&lt;C^{\prime}$ 时, 则采用 Good-Turing 折扣法。 $d$ 是折扣系数。backoff $\left(w_{t-2} w_{t-1}\right)$ 是回退权重, 计算回退权 重, 是先采用折扣法计算低阶统计概率, 然后得到<br>$$<br>\text { backoff }\left(w_{t-2} w_{t-1}\right)&#x3D;\frac{1-\sum P\left(w \mid w_{t-2} w_{t-1}\right)}{\sum P\left(w^{\prime} \mid w_{t-1}\right)}&#x3D;\frac{1-\sum P\left(w \mid w_{t-2} w_{t-1}\right)}{1-\sum P\left(w \mid w_{t-1}\right)}<br>$$<br>其中, $w$ 是在训练语料中 $w_{t-2} w_{t-1}$ 之后出现的词, $w^{\prime}$ 是在训练语料中 $w_{t-2} w_{t-1}$ 之后 末出现的词。</p>
<p>采用 Katz 回退法, 训练好的语宆模型格式如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\data</span><br><span class="line">ngram 1=n1 # 一元语言模型</span><br><span class="line">ngram 2=n2二元语言模型 </span><br><span class="line">ngram 3=n3三元语言模型</span><br><span class="line"></span><br><span class="line">\1-grams :</span><br><span class="line">pro_1 wordl back_pro1</span><br><span class="line"></span><br><span class="line">\2-grams :</span><br><span class="line">pro_2 word1 word2 back_pro2</span><br><span class="line"></span><br><span class="line">\3-grams:</span><br><span class="line">pro_3 word1 word2 word3</span><br><span class="line"></span><br><span class="line">\end \</span><br></pre></td></tr></table></figure>



<p>其中, pro_1 是一元模型 (1-grams) 单词的对数概率, pro_2 是二元模型 (2-grams 的对数概率, pro_3 是三元模型 (3-grams) 的对数概率。一元模型和二元模型后面分别带有回退权重 back_pro1 和 back_pro2。</p>
<p>如果要得到三个词出现的概率 $P$ (word3&#x2F;word1,word2), 则根据以上语言模型, 其计算过程如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (存在 (word1, word2, word3) 的三元模型) &#123; </span><br><span class="line">	return pro_ 3 (word1, word2, word3) ;</span><br><span class="line">&#125;else if (存在 (word1, word2) 二元模型) &#123;</span><br><span class="line">	return back_pro2 (word1, word2) *P (word3 / word2) ; </span><br><span class="line">&#125;else&#123;</span><br><span class="line">	return P(word3 | word2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (存在 (word1, word2) 的二元模型) &#123;</span><br><span class="line">	return pro_ 2 (word1, word2);</span><br><span class="line">&#125;else&#123;</span><br><span class="line">	return back_pro2(word1)*pro_1 (word2) :</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>如果不存在(word 1,word 2 ,word 3 )的三元模型, 则采用回退法, 即结合回退权 重 back_pro2(word1,word2) 来计算: back_pro2(word1,word2) $* P($ word3&#x2F;word2)。如 “拨打 郑州 局” 这样的组合, 如果语料库中没有，即没有相应的三元模型, 则 查找 “拨打 郑州” 和 “郑州 局” 的组合概率和回退概率。注意, 概率均为对数 概率，假设值如下：</p>
<p>$-3.220352$ 拨打 郑州 $-0.4072262$</p>
<p>$-3.012735$ 郑州 局 $-0.3083073$</p>
<p>则 $P($ “拨打 郑州 局” $)&#x3D;P($ “局 | 拨打 郑州” $)&#x3D;$ back_pro2(拨打,郑州)*P(局 郑州 $)&#x3D;\ln \left(\mathrm{e}^{-0.4072262 *} \mathrm{e}^{-3.012735}\right)&#x3D;-3.4199612$ 。</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>《语音识别原理与应用》</tag>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>筛选文本论文笔记（一）筛选文本来训练领域LM</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E7%AD%9B%E9%80%89%E6%96%87%E6%9C%AC%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="筛选文本-来训练领域LM"><a href="#筛选文本-来训练领域LM" class="headerlink" title="筛选文本 来训练领域LM"></a>筛选文本 来训练领域LM</h1><blockquote>
<p>&#x3D;&#x3D;Moore, Robert C., and William Lewis. “Intelligent selection of language model training data.” <em>Proceedings of the ACL 2010 conference short papers</em>. 2010.&#x3D;&#x3D;citations：588</p>
</blockquote>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>输出质量总是可以通过使用更多的语言模型训练数据来提高，这似乎是一个普遍的真理，但前提是训练数据与期望的输出相当匹配。</p>
<p>结合领域数据和其他数据构建LM的常规方法：</p>
<p>1）领域数据和其他数据结合训练LM；</p>
<p>2）基于领域数据和其他数据的ngram count来结合（加权这个count）；</p>
<p>2）领域LM和其他LM做权重的combine，（线性或log线性的）插值LM概率；</p>
<p>机器翻译的模型的训练数据的常规做法是用尽可能多的数据，并依赖于特征权重优化来降低与翻译应用程序匹配较差的数据的影响。</p>
<p>本文从数据入手，挑出领域的数据。</p>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>主要方法是利用交叉熵原理，已有一个语料的文本分布，我们通过交叉熵去找跟这个语料的文本分布相近的文本，从而找到匹配的文本语料。</p>
<p>前提假设：有足够多的领域数据来训练领域语言模型，用该模型来帮助对来自其他数据源的文本片段进行打分，并基于对域内数据进行优化的打分临界值score cutoff来选择文本片段，based on a score cutoff optimized on held-out in-domain data.  </p>
<p>基于困惑度阈值的文本选择等价于基于交叉熵阈值的文本选择（困惑度和交叉熵是单调相关的）；LM记为M，文本片段记为s，困惑度为 $\large b^{H_M(s)}$，其中 $H_M(s)$ 是交叉熵，b是bits或nats的单位，比如10、e；</p>
<ul>
<li>打分原则：$H_I(s) - H_N(s)$</li>
</ul>
<p>其中 ：$H_I(s)$：领域数据集I训练的模型I，对文本片段s的交叉熵  ；$H_N(s)$：领域外文本集N训练的模型N，对文本片段s的交叉熵 （s是领域外文本集N的一个片段）</p>
<p>差值作为分数，把分数小于阈值的挑出来，作为领域数据；</p>
<p>其中，$H_I(s)&#x3D;-\frac{logP_I(s)}{S}$ ，S是文本s长度</p>
<p>$\large log_{10}ppl&#x3D;交叉熵&#x3D;H(s)$</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>语言模型经验</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%BB%8F%E9%AA%8C/</url>
    <content><![CDATA[<h1 id="语言模型经验"><a href="#语言模型经验" class="headerlink" title="语言模型经验"></a>语言模型经验</h1><blockquote>
<p><a href="https://cloud.tencent.com/developer/article/1116533">https://cloud.tencent.com/developer/article/1116533</a></p>
</blockquote>
<p>我们首先使用 n-gram LM 生成了词网格（word lattices），而我们最好的声学模型由 ResNet 和两个 LSTM 组成。然后我们使用 model-M 对该词网络进行了重新评分并从这些被重新评分的网格中生成了 n 最佳列表。最后，我们应用了这四种基于 LSTM 的 LM 和基于卷积的 LM。注意其 LM 概率是被线性地内插（interpolated）进去的，且所有 LM 的插值权重（interpolation weights）都使用了 heldout 数据进行估计。</p>
<p>先用ngram LM生成lattice，然后用NN rescore</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>语言模型论文笔记（一）语言模型 自回归</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="语言模型-自回归"><a href="#语言模型-自回归" class="headerlink" title="语言模型 自回归"></a>语言模型 自回归</h1><blockquote>
<p><a href="https://github.com/DengBoCong/nlp-paper">https://github.com/DengBoCong/nlp-paper</a></p>
<p><a href="https://github.com/infinitylogesh/mutate">https://github.com/infinitylogesh/mutate</a></p>
</blockquote>
<blockquote>
<p>&#x3D;&#x3D;Sarzynska-Wawer, Justyna, et al. “Detecting formal thought disorder by deep contextualized word representations.” <em>Psychiatry Research</em> 304 (2021): 114135.&#x3D;&#x3D; citations：10182</p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/102091595">Deep contextualized word representations [文献阅读笔记]</a></p>
<p><a href="https://sh-tsang.medium.com/review-elmo-deep-contextualized-word-representations-8eb1e58cd25c">https://sh-tsang.medium.com/review-elmo-deep-contextualized-word-representations-8eb1e58cd25c</a></p>
</blockquote>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>提出一种新的深度上下文词表示（word embedding），能够建模</p>
<ol>
<li>复杂的语意和语法信息。(比如 句法和语义)  ；</li>
<li>同样的词在不同的语境中含义差距比较大， 所谓一词多义的情况。</li>
</ol>
</li>
<li><p>提出 <strong>ELMo (Embeddings from Language Models)</strong> 表示，它并不是学习上下文词向量的方法，而是学习一个网络（biLM）函数，使用bidirectional LSTM 使用包含上下文的整个句子作为语句进行训练和建模；</p>
</li>
<li><p>其高level隐层节点捕捉上下文相关的词义（可以用在语义消歧任务，直接用这部分特征），低level隐层节点捕捉语法的各个方面进行建模（可以用在词性标记）；</p>
<p>我的理解是低level特征更容易捕捉输入的很小范围之间的不同之处，高level特征更容易捕捉上下文，较大范围之间的不同之处（小范围内的不敏感了）</p>
</li>
<li><p>模型特点：（1）深度很深（2）每一层学到的信息可以进行线性组合来适用于不同的下游任务。</p>
</li>
<li><p>效果：下游任务为nlp的六个任务，都是SOTA；</p>
</li>
<li><p>ELMo 中 biLM 不同层输出可根据不同的下游任务进行组合。 比如说对于输入序列中的一个词，使用L层的biLM模型映射后就得到一组2L+1种的映射组合：</p>
<p>$\begin{aligned} R_k &amp;&#x3D;\left{\mathbf{x}<em>k^{L M}, \overrightarrow{\mathbf{h}}</em>{k, j}^{L M}, \overleftarrow{\mathbf{h}} \frac{L M}{k, j} \mid j&#x3D;1, \ldots, L\right} \ &amp;&#x3D;\left{\mathbf{h}_{k, j}^{L M} \mid j&#x3D;0, \ldots, L\right} \end{aligned}$</p>
</li>
<li><p>表达式为：其中j是不同layer，k是不同token position，s是softmax-normalized weights ，$\gamma$是缩放参数；每层后接layer norm；</p>
<p>$\mathbf{E} \mathbf{L M} \mathbf{o}<em>k^{\text {task }}&#x3D;E\left(R_k ; \Theta^{\text {task }}\right)&#x3D;\gamma^{\text {task }} \sum</em>{j&#x3D;0}^L s_j^{\text {task }} \mathbf{h}_{k, j}^{L M}$</p>
</li>
<li><p>ELMo 的预训练模型结构基本就是一个两层的biLSTM, 每一层包含4096个unit， 每个词会被映射为512维的向量。 特殊的点是在一层和二层之间增加了残差连接。 一旦预训练模型训练好后就可以直接计算词向量用于下游任务，或者进行 fine-tuned用于下游任务。</p>
</li>
<li><p>训练ELMo就也可以当语言模型来训练，拿它的输出来用做语言模型也是可以的；</p>
</li>
</ul>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><ul>
<li>双向biLSTM，使用独立训练的从左到右和从右到左lm的浅级联</li>
<li>目标函数：分别以$\large P(w_i|w_1,…,w_{i-1})$ 和 $\large P(w_i|w_{i+1},…,w_n)$ 作为目标函数，独立训练两个representation然后拼接</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Howard, Jeremy, and Sebastian Ruder. “Universal language model fine-tuning for text classification.” <em>arXiv preprint arXiv:1801.06146</em> (2018).&#x3D;&#x3D; citations：2702</p>
<p>开源预训练模型和代码：<a href="http://nlp.fast.ai/ulmfit">http://nlp.fast.ai/ulmfit</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/42618178">NLP之语言模型和迁移学习</a></p>
</blockquote>
<h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>提出一种通用的语言模型，微调语言模型来适应下游任务，称为 <strong>Universal Language Model Fine-tuning (ULMFiT)</strong>  ，一种有效的迁移学习方法；</p>
</li>
<li><p>提出保留以前的知识，避免在微调时遗忘原本知识的方法：称为 区分式微调、斜的三角学习率、逐渐冻结。。？discriminative fine-tuning，slanted triangular learning rates, and gradual unfreezing</p>
</li>
<li><p>相关工作：</p>
<ul>
<li>CV领域里的迁移学习：近几年finetune的一种方法是微调预训练模型的最后一&#x2F;几层，前面层参数不变，来达到下游任务目的；</li>
<li>NLP领域里的迁移学习：预训练模型通过其他任务捕获额外上下文的embedding。然后，不同层次的embedding被用作特征，与单词embedding或中间层的输入连接，来达到下游任务目的；该方法称为 <strong>hypercolumns</strong>  </li>
<li>Multi-task learning ：语言模型作为目标函数之一，和主任务一起联合训练，多任务学习 ；但是MTL每次都要求从头开始训练任务，这使得它效率低下，并且经常需要仔细权衡任务特定的目标函数；</li>
<li>Fine-tuning  ：在语言模型上进行微调，但是如果微调训练数据少，容易过拟合，数据量大，又不容易有那么多数据；</li>
</ul>
</li>
<li><p>ULMFiT：分为三个步骤：</p>
<ol>
<li>预训练通用领域的LM；</li>
<li>target task LM fine-tuning；（该步骤运用的trick：Discriminative fine-tuning、Slanted triangular learning rates）</li>
<li>target task下游任务fine-tuning；只更新后接层的参数，前面层参数冻结；（该步骤运用的trick：Discriminative fine-tuning、Slanted triangular learning rates、gradual unfreezing）</li>
</ol>
</li>
</ul>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220615151145845-16368823432881.png" alt="image-20220615151145845" style="zoom: 67%;">

<ul>
<li><p>文章提出了一些finetune种的训练方法（trick）：</p>
<ul>
<li><p><strong>Discriminative fine-tuning</strong>：（不是鉴别性训练），因为不同层提取的特征不同，所以给不同层不同的学习率是比较合适的；经验：finetune时最后一层学习率$\gamma$，其他层学习率$\gamma&#x2F;2.6$，（其他层学习率小一点，最后一层学习率大一点）；</p>
</li>
<li><p><strong>Slanted triangular learning rates</strong>  ：因为希望模型尽快收敛，所以修改不同迭代数时的学习率，先增后减；（这个和我之前的想法一样啊，我也觉得finetune需要先增加学习率，训练得比较好，再减小学习率）</p>
<p>学习率的表示为：T为迭代数，经验：cut_frac &#x3D; 0.1, ratio &#x3D; 32 ，ηmax &#x3D; 0.01；</p>
<p>和 aggressive cosine annealing 的学习率策略 有点像</p>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220615155537958-16368823432892.png" alt="image-20220615155537958" style="zoom:80%;">

<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220615155458044-16368823432893.png" alt="image-20220615155458044" style="zoom:80%;">
</li>
<li><p><strong>Gradual unfreezing</strong> ：应用于下游任务，因为怕遗忘之前LM的能力，因此从最后一层开始更新模型参数，逐渐往前面层更新，这是基于最后一层学到的知识最少的假设；逐渐解冻；这类似于chain-thaw (Felbo et al., 2017)</p>
</li>
<li><p><strong>BPTT for Text Classification (BPT3C)</strong>   ：为了在large documents上进行模型精调，作者将文档分为固定长度为b的batches，并在每个batch训练时记录mean和max池化，梯度会被反向传播到对最终预测有贡献的batches。(Merity et al., 2017a)；【？？】</p>
</li>
</ul>
</li>
<li><p>本文的下游任务是文本分类任务，因此第三步是在第二步的LM后接一个分类linear层，因为输入给线性层是多个词，因此取最后一个输出特征，和maxpooling和meanpooling的输出特征，concat作为总的特征，再接一个linear输出：</p>
<p>$\mathbf{h}_c&#x3D;\left[\mathbf{h}_T, \operatorname{maxpool}(\mathbf{H})\right., \operatorname{meanpool} \left.(\mathbf{H})\right]$</p>
</li>
</ul>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><ul>
<li>用预训练语言模型AWD-LSTM  (Merity et al.,2017a)</li>
</ul>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点</strong>：</p>
<p>对比其他迁移学习方法（ELMo）更适合以下任务：</p>
<ul>
<li><p>非英语语言，有标签训练数据很少</p>
</li>
<li><p>没有state-of-the-art模型的新NLP任务</p>
</li>
<li><p>只有部分有标签数据的任务</p>
</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>对于分类和序列标注任务比较容易迁移，对于复杂任务（问答等）需要新的精调方法。</li>
<li>模型用的LSTM，对于长距离的输入捕捉不好；</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Radford, Alec, et al. “Improving language understanding by generative pre-training.” (2018).&#x3D;&#x3D;citations：3533 OpenAI</p>
</blockquote>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul>
<li>无标注数据多，过去研究发现即使在有相当多的监督可用的情况下，以无监督的方式学习良好的表示也可以提供显著的性能提升（代表研究：词向量）。</li>
<li>利用无标注文本有两个挑战：<ol>
<li>目前还不清楚哪种优化目标，在学习对迁移有用的文本表示时，最有效；可能是语言模型，也可能是机器翻译等等（来自<a href="https://gluebenchmark.com/leaderboard">https://gluebenchmark.com/leaderboard</a>  ）</li>
<li>对于如何最有效地将这些学习到的表征迁移到目标任务上，目前还没有达成共识。（现有的方案有：对模型进行target任务的更改；使用复杂的学习方案；添加辅助学习目标）</li>
</ol>
</li>
</ul>
<h3 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出Generative Pre-Training (GPT)，通过对不同corpus上的无标注文本训练生成式预训练语言模型，该语言模型能提高下游任务模型能力；</li>
<li>微调中使用task-aware input transformations ，实现对模型最小的改动下，得到最佳的迁移效果；</li>
<li>探索了一种半监督语言理解任务的方法，使用无监督的预训练和有监督的微调相结合。</li>
<li>目标是学习一种通用的表示法，这种表示法几乎不需要适应广泛的任务，就能迁移？</li>
<li>target task的corpus和预训练的unlabeled的corpus不在一个领域，也可以，比如英文的预训练模型，中文的LM任务；</li>
<li><strong>Semi-supervised learning for NLP</strong> NLP中的半监督学习 ：一般是用无标注文本学习word embedding；词级别</li>
<li><strong>Unsupervised pre-training</strong>  ：其目标是找到一个好的初始化点，而不是修改监督学习目标，作为后续任务的初始模型；预训练作用类似正则化，使模型有更好的泛化性；</li>
<li><strong>Auxiliary training objectives</strong>  ：添加辅助无监督训练目标是半监督学习的另一种形式；</li>
</ul>
<h3 id="框架方法"><a href="#框架方法" class="headerlink" title="框架方法"></a>框架方法</h3><ul>
<li>采用了两个步骤：1. 用无标注文本训练一个预训练LM（Unsupervised pre-training ）；2. 用有监督数据将预训练模型迁移到下游任务中（Supervised  fine-tuning）；</li>
<li>迁移过程，用task-specific input adaptations derived from traversal-style approaches  ？？</li>
<li><strong>Unsupervised pre-training  ：</strong>语言模型loss function为路径概率，为在前k个token发生时当前token发生的概率的乘积；</li>
</ul>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220615194546564-16368823432894.png" alt="image-20220615194546564" style="zoom:80%;">

<ul>
<li><strong>Supervised fine-tuning</strong>  ：</li>
</ul>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220615195255249-16368823432895.png" alt="image-20220615195255249" style="zoom:80%;">

<p>​	将语言建模作为微调的辅助目标有助于(a)改进监督模型的泛化，(b)加快收敛速度。</p>
<h3 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h3><ul>
<li>transformer</li>
</ul>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/image-20220615195439608-16368823432896.png" alt="image-20220615195439608" style="zoom:80%;">

<h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点</strong>：</p>
<ol>
<li>循环神经网络所捕捉到的信息较少，而Transformer可以捕捉到更长范围的信息。</li>
<li>计算速度比循环神经网络更快，易于并行化</li>
<li>实验结果显示Transformer的效果比ELMo和LSTM网络更好</li>
</ol>
<p><strong>缺点</strong>：</p>
<p>对于某些类型的任务需要对输入数据的结构作调整</p>
<h3 id="适用任务"><a href="#适用任务" class="headerlink" title="适用任务"></a>适用任务</h3><ul>
<li>Natural Language Inference</li>
<li>Question Answering and commonsense reasoning</li>
<li>Classification</li>
<li>Semantic Similarity</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Radford, Alec, et al. “Language models are unsupervised multitask learners.” <em>OpenAI blog</em> 1.8 (2019): 9.&#x3D;&#x3D;citations：3193</p>
<p><a href="https://zhpmatrix.github.io/2019/02/16/transformer-multi-task/">https://zhpmatrix.github.io/2019/02/16/transformer-multi-task/</a></p>
</blockquote>
<h3 id="思路-3"><a href="#思路-3" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出GPT2.0</li>
</ul>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Chronopoulou, Alexandra, Christos Baziotis, and Alexandros Potamianos. “An embarrassingly simple approach for transfer learning from pretrained language models.” <em>arXiv preprint arXiv:1902.10547</em> (2019).&#x3D;&#x3D;citations：88</p>
<p>github：<a href="https://github.com/alexandra-chron/siatl">https://github.com/alexandra-chron/siatl</a></p>
</blockquote>
<blockquote>
<p>Larger-Scale Transformers for Multilingual Masked Language Modeling</p>
</blockquote>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>语言模型论文笔记（二）语言模型 自编码</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="语言模型-自编码"><a href="#语言模型-自编码" class="headerlink" title="语言模型 自编码"></a>语言模型 自编码</h1><blockquote>
<p>&#x3D;&#x3D;Devlin, Jacob, et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” <em>arXiv preprint arXiv:1810.04805</em> (2018).&#x3D;&#x3D;citations：41870！</p>
<p>code、pre-trained model ：github：<a href="https://github.com/google-research/bert">https://github.com/google-research/bert</a>  </p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/46652512">【NLP】Google BERT模型原理详解</a></p>
</blockquote>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul>
<li><strong>Unsupervised Feature-based Approaches</strong>  ：无标注文本训一个模型，用word embedding给下游任务</li>
<li><strong>Unsupervised Fine-tuning Approaches</strong>  ：无标注文本训一个模型，加下游任务层，或者只把下游任务的一部分用无标注文本训练</li>
</ul>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul>
<li><p>提出新的<strong>语言表示模型</strong>，称为Bidirectional Encoder Representations from Transformers  （BERT），通过联合从左和从后的所有layer的上下文，预训练deep、双向的语言表示，训练文本来自未标注文本；得到预训练语言表示，后接输出层，就可以适合很多下游任务；</p>
</li>
<li><p>BERT是一种基于微调的表示模型，finetuning based representation model  ，适合sentence-level 和token-level的下游任务；</p>
</li>
<li><p>ELMo、ULMFiT、GPT称为“单向的”语言模型，因为一般是从左往后单向的，不然就是双向biLSTM，使用独立训练的从左到右和从右到左lm的浅级联，deep bidirectional representations  其实学的并不好，因此叫单向；</p>
</li>
<li><p>BERT的“双向”，体现在用的attention结构，因此能看见上下文；</p>
</li>
</ul>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ul>
<li>masked language model” (MLM) pre-training objective ，masked LM从输入中随机屏蔽一些token，目标是只基于上下文的词，预测屏蔽的原始词汇表id；这种和之前ELMo、ULMFiT、GPT就不太一样，能够很好的学习deep bidirectional representations；</li>
<li>目标函数：$\large P(w_i|w_1,…,w_{i-1},w_{i+1},…,w_n)$</li>
</ul>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220616094327833.png" alt="image-20220616094327833" style="zoom:80%;">

<ul>
<li>input由三个特征embedding求和组成，分别是<ul>
<li>token embedding：第一个单词是CLS标志，可以用于之后的分类任务</li>
<li>position embedding</li>
<li>segment embedding：代表是不是属于同一段segment的信息特征，用来区别两种句子，因为预训练不光做LM还要做以两个句子为输入的分类任务</li>
</ul>
</li>
</ul>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/image-20220616102940478.png" alt="image-20220616102940478" style="zoom:80%;">

<ul>
<li><p><strong>“masked LM” (MLM)</strong>  ：随机屏蔽输入token的一部分，然后只预测那些被屏蔽的token；经验：每句话15%masked；</p>
<p>一开始的masked做法：输入15%的单词变成[MASK]这个token，然后目标是**[MASK]token位置对应的输出概率为真实token要交叉熵最大** We only compute loss on masked tokens；</p>
<p>后来的masked做法：输出的15%的单词不是全变成[MASK]这个token，而是80%可能性变成[MASK]，10%可能性变成随机token，10%可能性不变；</p>
</li>
<li><p><strong>Next Sentence Prediction (NSP)</strong>  ：训练预训练模型中，给输出又引入说一个任务（多任务？），叫做是不是”下一句话“的判断，输出二分类，判断是不是下一句话？这对于微调任务比如QA和NLI很有用，如果不是这些微调任务，预训练模型训练不需要这个C向量；</p>
</li>
<li><p><strong>Pre-training data</strong>  ：要用document-level corpus ，而不要用sentence-level的corpus，训练LM的文本一定要长，这样才能具备抽取长序列知识的能力；</p>
</li>
<li><p><strong>Fine-tuning BERT</strong>  ：？？？【TODO】</p>
</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>multi-layer bidirectional Transformer  encoder  ，transformer decoder （用tensor2tensor库）</p>
<p>词典：wordpiece后的30000个token</p>
<hr>
<blockquote>
<p>&#x3D;&#x3D;Song, Kaitao, et al. “Mass: Masked sequence to sequence pre-training for language generation.” <em>arXiv preprint arXiv:1905.02450</em> (2019).&#x3D;&#x3D;citations：660</p>
<p>github：<a href="https://github.com/microsoft/MASS">https://github.com/microsoft/MASS</a>  </p>
</blockquote>
<h3 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h3><ul>
<li>和bert一样的预训练模型，Pre-training and fine-tuning 方式训练</li>
</ul>
<h3 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出 MAsked Sequence to Sequence pre-training (MASS)  ，用于基于encoder-decoder的language generation</li>
</ul>
<h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><h3 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h3><hr>
<blockquote>
<p>&#x3D;&#x3D;Lan, Zhenzhong, et al. “Albert: A lite bert for self-supervised learning of language representations.” <em>arXiv preprint arXiv:1909.11942</em> (2019).&#x3D;&#x3D;citations：3054 Google Research</p>
<p>github：<a href="https://github.com/google-research/ALBERT">https://github.com/google-research/ALBERT</a>  </p>
</blockquote>
<h3 id="背景-2"><a href="#背景-2" class="headerlink" title="背景"></a>背景</h3><ul>
<li>虽然预训练模型能改善下游任务性能，但是由于预训练模型较大，也会造成计算量、内存、延时增加，为了解决该预训练模型带来的问题，本文提出两种更小内存消耗的方法，并且能减小训练BERT的速度；</li>
</ul>
<h3 id="思路-2"><a href="#思路-2" class="headerlink" title="思路"></a>思路</h3><ul>
<li>提出 A lite bert 轻量级的BERT，自监督学习，语言表示</li>
<li>用关注于建模句间相关性的自监督loss，改善了下游任务的输入是多句输入的任务性能；</li>
</ul>
<h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h3><ul>
<li>SCALING UP REPRESENTATION LEARNING FOR NATURAL LANGUAGE  对于自然语言的scaling up表示学习</li>
<li>CROSS-LAYER PARAMETER SHARING  </li>
<li>SENTENCE ORDERING OBJECTIVES</li>
</ul>
<hr>
<blockquote>
<p>DistilBERT</p>
<p><a href="https://medium.com/huggingface/distilbert-8cf3380435b5">Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT</a></p>
</blockquote>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练模型数据</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="预训练数据集"><a href="#预训练数据集" class="headerlink" title="预训练数据集"></a>预训练数据集</h1><blockquote>
<p>官网地址：<a href="https://www.cluebenchmarks.com/">https://www.cluebenchmarks.com/</a></p>
<p>数据地址：<a href="https://github.com/CLUEbenchmark/CLUE">https://github.com/CLUEbenchmark/CLUE</a></p>
</blockquote>
<p>100GB原始语料库的大规模预训练数据集 </p>
<p>CLUE官方总共收集了214 GB的原始语料库，大约760亿个单词，包含三个部分，CLUECorpus2020-small，CLUECorpus2020和CLUEOSCAR。 </p>
<p>CLUECorpus2020-small包含14 GB的中文语料库，包括四个子部分：新闻，网页文本，维基百科和评论。 CLUECorpus2020包含100 GB的中文原始语料库，该语料库可从Common Crawl中检索。这个数据集可以直接用于预训练，而无需其他预处理，包含约2万9千个单独的文件，每个文件都处理成了预训练格式。</p>
<p> CLUEOSCAR是一个庞大的多语种语料库，它是通过Common Crawl语料库的语言分类过滤得到的，包含250 GB的中文原始语料库，做进一步的处理后，最终得到100 GB的中文数据。</p>
<p> 这部分数据可以用于LM的训练。</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练模型汇总</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<h1 id="模型汇总"><a href="#模型汇总" class="headerlink" title="模型汇总"></a>模型汇总</h1><h2 id="huggingface-transformers-抱抱脸"><a href="#huggingface-transformers-抱抱脸" class="headerlink" title="huggingface transformers 抱抱脸"></a>huggingface transformers 抱抱脸</h2><blockquote>
<p><a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
<p><a href="https://huggingface.co/models">https://huggingface.co/models</a></p>
</blockquote>
<p>transformer大全</p>
<p>找了几个模型比较小的：</p>
<p><a href="https://huggingface.co/uer/albert-base-chinese-cluecorpussmall">albert-base-chinese-cluecorpussmall</a> </p>
<p><a href="https://huggingface.co/voidful/albert_chinese_small">albert_chinese_small</a> </p>
<p><a href="https://huggingface.co/albert-base-v2">albert-base-v2</a> </p>
<p><a href="https://huggingface.co/voidful/albert_chinese_tiny">albert_chinese_tiny</a></p>
<p><a href="https://huggingface.co/clue/albert_chinese_tiny">albert_chinese_tiny</a></p>
<p><a href="https://huggingface.co/ckiplab/albert-tiny-chinese"> albert-tiny-chinese</a> </p>
<p><a href="https://huggingface.co/voidful/albert_chinese_base">albert_chinese_base</a></p>
<p>可以参考中文拼写纠错模型的任务</p>
<h2 id="Awesome-Pretrained-Chinese-NLP-Models"><a href="#Awesome-Pretrained-Chinese-NLP-Models" class="headerlink" title="Awesome Pretrained Chinese NLP Models"></a>Awesome Pretrained Chinese NLP Models</h2><blockquote>
<p><a href="https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models">https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models</a></p>
</blockquote>
<p>一个多个模型的汇总项目，挺全的</p>
<h2 id="Chinese-Transformer-XL"><a href="#Chinese-Transformer-XL" class="headerlink" title="Chinese-Transformer-XL"></a>Chinese-Transformer-XL</h2><blockquote>
<p><a href="https://github.com/THUDM/Chinese-Transformer-XL">https://github.com/THUDM/Chinese-Transformer-XL</a></p>
</blockquote>
<p>智源研究院”文汇” 预训练模型Chinese-Transformer-XL的预训练和文本生成代码</p>
<p>本模型使用了智源研究院发布的中文预训练语料<a href="https://data.baai.ac.cn/data-set-details/0c8dc71dd06ae75a10ca422fb49b0751">WuDaoCorpus</a> 。具体地，我们使用了WuDaoCorpus中来自百度百科+搜狗百科（133G）、知乎（131G）、百度知道（38G）的语料，一共303GB数据。</p>
<p>本模型使用了<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> 的训练目标，同时使用能够更好地处理长序列建模的<a href="https://arxiv.org/abs/1901.02860">Transformer-XL</a> 替代了GPT中的Transformer。模型的结构与GPT-3 2.7B（32层，隐表示维度2560，每层32个注意力头）基本相同，因为Transformer-XL的结构改动，模型参数增加到了29亿。</p>
<p>预训练模型大小：5.3G</p>
<h2 id="GPT2-for-Multiple-Languages"><a href="#GPT2-for-Multiple-Languages" class="headerlink" title="GPT2 for Multiple Languages"></a><strong>GPT2</strong> for Multiple Languages</h2><blockquote>
<p><a href="https://github.com/imcaspar/gpt2-ml">https://github.com/imcaspar/gpt2-ml</a></p>
</blockquote>
<p>训练数据15G</p>
<p>预训练模型大小：15亿参数量（5G大小）</p>
<h2 id="albert-zh"><a href="#albert-zh" class="headerlink" title="albert_zh"></a>albert_zh</h2><blockquote>
<p><a href="https://github.com/brightmart/albert_zh">https://github.com/brightmart/albert_zh</a></p>
</blockquote>
<p>tf版本</p>
<p>预训练模型大小：4M参数量</p>
<h2 id="albert-pytorch"><a href="#albert-pytorch" class="headerlink" title="albert_pytorch"></a>albert_pytorch</h2><blockquote>
<p><a href="https://github.com/lonePatient/albert_pytorch">https://github.com/lonePatient/albert_pytorch</a></p>
</blockquote>
<p>pytorch版本</p>
<h2 id="OpenCLaP：多领域开源中文预训练语言模型仓库"><a href="#OpenCLaP：多领域开源中文预训练语言模型仓库" class="headerlink" title="OpenCLaP：多领域开源中文预训练语言模型仓库"></a>OpenCLaP：多领域开源中文预训练语言模型仓库</h2><blockquote>
<p><a href="https://github.com/thunlp/OpenCLaP">https://github.com/thunlp/OpenCLaP</a></p>
</blockquote>
<p>数据来源法律文本和百度百科</p>
<p>Bert模型大小370MB</p>
<h2 id="好未来开源教育领域首个在线教学中文预训练模型TAL-EduBERT"><a href="#好未来开源教育领域首个在线教学中文预训练模型TAL-EduBERT" class="headerlink" title="好未来开源教育领域首个在线教学中文预训练模型TAL-EduBERT"></a>好未来开源教育领域首个在线教学中文预训练模型TAL-EduBERT</h2><blockquote>
<p><a href="https://github.com/tal-tech/edu-bert">https://github.com/tal-tech/edu-bert</a></p>
</blockquote>
<p>数据2000万条（约包含3.8亿Tokens）教育领域中文ASR文本数据</p>
<p>BERT 预训练模型大小：400M</p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>预训练语言模型</title>
    <url>/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="预训练语言模型"><a href="#预训练语言模型" class="headerlink" title="预训练语言模型"></a>预训练语言模型</h1><h2 id="开源预训练语言模型合集"><a href="#开源预训练语言模型合集" class="headerlink" title="开源预训练语言模型合集"></a>开源预训练语言模型合集</h2><blockquote>
<p>github：<a href="https://github.com/ZhuiyiTechnology/pretrained-models">https://github.com/ZhuiyiTechnology/pretrained-models</a></p>
<p>[好] github：<a href="https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models">https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models</a></p>
<p>github：<a href="https://github.com/ymcui/Chinese-BERT-wwm">https://github.com/ymcui/Chinese-BERT-wwm</a></p>
<p><a href="https://huggingface.co/docs/transformers/index">https://huggingface.co/docs/transformers/index</a></p>
<p>github：<a href="https://github.com/thunlp/OpenCLaP">OpenCLaP：多领域开源中文预训练语言模型仓库</a></p>
<p>github：<a href="https://github.com/BrikerMan/Kashgari">https://github.com/BrikerMan/Kashgari</a></p>
<p>github：<a href="https://github.com/fighting41love/funNLP">https://github.com/fighting41love/funNLP</a></p>
<p>github：<a href="https://github.com/ymcui/Chinese-XLNet">https://github.com/ymcui/Chinese-XLNet</a>    <a href="https://cloud.tencent.com/developer/article/1865707">https://cloud.tencent.com/developer/article/1865707</a></p>
<p>github：好未来：<a href="https://github.com/tal-tech/edu-bert">https://github.com/tal-tech/edu-bert</a></p>
<p><a href="https://www.oschina.net/p/chinese-bert">https://www.oschina.net/p/chinese-bert</a></p>
<p><a href="https://lonepatient.top/archives/">https://lonepatient.top/archives/</a></p>
<p><a href="https://github.com/imcaspar/gpt2-ml">https://github.com/imcaspar/gpt2-ml</a></p>
<p><a href="https://github.com/google-research/bert">https://github.com/google-research/bert</a></p>
</blockquote>
<h2 id="预训练语言模型-1"><a href="#预训练语言模型-1" class="headerlink" title="预训练语言模型"></a>预训练语言模型</h2><blockquote>
<p>知乎：<a href="https://zhuanlan.zhihu.com/p/76912493">nlp中的预训练语言模型总结(单向模型、BERT系列模型、XLNet)</a>  、 <a href="https://zhuanlan.zhihu.com/p/115014536">NLP算法面试必备！PTMs：NLP预训练模型的全面总结</a></p>
</blockquote>
<h3 id="预训练语言模型解释："><a href="#预训练语言模型解释：" class="headerlink" title="预训练语言模型解释："></a>预训练语言模型解释：</h3><p>预训练语言模型已经形成了一种新的 NLP 范式: 使用大规模文本语料库进行预训练，对特定任务的小数据集微调，降低单个 NLP 任务的难度。</p>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/v2-d8fd47547f5a8230372ceaa894e52feb_r.jpg" alt="preview" style="zoom:50%;">

<p>预训练思想的本质是模型参数不再是随机初始化，而是通过一些任务（如语言模型）进行预训练；预训练属于迁移学习的范畴，本文的【<strong>预训练语言模型</strong>】主要指无监督预训练任务（有时也称自学习或自监督），迁移的范式主要为特征集成和模型精调（finetune）。</p>
<p>语言模型表示序列文本的联合概率分布，为降低对长文本的概率估算难度，通常使用一个简化的n-gram模型。为缓解n元语言模型概率估计时遇到的数据稀疏问题，提出了神经网络语言模型NNLM，第一层参数可用作词向量表示。词向量可看作是NNLM的一个副产品，而word2vec通过一些优化技巧专注于词向量的产生，后来的glove词向量是通过共现语料矩阵进行高效分解产生的，glove也可看作是更换了目标函数和权重函数的全局word2vec。由于word2vec、glove等静态词向量未考虑一词多义、无法理解复杂语境，可通过预训练语言模型产生上下文相关的特征表示（动态词向量）。</p>
<p>（注：本文没有把word2vec纳入预训练语言模型的范畴，虽然word2vec可看作语言模型，但其更专注于词向量的产生。本文的预训练语言模型主要指能够产生上下文相关的特征表示）</p>
<h2 id="预训练模型分类"><a href="#预训练模型分类" class="headerlink" title="预训练模型分类"></a>预训练模型分类</h2><ul>
<li><p><strong>单向</strong>特征表示的<strong>自回归</strong>预训练语言模型，统称为<strong>单向模型</strong>：</p>
</li>
<li><ul>
<li>ELMO&#x2F;ULMFiT&#x2F;SiATL&#x2F;GPT1.0&#x2F;GPT2.0；</li>
</ul>
</li>
<li><p><strong>双向</strong>特征表示的<strong>自编码</strong>预训练语言模型，统称为<strong>BERT系列模型：</strong></p>
</li>
<li><ul>
<li>(BERT&#x2F;MASS&#x2F;UNILM&#x2F;ERNIE1.0&#x2F;ERNIE(THU)&#x2F;MTDNN&#x2F;ERNIE2.0&#x2F;SpanBERT&#x2F;RoBERTa)</li>
</ul>
</li>
<li><p><strong>双向</strong>特征表示的<strong>自回归</strong>预训练语言模型：<strong>XLNet</strong>；</p>
</li>
</ul>
<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/v2-7734b2580b943573685b9477c2a9e9be_r.jpg" alt="preview" style="zoom: 50%;">



<img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/v2-adf45870fa647599bd4332efd2b44964_r.jpg" alt="preview" style="zoom:50%;">





<p><img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20220614121931241.png" alt="image-20220614121931241"></p>
<ul>
<li><p>不同的特征抽取机制</p>
</li>
<li><ul>
<li>RNNs：ELMO&#x2F;ULMFiT&#x2F;SiATL；</li>
<li>Transformer：GPT1.0&#x2F;GPT2.0&#x2F;BERT系列模型；</li>
<li>Transformer-XL：XLNet；</li>
</ul>
</li>
<li><p>不同的预训练语言目标</p>
</li>
<li><ul>
<li>自编码（AutoEncode）：BERT系列模型；</li>
<li>自回归（AutoRegression）：单向模型（ELMO&#x2F;ULMFiT&#x2F;SiATL&#x2F;GPT1.0&#x2F;GPT2.0）和XLNet；</li>
</ul>
</li>
<li><p>BERT系列模型的改进</p>
</li>
<li><ul>
<li>引入常识：ERNIE1.0&#x2F;ERNIE(THU)&#x2F;ERNIE2.0（简称为“ERNIE系列”）；</li>
<li>引入多任务学习：MTDNN&#x2F;ERNIE2.0；</li>
<li>基于生成任务的改进：MASS&#x2F;UNILM；</li>
<li>不同的mask策略：WWM&#x2F;ERNIE系列&#x2F;SpanBERT；</li>
<li>精细调参：RoBERTa；</li>
</ul>
</li>
<li><p>特征表示（是否能表示上下文）：</p>
</li>
<li><ul>
<li>单向特征表示：单向模型（ELMO&#x2F;ULMFiT&#x2F;SiATL&#x2F;GPT1.0&#x2F;GPT2.0）；</li>
<li>双向特征表示：BERT系列模型+XLNet；</li>
</ul>
</li>
</ul>
<h2 id="二、预训练语言模型的基础：特征抽取机制-语言模型的分类"><a href="#二、预训练语言模型的基础：特征抽取机制-语言模型的分类" class="headerlink" title="二、预训练语言模型的基础：特征抽取机制+语言模型的分类"></a>二、预训练语言模型的基础：特征抽取机制+语言模型的分类</h2><p><strong>Q2：基于深度学习的NLP特征抽取机制有哪些？各有哪些优缺点？</strong></p>
<p>1）能否处理长距离依赖问题</p>
<p><strong>长距离依赖建模能力</strong>： Transformer-XL &gt; Transformer &gt; RNNs &gt; CNNs</p>
<ul>
<li><ul>
<li>MLP：不考虑序列（位置）信息，不能处理变长序列，如NNLM和word2vec；</li>
<li>CNNs：考虑序列（位置）信息，不能处理长距离依赖，聚焦于n-gram提取，pooling操作会导致序列（位置）信息丢失；</li>
<li>RNNs：天然适合处理序列（位置）信息，但仍不能处理长距离依赖（由于BPTT导致的梯度消失等问题），故又称之为“较长的短期记忆单元(LSTM)”；</li>
<li>Transformer&#x2F;Transformer-XL：self-attention解决长距离依赖，无位置偏差；</li>
</ul>
</li>
</ul>
<p>2）前馈&#x2F;循环网络 or 串行&#x2F;并行计算</p>
<ul>
<li><ul>
<li>MLP&#x2F;CNNs&#x2F;Transformer：前馈&#x2F;并行</li>
<li>RNNs&#x2F; Transformer-XL：循环&#x2F;串行：</li>
</ul>
</li>
</ul>
<p>3）计算时间复杂度（序列长度n，embedding size为d，filter大小k）</p>
<ul>
<li>CNNs：$O(k\cdot n\cdot d^2)$</li>
<li>RNNs：$O(n\cdot d^2)$</li>
<li>Self Attention：$O(n^2\cdot d)$</li>
</ul>
<p><strong>Q3：自回归和自编码语言模型各有什么优缺点？</strong></p>
<p><strong>1.自回归语言模型</strong></p>
<p><img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/v2-4f6492d8b4303d278441bbb4c933a20a_r.jpg" alt="preview"></p>
<ul>
<li><p>优点：</p>
</li>
<li><ul>
<li>文本序列<strong>联合概率的密度估计</strong>，即为传统的语言模型，天然适合处理自然生成任务；</li>
</ul>
</li>
<li><p>缺点：</p>
</li>
<li><ul>
<li>联合概率按照文本序列从左至右分解（<strong>顺序拆解</strong>），无法通过上下文信息进行双向特征表征；</li>
</ul>
</li>
<li><p>代表模型：ELMO&#x2F;GPT1.0&#x2F;GPT2.0；</p>
</li>
<li><p>改进：XLNet将传统的自回归语言模型进行推广，将顺序拆解变为<strong>随机拆解</strong>（排列语言模型），产生上下文相关的双向特征表示；</p>
</li>
</ul>
<p><strong>2.自编码语言模型</strong></p>
<p><img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/v2-ac5de7890849432e16681a881fea5e50_r.jpg" alt="preview"></p>
<ul>
<li><p>优点：本质为降噪自编码特征表示，通过引入噪声[MASK]构建MLM，获取上下文相关的双向特征表示；</p>
</li>
<li><p>引入独立性假设，为<strong>联合概率的有偏估计</strong>，没有考虑预测[MASK]之间的相关性</p>
</li>
<li><ul>
<li>不适合直接处理生成任务，MLM预训练目标的设置造成预训练过程和生成过程不一致；</li>
<li>预训练时的[MASK]噪声在finetune阶段不会出现，造成两阶段不匹配问题；</li>
</ul>
</li>
<li><p>代表模型：BERT系列模型；</p>
</li>
</ul>
<p><img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/v2-0ace60ca3d843fc9b69c6965731f288e_r.jpg" alt="preview"></p>
<p><img src="/2022/07/22/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/v2-caa9a5a28fa2e4396c2cbaaf20047e5c_r.jpg" alt="preview"></p>
]]></content>
      <categories>
        <category>语言模型</category>
      </categories>
      <tags>
        <tag>语言模型</tag>
      </tags>
  </entry>
  <entry>
    <title>参数服务器</title>
    <url>/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<h1 id="参数服务器"><a href="#参数服务器" class="headerlink" title="参数服务器"></a>参数服务器</h1><blockquote>
<p>Li, Mu, et al. “Scaling distributed machine learning with the parameter server.” <em>11th USENIX Symposium on operating systems design and implementation (OSDI 14)</em>. 2014. citations：2259</p>
<p>李沐 <a href="https://www.bilibili.com/video/BV1YA4y197G8/?spm_id_from=333.999.0.0&vd_source=78ac87a714420a3f1e255985e582fe9c">参数服务器（Parameter Server）逐段精读【论文精读】</a></p>
<p><a href="https://www.usenix.org/conference/osdi14/technical-sessions/presentation/li_mu">https://www.usenix.org/conference/osdi14/technical-sessions/presentation/li_mu</a></p>
<p><a href="https://github.com/dmlc/ps-lite">https://github.com/dmlc/ps-lite</a></p>
</blockquote>
<p>osdi 系统会议</p>
<ul>
<li><p>解决什么问题</p>
<ol start="0">
<li><p>在大规模分布式环境中有效地进行机器学习任务，通过参数服务器框架来扩展分布式机器学习。</p>
</li>
<li><p>该问题的研究难点包括：数据通信量大、计算负载高、算法的顺序性导致的性能瓶颈。网络带宽的利用；对于大规模数据量、大模型参数量的模型训练时，所有计算节点都要频繁的访问模型参数，有大量的网络通讯耗时；</p>
</li>
<li><p>机器学习算法要不断的做全局通讯；bacth逐iter计算，导致大量的全局的同步会影响性能。</p>
</li>
<li><p>容灾 fault tolerance，挂掉的那台机器能1s恢复，在大规模环境下的容错性和可扩展性。</p>
</li>
</ol>
</li>
<li><p>用了什么方法</p>
<ol>
<li>提出参数服务器，提供有一个机制，有效的汇聚和同步计算节点和节点之间的统计信息；</li>
<li>容灾用的vector clocks 向量钟，方法是做实时的复制，使得一台节点挂了，数据在另一地方还有；热备份机制，确保在节点故障时系统的连续性和一致性。</li>
<li><strong>易用性:</strong> 全局共享参数以稀疏向量和矩阵的形式表示，便于线性代数操作。</li>
</ol>
</li>
</ul>
<p>服务节点 server node ：维护全局共享参数的一部分。参数量大时，由多台机器维护；</p>
<p>计算节点 worker node ：拿参数的一块或全部，再读入一些数据进行计算；</p>
<p>其中的挑战：计算节点不断向服务节点要数据，有传输开销；在分布式系统中可以解决这个问题，叫做分布式的key value，但是这里的key一般是指向某一个神经元参数，这样参数量上来后，开销太大了，要开辟太多的key；本文用的segment，发送一个层的参数</p>
<p>节点就是进程</p>
<p>这个伪代码意思是 有m个计算节点，每个节点分配了一部分的计算权重，然后计算每个节点的梯度；然后服务节点在不同时刻汇总梯度 进行梯度更新；这里写的很简单；</p>
<img src="/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/image-20241209001628081.png" alt="image-20241209001628081" style="zoom:80%;">

<p>计算流程： 一个框是一个节点（进程）</p>
<img src="/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/image-20241210020509135.png" alt="image-20241210020509135" style="zoom:80%;">


<p><strong>异步通信模型</strong>：参数服务器框架采用异步通信模型，允许计算不阻塞（除非请求）。这种模型优化了机器学习任务的通信，减少了网络流量和开销。</p>
<img src="/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/image-20241212004022375.png" alt="image-20241212004022375" style="zoom:80%;">


<p>(key, value) vector：key是w的下标 不连续 稀疏的 哈希出来的值，int整型；value：浮点数&#x2F;向量（一串浮点数）&#x2F;一层的w；</p>
<p>带区间的 range push and pull：push是把梯度push回server节点；pull是把weight pull回来；只把部分的(key, value)发出去；这样可以节省带宽，不用把所有的weight都传输；</p>
<p>server端，user-defined functions</p>
<p>asynchronous tasks and dependency 就是网络前向如果计算也是直接串行的，那其实没怎么节省时间，所以任务要异步，计算节点计算完了就去计算其他的，没有一个等待的过程；。。。</p>
<p>但是任务之间有依赖怎么办，这里用了execute-after-finish 完成后才执行</p>
<img src="/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/image-20241213011836929.png" alt="image-20241213011836929" style="zoom:80%;">

<p> <strong>灵活的一致性模型</strong>：框架支持灵活的一致性模型，允许算法设计师在算法收敛速度和系统效率之间进行权衡。一致性模型包括顺序一致性、最终一致性和有界延迟一致性。</p>
<img src="/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/image-20241213013134254.png" alt="image-20241213013134254" style="zoom:80%;">



<img src="/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/image-20241213012259357.png" alt="image-20241213012259357" style="zoom:80%;">

<p>vector clock：需要记录不同计算节点上维护的是哪些权重，记录下是哪个时间算好的值；</p>
<img src="/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/image-20241214013034207.png" alt="image-20241214013034207" style="zoom:80%;">

<p>减少网络通讯时延：对服务器节点和计算节点做压缩，压缩后再通讯，再解压缩。</p>
<img src="/2024/12/18/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/image-20241217005446103.png" alt="image-20241217005446103" style="zoom:80%;">

<p>这里KKT filter：算权重的KKT。（KKT：凸函数中离最优解的距离），如果weight与kkt值接近，认为优化得很好，则不太更新了，梯度&#x3D;0，好压缩。</p>
<p>实验中有可能哪些是瓶颈：1.网络通讯带宽；2.cpu核数；3.内存带宽，内存访问速度，server端读写的速度慢；</p>
<p>参数服务器（Parameter Server）是一种分布式机器学习系统中常见的架构组件，主要用于存储和更新模型参数。在训练大型机器学习模型时，尤其是深度学习模型，由于数据量和模型复杂度的增加，单机训练往往无法满足需求。因此，研究者们提出了分布式训练的方法来加速模型训练过程。</p>
<p>参数服务器架构一般包含两个主要部分：</p>
<ol>
<li><strong>Worker节点</strong>：负责计算梯度。每个Worker节点会接收到一部分数据集，并根据当前的模型参数进行前向传播计算损失函数，然后通过反向传播计算出参数的梯度。</li>
<li><strong>Server节点（参数服务器）</strong>：负责存储模型参数，并收集来自各个Worker节点的梯度更新。它会根据这些梯度信息来更新模型参数，并将最新的参数广播给所有Worker节点。</li>
</ol>
<p>参数服务器的工作流程大致如下：</p>
<ul>
<li>初始化阶段，参数服务器初始化模型参数。</li>
<li>训练过程中，各Worker节点从参数服务器获取最新的模型参数，使用本地的数据子集计算梯度，并将梯度发送回参数服务器。</li>
<li>参数服务器接收到梯度后，执行参数更新操作（如应用随机梯度下降算法），并将更新后的参数同步给所有Worker节点。</li>
<li>这个过程不断重复，直到模型收敛或达到预定的迭代次数。</li>
</ul>
<p>参数服务器架构能够有效地支持大规模分布式机器学习任务，但它也存在一些挑战，比如网络延迟、通信成本、容错性等问题。随着技术的发展，出现了许多改进版本，如异步更新机制、稀疏梯度传输等，以提高系统的效率和性能。</p>
<h3 id="开源项目"><a href="#开源项目" class="headerlink" title="开源项目"></a>开源项目</h3><blockquote>
<p><a href="https://github.com/dmlc/ps-lite">https://github.com/dmlc/ps-lite</a></p>
<p><a href="https://github.com/Angel-ML/angel/tree/master">https://github.com/Angel-ML/angel/tree/master</a></p>
</blockquote>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>GPipe</title>
    <url>/2024/12/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/GPipe/</url>
    <content><![CDATA[<h1 id="GPipe"><a href="#GPipe" class="headerlink" title="GPipe"></a>GPipe</h1><blockquote>
<p>Huang, Yanping, et al. “Gpipe: Efficient training of giant neural networks using pipeline parallelism.” <em>Advances in neural information processing systems</em> 32 (2019). citations:1695</p>
<p>李沐 <a href="https://www.bilibili.com/video/BV1v34y1E7zu/?spm_id_from=333.999.0.0&vd_source=78ac87a714420a3f1e255985e582fe9c">GPipe论文精读【论文精读】</a></p>
<p>开源项目：<a href="https://github.com/kakaobrain/torchgpipe">https://github.com/kakaobrain/torchgpipe</a></p>
<p>github：<a href="https://github.com/tensorflow/lingvo/blob/master/lingvo/core/gpipe.py">https://github.com/tensorflow/lingvo/blob/master/lingvo/core/gpipe.py</a></p>
</blockquote>
<ul>
<li><p>用了什么方法</p>
<ul>
<li>提出流水线并行方法，在对数据切分（和数据并行的思路一样）能提升并行度；模型并行，可用在任意串联、堆叠起来的网络结构中；</li>
<li>通过re-materialization方法，支持训练更大的模型，但是需要额外付出20%的开销；</li>
</ul>
</li>
</ul>
<p>re-materialization：训练时把一些中间结果丢掉，下次用到时重新计算，可以减少内存的占有率。</p>
<p>micro-batches </p>
<img src="/2024/12/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/GPipe/image-20241220014759353.png" alt="image-20241220014759353" style="zoom:80%;">

<p>model parallelism：多层模型拆成多个层放到不同gpu上，每个gpu只执行一部分计算，就把计算结果传输给下一个gpu再计算； </p>
<p>data parallelism：模型复制放在每个gpu上，batch样本分成子batch分到不同gpu上做前向和保存梯度值。因为每个GPU上复制一份，保存整个模型开销大；</p>
<img src="/2024/12/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/GPipe/image-20241219003319480.png" alt="image-20241219003319480" style="zoom:80%;">


<p>activation ：指的不是激活函数，而是中间变量，前向每层的输出值，由于反向传播是链式，所以需要存储这些中间值。因此这些activation占用的内存为 $O(l<em>d</em>n)$ ，l是层数，n是batch大小，d是网络宽度；</p>
<p>用re-materialization，因此这里 $l$ 为$\frac{l}{k}$ ， k是gpu数；用微批量，因此这里 $n$ 为 $\frac{n}{m}$ ，m是切的小批量数（微批量），流水线指令的长度；</p>
<p>存储这些activation 内存占用会增加，可以用时间换空间的方法，也就是前向计算后，<strong>就把这些中间变量删掉 释放内存</strong>，由于是用的微批量的方法，等到微批量样本累积到一个批的loss值，需要反向传播时，再进行一次前向计算得到activation；（所以要计算两次forward（可能会带来30%额外开销））</p>
<img src="/2024/12/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/GPipe/image-20241220010649096.png" alt="image-20241220010649096" style="zoom:80%;">

<p>$O(\frac{K-1}{M+K-1})$ ， 当 $M\ge4K$  开销忽略不计</p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Megatron</title>
    <url>/2025/01/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/Megatron/</url>
    <content><![CDATA[<h1 id="Megatron"><a href="#Megatron" class="headerlink" title="Megatron"></a>Megatron</h1><blockquote>
<p>Shoeybi, Mohammad, et al. “Megatron-lm: Training multi-billion parameter language models using model parallelism.” <em>arXiv preprint arXiv:1909.08053</em> (2019). citations：1837</p>
<p>开源代码：<a href="https://github:com/NVIDIA/Megatron-LM">https://github:com/NVIDIA/Megatron-LM</a>  </p>
</blockquote>
<ul>
<li><p>解决什么问题</p>
</li>
<li><p>提出什么方法</p>
<p>提出一个方法，将transformer层从中间剖开，使得多GPU计算时每一个GPU计算重建的一块。好处是剖起来容易（按head的个数&#x2F;中间隐藏层大小剖开（在层里面切开））ps. gpipe是在层之间切；</p>
</li>
<li><p>存在问题：1. 通讯量很大，并且不能和计算做异步，因此要求GPU之间连接要很好（Nvlink）；</p>
<ol start="2">
<li>不能扩展到多机（多机要数据并行）</li>
<li>GPU变多，冗余变多，因为输入输出都要在GPU上存放一遍；</li>
</ol>
</li>
</ul>
<p>张量并行</p>
<p>mlp结构模型并行（放在多个GPU上运行不同参数）的切法：</p>
<ul>
<li>第一种：对于权重张量A来说，A维度是 $k<em>k’$，假如有2个GPU，沿着行切，每个个GPU放$\frac{k}{2}<em>k’$ 的参数，则输入X（维度$bl</em>k$）也要切分，沿着列切，每个GPU的计算量是$bl</em>\frac{k}{2}*\frac{k}{2}*k’$，然后再求和（all reduce），求和操作需要GPU之间进行通讯。</li>
</ul>
<p>GPU之间需要通讯（比如做求和）才能获取完整的输出结果的操作叫all reduce</p>
<img src="/2025/01/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/Megatron/image-20241226001356344.png" alt="image-20241226001356344" style="zoom:80%;">



<ul>
<li>第二种：A沿着列切，参数分给不同GPU，则输入X在各个GPU都要复制一份，然后得到输出Y，不需要GPU之间进行通讯，各自保留了一块的结果，就直接输出X*A了。</li>
</ul>
<img src="/2025/01/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/Megatron/image-20241226002619623.png" alt="image-20241226002619623" style="zoom:80%;">



<p>mutli-head attention结构的模型并行：</p>
<p>不同head放不同gpu；如果head很多则一组head放一个GPU。</p>
<img src="/2025/01/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/Megatron/image-20241226003824191.png" alt="image-20241226003824191" style="zoom:80%;">


<p>to be continue</p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>End-to-end object detection with transformers</title>
    <url>/2025/01/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/DETR/</url>
    <content><![CDATA[<h1 id="End-to-end-object-detection-with-transformers"><a href="#End-to-end-object-detection-with-transformers" class="headerlink" title="End-to-end object detection with transformers"></a>End-to-end object detection with transformers</h1><blockquote>
<p>Carion, Nicolas, et al. “End-to-end object detection with transformers.” <em>European conference on computer vision</em>. Cham: Springer International Publishing, 2020. citations：15472</p>
<p><a href="https://github.com/facebookresearch/detr">https://github.com/facebookresearch/detr</a></p>
</blockquote>
<ul>
<li><p>目标检测背景</p>
<p>通常的目标检测是从一张图片中先生成很多个预测框，然后再对每个框进行物体类别分类。（可能在一个物体上不同坐标都有框，冗余），这个后处理步骤叫 nms（non-maximum suppersion非极大值抑制），用来去掉冗余的框。通常目标检测方法分为：proposal based和anchor based和non anchor based方法。</p>
<p>因为有nms后处理过程，非端到端，训练目标不等于最终目标，因此调参较为复杂。另外nms操作算子比较复杂，一些硬件可能不支持。</p>
</li>
<li><p>提出什么方法</p>
<p>在目标检测任务中提出一种端到端的方法DETR，把目标检测问题看成一个集合预测的问题，通过使用transformer进行全局建模，实现了集合预测，提出新的loss function叫set-based loss，通过二分图匹配 bi-partite matching，强制模型输出一组独一无二的预测（没有冗余框）</p>
<p>，一个物体只有一个框。</p>
<p>DETR的训练过程包括四步：特征提取、全局特征学习、预测框生成、匹配Ground Truth并计算目标检测loss，推理过程与训练相似，但不需要匹配loss，只保留置信度高的预测框（卡阈值）。</p>
<p>DETR模型通过卷积网络提取特征，加入位置编码后进入Transformer，经过6个Encoder和6个Decoder后，使用检测头进行物体类别和框的预测，最后通过辅助loss来稳定训练。</p>
</li>
</ul>
<img src="/2025/01/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/DETR/image-20250109020730128.png" alt="image-20250109020730128" style="zoom:80%;">

<h2 id="set-based-loss："><a href="#set-based-loss：" class="headerlink" title="set-based loss："></a>set-based loss：</h2><p>二分图匹配 bipartite matching 问题是DETR模型关键解决方案之一，通过匈牙利算法实现最优匹配，解决预测框和真实框之间的对应关系，进而计算损失。</p>
<p>假定每张图片都有固定N个框，因此要预测N个结果，N比图片中的物体objects数量多。$\varnothing$表示没object，<br>$$<br>\hat{\sigma}&#x3D;\underset{\sigma \in \mathfrak{S}<em>N}{\arg \min } \sum_i^N \mathcal{L}</em>{\text {match }}\left(y_i, \hat{y}_{\sigma(i)}\right)<br>$$<br>给abc分配不同的xyz，不同排列组合对应不同的总cost，任务是使得cost最小；（scipy ：linear_sum_assignment() ）</p>
<p>把abc看成预测框，xyz看成groundtruth；里面的cost是预测框的分类准确度+出框的准确度</p>
<img src="/2025/01/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/DETR/image-20250115001845125.png" alt="image-20250115001845125" style="zoom:80%;">

<p>$$<br>\mathcal{L}<em>{\text {match }}(y, \hat{y}</em>{\sigma(i)})&#x3D;-\mathbb{1}<em>{\left{c_i \neq \varnothing\right}} \hat{p}</em>{\sigma(i)}\left(c_i\right)+\mathbb{1}<em>{\left{c_i \neq \varnothing\right}} \mathcal{L}</em>{\text {box }}\left(b_i, \hat{b}_{\sigma(i)}\right)<br>$$</p>
<p>$$<br>\mathcal{L}<em>{\text {Hungarian }}(y, \hat{y})&#x3D;\sum</em>{i&#x3D;1}^N\left[-\log \hat{p}<em>{\hat{\sigma}(i)}\left(c_i\right)+\mathbb{1}</em>{\left{c_i \neq \varnothing\right}} \mathcal{L}<em>{\text {box }}\left(b_i, \hat{b}</em>{\hat{\sigma}}(i)\right)\right],<br>$$<br>这篇文章给出强假设：只有一个框和ground truth相匹配（其他目标检测一般可以多个框和ground truth匹配，也因此还需要nms后处理）。</p>
<p>用transformer学习到全局特征，对大物体很有效（作者认为这归因于使用全局建模和不采用Anchor机制），经常预测大框，loss就很大，不利于优化，因此使用了generalize IOU loss和L1 loss的组合，使得匹配更精确，优化效果更好。</p>
<p>DETR模型训练的细节，包括在Decoder后加入辅助loss来稳定训练、Object Query的自注意力操作（学习全局关系来避免冗余框）</p>
<img src="/2025/01/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/DETR/image-20250116013927955.png" alt="image-20250116013927955" style="zoom:80%;">

<p>object queries ： learnable 的 positional embedding</p>
<img src="/2025/01/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/DETR/image-20250116020528895.png" alt="image-20250116020528895" style="zoom:80%;">

<p>GFLOPS（每秒浮点运算数）越小，模型浮点运算量少 一般来说前向运算时间会越短，但是这个并不完全相关，还是得看FPS（单位时间能处理的帧数），FPS越大模型前向速度越快，处理图片的速度越快。</p>
<img src="/2025/01/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/DETR/image-20250117012828156.png" alt="image-20250117012828156" style="zoom:80%;">




<p>Object query的可视化展示了学习到的bounding box，object query是一个[100, 256]的张量，每个是256向量，取100中的20个向量可视化如下图，每个小图代表一个object query：</p>
<p>绿色点代表小bounding box，红色点代表横向bounding box 蓝色点代表竖向bounding box，这就很像anchor，只不过anchor是先验定义好的bounding box（预测与bounding box做对比），而object query是可学习的，最终起到的效果和anchor很类似，以第一个小图为例，它关注左下角的小bounding box，因此对于input图片，经过该object query时，就等同于该object query问这张图片的左下角有没有看到一些小物体，或者说有没有看到中间有大的横向物体；100个object query等同于100个问问题的人，每个人都有问问题的方式，关注的侧重点都不同，会问图片不同的问题，如果找到了合适的答案，就会输出bounding box；</p>
<img src="/2025/01/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/DETR/image-20250118022033315.png" alt="image-20250118022033315" style="zoom:80%;">


]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
</search>
